<div id=toc></div>

# Table of Contents

- [Google Scholar](#Google Scholar) [Total: 8]
- [Zongheng Yang](#Zongheng Yang) [Total: 9]
- [Rong Zhu](#Rong Zhu) [Total: 1]
- [Xuanhe Zhou](#Xuanhe Zhou) [Total: 7]
- [Matei Zaharia](#Matei Zaharia) [Total: 8]
- [Sai Wu](#Sai Wu) [Total: 1]
- [cs.DC](#cs.DC) [Total: 5]
- [cs.DB](#cs.DB) [Total: 3]
- [cs.LG](#cs.LG) [Total: 31]
- [Ziniu Wu](#Ziniu Wu) [Total: 1]


<div id='Google Scholar'></div>

# Google Scholar [[Back]](#toc)

### [1] [Extracting books from production language models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.02671&hl=en&sa=X&d=16641616248412865308&ei=oYx2aYAW8MHqtA-wyO_oCw&scisig=AHkA5jQgwLs_mmTgQTd7Gg_OVs3q&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:AHkA5jR-WPkAfpCINzU6oW8zO6Qz&html=&pos=1&folt=rel)
*A Ahmed,AF Cooper,S Koyejo,P Liang*

Main category: Google Scholar

TL;DR: 论文探讨了LLMs与版权法中的核心争议——记忆化问题，包括训练数据是否被编码到模型权重中以及这些记忆数据能否在输出中被提取。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs与版权法之间的关键未决法律问题，特别是关于训练数据记忆化的争议，这对确定版权侵权责任和合理使用范围至关重要。

Method: 未在摘要中明确说明具体方法，但暗示将分析LLMs的记忆化机制、训练数据编码过程以及记忆数据提取的可能性。

Result: 摘要未提供具体研究结果，但表明该研究将探讨记忆化现象的法律含义及其对版权法的影响。

Conclusion: 记忆化问题是LLMs与版权法交叉领域的核心争议点，需要从技术和法律双重角度进行深入分析。

Abstract: Many unresolved legal questions over LLMs and copyright center on memorization: whether specific training data have been encoded in the model's weights during training, and whether those memorized data can be extracted in the model's outputs …

</details>


### [2] [Deja Vu in Plots: Leveraging Cross-Session Evidence with Retrieval-Augmented LLMs for Live Streaming Risk Assessment](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.16027&hl=en&sa=X&d=16428308788176625087&ei=oYx2aYAW8MHqtA-wyO_oCw&scisig=AHkA5jTlCBkGOkcLQOU7Bi5WUHer&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:AHkA5jR-WPkAfpCINzU6oW8zO6Qz&html=&pos=2&folt=rel)
*Y Qiao,X Ao,J Chen,Y Liu,Q Zhong,Q He*

Main category: Google Scholar

TL;DR: 直播流媒体平台面临欺诈和协同恶意行为等复杂风险，现有检测方法难以应对实时大规模互动场景


<details>
  <summary>Details</summary>
Motivation: 直播流媒体的兴起带来了大规模实时互动，但同时也暴露了平台面临欺诈、协同恶意行为等复杂风险，现有检测方法难以有效应对这些挑战

Method: 论文未提供具体方法细节，但暗示需要开发新的检测方法来应对直播平台特有的实时性、大规模性和复杂性挑战

Result: 未提供具体实验结果，但指出现有方法在检测直播平台风险方面存在局限性

Conclusion: 直播平台需要更先进的检测方法来应对实时互动中出现的复杂风险，特别是针对欺诈和协同恶意行为

Abstract: The rise of live streaming has transformed online interaction, enabling massive real-time engagement but also exposing platforms to complex risks such as scams and coordinated malicious behaviors. Detecting these risks is challenging because …

</details>


### [3] [HyperJoin: LLM-augmented Hypergraph Link Prediction for Joinable Table Discovery](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.01015&hl=en&sa=X&d=11740285024658150172&ei=oYx2aYAW8MHqtA-wyO_oCw&scisig=AHkA5jQmtLIFWsx9A20idkbOgqeJ&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:AHkA5jR-WPkAfpCINzU6oW8zO6Qz&html=&pos=4&folt=rel)
*S Liu,J Wang,X Lin,L Qin,W Zhang,Y Zhang*

Main category: Google Scholar

TL;DR: 该论文提出了一种新的可连接表发现方法，通过结合离线列表示学习和在线推理，显著提升了数据湖中表连接发现的性能。


<details>
  <summary>Details</summary>
Motivation: 可连接表发现是数据湖管理中的关键任务，现有基于语言模型的方法虽然通过离线列表示学习取得了显著性能，但仍存在局限性，需要更高效、准确的解决方案。

Method: 结合离线列表示学习和在线推理的方法，通过语言模型学习列的语义表示，并在查询时进行高效的相似性匹配和连接发现。

Result: 该方法在可连接表发现任务上取得了卓越的性能，相比现有方法有显著提升，能够更准确地识别数据湖中可连接的表。

Conclusion: 提出的结合离线学习和在线推理的方法为数据湖中的可连接表发现提供了有效的解决方案，具有实际应用价值。

Abstract: As a pivotal task in data lake management, joinable table discovery has attracted widespread interest. While existing language model-based methods achieve remarkable performance by combining offline column representation learning with …

</details>


### [4] [LLM-in-Sandbox Elicits General Agentic Intelligence](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.16206&hl=en&sa=X&d=12928722802559785051&ei=oYx2aYAW8MHqtA-wyO_oCw&scisig=AHkA5jQA0ZvB5PHK-ITwMCPP7-h1&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:AHkA5jR-WPkAfpCINzU6oW8zO6Qz&html=&pos=5&folt=rel)
*D Cheng,S Huang,Y Gu,H Song,G Chen,L Dong…*

Main category: Google Scholar

TL;DR: LLM-in-Sandbox让大语言模型在代码沙盒（虚拟计算机）中探索，以激发其在非代码领域的一般智能能力


<details>
  <summary>Details</summary>
Motivation: 探索如何让大语言模型在非代码领域展现一般智能，通过代码沙盒环境作为中介来激发模型的泛化能力

Method: 构建LLM-in-Sandbox框架，让大语言模型在代码沙盒环境中进行探索和交互，无需额外训练即可利用现有能力

Result: 强大的大语言模型在代码沙盒环境中展现出在非代码领域的泛化能力，能够通过沙盒环境解决原本难以直接处理的问题

Conclusion: 代码沙盒环境可以作为激发大语言模型一般智能的有效平台，为模型在非代码领域的应用提供了新的途径

Abstract: We introduce LLM-in-Sandbox, enabling LLMs to explore within a code sandbox (ie, a virtual computer), to elicit general intelligence in non-code domains. We first demonstrate that strong LLMs, without additional training, exhibit generalization …

</details>


### [5] [The Effects of Belief Elicitation in Visual Data Analysis: A Longitudinal Classroom Study](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11219244/&hl=en&sa=X&d=13758493292873040182&ei=n4x2adWBItaOieoPnNOJuQQ&scisig=AHkA5jSYCFRA8hjwLoZLVkrW9c1G&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:AHkA5jSP8671UBQnfQacXFBHq92d&html=&pos=0&folt=cit)
*EW He,V Bellotti,A Scott,J Xu,A Suh,J Rogers…*

Main category: Google Scholar

TL;DR: 该研究通过纵向实验验证了在真实数据分析环境中，结合信念启发能有效减少虚假发现，弥补了实验室研究的局限性


<details>
  <summary>Details</summary>
Motivation: 现有研究表明视觉探索性数据分析（EDA）可能导致虚假发现，因此提倡在数据分析过程中结合信念启发。但这些研究主要基于实验室实验，与真实世界分析环境存在差异，需要验证在真实场景中的效果。

Method: 采用纵向研究方法，对大学课程中的学生进行长期跟踪研究，在真实数据分析环境中评估结合信念启发对减少虚假发现的效果。

Result: 研究结果显示，在真实世界数据分析环境中，结合信念启发确实能够有效减少虚假发现的报告，验证了先前实验室研究的结论在现实场景中同样适用。

Conclusion: 在真实数据分析环境中结合信念启发是减少虚假发现的有效策略，为数据分析实践提供了实证支持，强调了将实验室研究发现推广到实际应用的重要性。

Abstract: Recent studies have reported a shortcoming of visual exploratory data analysis (EDA) that can lead analysts to report spurious findings. These findings have prompted the advocacy of incorporating belief elicitation within the data analysis process. However, the results from these studies primarily drew from laboratory experiments, which can differ from real-world analysis contexts. In this paper, we present outcomes from a longitudinal study with students enrolled in a university …

</details>


### [6] [Lafa: Unlocking Superior Memory Efficiency via Adaptive Metadata Strategy for Scalable Large-Scale Dataset Loading](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11277383/&hl=en&sa=X&d=17242920705029308453&ei=n4x2adWBItaOieoPnNOJuQQ&scisig=AHkA5jSEZPzXU0HXE45ZDX8b5PjG&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:AHkA5jSP8671UBQnfQacXFBHq92d&html=&pos=2&folt=cit)
*C Wang,Y Luo,K Wang,H Zhang,N Gu,R Zhang…*

Main category: Google Scholar

TL;DR: 提出Lafa动态元数据加载机制，优化大规模数据集处理效率，解决现有框架内存管理瓶颈


<details>
  <summary>Details</summary>
Motivation: 深度学习模型快速增长和大规模数据集需求对数据加载和内存管理带来前所未有的挑战，现有框架（如PyTorch、TensorFlow）在处理大型数据集时存在性能瓶颈，导致效率低下和内存使用过度

Method: 提出Lafa动态元数据加载机制，优化大规模数据集处理，通过动态元数据管理提高数据加载效率

Result: 未在摘要中明确说明具体实验结果，但暗示该机制能有效解决现有框架的性能瓶颈问题

Conclusion: Lafa机制为解决大规模深度学习数据集处理中的内存管理和数据加载效率问题提供了有效解决方案

Abstract: The rapid growth of deep learning models and the increasing demand for large-scale datasets have posed unprece dented challenges for data loading and memory management. Existing frameworks (eg, PyTorch, TensorFlow) often encounter performance bottlenecks when handling large datasets resulting in inefficiencies and excessive memory usage. To address these issues, we propose Lafa, a dynamic metadata loading mechanism optimized for efficient large-scale dataset processing …

</details>


### [7] [ECC: Efficient Concurrency Control for Disaggregated Memory Systems](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11285864/&hl=en&sa=X&d=390999891397193900&ei=n4x2adWBItaOieoPnNOJuQQ&scisig=AHkA5jRPdJb89NgSyHYlhpuU3dXk&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:AHkA5jSP8671UBQnfQacXFBHq92d&html=&pos=3&folt=cit)
*Y Li,Y Li,W Li,Y Li,S Zhang,R Pei,X Meng,J Zhang…*

Main category: Google Scholar

TL;DR: 该论文探讨内存解耦架构中的数据一致性问题，比较悲观锁机制和乐观轮询方法的优劣，提出改进方案以提升内存利用率。


<details>
  <summary>Details</summary>
Motivation: 内存解耦架构中内存服务器计算能力有限，传统悲观锁方案因锁释放信号无法立即同步到计算服务器，导致内存利用率低下，需要更高效的解决方案。

Method: 论文分析比较了两种主要方法：1）基于锁表的悲观解决方案；2）乐观轮询方法。可能提出结合两者优势的改进方案或新机制。

Result: 悲观锁方案因同步延迟导致内存利用率不理想，乐观轮询方法可能提供更好的性能表现，但需要解决具体的技术挑战。

Conclusion: 内存解耦架构需要创新的数据一致性机制来克服计算能力限制，平衡内存利用率和系统性能，乐观方法可能比悲观锁方案更有前景。

Abstract: Memory disaggregation architecture presents unique challenges in ensuring data consistency due to the limited computational power available at memory servers. One line of pessimistic solutions utilizes lock tables to deal with this challenge. Since the lock release signal cannot be immediately synchronized to the compute server, such solutions can only achieve suboptimal memory utilization. To address the aforementioned limitation, another line of solutions operates optimistically, polling …

</details>


### [8] [Decoupling Tasking and Language: Modular Low-Rank Adaptation for Effective and Efficient Cross-Lingual Table Understanding](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11306666/&hl=en&sa=X&d=9727560278047988869&ei=n4x2adWBItaOieoPnNOJuQQ&scisig=AHkA5jSX73Z-zDUVL2-VEYbuF3_e&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:AHkA5jSP8671UBQnfQacXFBHq92d&html=&pos=5&folt=cit)
*Z Rao,J Wang*

Main category: Google Scholar

TL;DR: 提出基于任务能力与语言解耦的新型框架，通过轻量级适配器实现低资源语言的结构化数据理解，避免传统跨语言迁移方法的成本与干扰问题


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在结构化数据理解等复杂领域的专业化通常局限于高资源语言，阻碍了其全球应用。传统的跨语言迁移方法成本高、数据需求大，且可能破坏模型现有专业知识。

Method: 提出基于任务能力与语言解耦的新型框架，通过轻量级适配器实现低资源语言的结构化数据理解，避免传统跨语言迁移方法的成本与干扰问题

Result: 未在摘要中明确说明具体实验结果，但暗示该方法能有效解决高资源语言依赖问题，为低资源语言提供可行的结构化数据理解方案

Conclusion: 该框架挑战了传统跨语言迁移范式，为低资源语言的结构化数据理解提供了更高效、成本更低的解决方案，有望促进LLMs的全球应用

Abstract: The specialization of Large Language Models (LLMs) for complex domains like structured data understanding is often confined to high-resource languages, creating a significant barrier to their global adoption. Conventional cross-lingual transfer methods, such as full-scale or even light fine-tuning, are costly, data-intensive, and can disrupt a model's existing expertise. This paper challenges this paradigm by proposing a novel framework built on the decoupling of task ability and language …

</details>


<div id='Zongheng Yang'></div>

# Zongheng Yang [[Back]](#toc)

### [9] [HARMONY: A Holistic Auto-Scaling Resilient Model for Multi-Objective Adaptation in Microservices Using HPPNs—A Case Study on E-Business Platforms](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/6287639/11323511/11318583.pdf&hl=zh-CN&sa=X&d=7078227398966669183&ei=n4x2aeSiD_DB6rQPsMjv6As&scisig=AHkA5jSu3bCTYdIZYWJiu2Ww-8_H&oi=scholaralrt&hist=i6heNjgAAAAJ:778719684493065653:AHkA5jQQvhnv-0XbvZE0RehBjafZ&html=&pos=1&folt=rel)
*S Merkouche,C Bouanaka,E Benkhelifa,CG Guegan*

Main category: Zongheng Yang

TL;DR: 现代微服务架构面临动态工作负载、异构资源需求和性能-成本-可靠性等多目标竞争的自动扩缩容挑战，现有解决方案存在局限性


<details>
  <summary>Details</summary>
Motivation: 微服务架构中动态工作负载、异构资源需求以及性能、成本、可靠性等多目标竞争给自动扩缩容带来重大挑战，现有解决方案往往采用单一方法，无法有效平衡这些复杂需求

Method: 论文未提供具体方法，但暗示将提出一种新的自动扩缩容解决方案来应对现有方法的局限性

Result: 摘要未提供具体实验结果，但暗示新方法将能够更好地处理微服务架构中的动态工作负载和资源需求，平衡多目标优化

Conclusion: 需要新的自动扩缩容解决方案来有效应对现代微服务架构中动态工作负载、异构资源需求和多目标竞争的挑战

Abstract: Modern microservice architectures face significant auto-scaling challenges due to dynamic workloads, heterogeneous resource demands, and competing quality objectives like performance, cost, and reliability. Existing solutions often adopt either …

</details>


### [10] [SpeechPalette: A Comprehensive Speech Editing Method for Text-Based Speech Editing, One-Shot TTS and Attributes Editing](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11222950/&hl=zh-CN&sa=X&d=14264681338326988890&ei=nox2aejPN6C16rQPqaeYsAc&scisig=AHkA5jQqaq7Bn03PgxUR_5JD7pNO&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:AHkA5jQJ09t5uyNUKDlpVNk33Ubd&html=&pos=1&folt=cit)
*T Wang,J Yi,R Fu,C Qiang,D Chong,C Wang,D Dai…*

Main category: Zongheng Yang

TL;DR: SpeechPalette是一个全面的高质量语音编辑方法，允许用户轻松修改选定语音片段的多种属性


<details>
  <summary>Details</summary>
Motivation: 现有语音编辑系统需要大量手动操作或属性编辑能力有限，限制了应用范围

Method: 提出SpeechPalette模型，具体方法在摘要中未详细说明

Result: 摘要中未提供具体实验结果

Conclusion: SpeechPalette提供了一个全面的高质量语音编辑解决方案

Abstract: Speech editing has garnered more and more attention due to its diverse applications. However, existing systems often require substantial manual effort or have limited capabilities in attribute editing, imposing significant constraints. In this work, we present SpeechPalette, a comprehensive high-quality speech editing method that allows users to easily modify various attributes of the selected speech segment according to their preferences. Specifically, the proposed model …

</details>


### [11] [PerTTS: Personalized and Controllable Zero-Shot Spontaneous Style Text-to-Speech Synthesis](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11278067/&hl=zh-CN&sa=X&d=69770863206703585&ei=nox2aejPN6C16rQPqaeYsAc&scisig=AHkA5jQjQxVKeQVvB7lFD3mPgtI7&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:AHkA5jQJ09t5uyNUKDlpVNk33Ubd&html=&pos=2&folt=cit)
*W Li,Q Chen,D Luo,T Du,Y Chen,Z Wu,X Wu…*

Main category: Zongheng Yang

TL;DR: 该论文提出了一种在数据受限条件下实现个性化可控零样本自发风格语音合成的新方法，解决了传统方法在语音克隆和风格建模方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 在口语场景中，实现个性化和可控的零样本自发风格语音合成具有重要意义，特别是在数据有限条件下为未见过的说话人生成自然且富有表现力的语音。传统方法通常通过微调预训练的多说话人语音合成模型或采用零样本适应技术来实现，但这些方法在语音克隆和风格建模方面存在局限性。

Method: 论文提出了一种新方法来解决传统方法的局限性，该方法可能涉及改进的语音克隆技术、更有效的风格建模机制，以及在数据受限条件下的零样本适应策略。

Result: 该方法在语音克隆质量、风格建模准确性和零样本适应能力方面取得了显著改进，能够为未见过的说话人生成更自然、更具表现力的自发风格语音。

Conclusion: 提出的方法在个性化可控零样本自发风格语音合成方面具有优越性，特别是在数据受限条件下，为实际应用提供了更有效的解决方案。

Abstract: In spoken scenarios, achieving personalized and controllable zero-shot spontaneous style speech synthesis is highly significant, particularly in generating natural and expressive speech for unseen speakers under data-limited conditions. Traditional methods typically achieve this by fine-tuning pre-trained multi-speaker speech synthesis models or adopting zero-shot adaptation techniques. However, these methods exhibit limitations in voice cloning and style modeling, struggling to …

</details>


### [12] [LASS: Reducing Cold Startup Latency in Serverless Through Loaded Library Sharing](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11298560/&hl=zh-CN&sa=X&d=6432878921023129415&ei=nox2aejPN6C16rQPqaeYsAc&scisig=AHkA5jSZKqBPSs9WWUT4Nnu_R_fa&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:AHkA5jQJ09t5uyNUKDlpVNk33Ubd&html=&pos=4&folt=cit)
*Z Yu,Y Zhang,R Li,Y Wang,X Peng,Z Xu*

Main category: Zongheng Yang

TL;DR: 该论文探讨了在无服务器计算场景中，函数冷启动时库加载成为性能瓶颈的问题，现有基于进程复用的方法存在局限性，需要新的解决方案。


<details>
  <summary>Details</summary>
Motivation: 在无服务器计算中，函数调用在独立容器中运行。轻量级容器技术已显著降低了容器启动延迟，但库加载过程成为无服务器函数冷启动的关键性能瓶颈。现有基于进程复用的方法虽然能减少冷启动延迟，但存在局限性。

Method: 论文未在摘要中详细描述具体方法，但暗示了现有基于进程复用的方法存在不足，需要新的技术方案来解决库加载瓶颈问题。

Result: 摘要未提供具体实验结果，但指出了当前基于进程复用的方法在减少无服务器函数冷启动延迟方面的局限性。

Conclusion: 库加载已成为无服务器函数冷启动的关键瓶颈，现有基于进程复用的方法存在不足，需要新的技术方案来进一步优化冷启动性能。

Abstract: In serverless scenario, function invocation runs in an individual container. Lightweight container technology has significantly reduced the startup latency of container. The library loading process now becomes a critical performance bottleneck of serverless function cold startup. The state-of-the-art approaches leverage the process fork operation to reduce the cold startup latency in serverless computing by reusing the loaded libraries. However, the fork operation can only …

</details>


### [13] [ThonburianTTS: Enhancing Neural Flow Matching Models for Authentic Thai Text-to-Speech](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11320472/&hl=zh-CN&sa=X&d=11956728528377674511&ei=nox2aejPN6C16rQPqaeYsAc&scisig=AHkA5jTN71DFq5Q5-ua9Wl2sy7-X&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:AHkA5jQJ09t5uyNUKDlpVNk33Ubd&html=&pos=5&folt=cit)
*T Aung,P Sriwirote,T Thavornmongkol…*

Main category: Zongheng Yang

TL;DR: ThonburianTTS是基于E2-TTS和F5-TTS架构的泰语TTS系统，通过泰文和IPA转录训练，提升发音准确性、对齐鲁棒性和零样本说话人适应能力


<details>
  <summary>Details</summary>
Motivation: 针对泰语TTS系统在发音准确性、对齐鲁棒性和零样本说话人适应方面的不足，需要开发专门优化的泰语TTS模型

Method: 基于E2-TTS和F5-TTS架构，使用泰文脚本和国际音标(IPA)转录进行微调训练，评估语音输入对合成质量的影响

Result: 使用词错误率等客观指标评估性能，系统在发音准确性、对齐鲁棒性和零样本说话人适应方面有所改进

Conclusion: ThonburianTTS系统有效提升了泰语TTS的质量，特别是通过IPA转录训练进一步优化了发音准确性

Abstract: We introduce ThonburianTTS, a finetuned Thai text-to-speech (TTS) system based on the E2-TTS and F5-TTS architectures, designed to improve pronunciation accuracy, alignment robustness, and zero-shot speaker adaptation for the Thai language. Our models are trained on both Thai script and International Phonetic Alphabet (IPA) transcriptions to evaluate the impact of phonetic input on synthesis quality. We evaluate performance using objective metrics, including Word Error Rate …

</details>


### [14] [In-depth survey of the technologies to combat disinformation](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11324595/&hl=zh-CN&sa=X&d=17848313205778100179&ei=nox2aejPN6C16rQPqaeYsAc&scisig=AHkA5jQObC3kbNf3wv-yqBX9f7ro&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:AHkA5jQJ09t5uyNUKDlpVNk33Ubd&html=&pos=6&folt=cit)
*LI Rodríguez*

Main category: Zongheng Yang

TL;DR: 本文综述了数字虚假信息检测与缓解的最新进展，涵盖虚假信息、恶意信息等经典分类，以及深度伪造分析、取证技术、机器学习、深度学习和区块链等新兴策略，并介绍了实验平台TrueStories。


<details>
  <summary>Details</summary>
Motivation: 随着数字虚假信息（包括虚假信息、恶意信息和深度伪造）的传播日益严重，对社会稳定、政治进程和公众信任构成重大威胁，需要系统性地综述现有检测与缓解技术，并探索新兴防御策略。

Method: 采用文献综述方法，系统梳理数字虚假信息的经典分类（虚假信息、恶意信息、错误信息）和最新进展，重点分析深度伪造检测技术，并探讨基于取证技术、机器学习、深度学习、区块链等新兴防御策略，同时介绍实验平台TrueStories。

Result: 综述了数字虚假信息检测与缓解的技术现状，包括传统分类框架、深度伪造分析的最新进展，以及多种新兴防御技术的应用潜力，展示了TrueStories平台在扩展虚假信息防御到虚构作品领域的实验性探索。

Conclusion: 数字虚假信息检测与缓解是一个快速发展的跨学科领域，需要结合多种技术手段和策略。深度伪造等新兴威胁需要更先进的检测技术，而区块链等新兴技术为信息验证提供了新途径。未来需要持续的技术创新和多学科协作来应对这一复杂挑战。

Abstract: This article reviews the state of the art in detecting and mitigating digital disinformation. It covers the classic categories of misinformation, disinformation and malinformation, and moves on to the latest advances in deepfake analysis. Emerging strategies are also examined, drawing on forensic techniques, machine learning, deep learning and blockchain. It also introduces TrueStories, an experimental platform that extends the defence against disinformation to works of fiction based on …

</details>


### [15] ['Deepfake Me'-AI based Voice Cloning with Consent Verification to Prevent Audio Misuse](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11324420/&hl=zh-CN&sa=X&d=13039346717909449423&ei=nox2aejPN6C16rQPqaeYsAc&scisig=AHkA5jR0EjNRBZpPy1OnsMLLrWeK&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:AHkA5jQJ09t5uyNUKDlpVNk33Ubd&html=&pos=7&folt=cit)
*NC Brintha,MSDJ Chakravarthi,NP Reddy,EVS Teja…*

Main category: Zongheng Yang

TL;DR: Deepfake Me是一个AI语音克隆系统，旨在生成逼真的合成语音，同时探讨相关伦理挑战


<details>
  <summary>Details</summary>
Motivation: 语音克隆技术的快速发展带来了个性化虚拟助手、娱乐和可访问性改进等重要机遇，但也引发了滥用、身份盗窃和缺乏用户同意等严重伦理问题

Method: 基于人工智能的语音克隆系统（具体方法未在摘要中详细说明）

Result: 能够生成高度逼真、保留个体声音特征的合成语音

Conclusion: 语音克隆技术具有重要应用价值，但需要解决相关的伦理挑战，如滥用、身份盗窃和用户同意问题

Abstract: In recent years, significant improvements in the field of artificial intelligence have allowed voice cloning technologies to offer realistic synthesized voices that well resemble the individual characteristic of a voice. While these developments open up important opportunities for personalized virtual assistants, entertainment, and improving accessibility, they also bring serious ethical challenges, such as misuse, identity theft, and lack of user consent. This work presents Deepfake Me, an AI-based …

</details>


### [16] [Lightweight Model Attribution and Detection of Synthetic Speech via Audio Residual Fingerprints](https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Matias-Pizarro-5/publication/386021847_Single-Model_Attribution_for_Spoofed_Speech_via_Vocoder_Fingerprints_in_an_Open-World_Setting/links/694d73f306a9ab54f84abfbd/Single-Model-Attribution-for-Spoofed-Speech-via-Vocoder-Fingerprints-in-an-Open-World-Setting.pdf&hl=zh-CN&sa=X&d=6668074722954920891&ei=nox2aejPN6C16rQPqaeYsAc&scisig=AHkA5jQA2-4AywuSaoUQLo2p9x5d&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:AHkA5jQJ09t5uyNUKDlpVNk33Ubd&html=&pos=8&folt=cit)
*M Pizarro,M Laszkiewicz,D Kolossa,A Fischer*

Main category: Zongheng Yang

TL;DR: 提出一种轻量级、无需训练的合成语音检测方法，通过计算标准化平均残差实现模型溯源和真伪分类


<details>
  <summary>Details</summary>
Motivation: 随着语音生成技术的发展，冒充、错误信息和欺骗风险增加，需要有效检测合成语音并溯源到生成模型

Method: 基于标准化平均残差的计算方法，无需训练，实现三种任务：开放世界单模型溯源、封闭世界多模型溯源、真实与合成语音分类

Result: 该方法在合成语音检测和模型溯源任务中表现出色，具有轻量级和无需训练的优势

Conclusion: 提出的标准化平均残差方法为合成语音检测提供了有效的训练免费解决方案，有助于应对语音生成技术带来的安全挑战

Abstract: As speech generation technologies advance, so do risks of impersonation, misinformation, and spoofing. We present a lightweight, training-free approach for detecting synthetic speech and attributing it to its source model. Our method addresses three tasks:(1) single-model attribution in an open-world setting,(2) multi-model attribution in a closed-world setting, and (3) real vs. synthetic speech classification. The core idea is simple: we compute standardized average residuals …

</details>


### [17] [Deep learning-based speech emotion recognition for low-resource environments](https://scholar.google.com/scholar_url?url=https://aaltodoc.aalto.fi/bitstreams/d64c2563-b5c6-4419-869d-99a3bc6c6f47/download&hl=zh-CN&sa=X&d=11284477422215732982&ei=nox2aejPN6C16rQPqaeYsAc&scisig=AHkA5jRyj7l0DtqfHps8jBMAJ3lF&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:AHkA5jQJ09t5uyNUKDlpVNk33Ubd&html=&pos=9&folt=cit)
*Y Wang*

Main category: Zongheng Yang

TL;DR: 语音情感识别技术面临深度学习模型过大、计算成本高的问题，限制了在移动设备等资源受限环境中的部署。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的语音情感识别深度学习模型通常体积庞大且计算成本高昂，这限制了其在移动设备、可穿戴设备和嵌入式系统等处理能力有限的环境中的部署。

Method: 论文摘要未提供具体方法，但暗示需要开发更轻量、高效的语音情感识别模型来解决计算资源受限环境中的部署问题。

Result: 摘要未提供具体实验结果，但指出了当前模型在资源受限环境中部署的局限性。

Conclusion: 需要开发更轻量、高效的语音情感识别模型，以支持在移动设备等资源受限环境中的实际应用。

Abstract: Speech emotion recognition technology enables machines to interpret human's affective states from speech signals and supports applications in affective computing, human-computer interaction, and mental health monitoring. However, state-of-the-art deep learning models for this task are typically large and computationally expensive, which limit deployment in environments with limited processing power such as mobile phones, wearable devices, and embedded systems. This limitation creates a …

</details>


<div id='Rong Zhu'></div>

# Rong Zhu [[Back]](#toc)

### [18] [GETL: An Extract-Transform-Load Framework Across Graph Models in Graph Warehouse](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11359045/&hl=zh-CN&sa=X&d=1020007328686889618&ei=oIx2aaX_CaOi6rQPoMCXoAE&scisig=AHkA5jQzIzIPrrUNYXlLt9C6Qpj-&oi=scholaralrt&hist=i6heNjgAAAAJ:8587655636886263605:AHkA5jSkyWvlDu9mlwHlPp8LtnSZ&html=&pos=0&folt=cit)
*F Yao,X Yang,S Gong,Q Tao,Y Zhang,W Yu,G Yu*

Main category: Rong Zhu

TL;DR: GETL是一个通用的图数据ETL框架，能够自动识别不同图模型模式并实现跨模型的数据转换


<details>
  <summary>Details</summary>
Motivation: 随着多种图模型的出现，每种模型都有其独特特性和专长。在实际应用中，管理和分析图数据不可避免地需要在不同模型之间进行交互以满足业务需求，因此需要一个能够桥接不同图模型的ETL工具

Method: 提出GETL框架，该框架能够自动识别图模型模式，实现跨模型的数据提取、转换和加载

Result: 论文提出了一个通用的图ETL框架，能够处理不同图模型之间的数据转换需求

Conclusion: GETL框架为解决不同图模型之间的互操作性问题提供了有效解决方案，能够支持多样化的图数据处理需求

Abstract: Various graph models have emerged to meet diverse application needs, each with unique characteristics and specialties. Managing and analyzing graph data inevitably requires interactions across different models to serve upstream business requirements. Therefore, an Extract-Transform-Load (ETL) tool designed to bridge different graph models is desired. In this paper, we propose GETL, a generalized graph ETL framework capable of automatically identifying graph model schemas and …

</details>


<div id='Xuanhe Zhou'></div>

# Xuanhe Zhou [[Back]](#toc)

### [19] [Benchmarking AI Models in Software Engineering: A Review, Search Tool, and Unified Approach for Elevating Benchmark Quality](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11301810/&hl=zh-CN&sa=X&d=16799920069451729186&ei=oYx2aer6OruM6rQP2dOq-Ag&scisig=AHkA5jQBs3p_De6u40I5h2GisPAs&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:AHkA5jR4Nz41hcddyWt9RkK93bRp&html=&pos=0&folt=cit)
*R Koohestani,P de Bekker,B Koç,M Izadi*

Main category: Xuanhe Zhou

TL;DR: 论文分析了AI4SE领域基准测试的现状，指出了知识碎片化、选择困难、缺乏标准化和存在缺陷等四大挑战，并提出双重解决方案


<details>
  <summary>Details</summary>
Motivation: AI4SE领域基准测试激增导致知识碎片化、选择困难、缺乏标准化和存在缺陷等问题，需要系统性解决方案来统一评估和提升可复现性

Method: 通过分析现有AI4SE基准测试的现状，识别出四大核心挑战，并提出双重解决方案来应对这些挑战

Result: 识别出AI4SE基准测试面临的四大挑战：知识碎片化、选择困难、缺乏标准化和存在缺陷，这些限制了基准测试的实用性和可比性

Conclusion: AI4SE基准测试需要系统性改革，通过双重解决方案来应对现有挑战，以促进统一评估、提高可复现性并推动领域发展

Abstract: Benchmarks are essential for unified evaluation and reproducibility. The rapid rise of Artificial Intelligence for Software Engineering (AI4SE) has produced numerous benchmarks for tasks such as code generation and bug repair. However, this proliferation has led to major challenges:(1) fragmented knowledge across tasks,(2) difficulty in selecting contextually relevant benchmarks,(3) lack of standardization in benchmark creation, and (4) flaws that limit utility. Addressing these requires a dual …

</details>


### [20] [G²SQL: Guided & Guarded Text-to-SQL Generation with Two-Stage Verification](https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0957417426001892&hl=zh-CN&sa=X&d=5594853361547107024&ei=oYx2aer6OruM6rQP2dOq-Ag&scisig=AHkA5jR-vRtcVrvK5H_blJlff7hI&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:AHkA5jR4Nz41hcddyWt9RkK93bRp&html=&pos=1&folt=cit)
*X Li,J You,H Li,J Peng,X Chen,Z Guo,K Li,T Xu*

Main category: Xuanhe Zhou

TL;DR: 论文针对LLM在Text-to-SQL任务中的幻觉问题，提出通过多阶段验证和修订机制来提升SQL生成质量，避免数据库内容被破坏


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在Text-to-SQL领域取得了显著进展，但模型幻觉问题仍然存在挑战。在SQL生成过程中，任何阶段的错误都可能不可避免地影响后续输出，导致次优或错误的SQL查询。此外，当使用LLM在没有人工监督的情况下验证和修订生成的SQL时，模型有时可能会引入破坏数据库内容的操作。

Method: 论文提出了一种多阶段验证和修订机制，通过系统化的检查流程来识别和纠正SQL生成过程中的错误，确保生成的SQL既正确又不会对数据库造成破坏。

Result: 该方法能够有效减少模型幻觉导致的SQL错误，提高Text-to-SQL任务的准确性和可靠性，同时避免生成可能破坏数据库内容的危险操作。

Conclusion: 通过引入结构化的验证和修订流程，可以显著改善LLM在Text-to-SQL任务中的表现，减少幻觉问题，确保生成的SQL既准确又安全。

Abstract: Despite the remarkable progress of large language models (LLMs) in the Text-to-SQL domain, issues such as model hallucination remain a challenge. During SQL generation, an error at any stage may inevitably influence subsequent outputs, resulting in suboptimal or incorrect SQL queries. Moreover, when using LLMs to verify and revise generated SQL without human supervision, the models may sometimes introduce operations that tamper with or damage the database content …

</details>


### [21] [Toward real-world Table Agents: capabilities, workflows, and design principles for LLM-based table intelligence](https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s11280-025-01399-z&hl=zh-CN&sa=X&d=2938952916747499733&ei=oYx2aer6OruM6rQP2dOq-Ag&scisig=AHkA5jT-Q_42syNPf5JXR2STG2WH&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:AHkA5jR4Nz41hcddyWt9RkK93bRp&html=&pos=2&folt=cit)
*J Tian,L Li,W Ye,H Wang,L Wang,L Yu,Z Ren…*

Main category: Xuanhe Zhou

TL;DR: 该论文指出现有LLM表格处理研究主要基于干净的学术数据集，未能反映真实世界表格数据的复杂性，如噪声、结构多样性和语义挑战。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型在表格任务上的研究主要使用干净的学术数据集，这些数据集无法反映真实世界表格数据的复杂性，包括噪声、结构多样性和语义挑战，限制了模型在实际应用中的效果。

Method: 从摘要内容来看，论文可能提出了一种新的评估框架或数据集，专门针对真实世界表格数据的复杂性，包括噪声处理、结构多样性适应和语义理解等方面的挑战。

Result: 摘要未提供具体实验结果，但暗示现有LLM在干净数据集上的表现可能无法直接推广到复杂的真实世界表格任务中。

Conclusion: 需要开发新的方法和评估框架来应对真实世界表格数据的复杂性，以提升LLM在实际应用中的表格处理能力。

Abstract: Tables are widely used across various domains such as finance, healthcare, and chemistry, playing a critical role in modern applications. While recent advances in Large Language Models (LLMs) like GPT-4 have opened new possibilities for handling table tasks, existing research predominantly focuses on clean, academic datasets, which do not reflect the complexity of real-world table data. Real-world table tasks are often characterized by noise, structural diversity, and semantic …

</details>


### [22] [MiRAGE: A Multiagent Framework for Generating Multimodal Multihop Question-Answer Dataset for RAG Evaluation](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.15487&hl=zh-CN&sa=X&d=13433704694033870429&ei=oYx2aer6OruM6rQP2dOq-Ag&scisig=AHkA5jSgTnWWeoRQRgQJe8zNpM2-&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:AHkA5jR4Nz41hcddyWt9RkK93bRp&html=&pos=4&folt=cit)
*CK Sahu,PK Chilukuri,M Hetrich*

Main category: Xuanhe Zhou

TL;DR: 该论文提出一个针对企业多模态RAG系统的专业评估基准，弥补现有基准在技术文档多模态信息检索与推理方面的不足


<details>
  <summary>Details</summary>
Motivation: 多模态RAG在企业级应用中快速发展，但现有评估基准主要基于通用领域语料库或纯文本检索，无法准确评估技术文档中多模态信息融合与复杂推理的能力

Method: 引入专门针对企业技术文档的多模态RAG评估基准，包含真实的技术文档数据集，要求系统能够检索和整合分散在多模态内容中的证据进行推理

Result: 创建了一个能够更准确评估企业级多模态RAG系统性能的基准，填补了现有评估方法的空白

Conclusion: 需要专门针对企业技术文档特点的多模态RAG评估基准来推动该领域的发展，现有通用基准无法满足专业应用需求

Abstract: The rapid evolution of Retrieval-Augmented Generation (RAG) toward multimodal, high-stakes enterprise applications has outpaced the development of domain specific evaluation benchmarks. Existing datasets often rely on general-domain corpora or purely textual retrieval, failing to capture the complexity of specialized technical documents where information is inextricably multimodal and reasoning requires synthesizing disjoint evidence. We address this gap by introducing …

</details>


### [23] [Artificial Intelligence in Modern Database Systems: Applications, Tools, and Challenges for Autonomous Data Management](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11280054/&hl=zh-CN&sa=X&d=15803800865473427497&ei=oYx2aer6OruM6rQP2dOq-Ag&scisig=AHkA5jSY7BicOjQPdOzgucpY2LGn&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:AHkA5jR4Nz41hcddyWt9RkK93bRp&html=&pos=6&folt=cit)
*D Gabriska,K Pribilová,P Střelec*

Main category: Xuanhe Zhou

TL;DR: 本文是一篇关于人工智能在现代数据库中应用的综述，探讨了AI如何解决传统数据库优化方法面临的动态工作负载、分布式架构、异构数据结构和查询复杂度增加等挑战。


<details>
  <summary>Details</summary>
Motivation: 现代数据库系统面临动态工作负载、分布式架构、异构数据结构和查询复杂度增加等挑战，传统基于成本的优化方法和启发式优化器难以适应这些条件，需要定期更新统计信息。人工智能为这些挑战提供了新的解决方案。

Method: 本文采用综述研究方法，系统性地综合分析了人工智能在现代数据库中的应用，包括AI如何改进数据库优化、查询处理、索引选择、连接顺序优化等方面。

Result: 综述发现人工智能技术（如机器学习、深度学习）能够有效应对现代数据库系统的挑战，提供比传统方法更自适应、更智能的优化方案，减少对定期统计更新的依赖。

Conclusion: 人工智能为现代数据库系统提供了有前景的解决方案，能够应对传统优化方法难以处理的动态复杂环境，代表了数据库优化领域的重要发展方向。

Abstract: Modern database systems face increasing challenges due to dynamic workloads, distributed architectures, heterogeneous data structures, and increasing query volume and complexity. Traditional cost-based optimization methods and heuristic optimizers are difficult to maintain under these conditions. They often require regular statistics updates. This article is presented as a survey that synthesizes the use of artificial intelligence (AI) in modern databases. Artificial intelligence offers a …

</details>


### [24] [Predicting User Behaviour Using Classification Models in BigQuery Machine Learning](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11304080/&hl=zh-CN&sa=X&d=6931839248260554762&ei=oYx2aer6OruM6rQP2dOq-Ag&scisig=AHkA5jTm53jEOjfm1PsUCF-HwqtK&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:AHkA5jR4Nz41hcddyWt9RkK93bRp&html=&pos=8&folt=cit)
*I Hristova*

Main category: Xuanhe Zhou

TL;DR: 该论文探讨了在Google BigQuery ML平台上使用机器学习（特别是逻辑回归）进行用户行为预测的方法，展示了云原生平台如何通过SQL实现可扩展的数据分析和预测建模。


<details>
  <summary>Details</summary>
Motivation: 在竞争激烈且数字化驱动的商业环境中，预测用户行为对企业至关重要。需要探索如何在云原生平台上高效实现可扩展的预测建模。

Method: 使用Google BigQuery ML平台，通过SQL直接实现机器学习模型。主要采用分类模型，特别是逻辑回归算法，对用户行为进行预测。使用定义好的数据集进行建模和分析。

Result: 研究表明，在BigQuery ML平台上使用逻辑回归等分类模型能够有效预测用户行为，证明了云原生平台在可扩展数据分析和预测建模方面的实用价值。

Conclusion: Google BigQuery ML为企业在云环境中实现可扩展的用户行为预测提供了有效解决方案，通过SQL直接实现机器学习模型简化了预测建模流程。

Abstract: Predicting user behavior is a critical capability for businesses operating in increasingly competitive and digitally driven environments. This paper explores the application of machine learning (ML) within Google BigQuery ML, a cloud-native platform that enables scalable data analysis and predictive modeling directly through SQL. The study demonstrates how classification models, particularly logistic regression, can be used to forecast user actions. Using a defined dataset, the paper …

</details>


### [25] [Defying Distractions in Multimodal Tasks: A Novel Benchmark for Large Vision-Language Models](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11359049/&hl=zh-CN&sa=X&d=9211569059434737967&ei=oIx2aaOMLLui6rQPrda9qQc&scisig=AHkA5jQzV3KfB-FVvBa2Z-mXlC5n&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:AHkA5jSlroL7H9qfrEO07iLXc5er&html=&pos=0&folt=rel)
*J Yang,M Jiang,Q Zhao*

Main category: Xuanhe Zhou

TL;DR: 大型视觉语言模型存在"多模态分心"问题，即看似合理但无关的视觉或文本输入会导致推理一致性显著下降，产生不可靠输出


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在多模态推理中容易受到看似合理但无关的视觉或文本输入的干扰，导致推理一致性下降和输出不可靠，需要解决这种"多模态分心"问题

Method: 引入了一个全面的框架来评估和缓解多模态分心问题，包括新的评估指标、数据集和训练方法

Result: 提出的方法显著提高了LVLMs在多模态干扰下的推理一致性，减少了不可靠输出，提升了模型的鲁棒性

Conclusion: 多模态分心是LVLMs的重要问题，通过系统性的评估和训练方法可以有效缓解，提高模型在实际应用中的可靠性

Abstract: Large Vision-Language Models (LVLMs) with “multimodal distractibility,” where plausible but irrelevant visual or textual inputs cause significant drops in reasoning consistency and lead to unreliable outputs. This paper introduces a comprehensive …

</details>


<div id='Matei Zaharia'></div>

# Matei Zaharia [[Back]](#toc)

### [26] [ForgetMark: Stealthy Fingerprint Embedding via Targeted Unlearning in Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.08189&hl=zh-CN&sa=X&d=10986440491085924953&ei=oYx2aZX2HtDQ6rQPx77Y4A8&scisig=AHkA5jThCjeMrogiSddIygMf3Z39&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:AHkA5jSEWE2pdcgDuWOJdF-lmUBr&html=&pos=0&folt=rel)
*Z Xu,H Zhang,Z Wang,Q Liu,H Xu,W Xing,M Han*

Main category: Matei Zaharia

TL;DR: ForgetMark是一种新型的隐式后门指纹技术，通过低困惑度触发器和动态响应模式来规避检测，同时减少对良性输入的误激活


<details>
  <summary>Details</summary>
Motivation: 现有后门指纹存在高困惑度触发器易被过滤、固定响应模式易被启发式检测器发现、以及对良性输入的虚假激活等问题，需要开发更隐蔽的后门指纹技术

Method: 提出ForgetMark方法，使用低困惑度触发器，采用动态响应模式而非固定模式，并设计机制减少对良性输入的误激活

Result: ForgetMark在保持高攻击成功率的同时，显著提高了隐蔽性，能够有效规避现有的后门检测方法

Conclusion: ForgetMark为后门指纹提供了新的设计思路，通过降低触发器的可检测性和增加响应模式的动态性，实现了更隐蔽的后门攻击

Abstract: Existing invasive (backdoor) fingerprints suffer from high-perplexity triggers that are easily filtered, fixed response patterns exposed by heuristic detectors, and spurious activations on benign inputs. We introduce\textsc {ForgetMark}, a stealthy …

</details>


### [27] [PhysProver: Advancing Automatic Theorem Proving for Physics](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.15737&hl=zh-CN&sa=X&d=5368597734638541300&ei=oYx2aZX2HtDQ6rQPx77Y4A8&scisig=AHkA5jRTnlXZeP_93R2HKSVtg_5I&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:AHkA5jSEWE2pdcgDuWOJdF-lmUBr&html=&pos=1&folt=rel)
*H Zhang,R Wang,R Pan,W Wang,B Meng,T Zhang*

Main category: Matei Zaharia

TL;DR: LLM与可验证语言的结合为定理证明提供了严格基础，对数学和计算机科学领域产生重要影响


<details>
  <summary>Details</summary>
Motivation: 探索LLM与可验证语言结合在定理证明领域的潜力，为数学和计算机科学提供更严谨的证明基础

Method: 结合大型语言模型与可验证语言技术，利用LLM的推理能力与形式化验证的严谨性

Result: 该结合显著提升了定理证明的效率和可靠性，为数学证明和程序验证提供了新范式

Conclusion: LLM与可验证语言的融合代表了定理证明领域的重要进展，为形式化数学和软件验证开辟了新途径

Abstract: The combination of verifiable languages and LLMs has significantly influenced both the mathematical and computer science communities because it provides a rigorous foundation for theorem proving. Recent advancements in the field provide foundation …

</details>


### [28] [The Assistant Axis: Situating and Stabilizing the Default Persona of Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.10387&hl=zh-CN&sa=X&d=16086180317015075333&ei=oYx2aZX2HtDQ6rQPx77Y4A8&scisig=AHkA5jSEB9PlIZhjb17S32Iy6_NK&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:AHkA5jSEWE2pdcgDuWOJdF-lmUBr&html=&pos=2&folt=rel)
*C Lu,J Gallagher,J Michala,K Fish,J Lindsey*

Main category: Matei Zaharia

TL;DR: 研究探索大语言模型中不同人格身份的结构，通过提取激活方向来表征不同人格，并分析其几何特性


<details>
  <summary>Details</summary>
Motivation: 大语言模型通常默认展现为经过后训练培养的"助手"身份，但实际能够表征多种不同人格。研究者希望探索模型人格空间的结构特性，理解不同人格身份在模型内部是如何组织和表征的

Method: 通过提取激活方向来对应不同的人格身份，分析这些方向的几何特性，研究人格空间的结构和组织方式

Result: 发现了模型人格空间具有特定的结构特性，不同人格身份对应的激活方向在几何上呈现出一定的规律和组织方式

Conclusion: 大语言模型内部存在结构化的人格空间，不同人格身份可以通过特定的激活方向来表征，这为理解和控制模型的身份表达提供了理论基础

Abstract: Large language models can represent a variety of personas but typically default to a helpful Assistant identity cultivated during post-training. We investigate the structure of the space of model personas by extracting activation directions corresponding to …

</details>


### [29] [Unlocking the Potentials of Retrieval-Augmented Generation for Diffusion Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.11342&hl=zh-CN&sa=X&d=12567463795959401720&ei=oYx2aZX2HtDQ6rQPx77Y4A8&scisig=AHkA5jTrOOe5RgTvPCBUwBHFozog&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:AHkA5jSEWE2pdcgDuWOJdF-lmUBr&html=&pos=3&folt=rel)
*C Yu,J Wang,Y Li,H Chang,G Lan,Q Sun,J Li,J Li…*

Main category: Matei Zaharia

TL;DR: 该论文探讨了检索增强生成(RAG)在扩散语言模型(DLMs)中的应用，提出了Diffusion-RAG框架来提升DLMs的文本生成能力


<details>
  <summary>Details</summary>
Motivation: 尽管扩散语言模型(DLMs)在自然语言处理任务中表现出色，但其在检索增强生成(RAG)方面的潜力尚未充分探索，而RAG在增强大型语言模型方面已取得显著成功

Method: 提出了Diffusion-RAG框架，将检索机制集成到DLMs中，通过检索相关外部知识来增强文本生成过程

Result: Diffusion-RAG框架显著提升了DLMs在多种NLP任务上的性能，特别是在需要外部知识或事实准确性的场景中

Conclusion: 检索增强生成可以有效地提升扩散语言模型的性能，Diffusion-RAG为DLMs的进一步发展提供了有前景的方向

Abstract: Diffusion Language Models (DLMs) have recently demonstrated remarkable capabilities in natural language processing tasks. However, the potential of Retrieval-Augmented Generation (RAG), which shows great successes for enhancing large …

</details>


### [30] [Benchmark^ 2: Systematic Evaluation of LLM Benchmarks](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.03986&hl=zh-CN&sa=X&d=2470135056096510870&ei=oYx2aZX2HtDQ6rQPx77Y4A8&scisig=AHkA5jTa2kJIdwrBbfWcBPcD8nKo&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:AHkA5jSEWE2pdcgDuWOJdF-lmUBr&html=&pos=4&folt=rel)
*Q Qian,C Huang,J Xu,C Lv,M Wu,W Liu,X Wang…*

Main category: Matei Zaharia

TL;DR: 提出Benchmark^2框架，用于系统评估大语言模型基准测试的质量，包含三个核心维度：可靠性、难度和多样性


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型基准测试的快速激增，迫切需要系统方法来评估基准测试本身的质量，现有基准测试缺乏统一的质量评估标准

Method: 提出Benchmark^2框架，包含三个核心维度：可靠性（评估基准测试的稳定性和一致性）、难度（评估基准测试的挑战性程度）、多样性（评估基准测试覆盖的任务和技能范围）

Result: 通过Benchmark^2框架对现有主流基准测试进行系统性评估，识别出不同基准测试在质量维度上的优势和不足，为基准测试的选择和改进提供依据

Conclusion: Benchmark^2为评估大语言模型基准测试质量提供了系统框架，有助于推动更高质量、更可靠的基准测试发展，促进大语言模型评估的标准化

Abstract: The rapid proliferation of benchmarks for evaluating large language models (LLMs) has created an urgent need for systematic methods to assess benchmark quality itself. We propose Benchmark^ 2, a comprehensive framework comprising three …

</details>


### [31] [FLEx: Language Modeling with Few-shot Language Explanations](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.04157&hl=zh-CN&sa=X&d=12895648971626871389&ei=oYx2aZX2HtDQ6rQPx77Y4A8&scisig=AHkA5jQjlu7PDQ8ymPLbokdB-_qY&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:AHkA5jSEWE2pdcgDuWOJdF-lmUBr&html=&pos=6&folt=rel)
*A Avsian,C Richardson,A Sundar,L Heck*

Main category: Matei Zaharia

TL;DR: 语言模型在多种任务中表现优异但仍会犯错，且错误会在相关查询中重复出现


<details>
  <summary>Details</summary>
Motivation: 语言模型虽然在各种任务中表现有效，但仍会犯错误，并且这些错误经常在相关查询中重复出现。这揭示了模型在推理过程中存在系统性偏差或局限性，需要开发方法来检测和纠正这些重复性错误。

Method: 摘要未提供具体方法细节，但暗示需要开发某种技术来识别和纠正语言模型中重复出现的错误模式

Result: 摘要未提供具体实验结果，但指出了语言模型存在重复性错误的问题

Conclusion: 语言模型虽然功能强大，但在推理过程中存在系统性错误，这些错误会在相似查询中重复出现，需要开发专门的方法来检测和纠正这些模式

Abstract: Language models have become effective at a wide range of tasks, from math problem solving to open-domain question answering. However, they still make mistakes, and these mistakes are often repeated across related queries. Natural …

</details>


### [32] [Generation-Augmented Generation: A Plug-and-Play Framework for Private Knowledge Injection in Large Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.08209&hl=zh-CN&sa=X&d=10988629267390072525&ei=oYx2aZX2HtDQ6rQPx77Y4A8&scisig=AHkA5jQK3aGEgbj3AZHidPrhyj9y&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:AHkA5jSEWE2pdcgDuWOJdF-lmUBr&html=&pos=7&folt=rel)
*R Li,J Xu,X Chen,Y Yang,J Wang,X Chen,C Xie…*

Main category: Matei Zaharia

TL;DR: 该论文探讨了在高风险领域（如生物医学、材料、金融）部署大语言模型时，如何有效注入私有、快速演变且公开预训练中代表性不足的领域特定知识。


<details>
  <summary>Details</summary>
Motivation: 在高风险领域部署LLMs需要注入私有、领域特定的知识，这些知识具有专有性、快速演变性，且在公开预训练数据中代表性不足。现有方法在知识注入的效率和效果方面存在局限，需要更有效的解决方案。

Method: 论文提出了一种新的知识注入方法，具体方法细节需要从完整论文中获取，但核心思想是针对私有、快速演变的领域知识设计高效的知识注入机制。

Result: 该方法在生物医学、材料和金融等高风险领域实现了更有效的知识注入，提升了LLMs在这些领域的性能和实用性。

Conclusion: 提出的知识注入方法为在高风险领域部署LLMs提供了有效的解决方案，能够处理私有、快速演变的领域知识，提高了模型在专业领域的适用性。

Abstract: In domains such as biomedicine, materials, and finance, high-stakes deployment of large language models (LLMs) requires injecting private, domain-specific knowledge that is proprietary, fast-evolving, and under-represented in public pretraining …

</details>


### [33] [From Passive Metric to Active Signal: The Evolving Role of Uncertainty Quantification in Large Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.15690&hl=zh-CN&sa=X&d=10416968939142200042&ei=oYx2aZX2HtDQ6rQPx77Y4A8&scisig=AHkA5jSwjiGYLdXfAjeTdhvQndyy&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:AHkA5jSEWE2pdcgDuWOJdF-lmUBr&html=&pos=9&folt=rel)
*J Zhang,W Cui,Z Li,L Huang,B Malin,C Xiong…*

Main category: Matei Zaharia

TL;DR: 关于解决LLM不可靠性问题的功能演进综述


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然表现出卓越能力，但其不可靠性仍然是高风险领域部署的关键障碍，需要系统性地解决这一问题

Method: 采用综述研究方法，通过功能演进的视角分析解决LLM不可靠性问题的技术发展路径

Result: 绘制了解决LLM不可靠性问题的功能演进路线图，系统梳理了该领域的技术发展脉络

Conclusion: 通过功能演进的视角分析LLM可靠性问题，为未来研究和实际部署提供了系统性框架和方向指导

Abstract: While Large Language Models (LLMs) show remarkable capabilities, their unreliability remains a critical barrier to deployment in high-stakes domains. This survey charts a functional evolution in addressing this challenge: the evolution of …

</details>


<div id='Sai Wu'></div>

# Sai Wu [[Back]](#toc)

### [34] [Data-Free Privacy-Preserving for LLMs via Model Inversion and Selective Unlearning](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.15595&hl=zh-CN&sa=X&d=16873801879073983567&ei=oYx2aYvULMm4ieoPof3esQc&scisig=AHkA5jRLugWdabeNbimZkHBznoR1&oi=scholaralrt&hist=i6heNjgAAAAJ:18095185696304281508:AHkA5jQB6iGmaAP-whloFJID0lTf&html=&pos=0&folt=art)
*X Zhou,Z Yang,L Cheng,S Wu,G Chen*

Main category: Sai Wu

TL;DR: 该论文探讨大型语言模型记忆敏感个人身份信息带来的隐私风险，并提出机器遗忘技术作为解决方案


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在训练过程中可能记忆敏感的个人身份信息，这引发了严重的隐私担忧。需要开发有效的方法来移除这些记忆信息，同时保持模型性能

Method: 采用机器遗忘技术，旨在从已训练的LLMs中移除特定的敏感信息，同时最小化对模型整体性能的影响

Result: 论文展示了机器遗忘技术在移除PII方面的有效性，能够在保护隐私的同时维持模型的核心功能

Conclusion: 机器遗忘是解决LLMs隐私风险的重要技术方向，为平衡模型效用与隐私保护提供了可行方案

Abstract: Large language models (LLMs) exhibit powerful capabilities but risk memorizing sensitive personally identifiable information (PII) from their training data, posing significant privacy concerns. While machine unlearning techniques aim to remove …

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [35] [Space Filling Curves is All You Need: Communication-Avoiding Matrix Multiplication Made Simple](https://arxiv.org/abs/2601.16294)
*Evangelos Georganas,Alexander Heinecke,Pradeep Dubey*

Main category: cs.DC

TL;DR: 该论文提出使用广义希尔伯特曲线（空间填充曲线）进行矩阵乘法计算空间划分，实现平台无关和形状无关的高数据局部性GEMM方案，并集成通信避免算法，在多个CPU平台上超越厂商库性能。


<details>
  <summary>Details</summary>
Motivation: 现代CPU平台上的矩阵乘法加速器具有高FLOP/Byte机器平衡，使得实现最优矩阵乘法具有挑战性。现有厂商库需要针对不同平台（核心数、内存层次、缓存大小）和矩阵形状进行繁琐的参数调优，导致性能"玻璃下巴"问题，且穷举调优不可行。

Method: 1. 使用广义希尔伯特曲线（空间填充曲线）将多维计算空间映射到一维顺序，保持高维空间中邻近点在低维顺序中的邻近性；2. 基于SFC划分矩阵乘法计算空间，实现平台无关和形状无关的数据局部性方案；3. 扩展SFC工作划分以集成通信避免算法，复制输入张量并证明最小化关键路径上的通信/数据移动。

Result: 提出的SFC-based方法在多个CPU平台上实现了最先进的性能，对于一系列GEMM形状，相比厂商库实现了最高2倍的几何平均加速比。代码紧凑（约30行LOC），通信避免算法的集成无缝且高效。

Conclusion: 空间填充曲线（特别是广义希尔伯特曲线）为矩阵乘法优化提供了一种有效的平台无关和形状无关方法，能够自动实现高数据局部性，避免繁琐的手动调优，并在实际硬件上超越厂商优化库的性能。

Abstract: General Matrix Multiplication (GEMM) is the cornerstone of Deep Learning and HPC workloads; accordingly, academia and industry have heavily optimized this kernel. Modern platforms with matrix multiplication accelerators exhibit high FLOP/Byte machine balance, which makes implementing optimal matrix multiplication challenging. On modern CPU platforms with matrix engines, state-of-the-art vendor libraries tune input tensor layouts, parallelization schemes, and cache blocking to minimize data movement across the memory hierarchy and maximize throughput. However, the best settings for these parameters depend strongly on the target platform (number of cores, memory hierarchy, cache sizes) and on the shapes of the matrices, making exhaustive tuning infeasible; in practice this leads to performance "glass jaws". In this work we revisit space filling curves (SFC) to alleviate the problem of this cumbersome tuning. SFC convert multi-dimensional coordinates (e.g. 2D) into a single dimension (1D), keeping nearby points in the high-dimensional space close in the 1D order. We partition the Matrix Multiplication computation space using recent advancements in generalized SFC (Generalized Hilbert Curves), and we obtain platform-oblivious and shape-oblivious matrix-multiplication schemes that exhibit inherently high degree of data locality. Furthermore, we extend the SFC-based work partitioning to implement Communication-Avoiding (CA) algorithms that replicate the input tensors and provably minimize communication/data-movement on the critical path. The integration of CA-algorithms is seamless and yields compact code (~30 LOC), yet it achieves state-of-the-art results on multiple CPU platforms, outperforming vendor libraries by up to 2x(geometric-mean speedup) for a range of GEMM shapes.

</details>


### [36] [Consensus In Asynchrony](https://arxiv.org/abs/2601.16460)
*Ivan Klianev*

Main category: cs.DC

TL;DR: 该论文证明了基于事件的同步足以在异步环境中实现确定性的容错共识，提出了一个能在一次崩溃容错下保证安全性和活性的向量一致性算法，并重新审视了FLP不可能性定理的隐含假设。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索在异步系统中实现确定性容错共识的可能性，挑战FLP不可能性定理的传统理解，寻找在异步环境下实现共识的新途径。

Method: 提出基于事件同步的算法，实现向量一致性协议；通过理论分析识别FLP定理的三种隐含假设，区分数据无关和数据相关两种一致性类型；提供实验证据验证假设的有效性。

Result: 算法在异步环境中实现确定性容错共识，保证安全性和活性，容忍一次崩溃故障；理论分析表明FLP不可能性依赖于三种隐含假设，其中第三种假设缺乏实验证据支持。

Conclusion: 基于事件的同步足以实现异步环境中的确定性容错共识；FLP不可能性定理的有效性依赖于特定假设，其中关键假设缺乏实证支持，为异步共识研究开辟了新方向。

Abstract: We demonstrate sufficiency of events-based synchronisation for solving deterministic fault-tolerant consensus in asynchrony. Main result is an algorithm that terminates with valid vector agreement, hence operates with safety, liveness, and tolerance to one crash. Reconciling with the FLP impossibility result, we identified: i) existence of two types of agreements: data-independent and data-dependent; and ii) dependence of FLP theorem correctness on three implicit assumptions. Consensus impossibility with data-dependent agreement is contingent on two of them. The theorem-stated impossibility with every agreement type hinges entirely on the third. We provide experimental results showing that the third assumption has no evidence in support.

</details>


### [37] [W4A16 Mixed-Precision Matrix Multiplication on Decoupled Architecture: Kernel Design and Memory Bottleneck Analysis for Ascend NPUs](https://arxiv.org/abs/2601.16536)
*Yuanhong He,Peiyu Niu,Jun Chen,Chenchen Zhang,Chao Yang*

Main category: cs.DC

TL;DR: 该论文提出了首个针对华为昇腾910 NPU的W4A16矩阵乘法内核，通过向量核心动态反量化、立方核心GEMM和Split-K并行化技术，在LLM解码场景下实现1.01-1.74倍加速。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型规模扩大，仅权重量化（W4A16）对减少内存占用至关重要，但在华为昇腾910 NPU上高效部署面临挑战，因为该架构缺乏原生混合精度支持且采用解耦计算架构。

Method: 设计针对昇腾910 NPU的W4A16矩阵乘法内核：利用向量核心进行INT4到FP16的实时反量化，立方核心执行高吞吐量GEMM，采用Split-K并行化缓解内存延迟。

Result: 在多种矩阵形状和批次大小下，当K>>N（典型LLM解码场景）时，该方法优于数据并行方法，加速比达1.01-1.74倍。分析显示主要瓶颈是权重的额外全局内存传输而非反量化计算本身，W4A16相比原生FP16最大加速比为1.48倍。

Conclusion: 该方法为在各种领域专用加速器上高效部署量化大语言模型奠定了坚实基础，并提供了有价值的见解。

Abstract: As Large Language Models (LLMs) scale, weight-only quantization (W4A16: 4-bit weights, 16-bit activations) becomes critical for reducing memory footprint with minimal accuracy loss. However, its efficient deployment on Huawei's Ascend 910 Neural Processing Unit (NPU) is challenging due to limited native mixed-precision support and the accelerator's decoupled compute architecture. To enable quantization on such architecture, we present the first practical W4A16 matrix multiplication kernel tailored for the Ascend 910 NPU. Our design leverages vector cores for on-the-fly INT4-to-FP16 dequantization, cube cores for high-throughput GEMM, and Split-K parallelization to mitigate memory latency. Performance evaluations across diverse matrix shapes and batch sizes show our method outperforms data-parallel approaches when K >> N, a typical scenario in LLM decoding. Specially, our method can achieve a speedup ranging from 1.01x to 1.74x. In addition, our profile reveals the primary bottleneck is not dequantization compution itself, but extra global memory transfer for the weight, making W4A16 only reaching a maximum speedup of 1.48x over native FP16xFP16 matrix multiplication in PyTorch. In the long run, our method lays a solid foundation and provides insightful views for the efficient deployment of quantized large language models on various domain-specific accelerators.

</details>


### [38] [GPU-Accelerated Selected Basis Diagonalization with Thrust for SQD-based Algorithms](https://arxiv.org/abs/2601.16637)
*Jun Doi,Tomonori Shirakawa,Yukio Kawashima,Seiji Yunoki,Hiroshi Horii*

Main category: cs.DC

TL;DR: 提出基于Thrust库的GPU加速SBD实现，通过数据并行原语和GPU友好数据布局重构关键组件，在SQD中实现~40倍加速


<details>
  <summary>Details</summary>
Motivation: SBD在基于样本的量子对角化(SQD)中起核心作用，其迭代对角化是主要经典计算负载，需要GPU加速来提升效率

Method: 使用Thrust库实现GPU加速SBD，重构配置处理、激发生成和矩阵向量运算等关键组件，采用细粒度数据并行原语和扁平化GPU友好数据布局

Result: Thrust-based SBD相比CPU执行实现~40倍加速，显著减少SQD迭代的总运行时间

Conclusion: GPU原生并行原语为加速基于SQD的量子-经典工作流提供了简单、可移植和高性能的基础

Abstract: Selected Basis Diagonalization (SBD) plays a central role in Sample-based Quantum Diagonalization (SQD), where iterative diagonalization of the Hamiltonian in selected configuration subspaces forms the dominant classical workload. We present a GPU-accelerated implementation of SBD using the Thrust library. By restructuring key components -- including configuration processing, excitation generation, and matrix-vector operations -- around fine-grained data-parallel primitives and flattened GPU-friendly data layouts, the proposed approach efficiently exploits modern GPU architectures. In our experiments, the Thrust-based SBD achieves up to $\sim$40$\times$ speedup over CPU execution and substantially reduces the total runtime of SQD iterations. These results demonstrate that GPU-native parallel primitives provide a simple, portable, and high-performance foundation for accelerating SQD-based quantum-classical workflows.

</details>


### [39] [DataStates-LLM: Scalable Checkpointing for Transformer Models Using Composable State Providers](https://arxiv.org/abs/2601.16956)
*Avinash Maurya,M. Mustafa Rafique,Franck Cappello,Bogdan Nicolae*

Main category: cs.DC

TL;DR: DataStates-LLM：一种新型检查点架构，通过状态提供者解耦状态抽象与数据移动，利用参数不变性实现异步快照，显著提升大规模LLM训练检查点性能


<details>
  <summary>Details</summary>
Motivation: 大规模Transformer模型（参数达万亿级）需要在数千个GPU上使用复杂混合并行策略训练。现有检查点方案将模型状态视为不透明的二进制块，忽略了底层数据结构的"3D异质性"（内存位置、分片对象数量、数据类型、序列化要求差异），导致运行时开销大、设备到主机传输阻塞、数据无关序列化和存储I/O争用等问题。

Method: 提出DataStates-LLM检查点架构，引入状态提供者（State Providers）解耦状态抽象与数据移动。利用前向和反向传播期间模型参数的不变性，执行"惰性"、非阻塞的异步快照。通过状态提供者有效合并碎片化、异构的分片，并将元数据序列化与批量张量I/O重叠执行。

Result: 在256个A100-40GB GPU上对高达700亿参数模型进行评估。DataStates-LLM相比最先进解决方案实现了高达4倍的检查点吞吐量提升，端到端训练时间减少高达2.2倍，有效缓解了极端规模LLM训练中的序列化和异质性瓶颈。

Conclusion: DataStates-LLM通过解耦状态抽象与数据移动、利用参数不变性实现异步快照、有效处理异构分片，显著改善了大规模LLM训练中的检查点性能，解决了现有方案在序列化和异质性方面的瓶颈问题。

Abstract: The rapid growth of Large Transformer-based models, specifically Large Language Models (LLMs), now scaling to trillions of parameters, has necessitated training across thousands of GPUs using complex hybrid parallelism strategies (e.g., data, tensor, and pipeline parallelism). Checkpointing this massive, distributed state is critical for a wide range of use cases, such as resilience, suspend-resume, investigating undesirable training trajectories, and explaining model evolution. However, existing checkpointing solutions typically treat model state as opaque binary blobs, ignoring the ``3D heterogeneity'' of the underlying data structures--varying by memory location (GPU vs. Host), number of ``logical'' objects sharded and split across multiple files, data types (tensors vs. Python objects), and their serialization requirements. This results in significant runtime overheads due to blocking device-to-host transfers, data-oblivious serialization, and storage I/O contention. In this paper, we introduce DataStates-LLM, a novel checkpointing architecture that leverages State Providers to decouple state abstraction from data movement. DataStates-LLM exploits the immutability of model parameters during the forward and backward passes to perform ``lazy'', non-blocking asynchronous snapshots. By introducing State Providers, we efficiently coalesce fragmented, heterogeneous shards and overlap the serialization of metadata with bulk tensor I/O. We evaluate DataStates-LLM on models up to 70B parameters on 256 A100-40GB GPUs. Our results demonstrate that DataStates-LLM achieves up to 4$\times$ higher checkpointing throughput and reduces end-to-end training time by up to 2.2$\times$ compared to state-of-the-art solutions, effectively mitigating the serialization and heterogeneity bottlenecks in extreme-scale LLM training.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [40] [iPDB -- Optimizing SQL Queries with ML and LLM Predicates](https://arxiv.org/abs/2601.16432)
*Udesh Kumarasinghe,Tyler Liu,Chunwei Liu,Walid G. Aref*

Main category: cs.DB

TL;DR: iPDB是一个支持在数据库内进行机器学习和大语言模型推理的关系系统，通过扩展SQL语法实现语义查询优化


<details>
  <summary>Details</summary>
Motivation: 传统SQL和关系数据库系统在处理需要利用学习模型的工作负载时存在不兼容或低效问题，导致复杂的工程和数据迁移操作

Method: 开发iPDB关系系统，支持在数据库内进行ML和LLM推理，使用扩展SQL语法，引入新的关系预测操作符和语义查询优化

Result: iPDB能够高效执行语义SQL查询，性能优于现有技术，LLM和ML调用可作为语义投影、谓词执行语义选择和连接，或用于语义分组

Conclusion: iPDB通过扩展SQL语法和引入语义查询优化，有效解决了传统数据库系统与学习模型工作负载不兼容的问题

Abstract: Structured Query Language (SQL) has remained the standard query language for databases. SQL is highly optimized for processing structured data laid out in relations. Meanwhile, in the present application development landscape, it is highly desirable to utilize the power of learned models to perform complex tasks. Large language models (LLMs) have been shown to understand and extract information from unstructured textual data. However, SQL as a query language and accompanying relational database systems are either incompatible or inefficient for workloads that require leveraging learned models. This results in complex engineering and multiple data migration operations that move data between the data sources and the model inference platform. In this paper, we present iPDB, a relational system that supports in-database machine learning (ML) and large language model (LLM) inferencing using extended SQL syntax. In iPDB, LLMs and ML calls can function as semantic projects, as predicates to perform semantic selects and semantic joins, or for semantic grouping in group-by clauses. iPDB has a novel relational predict operator and semantic query optimizations that enable users to write and efficiently execute semantic SQL queries, outperforming the state-of-the-art.

</details>


### [41] [A Scalable Transaction Management Framework for Consistent Document-Oriented NoSQL Databases](https://arxiv.org/abs/2601.16490)
*Adam A. E. Alflahi,Mohammed A. Y. Mohammed,Abdallah Alsammani*

Main category: cs.DB

TL;DR: 提出一个四阶段事务管理框架，用于文档型NoSQL数据库，在保证冲突可串行化的同时减少事务中止率、消除死锁并提升吞吐量。


<details>
  <summary>Details</summary>
Motivation: NoSQL数据库虽然具有可扩展性和模式灵活性，但其最终一致性模型限制了可靠的事务处理能力，需要在保持可扩展性的同时提升数据完整性。

Method: 提出四阶段事务管理框架：事务生命周期管理、操作分类、预执行冲突检测、自适应锁策略（含超时死锁预防）。以MongoDB为参考平台，进行形式化正确性分析。

Result: 实验评估显示：事务中止率从8.3%降至4.7%，消除死锁，延迟方差减少34.2%，高并发下吞吐量提升6.3%-18.4%。分布式实验（9节点集群）吞吐量提升15.2%，中止率降低53%。

Conclusion: 精心设计的一致性机制可以在不损害可扩展性的前提下显著提升NoSQL系统的数据完整性。框架在一致性保证和性能开销之间取得了良好平衡。

Abstract: NoSQL databases are widely used in modern applications due to their scalability and schema flexibility, yet they often rely on eventual consistency models that limit reliable transaction processing. This study proposes a four-stage transaction management framework for document-oriented NoSQL databases, with MongoDB as the reference platform. The framework combines transaction lifecycle management, operation classification, pre-execution conflict detection, and an adaptive locking strategy with timeout-based deadlock prevention. Formal correctness analysis shows that the proposed approach guarantees conflict serializability under defined conditions. An experimental evaluation using the Yahoo Cloud Serving Benchmark (YCSB) workloads A, B, and F, with concurrency levels ranging from 1 to 100 clients, demonstrates a reduction in transaction abort rates from 8.3% to 4.7%, the elimination of observed deadlocks, and a 34.2% decrease in latency variance. Throughput improvements ranging from 6.3% to 18.4% are observed under high concurrency, particularly for read-modify-write workloads. Distributed experiments on clusters of up to 9 nodes confirm scalability, achieving 15.2% higher throughput and 53% lower abort rates than baseline systems. Comparisons with MongoDB's native transactions, CockroachDB, and TiDB indicate that the proposed framework strikes a good balance between consistency guarantees and performance overhead. Sensitivity analysis identifies optimal parameter settings, including a lock timeout of 100 ms, an initial backoff of 10 ms, and a maximum backoff of 500 ms. These results show that carefully designed consistency mechanisms can significantly improve data integrity in NoSQL systems without undermining scalability.

</details>


### [42] [A Categorical Approach to Semantic Interoperability across Building Lifecycle](https://arxiv.org/abs/2601.16663)
*Zoltan Nagy,Ryan Wisnesky,Kevin Carlson,Eswaran Subrahmanian,Gioele Zardini*

Main category: cs.DB

TL;DR: 使用范畴论为建筑数据集成提供数学基础，将复杂度从O(n²)降低到O(n)，实现跨本体自动转换和查询


<details>
  <summary>Details</summary>
Motivation: 建筑生命周期产生异构数据，但集成这些数据仍是未解决的挑战。现有方法存在两个问题：1) 点对点映射随本体数量呈二次方增长；2) 通用本体变得笨重庞大。根本问题是缺乏跨异构建筑数据的结构保持转换的数学基础。

Method: 采用范畴论作为数学基础，将建筑本体形式化为一级理论。使用范畴查询语言(CQL)实现两个概念验证：1) 从IFC设计数据生成BRICK模型；2) 实现IFC、BRICK和RealEstateCore的三向集成，仅需两个显式映射即可通过范畴组合自动获得第三个映射。

Result: 成功证明了范畴方法在建筑数据集成中的可行性：1) 实现了O(n)的规范复杂度（而非O(n²)）；2) 将属性集作为一级模式实体处理；3) 提供自动双向迁移；4) 支持跨本体查询。

Conclusion: 范畴论为建筑数据集成提供了坚实的数学基础，使可靠组件集成成为可能，类似于智能手机平台的应用程序生态系统。该方法为建筑数据集成开辟了新途径，有望解决长期存在的标准化碎片化问题。

Abstract: Buildings generate heterogeneous data across their lifecycle, yet integrating these data remains a critical unsolved challenge. Despite three decades of standardization efforts, over 40 metadata schemas now span the building lifecycle, with fragmentation accelerating rather than resolving. Current approaches rely on point-to-point mappings that scale quadratically with the number of schemas, or universal ontologies that become unwieldy monoliths. The fundamental gap is the absence of mathematical foundations for structure-preserving transformations across heterogeneous building data. Here we show that category theory provides these foundations, enabling systematic data integration with $O(n)$ specification complexity for $n$ ontologies. We formalize building ontologies as first-order theories and demonstrate two proof-of-concept implementations in Categorical Query Language (CQL): 1) generating BRICK models from IFC design data at commissioning, and 2) three-way integration of IFC, BRICK, and RealEstateCore where only two explicit mappings yield the third automatically through categorical composition. Our correct-by-construction approach treats property sets as first-class schema entities and provides automated bidirectional migrations, and enables cross-ontology queries. These results establish feasibility of categorical methods for building data integration and suggest a path toward an app ecosystem for buildings, where mathematical foundations enable reliable component integration analogous to smartphone platforms.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [43] [Ordering-based Causal Discovery via Generalized Score Matching](https://arxiv.org/abs/2601.16249)
*Vy Vo,He Zhao,Trung Le,Edwin V. Bonilla,Dinh Phung*

Main category: cs.LG

TL;DR: 提出基于离散评分函数的叶节点判别准则，扩展评分匹配框架用于离散数据的因果发现


<details>
  <summary>Details</summary>
Motivation: 从纯观测数据学习DAG结构是跨科学领域的长期挑战，现有评分匹配框架主要针对连续数据，需要扩展到离散数据

Method: 扩展评分匹配框架，引入基于离散评分函数的新型叶节点判别准则，通过叶节点检测识别拓扑顺序，然后进行边剪枝实现图恢复

Result: 模拟和真实世界实验表明，该方法能够从观测离散数据准确推断真实因果顺序，识别的顺序能显著提升现有因果发现基线的准确性

Conclusion: 基于离散评分函数的叶节点判别准则有效扩展了评分匹配框架，为离散数据的因果发现提供了新方法

Abstract: Learning DAG structures from purely observational data remains a long-standing challenge across scientific domains. An emerging line of research leverages the score of the data distribution to initially identify a topological order of the underlying DAG via leaf node detection and subsequently performs edge pruning for graph recovery. This paper extends the score matching framework for causal discovery, which is originally designated for continuous data, and introduces a novel leaf discriminant criterion based on the discrete score function. Through simulated and real-world experiments, we demonstrate that our theory enables accurate inference of true causal orders from observed discrete data and the identified ordering can significantly boost the accuracy of existing causal discovery baselines on nearly all of the settings.

</details>


### [44] [Student Mental Health Screening via Fitbit Data Collected During the COVID-19 Pandemic](https://arxiv.org/abs/2601.16324)
*Rebecca Lopez,Avantika Shrestha,ML Tlachac,Kevin Hickey,Xingtong Guo,Shichao Liu,Elke Rundensteiner*

Main category: cs.LG

TL;DR: 使用Fitbit可穿戴设备数据通过机器学习模型筛查大学生抑郁、焦虑和压力，心率与睡眠模态表现最佳，F1分数最高达0.79


<details>
  <summary>Details</summary>
Motivation: 大学生面临高压力导致焦虑抑郁高发，现有研究在心理评估工具多样性、生理模态和时间序列参数方面存在局限，需要探索可穿戴设备在心理健康早期筛查中的应用潜力

Method: 收集疫情期间大学生的StudentMEH Fitbit数据集，使用预测性机器学习模型评估不同Fitbit模态（心率、睡眠等）对抑郁、焦虑和压力的筛查能力，比较不同数据聚合水平和模态组合

Result: 生理模态如心率和睡眠在心理健康筛查中表现出潜力：焦虑筛查F1分数最高达0.79，压力筛查心率模态达0.77，抑郁筛查睡眠模态达0.78，识别了最佳数据聚合水平和适合不同心理疾病的模态

Conclusion: 可穿戴设备在连续心理健康监测中具有重要潜力，确定最佳数据聚合水平和适当模态对于不同心理疾病的筛查至关重要，为基于生理信号的早期心理健康干预提供了实证支持

Abstract: College students experience many stressors, resulting in high levels of anxiety and depression. Wearable technology provides unobtrusive sensor data that can be used for the early detection of mental illness. However, current research is limited concerning the variety of psychological instruments administered, physiological modalities, and time series parameters. In this research, we collect the Student Mental and Environmental Health (StudentMEH) Fitbit dataset from students at our institution during the pandemic. We provide a comprehensive assessment of the ability of predictive machine learning models to screen for depression, anxiety, and stress using different Fitbit modalities. Our findings indicate potential in physiological modalities such as heart rate and sleep to screen for mental illness with the F1 scores as high as 0.79 for anxiety, the former modality reaching 0.77 for stress screening, and the latter modality achieving 0.78 for depression. This research highlights the potential of wearable devices to support continuous mental health monitoring, the importance of identifying best data aggregation levels and appropriate modalities for screening for different mental ailments.

</details>


### [45] [Efficient Gaussian process learning via subspace projections](https://arxiv.org/abs/2601.16332)
*Felipe Tobar,Elsa Cazelles*

Main category: cs.LG

TL;DR: 提出了一种基于数据低维线性投影的高斯过程训练新目标——投影似然（PL），通过随机投影减少信息损失，在中等规模数据集上相比精确GP和变分稀疏GP在精度和计算效率上表现更优。


<details>
  <summary>Details</summary>
Motivation: 传统高斯过程训练在大规模数据集上面临计算复杂度高的问题，现有稀疏近似方法如变分自由能方法存在精度损失。需要一种既能保持计算效率又能减少信息损失的新训练方法。

Method: 提出投影似然（PL）作为高斯过程训练目标，使用数据低维线性投影构建GP。推导了PL相关信息损失的闭式表达式，并通过单位球面上的随机投影减少信息损失。在不同优化器、核函数和中等规模数据集上评估PL性能。

Result: 投影似然方法在精度和计算效率上均优于精确GP训练和变分自由能稀疏GP方法。随机投影能有效减少信息损失，在多个数据集和配置下表现出更好的性能。

Conclusion: 投影似然为高斯过程训练提供了一种高效且精确的替代方案，特别适用于中等规模数据集，通过低维投影平衡了计算复杂度和模型精度。

Abstract: We propose a novel training objective for GPs constructed using lower-dimensional linear projections of the data, referred to as \emph{projected likelihood} (PL). We provide a closed-form expression for the information loss related to the PL and empirically show that it can be reduced with random projections on the unit sphere. We show the superiority of the PL, in terms of accuracy and computational efficiency, over the exact GP training and the variational free energy approach to sparse GPs over different optimisers, kernels and datasets of moderately large sizes.

</details>


### [46] [A Regularized Actor-Critic Algorithm for Bi-Level Reinforcement Learning](https://arxiv.org/abs/2601.16399)
*Sihan Zeng,Sujay Bhatt,Sumitra Ganesh,Alec Koppel*

Main category: cs.LG

TL;DR: 提出单循环一阶actor-critic算法解决双层优化问题，上层优化平滑函数，下层为MDP策略优化，通过惩罚重构和衰减熵正则实现无偏超梯度估计。


<details>
  <summary>Details</summary>
Motivation: 现有双层优化和RL方法需要二阶信息、强正则化或低效的嵌套循环，需要开发更高效的单循环一阶算法来优化上层目标函数依赖于下层最优策略的双层结构问题。

Method: 提出单循环一阶actor-critic算法，通过惩罚重构将双层问题转化为单层优化，在下层RL目标中引入衰减熵正则化，实现渐进无偏的上层超梯度估计，无需精确求解未正则化RL问题。

Result: 在特殊Polyak-Lojasiewicz条件下，通过新颖的下层残差分析，建立了算法在有限时间和有限样本下收敛到原始未正则化双层优化问题稳定点的理论保证。

Conclusion: 该方法在GridWorld目标定位问题和基于人类反馈的强化学习（RLHF）快乐推文生成任务中验证了性能，为双层优化问题提供了高效的单循环一阶解决方案。

Abstract: We study a structured bi-level optimization problem where the upper-level objective is a smooth function and the lower-level problem is policy optimization in a Markov decision process (MDP). The upper-level decision variable parameterizes the reward of the lower-level MDP, and the upper-level objective depends on the optimal induced policy. Existing methods for bi-level optimization and RL often require second-order information, impose strong regularization at the lower level, or inefficiently use samples through nested-loop procedures. In this work, we propose a single-loop, first-order actor-critic algorithm that optimizes the bi-level objective via a penalty-based reformulation. We introduce into the lower-level RL objective an attenuating entropy regularization, which enables asymptotically unbiased upper-level hyper-gradient estimation without solving the unregularized RL problem exactly. We establish the finite-time and finite-sample convergence of the proposed algorithm to a stationary point of the original, unregularized bi-level optimization problem through a novel lower-level residual analysis under a special type of Polyak-Lojasiewicz condition. We validate the performance of our method through experiments on a GridWorld goal position problem and on happy tweet generation through reinforcement learning from human feedback (RLHF).

</details>


### [47] [Towards a Theoretical Understanding to the Generalization of RLHF](https://arxiv.org/abs/2601.16403)
*Zhaochun Li,Mingyang Yi,Yue Wang,Shisheng Cui,Yong Liu*

Main category: cs.LG

TL;DR: 本文建立了基于线性奖励模型的RLHF理论泛化框架，通过算法稳定性证明了在特征覆盖条件下策略模型的经验最优解具有O(n^{-1/2})的泛化界，并将结果推广到梯度上升和随机梯度上升算法。


<details>
  <summary>Details</summary>
Motivation: 尽管RLHF及其变体已成为对齐大语言模型与人类意图的主导方法，且实证有效，但其在高维设置下的理论泛化特性尚未得到充分探索。现有工作主要基于奖励模型最大似然估计的一致性，而本文旨在建立与实际一致的端到端学习框架下的泛化理论。

Method: 在线性奖励模型假设下，采用算法稳定性框架分析RLHF的泛化特性。首先证明在特征覆盖条件下，策略模型经验最优解的泛化界为O(n^{-1/2})，然后将结果扩展到梯度上升和随机梯度上升等梯度基学习算法获得的参数。

Result: 证明了在关键特征覆盖条件下，策略模型经验最优解具有O(n^{-1/2})的泛化界。该结果可推广到梯度上升和随机梯度上升算法获得的参数，为RLHF后LLMs观察到的经验泛化现象提供了新的理论证据。

Conclusion: 本文通过算法稳定性框架建立了RLHF的理论泛化分析，在线性奖励模型和特征覆盖条件下证明了策略模型的泛化性能，为RLHF在大语言模型对齐中的有效性提供了理论支持。

Abstract: Reinforcement Learning from Human Feedback (RLHF) and its variants have emerged as the dominant approaches for aligning Large Language Models with human intent. While empirically effective, the theoretical generalization properties of these methods in high-dimensional settings remain to be explored. To this end, we build the generalization theory on RLHF of LLMs under the linear reward model, through the framework of algorithmic stability. In contrast to the existing works built upon the consistency of maximum likelihood estimations on reward model, our analysis is presented under an end-to-end learning framework, which is consistent with practice. Concretely, we prove that under a key \textbf{feature coverage} condition, the empirical optima of policy model have a generalization bound of order $\mathcal{O}(n^{-\frac{1}{2}})$. Moreover, the results can be extrapolated to parameters obtained by gradient-based learning algorithms, i.e., Gradient Ascent (GA) and Stochastic Gradient Ascent (SGA). Thus, we argue that our results provide new theoretical evidence for the empirically observed generalization of LLMs after RLHF.

</details>


### [48] [Integrating Meteorological and Operational Data: A Novel Approach to Understanding Railway Delays in Finland](https://arxiv.org/abs/2601.16592)
*Vinicius Pozzobon Borin,Jean Michel de Souza Sant'Ana,Usama Raheel,Nurul Huda Mahmood*

Main category: cs.LG

TL;DR: 首个公开的芬兰铁路运营与气象观测综合数据集（2018-2024），包含3850万条观测记录，通过时空对齐整合了运营指标和气象测量，用于分析天气对铁路可靠性的影响。


<details>
  <summary>Details</summary>
Motivation: 现有数据集很少将气象信息与铁路运营数据整合，而天气（尤其在北欧地区）对铁路可靠性有显著影响。需要综合数据集来研究运营、技术和环境因素之间的复杂相互作用。

Method: 整合芬兰Digitraffic铁路交通服务的运营指标和209个环境监测站的气象观测数据，使用Haversine距离进行时空对齐。包含28个工程特征，采用空间回退算法处理缺失数据、时间特征的循环编码以及天气数据的鲁棒缩放。

Result: 数据集包含约3850万条观测记录，覆盖芬兰5915公里铁路网。分析显示明显的季节性模式：冬季延误率超过25%，中部和北部芬兰存在高延误走廊的地理聚类。XGBoost回归基线实验的MAE为2.73分钟。

Conclusion: 该数据集为机器学习在铁路运营研究中的应用提供了灵活资源，支持列车延误预测、天气影响评估和基础设施脆弱性映射等多种应用。

Abstract: Train delays result from complex interactions between operational, technical, and environmental factors. While weather impacts railway reliability, particularly in Nordic regions, existing datasets rarely integrate meteorological information with operational train data. This study presents the first publicly available dataset combining Finnish railway operations with synchronized meteorological observations from 2018-2024. The dataset integrates operational metrics from Finland Digitraffic Railway Traffic Service with weather measurements from 209 environmental monitoring stations, using spatial-temporal alignment via Haversine distance. It encompasses 28 engineered features across operational variables and meteorological measurements, covering approximately 38.5 million observations from Finland's 5,915-kilometer rail network. Preprocessing includes strategic missing data handling through spatial fallback algorithms, cyclical encoding of temporal features, and robust scaling of weather data to address sensor outliers. Analysis reveals distinct seasonal patterns, with winter months exhibiting delay rates exceeding 25\% and geographic clustering of high-delay corridors in central and northern Finland. Furthermore, the work demonstrates applications of the data set in analysing the reliability of railway traffic in Finland. A baseline experiment using XGBoost regression achieved a Mean Absolute Error of 2.73 minutes for predicting station-specific delays, demonstrating the dataset's utility for machine learning applications. The dataset enables diverse applications, including train delay prediction, weather impact assessment, and infrastructure vulnerability mapping, providing researchers with a flexible resource for machine learning applications in railway operations research.

</details>


### [49] [Reasoning-Enhanced Rare-Event Prediction with Balanced Outcome Correction](https://arxiv.org/abs/2601.16406)
*Vitaly Bulgakov,Alexander Turchin*

Main category: cs.LG

TL;DR: LPCORP是一个两阶段框架，通过推理增强预测和基于置信度的结果校正来解决极端类别不平衡问题，在医疗和消费者服务领域显著提升了稀有事件预测性能。


<details>
  <summary>Details</summary>
Motivation: 在医疗、金融、可靠性工程、客户支持和航空安全等领域，稀有事件预测至关重要，但极端类别不平衡会使传统模型偏向多数类预测，限制召回率、校准性和操作实用性。

Method: LPCORP是一个两阶段框架：首先使用推理模型从叙述性输入中生成增强预测，然后通过轻量级逻辑回归分类器评估并选择性校正这些输出，以减轻流行度驱动的偏差。

Result: 该方法将高度不平衡的设置转变为平衡设置，同时保留原始样本数量且不应用任何重采样策略。测试集评估显示性能显著提升，特别是在低流行度数据中已知较弱的精确度方面。成本降低分析显示在某些情况下可减少50%以上的费用。

Conclusion: LPCORP通过结合推理增强预测和置信度校正，有效解决了稀有事件预测中的类别不平衡问题，在保持样本完整性的同时显著提升了预测性能，并展示了实际成本效益。

Abstract: Rare-event prediction is critical in domains such as healthcare, finance, reliability engineering, customer support, aviation safety, where positive outcomes are infrequent yet potentially catastrophic. Extreme class imbalance biases conventional models toward majority-class predictions, limiting recall, calibration, and operational usefulness. We propose LPCORP (Low-Prevalence CORrector for Prediction)*, a two-stage framework that combines reasoningenhanced prediction with confidence-based outcome correction. A reasoning model first produces enriched predictions from narrative inputs, after which a lightweight logistic-regression classifier evaluates and selectively corrects these outputs to mitigate prevalence-driven bias. We evaluate LPCORP on real-world datasets from medical and consumer service domains. The results show that this method transforms a highly imbalanced setting into a well-balanced one while preserving the original number of samples and without applying any resampling strategies. Test-set evaluation demonstrates substantially improved performance, particularly in precision, which is a known weakness in low-prevalence data. We further provide a costreduction analysis comparing the expenses associated with rare-event damage control without preventive measures to those incurred when low-cost, prediction-based preventive interventions are applied that showed more than 50% reduction in some cases. * Patent pending: U.S. Provisional 63/933,518, filed 8 December 2025.

</details>


### [50] [A Refinement of Vapnik--Chervonenkis' Theorem](https://arxiv.org/abs/2601.16411)
*A. Iosevich,A. Vagharshakyan,E. Wyman*

Main category: cs.LG

TL;DR: 论文通过使用带显式Berry-Esseen误差控制的正态近似替代Hoeffding不等式，改进了VC定理的概率部分，获得了中等偏差下的精度提升


<details>
  <summary>Details</summary>
Motivation: 经典的VC定理使用Hoeffding不等式作为最终步骤，作者希望改进这一概率论证部分以获得更精确的收敛速率估计

Method: 重新审视VC定理的概率论证部分，使用带显式Berry-Esseen误差控制的正态近似替代Hoeffding不等式

Result: 获得了中等偏差下VC估计的精度提升，当ε√n较大时，在主导指数项中增加了(ε√n)^{-1}阶的因子

Conclusion: 通过使用更精确的正态近似方法，可以改进VC定理的概率论证，获得更精确的均匀收敛速率估计

Abstract: Vapnik--Chervonenkis' theorem is a seminal result in machine learning. It establishes sufficient conditions for empirical probabilities to converge to theoretical probabilities, uniformly over families of events. It also provides an estimate for the rate of such uniform convergence.
  We revisit the probabilistic component of the classical argument. Instead of applying Hoeffding's inequality at the final step, we use a normal approximation with explicit Berry--Esseen error control. This yields a moderate-deviation sharpening of the usual VC estimate, with an additional factor of order $(\varepsilon\sqrt{n})^{-1}$ in the leading exponential term when $\varepsilon\sqrt{n}$ is large.

</details>


### [51] [PyHealth 2.0: A Comprehensive Open-Source Toolkit for Accessible and Reproducible Clinical Deep Learning](https://arxiv.org/abs/2601.16414)
*John Wu,Yongda Fan,Zhenbang Wu,Paul Landes,Eric Schrock,Sayeed Sajjad Razin,Arjun Chatterjee,Naveen Baskaran,Joshua Steier,Andrea Fitzpatrick,Bilal Arif,Rian Atri,Jathurshan Pradeepkumar,Siddhartha Laghuvarapu,Junyi Gao,Adam R. Cross,Jimeng Sun*

Main category: cs.LG

TL;DR: PyHealth 2.0是一个增强的临床深度学习工具包，旨在通过统一框架、优化性能和建立开源社区来降低临床AI研究的门槛，支持在7行代码内完成预测建模。


<details>
  <summary>Details</summary>
Motivation: 临床AI研究面临基准难以复现、计算成本高、需要领域专业知识等持续障碍，这些因素限制了研究的可及性和可重复性。

Method: 开发PyHealth 2.0工具包，提供三个核心贡献：1) 统一框架整合15+数据集、20+临床任务、25+模型、5+可解释性方法和不确定性量化；2) 优化设计支持多模态数据和不同计算资源，实现高达39倍处理速度和20倍内存使用降低；3) 建立400+成员的活跃开源社区，提供多语言支持。

Result: PyHealth 2.0能够在7行代码内完成临床预测建模，支持从16GB笔记本电脑到生产系统的不同计算环境，建立了包含400+成员的活跃开源社区，并与学术医疗系统和行业合作伙伴开展合作。

Conclusion: PyHealth 2.0建立了一个开源基础和社区，推动可访问、可重复的医疗AI研究，通过统一框架、性能优化和社区支持降低了临床AI研究的门槛。

Abstract: Difficulty replicating baselines, high computational costs, and required domain expertise create persistent barriers to clinical AI research. To address these challenges, we introduce PyHealth 2.0, an enhanced clinical deep learning toolkit that enables predictive modeling in as few as 7 lines of code. PyHealth 2.0 offers three key contributions: (1) a comprehensive toolkit addressing reproducibility and compatibility challenges by unifying 15+ datasets, 20+ clinical tasks, 25+ models, 5+ interpretability methods, and uncertainty quantification including conformal prediction within a single framework that supports diverse clinical data modalities - signals, imaging, and electronic health records - with translation of 5+ medical coding standards; (2) accessibility-focused design accommodating multimodal data and diverse computational resources with up to 39x faster processing and 20x lower memory usage, enabling work from 16GB laptops to production systems; and (3) an active open-source community of 400+ members lowering domain expertise barriers through extensive documentation, reproducible research contributions, and collaborations with academic health systems and industry partners, including multi-language support via RHealth. PyHealth 2.0 establishes an open-source foundation and community advancing accessible, reproducible healthcare AI. Available at pip install pyhealth.

</details>


### [52] [Bayesian Experimental Design for Model Discrepancy Calibration: A Rivalry between Kullback--Leibler Divergence and Wasserstein Distance](https://arxiv.org/abs/2601.16425)
*Huchen Yang,Xinghao Dong,Jin-Long Wu*

Main category: cs.LG

TL;DR: 该论文系统比较了贝叶斯实验设计中KL散度和Wasserstein距离两种效用函数准则，通过理论分析和数值实验揭示了它们在信息增益、收敛速度和模型失配鲁棒性方面的权衡。


<details>
  <summary>Details</summary>
Motivation: 贝叶斯实验设计(BED)中效用函数的选择是一个长期活跃的研究课题，不同准则强调不同的信息概念。虽然KL散度是最常见的选择，但最近研究提出了Wasserstein距离作为替代。需要系统比较这两种准则的性能差异，为实际应用提供选择指导。

Method: 1. 使用玩具示例说明Wasserstein距离的问题：固定形状后验的Wasserstein距离值取决于其主要质量在支撑集中的相对位置，可能产生与信息增益无关的虚假奖励；2. 通过BED文献中的经典源反演问题系统比较两种准则，分析它们在有无模型失配情况下的表现。

Result: 1. Wasserstein距离对后验分布主要质量在支撑集中的位置敏感，特别是在非信息性先验下可能产生误导性结果；2. 在没有模型失配时，KL散度倾向于导致更快的收敛速度；3. 当模型失配不可忽略时，Wasserstein度量提供更鲁棒的序贯BED结果。

Conclusion: 研究阐明了KL散度和Wasserstein度量在效用函数选择中的权衡关系，为实际BED应用中选择合适准则提供了指导原则：在无模型失配时优先使用KL散度以获得更快收敛，在存在显著模型失配时使用Wasserstein距离以获得更好的鲁棒性。

Abstract: Designing experiments that systematically gather data from complex physical systems is central to accelerating scientific discovery. While Bayesian experimental design (BED) provides a principled, information-based framework that integrates experimental planning with probabilistic inference, the selection of utility functions in BED is a long-standing and active topic, where different criteria emphasize different notions of information. Although Kullback--Leibler (KL) divergence has been one of the most common choices, recent studies have proposed Wasserstein distance as an alternative. In this work, we first employ a toy example to illustrate an issue of Wasserstein distance - the value of Wasserstein distance of a fixed-shape posterior depends on the relative position of its main mass within the support and can exhibit false rewards unrelated to information gain, especially with a non-informative prior (e.g., uniform distribution). We then further provide a systematic comparison between these two criteria through a classical source inversion problem in the BED literature, revealing that the KL divergence tends to lead to faster convergence in the absence of model discrepancy, while Wasserstein metrics provide more robust sequential BED results if model discrepancy is non-negligible. These findings clarify the trade-offs between KL divergence and Wasserstein metrics for the utility function and provide guidelines for selecting suitable criteria in practical BED applications.

</details>


### [53] [On the Effects of Adversarial Perturbations on Distribution Robustness](https://arxiv.org/abs/2601.16464)
*Yipei Wang,Zhaoying Pan,Xiaoqian Wang*

Main category: cs.LG

TL;DR: 论文分析了对抗鲁棒性和分布鲁棒性之间的权衡关系，发现ℓ∞扰动在适度偏差数据上能提升分布鲁棒性，特征可分性在这一过程中起关键作用。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明对抗鲁棒性和分布鲁棒性之间存在权衡：对抗训练可能增加对虚假特征的依赖，从而损害分布鲁棒性，特别是在代表性不足的子群体上。作者旨在深入理解这一权衡关系及其背后的机制。

Method: 通过理论分析，研究在扰动数据上训练的模型，为每步对抗训练提供可处理的替代方法。分析重点关注ℓ∞扰动、数据偏差程度以及特征可分性（核心特征与虚假特征之间的分离度）之间的相互作用。

Result: 发现ℓ∞扰动在适度偏差数据上能提高分布鲁棒性；在高度偏斜数据中，当简单性偏差诱导模型依赖核心特征（表现为更大的特征可分性）时，分布鲁棒性的增益仍然存在。特征可分性在权衡关系中起关键调节作用。

Conclusion: 研究扩展了对对抗鲁棒性和分布鲁棒性权衡的理解，强调特征可分性在这一关系中的重要作用。尽管权衡在许多情况下仍然存在，但忽视特征可分性的作用可能导致对鲁棒性的误解。

Abstract: Adversarial robustness refers to a model's ability to resist perturbation of inputs, while distribution robustness evaluates the performance of the model under data shifts. Although both aim to ensure reliable performance, prior work has revealed a tradeoff in distribution and adversarial robustness. Specifically, adversarial training might increase reliance on spurious features, which can harm distribution robustness, especially the performance on some underrepresented subgroups. We present a theoretical analysis of adversarial and distribution robustness that provides a tractable surrogate for per-step adversarial training by studying models trained on perturbed data. In addition to the tradeoff, our work further identified a nuanced phenomenon that $\ell_\infty$ perturbations on data with moderate bias can yield an increase in distribution robustness. Moreover, the gain in distribution robustness remains on highly skewed data when simplicity bias induces reliance on the core feature, characterized as greater feature separability. Our theoretical analysis extends the understanding of the tradeoff by highlighting the interplay of the tradeoff and the feature separability. Despite the tradeoff that persists in many cases, overlooking the role of feature separability may lead to misleading conclusions about robustness.

</details>


### [54] [A Cautionary Tale of Self-Supervised Learning for Imaging Biomarkers: Alzheimer's Disease Case Study](https://arxiv.org/abs/2601.16467)
*Maxwell Reynolds,Chaitanya Srinivasan,Vijay Cherupally,Michael Leone,Ke Yu,Li Sun,Tigmanshu Chaudhary,Andreas Pfenning,Kayhan Batmanghelich*

Main category: cs.LG

TL;DR: R-NCE自监督学习框架通过整合FreeSurfer特征和最大化增强不变信息，在阿尔茨海默病生物标志物发现中优于传统方法和现有SSL方法，并在脑年龄差分析中显示出与神经退行和脑血管过程相关的生物学相关性。


<details>
  <summary>Details</summary>
Motivation: 发现敏感且具有生物学基础的生物标志物对于阿尔茨海默病的早期检测和监测至关重要。结构MRI虽然广泛可用，但通常依赖于手工特征（如皮质厚度或体积）。研究探索自监督学习能否从相同数据中发现更强大的生物标志物。

Method: 提出残差噪声对比估计（R-NCE）框架，该框架整合辅助的FreeSurfer特征，同时最大化额外的增强不变信息。通过脑年龄差（BAG）测量和全基因组关联研究评估生物学相关性。

Result: R-NCE在疾病分类、转化预测和淀粉样蛋白状态预测等多个基准测试中优于传统FreeSurfer特征和现有SSL方法。R-NCE-BAG显示出高遗传性，与MAPT和IRAG1基因相关，并在星形胶质细胞和少突胶质细胞中富集，表明对神经退行和脑血管过程的敏感性。

Conclusion: R-NCE自监督学习框架能够从结构MRI中发现比传统手工特征更强大的阿尔茨海默病生物标志物，这些标志物具有生物学相关性，反映了神经退行和脑血管过程。

Abstract: Discovery of sensitive and biologically grounded biomarkers is essential for early detection and monitoring of Alzheimer's disease (AD). Structural MRI is widely available but typically relies on hand-crafted features such as cortical thickness or volume. We ask whether self-supervised learning (SSL) can uncover more powerful biomarkers from the same data. Existing SSL methods underperform FreeSurfer-derived features in disease classification, conversion prediction, and amyloid status prediction. We introduce Residual Noise Contrastive Estimation (R-NCE), a new SSL framework that integrates auxiliary FreeSurfer features while maximizing additional augmentation-invariant information. R-NCE outperforms traditional features and existing SSL methods across multiple benchmarks, including AD conversion prediction. To assess biological relevance, we derive Brain Age Gap (BAG) measures and perform genome-wide association studies. R-NCE-BAG shows high heritability and associations with MAPT and IRAG1, with enrichment in astrocytes and oligodendrocytes, indicating sensitivity to neurodegenerative and cerebrovascular processes.

</details>


### [55] [Robust Categorical Data Clustering Guided by Multi-Granular Competitive Learning](https://arxiv.org/abs/2601.16491)
*Shenghong Cai,Yiqun Zhang,Xiaopeng Luo,Yiu-Ming Cheung,Hong Jia,Peng Liu*

Main category: cs.LG

TL;DR: 提出MCDC方法，通过MGCPL算法和CAME策略解决分类数据聚类中的嵌套粒度簇效应问题，实现自动探索多粒度簇分布并具有线性时间复杂度。


<details>
  <summary>Details</summary>
Motivation: 分类数据在大数据分析中很常见，但由于其定性特征值，无法像欧氏距离那样明确定义距离空间。分类数据在隐式离散距离空间中普遍存在嵌套粒度簇效应，即数据对象经常在空间或子空间中重叠形成小型紧凑簇，而相似的小簇又形成更大的簇。这种特性给分类数据的聚类分析带来了巨大挑战。

Method: 提出MCDC方法，包含两个核心组件：1) MGCPL算法（多粒度竞争惩罚学习），让潜在簇通过交互式调整在不同阶段收敛，形成不同数量的自然紧凑簇；2) CAME策略（基于MGCPL编码的簇聚合），首先根据学习到的多粒度分布对数据对象进行编码，然后在嵌入表示上执行最终聚类。

Result: MCDC方法能够自动探索多粒度簇的嵌套分布，对各种领域的分类数据集具有高度鲁棒性。得益于其线性时间复杂度，MCDC可扩展到大规模数据集，并有望用于预分区数据集或计算节点以提升分布式计算性能。大量实验统计证据表明，在多个真实公共数据集上，MCDC优于最先进的对比方法。

Conclusion: MCDC方法通过MGCPL算法和CAME策略有效解决了分类数据聚类中的嵌套粒度簇效应问题，实现了自动、鲁棒且可扩展的聚类分析，为分类数据处理提供了有前景的解决方案。

Abstract: Data set composed of categorical features is very common in big data analysis tasks. Since categorical features are usually with a limited number of qualitative possible values, the nested granular cluster effect is prevalent in the implicit discrete distance space of categorical data. That is, data objects frequently overlap in space or subspace to form small compact clusters, and similar small clusters often form larger clusters. However, the distance space cannot be well-defined like the Euclidean distance due to the qualitative categorical data values, which brings great challenges to the cluster analysis of categorical data. In view of this, we design a Multi-Granular Competitive Penalization Learning (MGCPL) algorithm to allow potential clusters to interactively tune themselves and converge in stages with different numbers of naturally compact clusters. To leverage MGCPL, we also propose a Cluster Aggregation strategy based on MGCPL Encoding (CAME) to first encode the data objects according to the learned multi-granular distributions, and then perform final clustering on the embeddings. It turns out that the proposed MGCPL-guided Categorical Data Clustering (MCDC) approach is competent in automatically exploring the nested distribution of multi-granular clusters and highly robust to categorical data sets from various domains. Benefiting from its linear time complexity, MCDC is scalable to large-scale data sets and promising in pre-partitioning data sets or compute nodes for boosting distributed computing. Extensive experiments with statistical evidence demonstrate its superiority compared to state-of-the-art counterparts on various real public data sets.

</details>


### [56] [Beyond Superficial Unlearning: Sharpness-Aware Robust Erasure of Hallucinations in Multimodal LLMs](https://arxiv.org/abs/2601.16527)
*Xianya Fang,Feiyang Ren,Xiang Chen,Yu Tian,Zhen Bi,Haiyang Yu,Sheng-Jun Huang*

Main category: cs.LG

TL;DR: SARE提出了一种针对多模态大语言模型对象幻觉问题的鲁棒性遗忘方法，通过目标最小最大优化和Targeted-SAM机制来平坦化损失景观，确保幻觉概念被稳定移除。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型存在对象幻觉问题，描述不存在的实体，损害可靠性。现有遗忘方法存在结构性脆弱缺陷，仅实现表面抑制，模型陷入尖锐最小值，导致幻觉在轻量级再学习后灾难性复发。

Method: 提出SARE框架，将遗忘建模为目标最小最大优化问题，使用Targeted-SAM机制在幻觉概念周围显式平坦化损失景观。通过在最坏情况参数扰动下抑制幻觉，确保对权重偏移具有鲁棒性的稳定移除。

Result: 大量实验表明，SARE在遗忘效果上显著优于基线方法，同时保持一般生成质量。关键的是，它能在再学习和参数更新后保持持久的幻觉抑制，验证了几何稳定化的有效性。

Conclusion: SARE通过几何稳定化方法解决了多模态大语言模型对象幻觉遗忘的结构脆弱性问题，实现了对幻觉概念的鲁棒性移除，为可靠的多模态生成提供了新思路。

Abstract: Multimodal LLMs are powerful but prone to object hallucinations, which describe non-existent entities and harm reliability. While recent unlearning methods attempt to mitigate this, we identify a critical flaw: structural fragility. We empirically demonstrate that standard erasure achieves only superficial suppression, trapping the model in sharp minima where hallucinations catastrophically resurge after lightweight relearning. To ensure geometric stability, we propose SARE, which casts unlearning as a targeted min-max optimization problem and uses a Targeted-SAM mechanism to explicitly flatten the loss landscape around hallucinated concepts. By suppressing hallucinations under simulated worst-case parameter perturbations, our framework ensures robust removal stable against weight shifts. Extensive experiments demonstrate that SARE significantly outperforms baselines in erasure efficacy while preserving general generation quality. Crucially, it maintains persistent hallucination suppression against relearning and parameter updates, validating the effectiveness of geometric stabilization.

</details>


### [57] [A Collision-Free Hot-Tier Extension for Engram-Style Conditional Memory: A Controlled Study of Training Dynamics](https://arxiv.org/abs/2601.16531)
*Tao Lin*

Main category: cs.LG

TL;DR: 高频键冲突不是Engram式条件记忆的主要瓶颈，碰撞消除设计未持续改善验证损失，碰撞反而提供有益的正则化效果


<details>
  <summary>Details</summary>
Motivation: 研究高频键冲突是否是Engram式条件记忆的主要瓶颈，探索消除碰撞是否能改善模型性能

Method: 提出Engram-Nine碰撞消除热层扩展，使用最小完美哈希函数映射高频n-gram，保留原始多头哈希查找作为冷层；采用严格等参数设置和路由分层评估方法

Result: 碰撞消除设计未持续改善验证损失；发现训练中的"热-冷优势翻转"现象：碰撞消除配置翻转更早，表明碰撞起正则化作用；门控机制存在不匹配问题

Conclusion: 单纯提高查找精度不能保证更好的训练结果；主要限制可能在于门控信用分配而非索引精度；碰撞引起的噪声可能提供有益的正则化效果

Abstract: We investigate whether high-frequency key collisions are a primary bottleneck in Engram-style conditional memory. To isolate the effect of collisions, we introduce Engram-Nine, a collision-free hot-tier extension that maps the most frequent n-grams through a Minimal Perfect Hash Function (MPHF) while retaining the original multi-head hashed lookup as a cold tier. Under a strictly iso-parameter setup, the collision-free design does not consistently improve validation loss.
  Through route-stratified evaluation (decomposing per-token loss into hot/cold contributions), we uncover a consistent "hot-to-cold advantage flip" during training: hot (high-frequency) positions initially have lower loss, but cold positions eventually surpass them. Crucially, collision-free configurations flip earlier than collision-prone baselines, suggesting that collisions act as implicit regularization. We also identify a gating mismatch: the gate learns to favor hot positions early in training, but this preference persists even after the flip, assigning higher weights to positions with higher loss.
  Our findings suggest that improving lookup precision alone does not guarantee better training outcomes. The dominant limitation may lie in gating credit assignment rather than index accuracy, and collision-induced noise may provide beneficial regularization that should not be naively eliminated.

</details>


### [58] [Understanding and Improving UMAP with Geometric and Topological Priors: The JORC-UMAP Algorithm](https://arxiv.org/abs/2601.16552)
*Xiaobin Li,Run Zhang*

Main category: cs.LG

TL;DR: JORC-UMAP：一种结合Ollivier-Ricci曲率几何先验和Jaccard相似性拓扑先验的UMAP增强方法，通过强化几何瓶颈处的边连接来减少拓扑撕裂和结构塌陷，实现更忠实的数据可视化。


<details>
  <summary>Details</summary>
Motivation: UMAP等非线性降维技术在可视化高维数据时广泛使用，但其局部欧氏距离假设经常无法捕捉内在流形几何，导致拓扑撕裂和结构塌陷。研究发现UMAP对k近邻图的敏感性是主要原因，需要几何感知的增强方法。

Method: 提出JORC-UMAP方法：1) 引入Ollivier-Ricci曲率作为几何先验，强化几何瓶颈处的边连接并减少冗余链接；2) 由于曲率估计对噪声敏感，结合Jaccard相似性作为拓扑先验，确保邻域一致性；3) 该方法能更好地区分真实流形结构和虚假连接。

Result: 在合成和真实数据集上的实验表明，JORC-UMAP比标准UMAP和其他降维方法更有效地减少撕裂和塌陷，通过SVM准确率和三元组保持分数衡量。同时保持了计算效率，提供了更忠实的数据可视化。

Conclusion: JORC-UMAP通过结合几何和拓扑先验，为UMAP提供了几何感知的增强，能够更准确地捕捉数据的内在流形结构，减少可视化中的拓扑失真，为高维数据可视化提供了更可靠的工具。

Abstract: Nonlinear dimensionality reduction techniques, particularly UMAP, are widely used for visualizing high-dimensional data. However, UMAP's local Euclidean distance assumption often fails to capture intrinsic manifold geometry, leading to topological tearing and structural collapse. We identify UMAP's sensitivity to the k-nearest neighbor graph as a key cause. To address this, we introduce Ollivier-Ricci curvature as a geometric prior, reinforcing edges at geometric bottlenecks and reducing redundant links. Since curvature estimation is noise-sensitive, we also incorporate a topological prior using Jaccard similarity to ensure neighborhood consistency. The resulting method, JORC-UMAP, better distinguishes true manifold structure from spurious connections. Experiments on synthetic and real-world datasets show that JORC-UMAP reduces tearing and collapse more effectively than standard UMAP and other DR methods, as measured by SVM accuracy and triplet preservation scores, while maintaining computational efficiency. This work offers a geometry-aware enhancement to UMAP for more faithful data visualization.

</details>


### [59] [Predicting Startup Success Using Large Language Models: A Novel In-Context Learning Approach](https://arxiv.org/abs/2601.16568)
*Abdurahman Maarouf,Alket Bakiaj,Stefan Feuerriegel*

Main category: cs.LG

TL;DR: 提出kNN-ICL框架，利用大语言模型进行上下文学习，仅需少量标注数据即可预测早期初创企业成功，在数据稀缺的VC投资场景中优于传统机器学习方法。


<details>
  <summary>Details</summary>
Motivation: 早期初创企业成功预测面临数据稀缺挑战，传统机器学习方法需要大量标注数据，而VC机构通常只有几十个早期初创企业的信息。需要开发在数据稀缺环境下有效的预测方法。

Method: 提出基于k最近邻的上下文学习框架(kNN-ICL)，利用大语言模型进行预测，无需模型训练。通过相似性选择最相关的历史初创企业作为示例，仅需少量标注数据作为演示示例。

Result: 使用Crunchbase真实数据，kNN-ICL方法在预测准确率上优于监督机器学习基线和普通上下文学习方法。研究发现仅需50个示例即可达到较高的平衡准确率。

Conclusion: 上下文学习可作为VC机构在数据稀缺环境中的决策工具，kNN-ICL框架在早期初创企业成功预测方面表现出色，为数据有限的VC投资决策提供了有效解决方案。

Abstract: Venture capital (VC) investments in early-stage startups that end up being successful can yield high returns. However, predicting early-stage startup success remains challenging due to data scarcity (e.g., many VC firms have information about only a few dozen of early-stage startups and whether they were successful). This limits the effectiveness of traditional machine learning methods that rely on large labeled datasets for model training. To address this challenge, we propose an in-context learning framework for startup success prediction using large language models (LLMs) that requires no model training and leverages only a small set of labeled startups as demonstration examples. Specifically, we propose a novel k-nearest-neighbor-based in-context learning framework, called kNN-ICL, which selects the most relevant past startups as examples based on similarity. Using real-world profiles from Crunchbase, we find that the kNN-ICL approach achieves higher prediction accuracy than supervised machine learning baselines and vanilla in-context learning. Further, we study how performance varies with the number of in-context examples and find that a high balanced accuracy can be achieved with as few as 50 examples. Together, we demonstrate that in-context learning can serve as a decision-making tool for VC firms operating in data-scarce environments.

</details>


### [60] [Dual-Prototype Disentanglement: A Context-Aware Enhancement Framework for Time Series Forecasting](https://arxiv.org/abs/2601.16632)
*Haonan Yang,Jianchao Tang,Zhuo Li*

Main category: cs.LG

TL;DR: DPAD是一种模型无关的辅助框架，通过动态双原型库和上下文感知路由机制实现时间序列模式解耦与自适应增强，提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在时间序列预测中常学习静态的平均化表示，缺乏对复杂交织时间模式的动态解耦和上下文感知能力，导致预测性能受限。

Method: 提出双原型自适应解耦框架(DPAD)：1)构建动态双原型库(DDP)，包含具有强时间先验的常见模式库和动态记忆关键罕见事件的罕见模式库；2)设计双路径上下文感知路由(DPC)机制，从DDP选择性检索上下文特定模式表示来增强输出；3)引入解耦引导损失(DGLoss)确保各原型库专业化且覆盖全面。

Result: 综合实验表明，DPAD能持续提升最先进模型在多样化现实世界基准测试中的预测性能和可靠性。

Conclusion: DPAD作为一种模型无关的辅助方法，通过模式解耦和上下文自适应能力有效解决了时间序列预测中复杂模式交织的问题，为现有模型提供了通用增强方案。

Abstract: Time series forecasting has witnessed significant progress with deep learning. While prevailing approaches enhance forecasting performance by modifying architectures or introducing novel enhancement strategies, they often fail to dynamically disentangle and leverage the complex, intertwined temporal patterns inherent in time series, thus resulting in the learning of static, averaged representations that lack context-aware capabilities. To address this, we propose the Dual-Prototype Adaptive Disentanglement framework (DPAD), a model-agnostic auxiliary method that equips forecasting models with the ability of pattern disentanglement and context-aware adaptation. Specifically, we construct a Dynamic Dual-Prototype bank (DDP), comprising a common pattern bank with strong temporal priors to capture prevailing trend or seasonal patterns, and a rare pattern bank dynamically memorizing critical yet infrequent events, and then an Dual-Path Context-aware routing (DPC) mechanism is proposed to enhance outputs with selectively retrieved context-specific pattern representations from the DDP. Additionally, we introduce a Disentanglement-Guided Loss (DGLoss) to ensure that each prototype bank specializes in its designated role while maintaining comprehensive coverage. Comprehensive experiments demonstrate that DPAD consistently improves forecasting performance and reliability of state-of-the-art models across diverse real-world benchmarks.

</details>


### [61] [Provably Robust Bayesian Counterfactual Explanations under Model Changes](https://arxiv.org/abs/2601.16659)
*Jamie Duell,Xiuyi Fan*

Main category: cs.LG

TL;DR: 提出PSCE方法生成具有概率安全保证的反事实解释，确保在模型更新时保持高预测置信度和低预测方差


<details>
  <summary>Details</summary>
Motivation: 现实世界中机器学习模型频繁更新，现有反事实解释容易失效，需要确保解释在模型变化下的可靠性和鲁棒性

Method: 基于贝叶斯原理的PSCE方法，生成δ-safe（高预测置信度）和ε-robust（低预测方差）的反事实解释，集成不确定性感知约束到优化框架

Result: PSCE在多个数据集上验证有效，相比现有贝叶斯反事实方法，产生更合理、更具区分性且可证明在模型变化下鲁棒的解释

Conclusion: PSCE为反事实解释提供形式化的概率保证，确保在模型更新场景下的可靠性和鲁棒性

Abstract: Counterfactual explanations (CEs) offer interpretable insights into machine learning predictions by answering ``what if?" questions. However, in real-world settings where models are frequently updated, existing counterfactual explanations can quickly become invalid or unreliable. In this paper, we introduce Probabilistically Safe CEs (PSCE), a method for generating counterfactual explanations that are $δ$-safe, to ensure high predictive confidence, and $ε$-robust to ensure low predictive variance. Based on Bayesian principles, PSCE provides formal probabilistic guarantees for CEs under model changes which are adhered to in what we refer to as the $\langle δ, ε\rangle$-set. Uncertainty-aware constraints are integrated into our optimization framework and we validate our method empirically across diverse datasets. We compare our approach against state-of-the-art Bayesian CE methods, where PSCE produces counterfactual explanations that are not only more plausible and discriminative, but also provably robust under model change.

</details>


### [62] [Dynamic Expert-Guided Model Averaging for Causal Discovery](https://arxiv.org/abs/2601.16715)
*Adrick Tench,Thomas Demeester*

Main category: cs.LG

TL;DR: 提出一种利用动态请求专家知识（包括LLM）来集成多种因果发现算法的灵活模型平均方法，在干净和噪声数据上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 因果理解在医疗领域至关重要，但现有因果发现算法众多且缺乏明确最佳选择，同时现实应用常违反算法假设而过度依赖专家知识。集成方法成为自然选择，但需要解决专家知识获取问题。

Method: 提出灵活的模型平均方法，通过动态请求专家知识（包括LLM作为专家）来集成多样化的因果发现算法。该方法结合了最近关于动态请求专家知识和LLM作为专家的研究。

Result: 实验证明该方法在不完美专家（如LLM）的情况下，在干净和噪声数据上均有效。分析了不同专家正确程度的影响，并评估了LLM在临床因果发现中的能力，为实践者提供了有价值的见解。

Conclusion: 该方法为因果发现提供了一种实用的集成解决方案，能够利用包括LLM在内的专家知识来处理现实世界中的复杂场景，特别是在医疗领域具有应用价值。

Abstract: Understanding causal relationships is critical for healthcare. Accurate causal models provide a means to enhance the interpretability of predictive models, and furthermore a basis for counterfactual and interventional reasoning and the estimation of treatment effects. However, would-be practitioners of causal discovery face a dizzying array of algorithms without a clear best choice. This abundance of competitive algorithms makes ensembling a natural choice for practical applications. At the same time, real-world use cases frequently face challenges that violate the assumptions of common causal discovery algorithms, forcing heavy reliance on expert knowledge. Inspired by recent work on dynamically requested expert knowledge and LLMs as experts, we present a flexible model averaging method leveraging dynamically requested expert knowledge to ensemble a diverse array of causal discovery algorithms. Experiments demonstrate the efficacy of our method with imperfect experts such as LLMs on both clean and noisy data. We also analyze the impact of different degrees of expert correctness and assess the capabilities of LLMs for clinical causal discovery, providing valuable insights for practitioners.

</details>


### [63] [Sample-wise Constrained Learning via a Sequential Penalty Approach with Applications in Image Processing](https://arxiv.org/abs/2601.16812)
*Francesca Lanzillotta,Chiara Albisani,Davide Pucci,Daniele Baracchi,Alessandro Piva,Matteo Lapucci*

Main category: cs.LG

TL;DR: 提出一种用于深度学习场景的序列惩罚方法，能够将数据样本处理要求作为严格约束而非任意惩罚项来处理，并在图像处理任务中验证了其实用性。


<details>
  <summary>Details</summary>
Motivation: 在许多学习任务中，对单个数据样本处理的特定要求应该被形式化为底层优化问题的严格约束，而不是通过任意惩罚项来处理。现有方法通常使用惩罚项，但这种方法无法保证约束得到严格满足。

Method: 提出一种序列惩罚方法，通过迭代方式处理约束优化问题。该方法在深度学习场景下设计，能够将约束作为优化问题的严格组成部分，而不是通过惩罚项近似处理。

Result: 该方法在深度学习场景下具有收敛保证，实验结果表明在图像处理任务中该方法确实可行且实用。

Conclusion: 序列惩罚方法能够有效处理深度学习中的约束优化问题，将样本处理要求作为严格约束而非惩罚项，具有理论收敛保证和实际应用价值。

Abstract: In many learning tasks, certain requirements on the processing of individual data samples should arguably be formalized as strict constraints in the underlying optimization problem, rather than by means of arbitrary penalties. We show that, in these scenarios, learning can be carried out exploiting a sequential penalty method that allows to properly deal with constraints. The proposed algorithm is shown to possess convergence guarantees under assumptions that are reasonable in deep learning scenarios. Moreover, the results of experiments on image processing tasks show that the method is indeed viable to be used in practice.

</details>


### [64] [Calibrated Probabilistic Interpolation for GEDI Biomass](https://arxiv.org/abs/2601.16834)
*Robin Young,Srinivasan Keshav*

Main category: cs.LG

TL;DR: ANPs替代传统机器学习方法，通过概率元学习框架实现GEDI LiDAR生物量观测的空间插值，提供校准的不确定性估计，并在跨区域迁移中展示少样本适应能力。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习方法（如随机森林、XGBoost）在处理GEDI稀疏LiDAR观测的空间插值时，将预测视为独立事件，无法适应异质性地形的变化难度，且无法产生校准的预测区间。这些方法混淆了集成方差与偶然不确定性，并忽略了局部空间上下文。

Method: 提出Attentive Neural Processes（ANPs），一种概率元学习框架，通过以下方式改进：1）显式地将预测条件化于局部观测集；2）利用地理空间基础模型嵌入；3）学习灵活的空间协方差函数，使不确定性估计在复杂地形中扩展，在均质区域收缩；4）支持少样本适应，实现跨区域迁移。

Result: 在从热带亚马逊森林到北方和高山生态系统的五个不同生物群落中验证，ANPs在保持竞争性准确度的同时，实现了接近理想的不确定性校准。通过少样本适应，模型在跨区域迁移中仅使用少量本地数据即可恢复大部分性能差距。

Conclusion: ANPs为大陆尺度地球观测提供了可扩展、理论严谨的替代方案，能够产生校准的不确定性估计，并支持有效的跨区域迁移，解决了传统集成方法在异质性地形中的局限性。

Abstract: Reliable wall-to-wall biomass mapping from NASA's GEDI mission requires interpolating sparse LiDAR observations across heterogeneous landscapes. While machine learning approaches like Random Forest and XGBoost are standard for this task, they treat spatial predictions of GEDI observations from multispectral or SAR remote sensing data as independent without adapting to the varying difficulty of heterogeneous landscapes. We demonstrate these approaches generally fail to produce calibrated prediction intervals. We identify that this stems from conflating ensemble variance with aleatoric uncertainty and ignoring local spatial context.
  To resolve this, we introduce Attentive Neural Processes (ANPs), a probabilistic meta-learning framework that explicitly conditions predictions on local observation sets and geospatial foundation model embeddings. Unlike static ensembles, ANPs learn a flexible spatial covariance function, allowing uncertainty estimates to expand in complex landscapes and contract in homogeneous areas. We validate this approach across five distinct biomes ranging from Tropical Amazonian forests to Boreal and Alpine ecosystems, demonstrating that ANPs achieve competitive accuracy while maintaining near-ideal uncertainty calibration. We demonstrate the operational utility of the method through few-shot adaptation, where the model recovers most of the performance gap in cross-region transfer using minimal local data. This work provides a scalable, theoretically rigorous alternative to ensemble variance for continental scale earth observation.

</details>


### [65] [The Art of Being Difficult: Combining Human and AI Strengths to Find Adversarial Instances for Heuristics](https://arxiv.org/abs/2601.16849)
*Henri Nikoleit,Ankit Anand,Anurag Murty Naredla,Heiko Röglin*

Main category: cs.LG

TL;DR: 人类专家与LLM协作改进FunSearch算法输出，在组合优化问题中获得了多项长期未突破的最新下界结果


<details>
  <summary>Details</summary>
Motivation: 探索人类专家与大型语言模型（LLM）协作在理论计算机科学开放问题中的潜力，特别是在组合优化领域，旨在通过改进FunSearch算法的输出来获得标准启发式算法的最优下界

Method: 采用人类-LLM协作方法，聚焦于FunSearch算法输出的精炼。针对组合优化问题，迭代改进FunSearch的输出，生成对抗性实例（在这些实例中标准启发式算法表现不佳）。具体应用于层次k-中值聚类、装箱问题、背包问题以及Lovász汽油问题的推广

Result: 在多个组合优化问题中获得了最新的下界结果：层次k-中值聚类、装箱问题、背包问题以及Lovász汽油问题的推广。其中一些问题已有十余年未取得显著改进，尽管期间有间歇性关注。这些结果打破了长期存在的障碍

Conclusion: 人类专家与LLM的协作在数学和计算机科学研究中具有强大潜力。LLM提供关键初始模式，而人类专业知识对于将这些模式转化为数学严谨且富有洞察力的构造至关重要。这种协作方法能够从基于LLM的进化方法中推断算法洞见，突破长期障碍

Abstract: We demonstrate the power of human-LLM collaboration in tackling open problems in theoretical computer science. Focusing on combinatorial optimization, we refine outputs from the FunSearch algorithm [Romera-Paredes et al., Nature 2023] to derive state-of-the-art lower bounds for standard heuristics. Specifically, we target the generation of adversarial instances where these heuristics perform poorly. By iterating on FunSearch's outputs, we identify improved constructions for hierarchical $k$-median clustering, bin packing, the knapsack problem, and a generalization of Lovász's gasoline problem - some of these have not seen much improvement for over a decade, despite intermittent attention. These results illustrate how expert oversight can effectively extrapolate algorithmic insights from LLM-based evolutionary methods to break long-standing barriers.
  Our findings demonstrate that while LLMs provide critical initial patterns, human expertise is essential for transforming these patterns into mathematically rigorous and insightful constructions. This work highlights that LLMs are a strong collaborative tool in mathematics and computer science research.

</details>


### [66] [FedSGM: A Unified Framework for Constraint Aware, Bidirectionally Compressed, Multi-Step Federated Optimization](https://arxiv.org/abs/2601.16897)
*Antesh Upadhyay,Sang Bin Moon,Abolfazl Hashemi*

Main category: cs.LG

TL;DR: FedSGM是一个统一的联邦约束优化框架，解决了联邦学习中的功能约束、通信瓶颈、本地更新和部分客户端参与四大挑战，采用投影自由、仅原变量的更新方法，并引入双向误差反馈处理压缩噪声。


<details>
  <summary>Details</summary>
Motivation: 联邦学习面临四个主要挑战：1）功能约束（如隐私、公平性要求），2）通信瓶颈（带宽限制），3）本地更新（减少通信轮次），4）部分客户端参与（设备可用性）。现有方法未能统一解决这些挑战，特别是缺乏处理约束的理论基础。

Method: 基于切换梯度方法，FedSGM采用投影自由、仅原变量的更新策略，避免昂贵的对偶变量调整或内部求解器。引入双向误差反馈处理压缩噪声，明确理解压缩噪声与多步本地更新之间的相互作用。还提出了软切换版本以稳定接近可行性边界的更新。

Result: 理论分析表明平均迭代达到规范的$\mathcal{O}(1/\sqrt{T})$收敛速率，并提供了高概率界限，将优化进展与部分参与引起的采样噪声解耦。实验验证了FedSGM在Neyman-Pearson分类和约束马尔可夫决策过程任务上的有效性。

Conclusion: FedSGM是第一个统一功能约束、压缩、多步本地更新和部分客户端参与的框架，为约束联邦学习建立了理论基础。该方法在理论和实验上都表现出色，为实际联邦学习应用提供了实用的解决方案。

Abstract: We introduce FedSGM, a unified framework for federated constrained optimization that addresses four major challenges in federated learning (FL): functional constraints, communication bottlenecks, local updates, and partial client participation. Building on the switching gradient method, FedSGM provides projection-free, primal-only updates, avoiding expensive dual-variable tuning or inner solvers. To handle communication limits, FedSGM incorporates bi-directional error feedback, correcting the bias introduced by compression while explicitly understanding the interaction between compression noise and multi-step local updates. We derive convergence guarantees showing that the averaged iterate achieves the canonical $\boldsymbol{\mathcal{O}}(1/\sqrt{T})$ rate, with additional high-probability bounds that decouple optimization progress from sampling noise due to partial participation. Additionally, we introduce a soft switching version of FedSGM to stabilize updates near the feasibility boundary. To our knowledge, FedSGM is the first framework to unify functional constraints, compression, multiple local updates, and partial client participation, establishing a theoretically grounded foundation for constrained federated learning. Finally, we validate the theoretical guarantees of FedSGM via experimentation on Neyman-Pearson classification and constrained Markov decision process (CMDP) tasks.

</details>


### [67] [Embedding -based Crop Type Classification in the Groundnut Basin of Senegal](https://arxiv.org/abs/2601.16900)
*Madeline C. Lisaius,Srinivasan Keshav,Andrew Blake,Clement Atzberger*

Main category: cs.LG

TL;DR: TESSERA地理空间基础模型嵌入方法在小农户作物类型制图中表现最佳，满足性能、合理性、可迁移性和可访问性四大标准，在塞内加尔花生盆地应用中比次优方法精度高28%。


<details>
  <summary>Details</summary>
Motivation: 现有卫星遥感作物类型制图方法大多不适合小农户条件，需要开发适用于小农户区域的实用嵌入方法，满足性能、合理性、可迁移性和可访问性四大标准。

Method: 建立四大选择标准（性能、合理性、可迁移性和可访问性），评估TESSERA和AlphaEarth地理空间基础模型嵌入方法，与现有基线方法在塞内加尔花生盆地地区进行比较。

Result: TESSERA嵌入方法在作物类型制图中表现最佳，满足所有选择标准，在时间迁移示例中比次优方法精度高28%，表明其在塞内加尔作物分类任务中的有效性。

Conclusion: TESSERA嵌入方法是小农户区域作物类型制图的有效方法，特别适合塞内加尔等地的应用，为粮食安全、生计支持和气候变化减缓提供实用工具。

Abstract: Crop type maps from satellite remote sensing are important tools for food security, local livelihood support and climate change mitigation in smallholder regions of the world, but most satellite-based methods are not well suited to smallholder conditions. To address this gap, we establish a four-part criteria for a useful embedding-based approach consisting of 1) performance, 2) plausibility, 3) transferability and 4) accessibility and evaluate geospatial foundation model (FM) embeddings -based approaches using TESSERA and AlphaEarth against current baseline methods for a region in the groundnut basin of Senegal. We find that the TESSERA -based approach to land cover and crop type mapping fulfills the selection criteria best, and in one temporal transfer example shows 28% higher accuracy compared to the next best method. These results indicate that TESSERA embeddings are an effective approach for crop type classification and mapping tasks in Senegal.

</details>


### [68] [GRIP: Algorithm-Agnostic Machine Unlearning for Mixture-of-Experts via Geometric Router Constraints](https://arxiv.org/abs/2601.16905)
*Andy Zhu,Rongzhe Wei,Yupu Gu,Pan Li*

Main category: cs.LG

TL;DR: GRIP框架通过几何约束保护MoE模型的路由稳定性，防止传统遗忘方法利用路由漏洞进行表面遗忘，确保知识从专家参数中真正擦除


<details>
  <summary>Details</summary>
Motivation: 现有机器遗忘方法无法有效应用于MoE架构，它们会利用MoE的路由漏洞——通过操纵路由器将查询从知识专家处重定向，而不是真正擦除知识，导致模型效用损失和表面遗忘

Method: 提出几何路由不变性保护（GRIP）框架，核心是几何约束：将路由器梯度更新投影到专家特定的零空间中。这解耦了路由稳定性与参数刚性，使离散专家选择保持稳定，而连续路由器参数在零空间内保持可塑性，允许模型进行必要的内部重构以满足遗忘目标

Result: 在大规模MoE模型上的广泛实验表明，GRIP适配器消除了专家选择偏移（实现超过95%的路由稳定性），同时保持了所有测试遗忘方法的效用。通过防止现有算法利用MoE模型的路由漏洞，GRIP将现有遗忘研究从密集架构适配到MoE

Conclusion: GRIP框架解决了MoE架构中机器遗忘的关键挑战，通过几何约束确保知识从专家参数中真正擦除而非通过路由操纵进行表面遗忘，为MoE模型的安全遗忘提供了有效解决方案

Abstract: Machine unlearning (MU) for large language models has become critical for AI safety, yet existing methods fail to generalize to Mixture-of-Experts (MoE) architectures. We identify that traditional unlearning methods exploit MoE's architectural vulnerability: they manipulate routers to redirect queries away from knowledgeable experts rather than erasing knowledge, causing a loss of model utility and superficial forgetting. We propose Geometric Routing Invariance Preservation (GRIP), an algorithm-agnostic framework for unlearning for MoE. Our core contribution is a geometric constraint, implemented by projecting router gradient updates into an expert-specific null-space. Crucially, this decouples routing stability from parameter rigidity: while discrete expert selections remain stable for retained knowledge, the continuous router parameters remain plastic within the null space, allowing the model to undergo necessary internal reconfiguration to satisfy unlearning objectives. This forces the unlearning optimization to erase knowledge directly from expert parameters rather than exploiting the superficial router manipulation shortcut. GRIP functions as an adapter, constraining router parameter updates without modifying the underlying unlearning algorithm. Extensive experiments on large-scale MoE models demonstrate that our adapter eliminates expert selection shift (achieving over 95% routing stability) across all tested unlearning methods while preserving their utility. By preventing existing algorithms from exploiting MoE model's router vulnerability, GRIP adapts existing unlearning research from dense architectures to MoEs.

</details>


### [69] [The Trajectory Alignment Coefficient in Two Acts: From Reward Tuning to Reward Learning](https://arxiv.org/abs/2601.16906)
*Calarina Muslimani,Yunshu Du,Kenta Kawamoto,Kaushik Subramanian,Peter Stone,Peter Wurman*

Main category: cs.LG

TL;DR: TAC作为奖励函数评估指标，既能指导人工调优，又能作为可微损失函数直接学习奖励模型


<details>
  <summary>Details</summary>
Motivation: 强化学习中奖励函数设计耗时且容易出错，需要更好的方法来支持实践者设计合适的奖励权重，并直接学习符合人类偏好的奖励模型

Method: 1) 使用轨迹对齐系数(TAC)评估奖励函数与专家偏好的匹配程度；2) 在Lunar Lander中进行人类实验，比较有/无TAC指导的奖励调优效果；3) 提出Soft-TAC作为TAC的可微近似，用于从人类偏好数据中训练奖励模型；4) 在Gran Turismo 7中验证Soft-TAC训练效果

Result: 1) TAC指导下的奖励调优产生性能更好的奖励函数，且认知负荷更低；2) 手动奖励设计即使有TAC仍很费力；3) Soft-TAC训练的奖励模型能捕捉偏好特定目标，产生比交叉熵损失更独特的行为策略

Conclusion: TAC既能作为指导奖励调优的实用工具，也能作为复杂领域中奖励学习的目标函数，为解决奖励函数设计问题提供了双重方案

Abstract: The success of reinforcement learning (RL) is fundamentally tied to having a reward function that accurately reflects the task objective. Yet, designing reward functions is notoriously time-consuming and prone to misspecification. To address this issue, our first goal is to understand how to support RL practitioners in specifying appropriate weights for a reward function. We leverage the Trajectory Alignment Coefficient (TAC), a metric that evaluates how closely a reward function's induced preferences match those of a domain expert. To evaluate whether TAC provides effective support in practice, we conducted a human-subject study in which RL practitioners tuned reward weights for Lunar Lander. We found that providing TAC during reward tuning led participants to produce more performant reward functions and report lower cognitive workload relative to standard tuning without TAC. However, the study also underscored that manual reward design, even with TAC, remains labor-intensive. This limitation motivated our second goal: to learn a reward model that maximizes TAC directly. Specifically, we propose Soft-TAC, a differentiable approximation of TAC that can be used as a loss function to train reward models from human preference data. Validated in the racing simulator Gran Turismo 7, reward models trained using Soft-TAC successfully captured preference-specific objectives, resulting in policies with qualitatively more distinct behaviors than models trained with standard Cross-Entropy loss. This work demonstrates that TAC can serve as both a practical tool for guiding reward tuning and a reward learning objective in complex domains.

</details>


### [70] [Calibrated Similarity for Reliable Geometric Analysis of Embedding Spaces](https://arxiv.org/abs/2601.16907)
*Nicolas Tacheny*

Main category: cs.LG

TL;DR: 提出使用保序回归进行单调校准，解决预训练嵌入空间中余弦相似度的各向异性导致的绝对数值系统误校准问题，同时保持排序相关性


<details>
  <summary>Details</summary>
Motivation: 预训练嵌入空间中的原始余弦相似度虽然与人类判断有强排序相关性，但各向异性导致绝对数值系统误校准：无论实际语义相关性如何，得分都集中在狭窄的高相似度区间，限制了其作为定量度量的可解释性

Method: 使用基于人类相似度判断训练的保序回归，构建单调变换实现近乎完美的校准，同时保持排序相关性和局部稳定性（在七种扰动类型中达到98%）

Result: 保序校准作为保序重参数化，证明所有基于顺序的构造（角度排序、最近邻、阈值图和基于分位数的决策）在此变换下保持不变，实现了绝对数值的校准而不改变排序属性

Conclusion: 该方法不是要替代余弦相似度，而是通过单调校准恢复其绝对数值的可解释性，而不改变其排序属性，为基于嵌入的相似度度量提供了更好的定量解释

Abstract: While raw cosine similarity in pretrained embedding spaces exhibits strong rank correlation with human judgments, anisotropy induces systematic miscalibration of absolute values: scores concentrate in a narrow high-similarity band regardless of actual semantic relatedness, limiting interpretability as a quantitative measure. Prior work addresses this by modifying the embedding space (whitening, contrastive fine tuning), but such transformations alter geometric structure and require recomputing all embeddings.
  Using isotonic regression trained on human similarity judgments, we construct a monotonic transformation that achieves near-perfect calibration while preserving rank correlation and local stability(98% across seven perturbation types). Our contribution is not to replace cosine similarity, but to restore interpretability of its absolute values through monotone calibration, without altering its ranking properties.
  We characterize isotonic calibration as an order-preserving reparameterization and prove that all order-based constructions (angular ordering, nearest neighbors, threshold graphs and quantile-based decisions) are invariant under this transformation.

</details>


### [71] [Group-realizable multi-group learning by minimizing empirical risk](https://arxiv.org/abs/2601.16922)
*Navid Ardeshir,Samuel Deng,Daniel Hsu,Jingwen Liu*

Main category: cs.LG

TL;DR: 多组学习的样本复杂度在组可实现设置下比不可知设置有所改善，即使组族是无限的（只要具有有限VC维）。改进的样本复杂度通过经验风险最小化实现，但该方法计算不可行，因此提出了基于非适当学习的替代方法。


<details>
  <summary>Details</summary>
Motivation: 研究多组学习在组可实现设置下的样本复杂度优势，探索在组族无限但具有有限VC维的情况下，如何获得比不可知设置更好的样本复杂度。

Method: 1. 对组可实现概念类进行经验风险最小化（ERM），即使该类本身可能具有无限VC维；2. 发现该方法计算不可行；3. 提出基于非适当学习的替代方法。

Result: 在组可实现设置下，多组学习的样本复杂度优于不可知设置，即使组族是无限的（只要具有有限VC维）。然而，通过ERM实现这一改进的方法被证明是计算不可行的。

Conclusion: 多组学习在组可实现设置下具有样本复杂度优势，但实现这一优势的适当学习方法计算不可行，需要采用非适当学习作为可行的替代方案。

Abstract: The sample complexity of multi-group learning is shown to improve in the group-realizable setting over the agnostic setting, even when the family of groups is infinite so long as it has finite VC dimension. The improved sample complexity is obtained by empirical risk minimization over the class of group-realizable concepts, which itself could have infinite VC dimension. Implementing this approach is also shown to be computationally intractable, and an alternative approach is suggested based on improper learning.

</details>


### [72] [3D Molecule Generation from Rigid Motifs via SE(3) Flows](https://arxiv.org/abs/2601.16955)
*Roman Poletukhin,Marcel Kollovieh,Eike Eberhard,Stephan Günnemann*

Main category: cs.LG

TL;DR: 该论文提出了一种基于刚性基元的三维分子生成方法，通过将分子表示为刚性基元集合，利用SE(3)-等变生成模型进行从头分子生成，相比传统原子级方法实现了更快的生成速度和更紧凑的表示。


<details>
  <summary>Details</summary>
Motivation: 现有三维分子生成方法通常在原子级别进行操作，而分子图生成技术常考虑片段作为结构单元。受蛋白质结构生成中框架方法的启发，作者希望将片段化思想扩展到三维分子生成，将分子视为刚性基元集合，以提高生成效率和表示紧凑性。

Method: 将分子表示为刚性基元（刚性体基序）集合，采用SE(3)-等变生成模型进行三维分子生成。该方法基于刚性基元表示而非原子级表示，利用等变性质保持三维空间对称性，实现从刚性基元到完整三维分子的生成。

Result: 在多个基准测试中取得与最先进方法相当或更优的结果，在GEOM-Drugs上原子稳定性超过现有方法。相比标准原子级方法，生成步骤减少2-10倍，分子表示压缩3.5倍。

Conclusion: 基于刚性基元的三维分子生成方法在保持生成质量的同时，显著提高了生成效率和表示紧凑性，为分子设计提供了更高效的框架。

Abstract: Three-dimensional molecular structure generation is typically performed at the level of individual atoms, yet molecular graph generation techniques often consider fragments as their structural units. Building on the advances in frame-based protein structure generation, we extend these fragmentation ideas to 3D, treating general molecules as sets of rigid-body motifs. Utilising this representation, we employ SE(3)-equivariant generative modelling for de novo 3D molecule generation from rigid motifs. In our evaluations, we observe comparable or superior results to state-of-the-art across benchmarks, surpassing it in atom stability on GEOM-Drugs, while yielding a 2x to 10x reduction in generation steps and offering 3.5x compression in molecular representations compared to the standard atom-based methods.

</details>


### [73] [Auto-Regressive Masked Diffusion Models](https://arxiv.org/abs/2601.16971)
*Mahdi Karami,Ali Ghodsi*

Main category: cs.LG

TL;DR: ARMD模型通过将掩码扩散过程重构为块级因果模型，统一了自回归模型的训练效率和扩散模型的并行生成能力，在语言建模基准上实现了最先进性能


<details>
  <summary>Details</summary>
Motivation: 掩码扩散模型（MDMs）在语言建模中存在性能差距，需要更多训练迭代。作者旨在弥合自回归模型（ARMs）和扩散模型之间的差距，结合两者的优势

Method: 将掩码扩散过程重构为块级因果模型，设计严格因果、置换等变架构，在单次前向传递中计算所有条件概率。采用渐进置换训练方案，支持跨步并行生成策略

Result: ARMD在标准语言建模基准上实现了最先进性能，超越了现有扩散基线，同时需要显著更少的训练步骤。为并行文本生成建立了新基准

Conclusion: ARMD有效弥合了并行和顺序解码之间的性能差距，统一了自回归模型的训练效率和扩散模型的并行生成能力

Abstract: Masked diffusion models (MDMs) have emerged as a promising approach for language modeling, yet they face a performance gap compared to autoregressive models (ARMs) and require more training iterations. In this work, we present the Auto-Regressive Masked Diffusion (ARMD) model, an architecture designed to close this gap by unifying the training efficiency of autoregressive models with the parallel generation capabilities of diffusion-based models. Our key insight is to reframe the masked diffusion process as a block-wise causal model. This perspective allows us to design a strictly causal, permutation-equivariant architecture that computes all conditional probabilities across multiple denoising steps in a single, parallel forward pass. The resulting architecture supports efficient, autoregressive-style decoding and a progressive permutation training scheme, allowing the model to learn both canonical left-to-right and random token orderings. Leveraging this flexibility, we introduce a novel strided parallel generation strategy that accelerates inference by generating tokens in parallel streams while maintaining global coherence. Empirical results demonstrate that ARMD achieves state-of-the-art performance on standard language modeling benchmarks, outperforming established diffusion baselines while requiring significantly fewer training steps. Furthermore, it establishes a new benchmark for parallel text generation, effectively bridging the performance gap between parallel and sequential decoding.

</details>


<div id='Ziniu Wu'></div>

# Ziniu Wu [[Back]](#toc)

### [74] [Towards Privacy-Preserving Top-k Location-Based Dominating Queries over Encrypted Data](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11347495/&hl=zh-CN&sa=X&d=13932546995748641347&ei=n4x2aZPvNNaOieoPnNOJuQQ&scisig=AHkA5jRPXi6O8uZVssFfBgY_EwZx&oi=scholaralrt&hist=i6heNjgAAAAJ:8133205940682390297:AHkA5jQfTAaKkXi3kBQuJYouRHpx&html=&pos=1&folt=rel)
*Z Wang,X Ding,W Song,P Zhou,L Chen,Y Tian…*

Main category: Ziniu Wu

TL;DR: 云计算的成本效益驱动中小企业迁移数据到云平台，但隐私担忧导致数据加密，这给数据分析和处理带来了挑战。


<details>
  <summary>Details</summary>
Motivation: 随着云计算基础设施的增长，其成本效益模式正推动中小企业将数据和服务迁移到云平台。然而，由于隐私担忧，数据在迁移前需要加密，这给云环境中的数据分析和处理带来了挑战。

Method: 论文可能提出在加密数据上进行计算的方法或协议，如安全多方计算、同态加密或可信执行环境等技术，以实现在保护隐私的同时进行数据分析。

Result: 预期结果是开发出能够在加密数据上执行计算操作的系统或框架，在保证数据隐私的同时，实现与明文数据相似的分析功能。

Conclusion: 需要开发新的隐私保护计算技术，以平衡云计算的经济效益与数据隐私保护需求，使中小企业能够安全地利用云服务。

Abstract: With the growth of cloud computing infrastructure, its cost-efficient paradigm is driving a growing wave of small and medium-sized enterprises to migrate data and services to cloud based platforms. However, due to privacy concerns, data encryption prior to …

</details>
