<div id=toc></div>

# Table of Contents

- [Google Scholar](#Google Scholar) [Total: 75]
- [Carsten Binnig](#Carsten Binnig) [Total: 23]
- [您的个人学术档案](#您的个人学术档案) [Total: 1]
- [Matei Zaharia](#Matei Zaharia) [Total: 69]
- [Rong Zhu](#Rong Zhu) [Total: 6]
- [Thomas Neumann](#Thomas Neumann) [Total: 1]
- [Alekh Jindal](#Alekh Jindal) [Total: 17]
- [Xuanhe Zhou](#Xuanhe Zhou) [Total: 105]
- [Ziniu Wu](#Ziniu Wu) [Total: 8]
- [Ion Stoica](#Ion Stoica) [Total: 6]
- [Zongheng Yang](#Zongheng Yang) [Total: 49]
- [Bin CUI](#Bin CUI) [Total: 3]
- [Surajit Chaudhuri](#Surajit Chaudhuri) [Total: 41]
- [Feifei Li](#Feifei Li) [Total: 1]


<div id='Google Scholar'></div>

# Google Scholar [[Back]](#toc)

### [1] [Topological Data Analysis for Explainable and Fair AI: A Literature Review with Applications and Case Studies](https://scholar.google.com/scholar_url?url=https://www.techrxiv.org/doi/pdf/10.36227/techrxiv.176127186.61834058&hl=en&sa=X&d=2120912963646142901&ei=hoMGac_gK6PH6rQP48qQiAk&scisig=ABGrvjJqigJnzWjS5LH2MwHSuMt_&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=0&folt=cit)
*A Patel*

Main category: Google Scholar

TL;DR: 这篇综述论文探讨了如何将拓扑数据分析（TDA）应用于可解释人工智能（XAI），通过代数不变量提供数据表示的多尺度全局视图，补充传统XAI方法。


<details>
  <summary>Details</summary>
Motivation: 当前大多数XAI方法主要提供局部或特征级别的归因解释，缺乏对复杂模型的全局、多尺度理解。拓扑数据分析能够通过代数不变量（连通分量、环、空洞）提供数据表示的形状信息，这为XAI提供了新的解释视角。

Method: 论文采用综述研究方法，系统整合了拓扑数据分析在可解释AI中的应用定义、方法和工具。重点介绍了持久性图、持久性景观和持久性图像等稳定拓扑摘要技术，这些技术能够捕捉数据表示的多尺度形状特征。

Result: 综述表明，TDA提供的全局拓扑视角能够有效补充传统XAI工具包，通过代数不变量揭示数据表示的多尺度结构特征，为理解复杂模型的行为提供了新的解释维度。

Conclusion: 拓扑数据分析为可解释人工智能提供了有价值的补充方法，通过多尺度拓扑特征增强了模型解释的深度和广度，将局部特征归因与全局形状理解相结合。

Abstract: Explainable AI (XAI) seeks human-interpretable accounts of complex models. While most methods provide local or feature-level attributions, topological data analysis (TDA) offers a global, multi-scale view of data and representations via algebraic invariants (connected components, loops, voids). Through stable summaries such as persistence diagrams, landscapes, and images, TDA captures shape information that complements standard XAI toolkits. This review consolidates definitions, methods …

</details>


### [2] [Homomorphic Encryption for Privacy-Preserving SQL Query Processing in Financial Databases](https://scholar.google.com/scholar_url?url=https://ijetcsit.org/index.php/ijetcsit/article/view/421&hl=en&sa=X&d=890006921131531964&ei=iIMGabOIAfXSieoP5dXGqA0&scisig=ABGrvjJd6Ephau3t5ZJc5DrZVySx&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ABGrvjJkn-FcYY8t5hAtGXsL8UoX&html=&pos=0&folt=rel)
*SVK Gummadi*

Main category: Google Scholar

TL;DR: 提出基于同态加密的SQL查询框架，可在加密金融数据上直接执行SQL操作，保护数据机密性


<details>
  <summary>Details</summary>
Motivation: 金融数据安全与隐私保护需求日益增长，传统加密方案无法支持在加密数据上直接执行SQL查询，需要在安全性和功能性之间权衡

Method: 开发基于同态加密的新型框架，支持在加密数据上直接执行SQL操作，包括聚合、比较等核心功能，保持数据加密状态下的可计算性

Result: 实现了在加密金融数据上执行SQL查询的能力，在保持数据机密性的同时支持必要的SQL操作，平衡了安全性与功能性

Conclusion: 该框架为金融数据安全处理提供了可行方案，通过同态加密技术实现了加密数据上的SQL查询，为金融隐私保护开辟了新途径

Abstract: In this paper, we introduce a novel framework for processing SQL queries directly over encrypted financial data using homomorphic encryption (HE). Our solution preserves data confidentiality without sacrificing essential SQL operations, including …

</details>


### [3] [AQORA: A Learned Adaptive Query Optimizer for Spark SQL](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.10580&hl=en&sa=X&d=9411351542432758349&ei=LnEIadD6FoS6ieoP-NOQoQw&scisig=ABGrvjKhOI2x0wE6EMAPE8Ub0DDF&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ABGrvjJkn-FcYY8t5hAtGXsL8UoX&html=&pos=0&folt=rel)
*J He,Y Cui,C Li,J Jiang,Y Hou,H Chen*

Main category: Google Scholar

TL;DR: 该论文综述了学习查询优化（LQO）和自适应查询处理（AQP）两种主要方法，分析了各自的优缺点，并提出将两者结合的混合方法以克服各自局限性。


<details>
  <summary>Details</summary>
Motivation: 传统查询优化器存在静态优化、无法适应运行时变化的局限性。LQO和AQP作为两种改进方向各有优缺点，需要探索结合两者的方法以获得更好的查询性能。

Method: 论文通过系统分析LQO和AQP的优缺点，提出混合方法框架。LQO利用预训练模型在查询执行前优化计划，AQP在运行时根据实际数据调整执行策略。混合方法结合两者的优势，在静态优化基础上增加动态适应性。

Result: 分析表明LQO在静态优化方面表现良好但缺乏适应性，AQP能应对运行时变化但可能增加开销。混合方法理论上能结合两者优势，在复杂查询场景中提供更优性能。

Conclusion: LQO和AQP各有适用场景，未来研究方向应聚焦于两者的有效结合，开发既能利用历史数据学习优化，又能适应运行时变化的混合查询优化系统。

Abstract: Recent studies have identified two main approaches to improve query optimization: learned query optimization (LQO), which generates or selects better query plans before execution based on models trained in advance, and adaptive query …

</details>


### [4] [DGAI: Decoupled On-Disk Graph-Based ANN Index for Efficient Updates and Queries](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.25401&hl=en&sa=X&d=2890956920168801160&ei=LnEIadD6FoS6ieoP-NOQoQw&scisig=ABGrvjIVDv3N0QOpljk9d-hb0Q5s&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ABGrvjJkn-FcYY8t5hAtGXsL8UoX&html=&pos=2&folt=rel)
*J Lou,Q Yu,S Gong,S Yu,Y Zhang,G Yu*

Main category: Google Scholar

TL;DR: 传统耦合存储方法将向量存储在索引中，导致存储效率低下，本文提出解耦存储方案


<details>
  <summary>Details</summary>
Motivation: 基于磁盘的图索引在大规模高维向量近似最近邻搜索中广泛应用，但传统耦合存储方法将向量存储在索引内部，导致存储效率低下、更新困难等问题

Method: 提出解耦存储方案，将索引结构与向量数据分离存储，优化存储布局和访问模式

Result: 解耦存储方案显著提升存储效率，减少I/O开销，提高查询性能，同时支持更灵活的更新操作

Conclusion: 解耦存储是解决传统图索引存储效率问题的有效方案，为大规模向量搜索系统提供更优的存储架构

Abstract: On-disk graph-based indexes are widely used in approximate nearest neighbor (ANN) search systems for large-scale, high-dimensional vectors. However, traditional coupled storage methods, which store vectors within the index, are inefficient for …

</details>


### [5] [Neuro-Symbolic Adaptive Query Processing over Knowledge Graphs](https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-032-09527-5_14&hl=en&sa=X&d=12222521029074495660&ei=LnEIadD6FoS6ieoP-NOQoQw&scisig=ABGrvjJfUaKf3u3m0j4jzEyAmTPq&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ABGrvjJkn-FcYY8t5hAtGXsL8UoX&html=&pos=3&folt=rel)
*C Qin,M Acosta*

Main category: Google Scholar

TL;DR: 自适应查询处理(AQP)通过基于实际执行条件动态调整查询计划，在动态查询环境（如Web知识图谱）中证明有效，其中eddy技术是关键方法


<details>
  <summary>Details</summary>
Motivation: 传统查询处理在静态环境中有效，但在动态查询环境（如Web知识图谱）中面临挑战，需要能够适应运行时条件的查询处理技术

Method: 使用自适应查询处理(AQP)技术，特别是eddy方法，通过运行时监控执行条件并动态调整查询计划

Result: AQP在动态查询环境中被证明有效，能够适应变化的执行条件并优化查询性能

Conclusion: 自适应查询处理是处理动态查询环境（如知识图谱）的有效方法，eddy技术在其中发挥关键作用

Abstract: In adaptive query processing (AQP), the query plan is adjusted based on actual execution conditions. AQP has proven effective in dynamic querying environments, such as knowledge graphs (KGs) on the web. The technique known as eddies …

</details>


### [6] [The German Commons-154 Billion Tokens of Openly Licensed Text for German Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.13996&hl=en&sa=X&d=17175197941039518473&ei=LnEIadD6FoS6ieoP-NOQoQw&scisig=ABGrvjK6_y9biDr-ex5t3shW3VDJ&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ABGrvjJkn-FcYY8t5hAtGXsL8UoX&html=&pos=4&folt=rel)
*L Gienapp,C Schröder,S Schweter,C Akiki,F Schlatt…*

Main category: Google Scholar

TL;DR: 论文指出大语言模型开发依赖大规模训练语料，但多数语料许可状态不明确，限制了真正开放模型的发展，非英语语言问题更严重。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型训练语料许可状态不明确的问题，特别是非英语语言语料，以促进真正开放模型的发展。

Method: 论文可能涉及构建或分析明确许可状态的大规模多语言训练语料库，采用法律合规的数据收集和处理方法。

Result: 可能创建了具有明确许可状态的多语言语料库，为开放模型开发提供了法律合规的基础设施。

Conclusion: 明确许可状态的训练语料对于开发真正开放的大语言模型至关重要，特别是在非英语语言领域需要更多关注和资源投入。

Abstract: Large language model development relies on large-scale training corpora, yet most contain data of unclear licensing status, limiting the development of truly open models. This problem is exacerbated for non-English languages, where openly …

</details>


### [7] [An unsupervised pipeline for class-agnostic object detection using self-supervised vision transformers and kolmogorov–arnold networks](https://scholar.google.com/scholar_url?url=https://digital.car.chula.ac.th/cgi/viewcontent.cgi%3Farticle%3D75058%26context%3Dchulaetd&hl=en&sa=X&d=6218800879389016472&ei=LXEIaeO1A8eB6rQP4ZrcmAM&scisig=ABGrvjJx_Jjt5bbfr0P4p-4YYwPZ&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=1&folt=cit)
*Y Otsuka*

Main category: Google Scholar

TL;DR: 提出一个完全无监督的四阶段流程，自动生成伪边界框，无需人工标注数据


<details>
  <summary>Details</summary>
Motivation: 当前实例分割的训练数据生成依赖人工标注边界框，成本高且耗时，需要自动化解决方案

Method: 四阶段无监督流程：1) 背景处理，2) 对象检测，3) 边界框生成，4) 伪标签生成，无需人工标注数据

Result: 能够自动生成高质量的伪边界框，显著降低实例分割训练数据的获取成本

Conclusion: 提出的无监督方法有效解决了实例分割训练数据标注的成本问题，为计算机视觉应用提供了实用的自动化解决方案

Abstract: Nowadays, object bounding boxes can help create training data for instance segmentation, which is essential for many computer vision applications. However, generating these bounding boxes still relies heavily on manual annotation, making the process costly and time-consuming. To address this, we propose a fully unsupervised four-stage pipeline that automatically generates pseudo-bounding boxes without any human-labeled data. The pipeline includes (1) Background …

</details>


### [8] [Advanced Filter Structure Handbook: From Design to Optimization](https://scholar.google.com/scholar_url?url=https://books.google.com/books%3Fhl%3Den%26lr%3Dlang_en%26id%3DNFKTEQAAQBAJ%26oi%3Dfnd%26pg%3DPP5%26ots%3DfdZOEB71iS%26sig%3D3MdtQeEOCYKqN1p2yz5JMBPSS9Q&hl=en&sa=X&d=12875827045779352278&ei=LXEIaeO1A8eB6rQP4ZrcmAM&scisig=ABGrvjJerEMRnuZkcEhELbSZP3UR&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=2&folt=cit)
*H Dai,M Li,G Chen*

Main category: Google Scholar

TL;DR: 一本关于高级过滤器结构从设计到优化的综合手册，涵盖从传统Bloom过滤器到Ribbon、Bamboo、SNARF等前沿技术的实现指南


<details>
  <summary>Details</summary>
Motivation: 随着数据呈指数级增长，高效过滤技术对性能和资源管理变得日益关键，需要系统性的指导来理解和实现先进的数据过滤器

Method: 提供从传统到前沿过滤器结构的全面指南，包括Bloom过滤器、Ribbon过滤器、Bamboo过滤器、SNARF等技术的设计原理和实现方法

Result: 创建了一个全面的资源手册，帮助数据管理专业人员理解和应用各种高级过滤器结构，从基础概念到优化技巧

Conclusion: 本书为处理大规模数据集的专业人员提供了从设计到优化的完整过滤器结构知识体系，是数据管理和处理领域的重要参考资源

Abstract: Advanced Filter Structure Handbook: From Design to Optimization is an essential resource for anyone involved in managing and processing large datasets. As data grows exponentially, efficient filtering techniques become increasingly critical to performance and resource management. This book provides a comprehensive guide to understanding and implementing advanced data filters, from traditional Bloom filters to cutting-edge innovations like Ribbon Filter, Bamboo Filter, and SNARF …

</details>


### [9] [Aggregation Hides Out-of-Distribution Generalization Failures from Spurious Correlations](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.24884&hl=en&sa=X&d=12905103792643290982&ei=LXEIaeO1A8eB6rQP4ZrcmAM&scisig=ABGrvjJq9TWaJm4rINwvAERuCB1C&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=4&folt=cit)
*O Salaudeen,H Zhang,K Alhamoud,S Beery…*

Main category: Google Scholar

TL;DR: 研究发现ID-OOD准确率正相关常是异质OOD样本聚合的假象，提出OODSelect方法识别有害的OOD子集，揭示实际存在更多伪相关性问题


<details>
  <summary>Details</summary>
Motivation: 现有OOD泛化基准中ID与OOD准确率的强正相关常被解释为伪相关性在实践中罕见，但作者认为这种模式可能是异质OOD样本聚合导致的假象，需要更精细的分析方法

Method: 提出OODSelect方法，使用基于梯度的技术识别对模型性能有害的OOD子集，通过分析这些子集揭示伪相关性的真实存在

Result: 应用OODSelect发现许多基准中存在显著的有害OOD子集，表明ID-OOD正相关模式常是聚合假象，实际伪相关性问题比表面更严重

Conclusion: ID-OOD准确率正相关不能简单推断伪相关性罕见，需要更细致的OOD样本分析，OODSelect方法有助于揭示隐藏的泛化问题

Abstract: Benchmarks for out-of-distribution (OOD) generalization frequently show a strong positive correlation between in-distribution (ID) and OOD accuracy across models, termed" accuracy-on-the-line." This pattern is often taken to imply that spurious correlations-correlations that improve ID but reduce OOD performance-are rare in practice. We find that this positive correlation is often an artifact of aggregating heterogeneous OOD examples. Using a simple gradient-based method, OODSelect …

</details>


### [10] [A Domain-Independent Approach for Semantic Table Interpretation](https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-032-09527-5_13&hl=en&sa=X&d=13332936756601625675&ei=LXEIaeO1A8eB6rQP4ZrcmAM&scisig=ABGrvjLOoJ-yVDF3KFWphX7NoRqN&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=6&folt=cit)
*B Vu,CA Knoblock,F Lin*

Main category: Google Scholar

TL;DR: 该论文提出了一种无需训练数据或重叠数据的表格语义结构理解方法，通过利用本体结构来预测列的类型和关系。


<details>
  <summary>Details</summary>
Motivation: 现有表格语义结构理解方法要么需要训练数据，要么依赖表格数据与知识图谱的重叠部分，无法应用于新领域或没有重叠数据的情况。

Method: 提出了一种利用目标本体结构的方法，通过分析本体中的类和谓词关系来预测表格列的类型和列间关系，不依赖训练数据或数据重叠。

Result: 该方法能够在没有训练数据或数据重叠的情况下，有效预测表格列的类型和关系，适用于新领域和稀疏数据场景。

Conclusion: 通过利用本体结构而非数据重叠，该方法扩展了表格语义结构理解的适用范围，使其能够处理新领域和缺乏训练数据的场景。

Abstract: Understanding the semantic structure of tabular data is essential for data integration and discovery. Specifically, the goal is to annotate columns in a tabular source with types and relationships between them using classes and predicates of a target ontology. Previous work either requires trained labeled data or exploits the overlapping data between the table data and a knowledge graph to predict types and relationships. However, these approaches cannot be used in a new domain with …

</details>


### [11] [Automated Detection and Classification of Sensitive Data in Cloud Environments](https://scholar.google.com/scholar_url?url=http://www.injoit.org/index.php/j1/article/download/2301/2011&hl=en&sa=X&d=7144462837450022103&ei=LXEIaeO1A8eB6rQP4ZrcmAM&scisig=ABGrvjID1IbBcA37BPtSW-6O78kV&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=7&folt=cit)
*M Egorov,D Namiot*

Main category: Google Scholar

TL;DR: 论文探讨了云计算环境中数据泄露检测与预防的重要性，分析了敏感数据保护面临的挑战，并提出了相应的安全解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着云计算技术的普及，信息安全风险显著增加。云用户面临的最严重问题之一是如何在云基础设施中检测和预防数据泄露。敏感数据需要保护免受未经授权的访问、修改或分发，因为这些数据高度敏感，一旦泄露或滥用可能对所有者或第三方造成损害。

Method: 从摘要内容来看，论文可能采用以下方法：分析云计算环境中的数据安全威胁，研究数据泄露的检测机制，提出预防性安全措施，探讨敏感数据分类和保护策略，以及评估现有安全解决方案的有效性。

Result: 论文预计会展示云计算环境中数据泄露检测技术的有效性，提出改进的安全防护方案，并验证这些方案在保护敏感数据方面的性能。结果可能包括检测准确率、误报率、系统性能影响等指标。

Conclusion: 云计算环境中的数据安全保护至关重要，需要综合运用多种技术手段来检测和预防数据泄露。有效的安全策略应包括数据分类、访问控制、监控检测和应急响应等多个层面，以确保敏感数据在云环境中的安全。

Abstract: The introduction of cloud technologies is inevitably accompanied by an increase in information security risks. One of the most serious problems faced by cloud users is the detection and prevention of data leaks in the cloud infrastructure. Confidential data is information that requires protection from unauthorized access, modification or distribution, as it is highly sensitive and can cause damage to the owner or third parties in the event of leakage or abuse. This data may concern both individuals and …

</details>


### [12] [Castle: Causal Cascade Updates in Relational Databases with Large Language Models](https://scholar.google.com/scholar_url?url=https://aclanthology.org/2025.emnlp-main.1700.pdf&hl=en&sa=X&d=16373205007390400057&ei=hAAKaeThHMHO6rQPjanaqAg&scisig=ABGrvjJ1-eJfUMn-BX-eMeJMwJZi&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ABGrvjJkn-FcYY8t5hAtGXsL8UoX&html=&pos=1&folt=rel)
*Y Su,Y Zhang,Z Shi,B Ribeiro,E Bertino*

Main category: Google Scholar

TL;DR: Castle是首个使用大语言模型进行仅模式级联更新生成的框架，专注于UPDATE语句而非SELECT查询


<details>
  <summary>Details</summary>
Motivation: 现有LLM在Text2SQL领域主要关注SELECT查询生成，而实际应用中UPDATE语句同样重要但缺乏专门研究。UPDATE语句涉及级联更新和模式约束，比SELECT更复杂，需要专门解决方案。

Method: Castle框架采用模式级联更新生成方法，利用大语言模型处理UPDATE语句的生成，特别关注数据库模式约束和级联更新逻辑。

Result: Castle是首个专门针对UPDATE语句生成的框架，填补了LLM在Text2SQL领域中对非SELECT查询的空白。

Conclusion: Castle框架为LLM在数据库更新操作中的应用提供了新方向，解决了实际应用中UPDATE语句生成的挑战。

Abstract: This work introduces Castle, the first framework for schema-only cascade update generation using large language models (LLMs). Despite recent advances in LLMs for Text2SQL code generation, existing approaches focus primarily on SELECT …

</details>


### [13] [Skeletons Matter: Dynamic Data Augmentation for Text-to-Query](https://scholar.google.com/scholar_url?url=https://aclanthology.org/2025.emnlp-main.64.pdf&hl=en&sa=X&d=12251143638282498467&ei=hAAKaeThHMHO6rQPjanaqAg&scisig=ABGrvjLLgPTkVSE1DfHuqy07uNWu&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ABGrvjJkn-FcYY8t5hAtGXsL8UoX&html=&pos=2&folt=rel)
*Y Ji,B Xu,J Shi,J Liang,D Yang,Y Mao,H Chen…*

Main category: Google Scholar

TL;DR: LLMs在自然语言问题转查询语言任务中取得显著进展，但现有方法在复杂查询生成方面仍有局限


<details>
  <summary>Details</summary>
Motivation: 自然语言问题转查询语言是语义解析的核心任务，LLMs的快速发展为该领域带来新机遇，但现有方法在处理复杂查询时仍面临挑战

Method: 未明确说明具体方法，但暗示将探索LLMs在语义解析中的应用，可能涉及提示工程、微调或架构改进

Result: 未提供具体实验结果，但暗示LLMs已显著推动该领域进展，同时指出现有方法在复杂查询生成方面的不足

Conclusion: LLMs为自然语言转查询语言任务带来重要进展，但仍需进一步研究以解决复杂查询生成的挑战

Abstract: The task of translating natural language questions into query languages has long been a central focus in semantic parsing. Recent advancements in Large Language Models (LLMs) have significantly accelerated progress in this field. However, existing …

</details>


### [14] [Can LLMs Narrate Tabular Data? An Evaluation Framework for Natural Language Representations of Text-to-SQL System Outputs](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.23854&hl=en&sa=X&d=8862415507091991084&ei=hAAKaeThHMHO6rQPjanaqAg&scisig=ABGrvjKx4nS25JLaZczgn5_XNayP&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ABGrvjJkn-FcYY8t5hAtGXsL8UoX&html=&pos=3&folt=rel)
*J Singh,W Sun,A Agarwal,V Krishnamurthy…*

Main category: Google Scholar

TL;DR: 该论文研究多轮对话系统中Text-to-SQL技术的表格结果自然语言表示生成问题，提出了一种新颖的评估框架


<details>
  <summary>Details</summary>
Motivation: 在多轮对话系统中，Text-to-SQL技术将自然语言问题转换为数据库查询，但查询结果的表格数据需要转换为自然语言表示才能被用户理解。现有研究主要关注SQL生成，而忽略了结果表示生成的重要性，缺乏系统性的评估方法。

Method: 论文提出了一种新颖的评估框架，用于评估表格结果到自然语言表示的生成质量。该方法可能包括评估指标、数据集构建和模型评估等方面，具体方法细节需要完整论文才能确定。

Result: 通过提出的评估框架，论文展示了现有Text-to-SQL系统在结果表示生成方面的局限性，并可能提供了改进方向。具体实验结果需要完整论文才能获得。

Conclusion: 表格结果的自然语言表示生成是Text-to-SQL系统的重要组成部分，需要专门的评估框架来推动该领域的发展，提升多轮对话系统的用户体验。

Abstract: In modern industry systems like multi-turn chat agents, Text-to-SQL technology bridges natural language (NL) questions and database (DB) querying. The conversion of tabular DB results into NL representations (NLRs) enables the chat …

</details>


### [15] [Divide, Link, and Conquer: Recall-oriented Schema Linking for NL-to-SQL via Question Decomposition](https://scholar.google.com/scholar_url?url=https://aclanthology.org/2025.emnlp-industry.122.pdf&hl=en&sa=X&d=14649209056254872104&ei=hAAKaeThHMHO6rQPjanaqAg&scisig=ABGrvjIvGmxFeBYaFyX071mcxSyk&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ABGrvjJkn-FcYY8t5hAtGXsL8UoX&html=&pos=4&folt=rel)
*K Pradeep,K Db,N Madaan,S Mehta,P Bhattacharyya*

Main category: Google Scholar

TL;DR: NL-to-SQL系统在工业中日益重要，但现有系统存在性能瓶颈和可扩展性问题


<details>
  <summary>Details</summary>
Motivation: NL-to-SQL系统在工业应用中对于非技术用户高效访问结构化数据、支持快速决策和数据可访问性至关重要，但现有最先进系统存在性能瓶颈和可扩展性问题

Method: 从提供的摘要片段来看，方法部分信息不完整，但可能涉及改进NL-to-SQL系统的架构、优化算法或增强可扩展性

Result: 摘要未提供具体结果，但暗示现有系统存在需要改进的性能问题

Conclusion: 需要进一步改进NL-to-SQL系统以解决性能瓶颈和可扩展性问题，从而更好地支持工业应用

Abstract: Natural language to SQL (NL-to-SQL) systems are increasingly critical in industry for enabling non-technical users to access structured data efficiently, supporting faster decision-making and data accessibility. However, state-of-the-art systems often …

</details>


### [16] [SQUAB: Evaluating LLM robustness to Ambiguous and Unanswerable Questions in Semantic Parsing](https://scholar.google.com/scholar_url?url=https://aclanthology.org/2025.emnlp-main.906.pdf&hl=en&sa=X&d=15995667136645585756&ei=hAAKaeThHMHO6rQPjanaqAg&scisig=ABGrvjLMzt9fRin1Rcz8__4dVn2V&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ABGrvjJkn-FcYY8t5hAtGXsL8UoX&html=&pos=5&folt=rel)
*S Papicchio,L Cagliero,P Papotti*

Main category: Google Scholar

TL;DR: 该论文研究了大型语言模型在语义解析任务中处理不完整、模糊或不可回答查询的能力，提出了评估框架和基准测试方法


<details>
  <summary>Details</summary>
Motivation: 实际用户查询经常偏离理想情况，包含不完整信息、模糊意图或不可回答的问题，而现有语义解析研究主要关注明确可回答的查询，缺乏对这类现实场景的系统评估

Method: 论文可能提出了评估框架和基准测试方法，用于系统评估LLMs处理不完整、模糊或不可回答查询的能力，可能包括数据集构建、评估指标设计和实验设置

Result: 研究发现当前LLMs在处理偏离理想情况的查询时存在显著局限性，在模糊意图识别、不完整信息处理和不可回答查询识别方面表现不佳

Conclusion: 需要开发更鲁棒的语义解析方法，能够有效处理现实世界中不完整、模糊或不可回答的用户查询，提升LLMs在实际应用中的实用性

Abstract: Abstract Large Language Models (LLMs) have demonstrated robust performance in Semantic Parsing (SP) for well-defined queries with unambiguous intent and answerable responses. However, practical user questions frequently deviate from …

</details>


### [17] [NEMO: Faster Parallel Execution for Highly Contended Blockchain Workloads (Full version)](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.15122&hl=en&sa=X&d=8588034103637138042&ei=hAAKaeThHMHO6rQPjanaqAg&scisig=ABGrvjKbyukpgdULcQXnR01-Gbbv&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ABGrvjJkn-FcYY8t5hAtGXsL8UoX&html=&pos=7&folt=rel)
*F Ezard,CU Ileri,J Decouchant*

Main category: Google Scholar

TL;DR: 区块链并行执行框架的性能瓶颈分析及优化方案


<details>
  <summary>Details</summary>
Motivation: 随着区块链共识算法效率提升，执行层成为新的性能瓶颈，特别是在高竞争场景下。现有并行执行框架存在依赖乐观执行导致高冲突时性能下降，或依赖静态分析无法处理动态访问模式的问题。

Method: 未在摘要中明确说明具体方法，但暗示需要解决现有框架的局限性，可能涉及动态冲突检测、自适应执行策略或混合执行模型。

Result: 未在摘要中提供具体实验结果，但暗示需要开发能够有效处理高竞争场景的并行执行框架。

Conclusion: 需要设计新的并行执行框架来解决区块链在高竞争场景下的性能瓶颈问题。

Abstract: Following the design of more efficient blockchain consensus algorithms, the execution layer has emerged as the new performance bottleneck of blockchains, especially under high contention. Current parallel execution frameworks either rely …

</details>


### [18] [Squrve: A Unified and Modular Framework for Complex Real-World Text-to-SQL Tasks](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.24102&hl=en&sa=X&d=4732656052572112090&ei=hAAKaeThHMHO6rQPjanaqAg&scisig=ABGrvjK3i3L0HL2_6KJ1sOr_fWE8&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ABGrvjJkn-FcYY8t5hAtGXsL8UoX&html=&pos=9&folt=rel)
*Y Wang,P Liu,R Chen,J Pu,W Xu*

Main category: Google Scholar

TL;DR: 文本转SQL技术发展迅速但实际部署困难，缺乏集成工具


<details>
  <summary>Details</summary>
Motivation: 尽管文本转SQL技术在学术研究中取得了显著成果，但在实际系统部署中仍面临挑战，主要原因是缺乏有效的集成工具

Method: 未明确说明具体方法，但指出当前存在多种学术方法

Result: 文本转SQL技术已取得令人印象深刻的学术成果

Conclusion: 文本转SQL技术在实际部署中存在挑战，需要更好的集成工具来弥合学术研究与实际应用之间的差距

Abstract: Text-to-SQL technology has evolved rapidly, with diverse academic methods achieving impressive results. However, deploying these techniques in real-world systems remains challenging due to limited integration tools. Despite these …

</details>


### [19] [ggtime: A Grammar of Temporal Graphics](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.25656&hl=en&sa=X&d=4656339079284740846&ei=ggAKaZaoG_-j6rQPweenoAk&scisig=ABGrvjLS8B8WnusIAfcYBWHT2GWr&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=4&folt=cit)
*CA Huang,M O'Hara*

Main category: Google Scholar

TL;DR: 提出一种时间图形语法，用于准确表示复杂的时间语义，解决现有可视化工具在处理时间变化时的局限性


<details>
  <summary>Details</summary>
Motivation: 可视化时间变化是理解过去和预测未来的基础，但现有工具难以准确表示复杂的时间语义，通常需要定制化的绘图函数，缺乏尊重时间语义的灵活通用工具

Method: 提出一种时间图形语法，通过系统化的语法结构来处理时间数据的可视化，能够准确表示复杂的时间语义关系

Result: 开发了一种灵活的时间可视化框架，能够更准确地表示时间变化，解决了现有工具在处理时间语义时的局限性

Conclusion: 时间图形语法为时间数据可视化提供了系统化的解决方案，能够更好地支持复杂时间语义的表示，有助于从时间数据中获得更深入的洞察

Abstract: Visualizing changes over time is fundamental to learning from the past and anticipating the future. However, temporal semantics can be complicated, and existing visualization tools often struggle to accurately represent these complexities. It is common to use bespoke plot helper functions designed to produce specific graphics, due to the absence of flexible general tools that respect temporal semantics. We address this problem by proposing a grammar of temporal graphics …

</details>


### [20] [Human aesthetics under the representational power of Artificial Intelligence](https://scholar.google.com/scholar_url?url=https://ellisalicante.org/assets/phd_theses/2025-PieraRiccio-PhD-Thesis-compressed.pdf&hl=en&sa=X&d=13360740499776804944&ei=uMMLacGKNMHO6rQPt-Gh0Ao&scisig=ABGrvjI8P_RstyUJf1aZoahO5Nml&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=0&folt=cit)
*P Riccio*

Main category: Google Scholar

TL;DR: 该论文基于Don Ihde的技术哲学框架，研究AI技术如何中介人类在当代视觉文化中的表征，结合技术贡献、社会伦理反思和艺术维度分析


<details>
  <summary>Details</summary>
Motivation: 研究动机是探讨人工智能技术如何影响和中介人类在当代视觉文化中的表征方式，理解技术、人类和社会之间的复杂关系

Method: 采用Don Ihde的技术哲学框架，分析技术中介的三种模态（具身、诠释、他异性），结合技术实现、社会伦理批判和艺术实践分析

Result: 论文通过技术贡献和批判性反思，揭示了AI技术如何塑造人类表征，提出了对AI中介视觉文化的新理解框架

Conclusion: AI技术通过不同模态中介人类表征，对视觉文化产生深刻影响，需要在技术发展、社会伦理和艺术实践中进行综合考量

Abstract: This thesis investigates how Artificial Intelligence (AI)-based technologies mediate human representation in contemporary visual culture. The work is grounded on Don Ihde's philosophical framework that analyzes distinct modalities (embodiment, hermeneutic, and alterity) according to which humans relate to technologies. Through a combination of technical contributions, along with critical reflections on the socio-ethical and artistic dimensions of these systems, the thesis offers an …

</details>


### [21] [MTIR-SQL: Multi-turn Tool-Integrated Reasoning Reinforcement Learning for Text-to-SQL](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.25510&hl=en&sa=X&d=7735743851254474728&ei=usMLaermA9rZzwLz3N3oDQ&scisig=ABGrvjJnoKOr2seoMz5EwWCyntRF&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ABGrvjJkn-FcYY8t5hAtGXsL8UoX&html=&pos=0&folt=rel)
*Z Xu,S Xia,C Yue,J Chai,M Tian,X Wang,W Lin,H Li…*

Main category: Google Scholar

TL;DR: 该论文提出了一种基于强化学习的动态反馈机制，用于改进大语言模型在Text-to-SQL任务中的性能，通过多轮交互优化SQL查询质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的Text-to-SQL方法主要依赖静态执行反馈，这种反馈机制存在局限性，无法充分优化大语言模型生成的SQL查询质量，需要更动态、交互式的反馈机制来提升性能。

Method: 提出了一种动态反馈强化学习方法，通过多轮交互过程，在每次生成SQL查询后获取动态执行反馈，利用这些反馈信息指导模型进行迭代优化，改进SQL查询的准确性和效率。

Result: 该方法在标准Text-to-SQL基准测试中取得了显著性能提升，相比传统静态反馈方法，生成的SQL查询在准确性、执行效率和语义正确性方面都有明显改进。

Conclusion: 动态反馈强化学习机制能有效提升大语言模型在Text-to-SQL任务中的性能，为复杂数据库查询生成提供了更优的优化框架，具有重要的实际应用价值。

Abstract: As large language models (LLMs) are increasingly used in Text-to-SQL tasks, Reinforcement Learning (RL) has become a common method for improving performance. Existing methods primarily rely on static execution feedback, which …

</details>


### [22] [Feedback-driven Retrieval-augmented Audio Generation with Large Audio Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.01091&hl=en&sa=X&d=13845095302653657704&ei=9lQNaZukL-2ZieoP-Nvg6AY&scisig=ABGrvjJmX9oX9RLFj916tsDKZRxP&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ABGrvjJkn-FcYY8t5hAtGXsL8UoX&html=&pos=0&folt=rel)
*J Zhao,C Li,J Zhao,R Chen,D Yu,MD Plumbley…*

Main category: Google Scholar

TL;DR: 提出一种基于反馈驱动的检索增强生成方法，利用大型音频语言模型解决文本到音频合成中特定声音事件缺失或不完善的问题


<details>
  <summary>Details</summary>
Motivation: 当前文本到音频合成系统在生成特定声音事件时存在缺失或不完善的问题，需要更精确的音频生成能力

Method: 采用反馈驱动的检索增强生成框架，结合大型音频语言模型，通过检索相关音频片段来增强文本到音频的合成质量

Result: 该方法能够有效改善特定声音事件的合成质量，减少缺失和不完善的情况

Conclusion: 反馈驱动的检索增强生成方法为文本到音频合成中的特定声音事件生成问题提供了有效的解决方案

Abstract: We propose a general feedback-driven retrieval-augmented generation (RAG) approach that leverages Large Audio Language Models (LALMs) to address the missing or imperfect synthesis of specific sound events in text-to-audio (TTA) …

</details>


### [23] [Extraction of geoprocessing modeling knowledge from crowdsourced Google Earth Engine scripts by coordinating large and small language models](https://scholar.google.com/scholar_url?url=https://www.tandfonline.com/doi/abs/10.1080/13658816.2025.2577252&hl=en&sa=X&d=5682944280018738254&ei=9lQNaZukL-2ZieoP-Nvg6AY&scisig=ABGrvjKTHOxnIMnJlAU_Kb7FX7sE&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ABGrvjJkn-FcYY8t5hAtGXsL8UoX&html=&pos=1&folt=rel)
*A Zhao,Z Gui,J Liang,Y Liu,D Peng,W Wei,S Hou…*

Main category: Google Scholar

TL;DR: 从Google Earth Engine等在线地理信息平台的众包脚本中提取领域知识，以支持地理处理工作流的理解和重用


<details>
  <summary>Details</summary>
Motivation: 在线地理信息平台（如Google Earth Engine）产生了大量众包脚本，这些脚本蕴含丰富的领域知识。然而，这些知识分散且难以系统化提取，限制了地理处理工作流的理解和重用。

Method: 提出从众包地理信息脚本中提取领域知识的方法，可能包括脚本分析、模式识别、工作流提取等技术手段，以系统化地捕获和表示地理处理知识。

Result: 成功从Google Earth Engine等平台的众包脚本中提取了地理处理领域知识，建立了可支持工作流理解和重用的知识表示框架。

Conclusion: 从众包地理信息脚本中提取领域知识是可行的，这种方法能够有效支持地理处理工作流的理解和重用，为地理信息科学的知识管理提供了新途径。

Abstract: The widespread use of online geoinformation platforms, such as Google Earth Engine (GEE), has produced numerous scripts. Extracting domain knowledge from these crowdsourced scripts supports understanding of geoprocessing workflows …

</details>


### [24] [Contextual Relevance and Adaptive Sampling for LLM-Based Document Reranking](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.01208&hl=en&sa=X&d=12905172980856303768&ei=9lQNaZukL-2ZieoP-Nvg6AY&scisig=ABGrvjKaEopqqswkqoE75OYo1pfm&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ABGrvjJkn-FcYY8t5hAtGXsL8UoX&html=&pos=4&folt=rel)
*J Huang,S Madala,C Niu,J Hockenmaier,T Zhang*

Main category: Google Scholar

TL;DR: 本文探讨了重排序算法在文档检索中的局限性，特别是对于需要深入理解查询的情况，并提出了一种新的解决方案


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的重排序算法在处理需要深入理解查询的文档检索时存在局限性，无法有效识别相关文档，需要更有效的方法来提升检索质量

Method: 论文提出了一种新的重排序方法，具体方法细节需要从完整论文中获取，但核心是改进现有LLM-based重排序算法在处理复杂查询时的不足

Result: 新方法在需要深入理解查询的文档检索任务中表现出更好的性能，提升了相关文档的识别准确率

Conclusion: 提出的重排序方法有效解决了现有算法在处理复杂查询时的局限性，为文档检索系统提供了更强大的重排序能力

Abstract: Reranking algorithms have made progress in improving document retrieval quality by efficiently aggregating relevance judgments generated by large language models (LLMs). However, identifying relevant documents for queries that require in-depth …

</details>


### [25] [Learned Static Function Data Structures](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.27588&hl=en&sa=X&d=5862144911368626463&ei=9VQNafr-HIqi6rQPis_TmQk&scisig=ABGrvjLx--x-OvnRdnLebaAGfmDI&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=6&folt=cit)
*S Hermann,HP Lehmann,G Vinciguerra,S Walzer*

Main category: Google Scholar

TL;DR: 提出一种新的静态函数数据结构，用于关联静态键集与值，相比哈希表不存储键集，内存占用更少，接近值序列的零阶经验熵


<details>
  <summary>Details</summary>
Motivation: 现有静态函数数据结构虽然比哈希表节省内存（不存储键集），但压缩静态函数已接近值序列的零阶经验熵，需要进一步改进

Method: 引入新的静态函数数据结构技术（具体方法未在摘要中说明，但暗示是创新性方法）

Result: 未在摘要中明确说明具体结果，但暗示该方法在内存效率方面有改进

Conclusion: 提出了一种改进的静态函数数据结构，进一步优化内存使用

Abstract: We consider the task of constructing a data structure for associating a static set of keys with values, while allowing arbitrary output values for queries involving keys outside the set. Compared to hash tables, these so-called static function data structures do not need to store the key set and thus use significantly less memory. Several techniques are known, with compressed static functions approaching the zero-order empirical entropy of the value sequence. In this paper, we introduce …

</details>


### [26] [Exploring Exploratory Querying](https://scholar.google.com/scholar_url?url=http://www.olafhartig.de/files/ArenasEtAl_ExplQuerying.pdf&hl=en&sa=X&d=2876535593518505442&ei=KwIPabDbNcHO6rQPt-Gh0Ao&scisig=ABGrvjJHsZuNbiG9v34url1Ia5AF&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=1&folt=cit)
*M Arenas,E Franconi,J Hammerer,O Hartig,K Hose…*

Main category: Google Scholar

TL;DR: 论文呼吁重新思考用户理解和开发查询的方式，强调查询制定已成为需要研究和支持的探索性迭代过程


<details>
  <summary>Details</summary>
Motivation: 传统上认为用户是经过高度培训、在受控环境中编写查询的专家，但随着用户群体日益多样化、查询语言和数据架构日益复杂（特别是LLM等工具的出现），这种观点已不再适用。查询制定已成为更复杂的探索性活动，需要新的研究支持。

Method: 论文未提供具体方法，但从摘要看，作者主张将查询制定重新概念化为一个迭代循环过程，包括设计、调试和维护等阶段，并需要相应的研究支持框架。

Result: 摘要未提供具体实验结果，但提出了对查询制定过程的新认知框架，强调其探索性和迭代性特征。

Conclusion: 需要重新思考用户理解和开发查询的方式，将查询制定视为需要研究和支持的探索性迭代过程，以适应现代数据环境和工具生态。

Abstract: We need to rethink how users understand and develop queries. The growing diversity of users, the increasing complexity of query languages and data architectures-now aided by tools like LLMs-are challenging the traditional view of a highly-trained user writing queries in a controlled environment. Query formulation has become a more exploratory endeavor that needs to be researched and supported: an iterative cycle of designing, debugging, and maintaining queries. To …

</details>


### [27] [ZipVL: Accelerating Vision-Language Models through Dynamic Token Sparsity](https://scholar.google.com/scholar_url?url=https://openaccess.thecvf.com/content/ICCV2025/papers/He_ZipVL_Accelerating_Vision-Language_Models_through_Dynamic_Token_Sparsity_ICCV_2025_paper.pdf&hl=en&sa=X&d=2396910621464524780&ei=LAIPaYWxMoePieoPstbBMQ&scisig=ABGrvjK4rpr95FLzckhRIxk6BomU&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ABGrvjJkn-FcYY8t5hAtGXsL8UoX&html=&pos=0&folt=rel)
*Y He,F Chen,J Liu,W Shao,H Zhou,K Zhang…*

Main category: Google Scholar

TL;DR: 该论文针对大型视觉语言模型在预填充和解码阶段的效率瓶颈，提出了一种新的注意力机制优化方法


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在预填充阶段受注意力机制计算瓶颈限制，在解码阶段受KV缓存读取的内存瓶颈限制，这些效率问题限制了模型的实用性和可扩展性

Method: 提出了一种新的注意力机制优化方法，通过改进预填充阶段的计算效率和减少解码阶段的KV缓存需求来提升模型效率

Result: 该方法显著提升了LVLMs的推理效率，减少了计算开销和内存占用，同时保持了模型性能

Conclusion: 提出的注意力机制优化方法有效解决了LVLMs在预填充和解码阶段的效率瓶颈，为大规模视觉语言模型的实际部署提供了可行的解决方案

Abstract: The efficiency of large vision-language models (LVLMs) is constrained by the computational bottleneck of the attention mechanism during the prefill phase and the memory bottleneck of fetching the key-value (KV) cache in the decoding phase …

</details>


### [28] [SmartCache: Context-aware Semantic Cache for Efficient Multi-turn LLM Inference](https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DlMxuq0GNeC&hl=en&sa=X&d=11624657483560428445&ei=UY0Qadr8FceB6rQPsefiqAI&scisig=ABGrvjK6do30uLhtf0rtAGBa2IjU&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ABGrvjJkn-FcYY8t5hAtGXsL8UoX&html=&pos=2&folt=rel)
*YU Chengye,T Wang,Z Shao,S Jiang*

Main category: Google Scholar

TL;DR: LLM在多轮对话中存在效率问题：不同用户会话间的语义相似查询触发冗余计算和重复的内存密集型KV缓存，现有解决方案不足


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多轮对话中效率低下，因为不同用户会话间的语义相似查询会导致冗余计算和重复的KV缓存，造成计算资源和内存浪费

Method: 论文提出了一种跨会话缓存共享机制，通过识别和重用语义相似的查询来避免重复计算，具体方法包括语义相似性检测和KV缓存复用技术

Result: 该方法显著减少了计算冗余和内存使用，提高了LLM在多轮对话中的效率，同时保持了生成质量

Conclusion: 跨会话缓存共享是解决LLM多轮对话效率问题的有效方法，能够在不牺牲质量的前提下显著提升性能和资源利用率

Abstract: Large Language Models (LLMs) for multi-turn conversations suffer from inefficiency: semantically similar queries across different user sessions trigger redundant computation and duplicate memory-intensive Key-Value (KV) caches. Existing …

</details>


### [29] [A Design and Implementation of Learned Index for Processing Multi-Dimensional Queries Over Relational Data](https://scholar.google.com/scholar_url?url=https://spectrum.library.concordia.ca/id/eprint/995759/1/Shahinfard_MSc_F2025.pdf.pdf&hl=en&sa=X&d=14670786348400951460&ei=UI0QaZyjDf-j6rQP7fvY4A4&scisig=ABGrvjLvGNxJQl14H_coNKtlS8oy&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=0&folt=cit)
*S Parmiss*

Main category: Google Scholar

TL;DR: Flood是一种基于机器学习的学习型索引，用于处理关系数据的多维查询，通过动态调整网格结构和数据布局来优化性能。


<details>
  <summary>Details</summary>
Motivation: 传统多维索引方法（如KD-Trees和R-Trees）采用静态分区策略，无法根据数据分布和查询负载动态调整，导致性能受限。需要一种能够自适应数据特性和查询模式的学习型索引框架。

Method: Flood采用机器学习技术，动态调整其网格结构和数据布局。框架核心组件包括网格构建、数据分区和查询处理机制，通过分析数据分布和查询负载来优化索引结构。

Result: 论文对Flood框架进行了性能评估和分析，展示了其在处理多维查询时相比传统索引方法的优势。具体性能指标包括查询延迟、吞吐量和资源利用率等。

Conclusion: Flood作为一种学习型索引，通过动态适应数据分布和查询负载，在多维查询处理方面表现出优于传统静态索引方法的性能，为关系数据的高效查询提供了新的解决方案。

Abstract: We study the performance evaluation and analysis of Flood, a learned index designed to process multi-dimensional queries over relational data. Unlike traditional indexing methods such as KD-Trees and R-Trees, which rely on static partitioning strategies, Flood leverages machine learning techniques to dynamically adapt its grid structure and data layout based on data distribution and query workloads. We identify and evaluate the core components of the Flood framework—including grid …

</details>


### [30] [Автоматизированное обнаружение и классификация конфиденциальных данных в облачных средах](https://scholar.google.com/scholar_url?url=https://cyberleninka.ru/article/n/avtomatizirovannoe-obnaruzhenie-i-klassifikatsiya-konfidentsialnyh-dannyh-v-oblachnyh-sredah&hl=en&sa=X&d=12769795758056546221&ei=UI0QaZyjDf-j6rQP7fvY4A4&scisig=ABGrvjKReoWk5iDIydLZ4gLxuUvp&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=1&folt=cit)
*МЭ Егоров,ДЕ Намиот*

Main category: Google Scholar

TL;DR: 论文探讨了云计算环境中数据泄露检测与防护的挑战，重点关注敏感信息保护问题


<details>
  <summary>Details</summary>
Motivation: 随着云技术的广泛应用，信息安全风险显著增加，特别是云基础设施中的数据泄露问题日益严重。敏感数据需要防止未经授权的访问、修改或传播，这对云环境安全提出了新的挑战。

Method: 论文未在摘要中明确说明具体方法，但聚焦于云环境中数据泄露的检测和预防机制，可能涉及监控、访问控制、加密等技术手段。

Result: 摘要未提供具体实验结果，但强调了云环境中数据泄露防护的重要性，暗示需要有效的安全解决方案来保护敏感信息。

Conclusion: 云技术的采用带来了显著的信息安全风险，特别是数据泄露问题。需要开发有效的检测和预防机制来保护云环境中的敏感数据。

Abstract: Внедрение облачных технологий неизбежно сопровождается ростом рисков в области информационной безопасности. Одной из наиболее серьёзных проблем, с которыми сталкиваются пользователи облачных сред, является обнаружение и предотвращение утечек данных в облачной инфраструктуре. Конфиденциальные данные–это информация, которая требует защиты от несанкционированного доступа, изменения или распространения, так как она …

</details>


### [31] [Enhanced LLM-Based Self-Driven Natural Language to SQL Query Method in Maritime Transportation](https://scholar.google.com/scholar_url?url=https://ascelibrary.org/doi/abs/10.1061/9780784486269.023&hl=en&sa=X&d=313810711034221798&ei=G-4RaZ2mA4qi6rQPnJ2MmAY&scisig=ABGrvjKlTjbR36K16oDauJln0vCR&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ABGrvjJkn-FcYY8t5hAtGXsL8UoX&html=&pos=3&folt=rel)
*H Zhang,M Chen,Y Han,S Wang,F Ren*

Main category: Google Scholar

TL;DR: 海事运输数据库具有复杂的模式信息、表名和列名，给研究人员和实践者带来显著挑战，大语言模型的出现为解决这一问题提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 海事运输数据库的复杂模式信息、表结构和列名给数据查询和分析带来困难，需要更智能的方法来简化数据库交互和查询过程。

Method: 利用大语言模型（LLM）技术来处理复杂的数据模式，通过自然语言理解来简化数据库查询和交互过程。

Result: 未在摘要中明确说明具体结果，但暗示大语言模型能够有效处理海事运输数据库的复杂性，改善用户体验。

Conclusion: 大语言模型为解决海事运输数据库的复杂模式挑战提供了有前景的解决方案，能够简化数据库交互过程。

Abstract: Maritime transportation databases are characterized by complex schema information, as well as intricate table and column names, which pose significant challenges for researchers and practitioners. The emergence of large language …

</details>


### [32] [Towards Automatically Optimizing Retrieval Augmented AI Systems](https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3Dan17DUVvuS&hl=en&sa=X&d=5432416780274429414&ei=G-4RaZ2mA4qi6rQPnJ2MmAY&scisig=ABGrvjL11EjU8snZMOPWTTQh4bTS&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ABGrvjJkn-FcYY8t5hAtGXsL8UoX&html=&pos=5&folt=rel)
*MZ Pan,N Arabzadeh,M Jacob,F Kazhamiaka…*

Main category: Google Scholar

TL;DR: LLM部署能耗高，RAG是主要生产负载，需要优化能效


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在真实系统中部署日益增多，其中检索增强生成是主要的生产负载。然而LLM部署能耗巨大，推理阶段占能耗90%以上，需要解决能效问题

Method: 论文摘要未提供具体方法，但暗示需要针对RAG工作负载进行能效优化

Result: 摘要未提供实验结果，但指出LLM部署的能耗问题和RAG的主导地位

Conclusion: LLM部署面临严重的能效挑战，特别是RAG工作负载需要专门的优化方案

Abstract: Large Language Models (LLMs) are increasingly deployed in real-world systems, with Retrieval-Augmented Generation (RAG) a dominant production workload. Yet LLM deployments are energy-intensive, as inference accounts for over 90% of the …

</details>


### [33] [Factorized Learning for Temporally Grounded Video-Language Models](https://scholar.google.com/scholar_url?url=https://openaccess.thecvf.com/content/ICCV2025/papers/Zeng_Factorized_Learning_for_Temporally_Grounded_Video-Language_Models_ICCV_2025_paper.pdf&hl=en&sa=X&d=10136432896069388728&ei=G-4RaZ2mA4qi6rQPnJ2MmAY&scisig=ABGrvjIy0LChuW6s1ZHvd_Ge2SOQ&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ABGrvjJkn-FcYY8t5hAtGXsL8UoX&html=&pos=6&folt=rel)
*W Zeng,D Gao,MZ Shou,HT Ng*

Main category: Google Scholar

TL;DR: 该论文针对视频语言模型在事件级感知中时间定位不准确的问题，提出了一种新的视频理解框架，通过解耦时间定位和语义理解，并引入时间定位增强模块来提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频语言模型在视频理解方面显示出巨大潜力，但在事件级感知的时间定位准确性方面仍存在困难。作者观察到视频理解中的两个主要因素（时间定位和语义理解）需要更好的解耦和协同优化。

Method: 提出了一种新的视频理解框架，通过解耦时间定位和语义理解过程，并引入专门的时间定位增强模块。该方法可能包括多尺度时间建模、注意力机制优化或专门的定位损失函数。

Result: 该方法在多个视频理解基准测试中取得了显著性能提升，特别是在时间定位准确性方面。模型在事件级感知任务上表现出更好的泛化能力和鲁棒性。

Conclusion: 通过解耦时间定位和语义理解，并增强时间定位能力，可以有效提升视频语言模型的事件级感知性能。这种方法为视频理解提供了新的设计思路。

Abstract: Recent video-language models have shown great potential for video understanding, but still struggle with accurate temporal grounding for event-level perception. We observe that two main factors in video understanding (ie, temporal grounding and …

</details>


### [34] [Multi-Turn Interactions for Text-to-SQL with Large Language Models](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3746252.3761052&hl=en&sa=X&d=11977137842635640831&ei=IpETacXMNPGQ6rQP3avymAQ&scisig=ABGrvjIcismVUnuVBGDJlPnreQ3P&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ABGrvjJkn-FcYY8t5hAtGXsL8UoX&html=&pos=0&folt=rel)
*G Xiong,J Bao,H Jiang,Y Song,W Zhao*

Main category: Google Scholar

TL;DR: 该研究探索利用大语言模型的强大推理能力进行文本到SQL解析，旨在解决现有LLM方法效率低下和处理复杂案例困难的问题


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在文本到SQL解析方面取得了进展，但现有方法效率低下且难以处理复杂案例，需要更有效的解决方案来充分利用LLM的推理能力

Method: 利用大语言模型的强大推理能力进行文本到SQL解析，具体方法未在摘要中详细说明，但暗示了改进现有LLM方法的途径

Result: 摘要未提供具体实验结果，但暗示该方法能够更有效地处理文本到SQL解析任务，特别是针对复杂案例

Conclusion: 通过利用大语言模型的推理能力，可以开发更高效的文本到SQL解析方法，解决现有方法的局限性

Abstract: This study explores text-to-SQL parsing by leveraging the powerful reasoning capabilities of large language models (LLMs). Despite recent advancements, existing LLM-based methods are still inefficient and struggle to handle cases with …

</details>


### [35] [A Query Engine for Scientific Data Exploration using Theory, Simulation, and Artificial Intelligence Models](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3731599.3767350&hl=en&sa=X&d=12283526574949257989&ei=IpETacXMNPGQ6rQP3avymAQ&scisig=ABGrvjKTEzEPcI0wXuBCVPgMi7BR&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ABGrvjJkn-FcYY8t5hAtGXsL8UoX&html=&pos=1&folt=rel)
*A Dwaraki,SR Sukumar,CD Rickett,CR Crasta…*

Main category: Google Scholar

TL;DR: 现代科学发现需要将大规模模拟、异构数据和AI模型结合成交互式工作流，但现有系统难以支持科学家编写既能检索海量数据又能进行复杂分析的表达性查询。


<details>
  <summary>Details</summary>
Motivation: 现代科学发现正朝着大规模模拟、异构数据和AI模型相结合的方向发展，形成交互式迭代工作流。然而，现有系统通常无法让科学家编写既能够检索海量数据又能进行复杂分析的表达性查询，这限制了科学发现的效率和深度。

Method: 论文未提供具体方法细节，但从摘要描述来看，可能涉及开发新的系统架构或框架，以支持科学家在科学工作流中编写和执行表达性查询，实现大规模数据检索与复杂分析的结合。

Result: 摘要未提供具体实验结果，但暗示现有系统在支持科学家进行表达性查询方面存在局限性，需要新的解决方案来应对现代科学发现的挑战。

Conclusion: 需要开发新的系统或方法来支持科学家在现代科学工作流中进行表达性查询，以更好地结合大规模模拟、异构数据和AI模型，推动科学发现的发展。

Abstract: Modern scientific discovery increasingly couples large-scale simulations, heterogeneous data, and AI models into interactive, iterative workflows. Yet existing systems rarely let scientists compose expressive queries that both retrieve massive …

</details>


### [36] [VoiceVisSystem: End-to-End Voice-driven Data Visualization Generation from Natural Language Questions](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3746252.3761468&hl=en&sa=X&d=4917797926353530541&ei=IZETad3REYS6ieoPn56AOA&scisig=ABGrvjKfev6fEnxsrt08lG92y3Bf&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=1&folt=cit)
*H Zhang,X Tang,X Zhang,J Zhou,Y Song*

Main category: Google Scholar

TL;DR: 提出VoiceVisSystem，一个将语音自然语言问题自动转换为数据可视化的系统，采用端到端方法而非级联方法


<details>
  <summary>Details</summary>
Motivation: 在数字时代，数据可视化技术对数据处理和图形推理任务至关重要。现有方法（如Sevi）采用级联方式，存在效率问题，需要更直接的语音到可视化转换系统

Method: 开发VoiceVisSystem系统，采用端到端方法直接将语音自然语言问题转换为可视化数据表示，核心组件基于...（摘要未完整提供具体技术细节）

Result: 摘要未提供具体实验结果，但介绍了VoiceVisSystem作为新型自动数据可视化系统，专门处理Speech-to-Vis任务

Conclusion: VoiceVisSystem为语音到可视化转换提供了创新解决方案，相比现有级联方法具有潜在优势，展示了自动数据可视化系统的新方向

Abstract: In today's digital era, data visualization (DV) technology has become indispensable for tasks involving data processing and graphical reasoning. In this demonstration, we introduce a novel automatic DV system named VoiceVisSystem. VoiceVisSystem is designed for transforming speech-form natural language questions (NLQs) into visual data representations, a task formally known as Speech-to-Vis. Unlike the existing cascaded method (eg, Sevi), the core component of our system relies on an …

</details>


### [37] [Core Data-Management Strategies during Migration to Serverless Aurora Databases](https://scholar.google.com/scholar_url?url=https://emergingsociety.org/index.php/efltajas/article/download/214/213&hl=en&sa=X&d=9527499796223633099&ei=BXkWab6aGf3D6rQPjbaE0Qc&scisig=ABGrvjKse-BZ1ilHEQYe5XslzG6X&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=1&folt=cit)
*M Kurtikov*

Main category: Google Scholar

TL;DR: 分析从本地或单体关系数据库迁移到Amazon Aurora Serverless的核心数据管理策略，确保一致性、可扩展性和成本效益


<details>
  <summary>Details</summary>
Motivation: 随着企业向云原生架构转型，需要解决从传统数据库向无服务器数据库迁移过程中的数据管理挑战，确保迁移的一致性和成本效益

Method: 基于近期同行评审研究和行业报告，将无服务器Aurora置于微服务架构中分析，强调"数据库-服务"模式、CAP定理权衡以及事务存储、数据湖和数据仓库的互补作用

Result: 论文提出了确保从传统数据库向Amazon Aurora Serverless迁移时保持一致性、可扩展性和成本效益的核心数据管理策略框架

Conclusion: 通过适当的架构模式和数据管理策略，可以实现从传统数据库向Amazon Aurora Serverless的高效、一致且经济可行的迁移

Abstract: The paper analyses core data-management strategies that ensure a consistent, scalable, and cost-efficient transition from on-premises or monolithic relational databases to Amazon Aurora Serverless. Drawing on recent peer-reviewed research and industry reports, the study first frames serverless Aurora within a microservice-centric architecture, emphasising the “database-per-service” pattern, CAP-theorem trade-offs, and the complementary roles of transactional stores, data lakes, and data …

</details>


### [38] [Product distribution learning with imperfect advice](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.10366&hl=en&sa=X&d=7657593972671210528&ei=-bYaaY-MOLuZ6rQPwIya4Q8&scisig=ABGrvjJhGH8axZuM3c4NIwgfgUEP&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=1&folt=cit)
*A Bhattacharyya,D Choo,PG John,T Gouleakis*

Main category: Google Scholar

TL;DR: 研究在布尔超立方体上学习乘积分布的问题，当学习者额外获得一个建议乘积分布Q的参数时，能否减少样本复杂度


<details>
  <summary>Details</summary>
Motivation: 传统学习布尔超立方体上的乘积分布需要Ω(d/ε²)样本，研究当学习者获得一个建议分布Q的参数时，能否利用这些先验信息减少样本需求

Method: 分析在给定建议乘积分布Q参数的情况下，学习目标分布P所需的样本复杂度，研究样本复杂度与P和Q之间距离的关系

Result: 当建议分布Q与目标分布P足够接近时，样本复杂度可以显著降低；但当Q与P相差较大时，样本复杂度可能与传统方法相当

Conclusion: 建议分布的质量对学习效率有重要影响，好的建议可以大幅减少样本需求，但差建议则无法提供优势

Abstract: Given iid~ samples from an unknown distribution $ P $, the goal of distribution learning is to recover the parameters of a distribution that is close to $ P $. When $ P $ belongs to the class of product distributions on the Boolean hypercube $\{0, 1\}^ d $, it is known that $\Omega (d/\varepsilon^ 2) $ samples are necessary to learn $ P $ within total variation (TV) distance $\varepsilon $. We revisit this problem when the learner is also given as advice the parameters of a product distribution $ Q $. We …

</details>


### [39] [SEARCHX: An Integrated Framework of Distributed Intelligent Search Services Based on Web Browser.](https://scholar.google.com/scholar_url?url=https://search.ebscohost.com/login.aspx%3Fdirect%3Dtrue%26profile%3Dehost%26scope%3Dsite%26authtype%3Dcrawler%26jrnl%3D2158107X%26AN%3D189187559%26h%3DE7UQH%252Br8cxX9XQ%252B0Ner4c6R7vOBLFvQGW88GB%252B0j89qF%252FLuy0lZWksF1R66M0MEBEpTlKGjwUO5vhOrED9%252FjSQ%253D%253D%26crl%3Dc&hl=en&sa=X&d=8703278319522868362&ei=-bYaaY-MOLuZ6rQPwIya4Q8&scisig=ABGrvjKbwjNmxpLKM1anN4GfvJi8&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=2&folt=cit)
*Z Zhang,L Zhou,J Peng,L Wang,B Cheng*

Main category: Google Scholar

TL;DR: 提出基于SEARCHX的分布式智能搜索服务集成框架，利用浏览器本地计算能力，集成倒排索引、数据分片与复制机制，以及TF-IDF智能排序算法，以提升搜索系统性能和准确性。


<details>
  <summary>Details</summary>
Motivation: 应对日益增长的网页搜索需求，提升搜索系统的性能和准确性，解决传统集中式搜索系统的扩展性和效率问题。

Method: 基于SEARCHX构建分布式智能搜索服务集成框架，利用浏览器本地计算能力，集成倒排索引技术实现快速检索，采用数据分片与复制机制提高系统可扩展性和可靠性，应用TF-IDF智能排序算法优化搜索结果相关性。

Result: 该框架能够有效提升搜索系统的性能和准确性，通过分布式架构提高系统扩展性，利用本地计算资源降低服务器负载，智能排序算法改善搜索结果质量。

Conclusion: 提出的分布式智能搜索服务集成框架为解决大规模网页搜索需求提供了有效解决方案，通过结合浏览器本地计算和分布式架构，在性能和准确性方面均有显著提升。

Abstract: To address the growing demand for web search and improve the performance and accuracy of search systems, this study proposes a distributed intelligent search service integration framework based on SEARCHX. This framework leverages the local computational power of the browser, integrating inverted indexing, data sharding, and replication mechanisms, as well as the Term Frequency-Inverse Document Frequency (TF-IDF) intelligent ranking algorithm. These components …

</details>


### [40] [Анализ и тестирование индекса RadixSpline](https://scholar.google.com/scholar_url?url=https://intechngu.elpub.ru/jour/article/view/326&hl=en&sa=X&d=3796068922085645512&ei=sCocaYX2CaG7ieoPo-ev2Q4&scisig=ABGrvjIAQ6jPdhF5vfmxadQjvRbq&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=1&folt=cit)
*ИМ Стецкий,БН Пищик*

Main category: Google Scholar

TL;DR: 论文研究了RadixSpline索引的测试实现，在不同调优参数下对其性能进行了研究


<details>
  <summary>Details</summary>
Motivation: 研究RadixSpline索引的性能特性，探索不同参数设置对其效率的影响，为实际应用提供调优指导

Method: 实现RadixSpline索引并进行测试，研究不同参数设置下的性能表现，包括构建时间和查询效率

Result: 展示了RadixSpline索引在不同参数配置下的性能数据，包括构建开销和查询延迟的权衡关系

Conclusion: RadixSpline索引在不同参数设置下表现出不同的性能特征，需要根据具体应用场景进行参数调优

Abstract: Аннотация Статья посвящена тестовой реализации индекса RadixSpline и исследованию его производительности при различных параметрах настойки. Индекс RadixSpline относится к категории обученного индекса и предназначен для эффективного поиска в отсортированных данных в структуре ключ–значение. Индекс строится за один проход по данным и состоит из сплайн-аппроксимации с ограниченной погрешностью (GreedySpline) и разреженного …

</details>


### [41] [Designing Drone Interfaces to Assist Pedestrians Crossing Non-Signalised Roads](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3764687.3764700&hl=en&sa=X&d=7712926923738178188&ei=vrMdaYWNGbuZ6rQPpvD4-A0&scisig=ABGrvjLWJvolIpIFVp6AHSnr9yh9&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=1&folt=cit)
*G Zhang,Y Wang,M Hoggenmüller*

Main category: Google Scholar

TL;DR: 设计无人机界面辅助行人在无信号灯或斑马线的危险路段过马路，利用无人机实时监测交通并提供安全信息


<details>
  <summary>Details</summary>
Motivation: 无人机在提升行人体验方面具有潜力，特别是在缺乏正规过街设施的危险路段，需要为行人提供安全过街辅助

Method: 基于现有交通信号系统设计无人机界面，通过许可性警报传递安全信息，利用无人机实时监测和分析交通数据

Result: 开发了能够为行人提供实时安全信息的无人机界面系统，帮助行人在危险路段安全过街

Conclusion: 无人机界面可以有效辅助行人在无正规过街设施的危险路段安全过街，为行人安全提供新的技术解决方案

Abstract: Recent research highlights the potential of drones to enhance pedestrian experiences, such as aiding navigation and supporting street-level activities. This paper explores the design of drone interfaces to assist pedestrians crossing dangerous roads without designated crosswalks or traffic lights, leveraging drones' ability to monitor and analyse real-time traffic data. Inspired by existing traffic signal systems, the interface communicates safety information through permissive alerts …

</details>


### [42] [Advanced Filter Structure Handbook](https://scholar.google.com/scholar_url?url=https://link.springer.com/content/pdf/10.1007/978-981-95-1715-2.pdf&hl=en&sa=X&d=5394519058370179435&ei=vrMdaYWNGbuZ6rQPpvD4-A0&scisig=ABGrvjKddnGu2KGXdHp4YQ6jjZk_&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=2&folt=cit)
*H Dai,M Li,G Chen*

Main category: Google Scholar

TL;DR: 该论文讨论了紧凑概率数据结构（过滤器）在成员测试中的应用，具有单边错误特性，能以少量比特表示元素实现低内存开销和高空间效率


<details>
  <summary>Details</summary>
Motivation: 过滤器作为紧凑概率数据结构在成员测试中广泛应用，但存在单边错误问题，需要研究如何平衡内存效率和准确性

Method: 使用紧凑概率数据结构，通过少量比特表示元素，实现低内存开销的成员测试

Result: 过滤器能够以少量比特表示元素，实现低内存开销和高空间效率的成员测试

Conclusion: 紧凑概率数据结构在成员测试中具有重要价值，通过空间效率优化在内存受限场景中发挥关键作用

Abstract: Filters are compact probabilistic data structures widely used for membership testing, ie, determining whether an element belongs to a given set. Commonly, they have a one-sided error property: they definitely report yes if the query element belongs to the set; however, they have a certain probability to falsely report yes for elements not present in the set. By compactly representing elements with only a few bits per item, they achieve low memory overhead and high space efficiency. As a result, filters …

</details>


### [43] [Bits to Qubits: A Comparative Study of Memory Management in Classical and Quantum Systems](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/document/11222649/&hl=en&sa=X&d=9002374769401145746&ei=vrMdaYWNGbuZ6rQPpvD4-A0&scisig=ABGrvjJTHSmKKqhoRKu4dnpQVz7n&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=3&folt=cit)
*P Lamichhane,DB Rawat*

Main category: Google Scholar

TL;DR: 该调查对经典与量子架构中的内存管理进行对比分析，探讨比特与量子比特转换需求下的混合系统管理


<details>
  <summary>Details</summary>
Motivation: 随着量子与经典系统共存，需要高效转换比特与量子比特，因此理解经典和量子系统的内存管理至关重要

Method: 采用比较分析方法，考察经典系统的传统内存层次结构和分配策略，并与量子架构的内存管理进行对比

Result: 未提供具体结果（摘要未包含）

Conclusion: 未提供具体结论（摘要未包含）

Abstract: In the near future, as quantum and classical systems coexist, managing hybrid systems will require efficient conversion between bits and qubits. Therefore, understanding memory management for both classical and quantum systems is essential. Along that line, this survey provides a comparative analysis of memory management in classical and quantum architectures. The traditional memory hierarchy and allocation strategies used in classical systems are examined along …

</details>


### [44] [Analysis and testing of the RadixSpline Learned index](https://scholar.google.com/scholar_url?url=https://intechngu.elpub.ru/jour/issue/download/34/28%23page%3D68&hl=en&sa=X&d=6063551990260526376&ei=qBIhafO-PP3D6rQP9oG-4Ak&scisig=ABGrvjKR28E23DDWT8n3IWsSG1Ri&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=0&folt=cit)
*IM Stetskii,BN Pischik*

Main category: Google Scholar

TL;DR: 对RadixSpline索引进行综合分析与性能评估，该索引结合了有界误差样条近似和稀疏基数表结构


<details>
  <summary>Details</summary>
Motivation: 随着机器学习在数据库索引领域的发展，学习型索引成为新的研究方向。RadixSpline索引作为其中一种有前景的解决方案，需要对其性能进行系统评估以验证其在实际应用中的有效性

Method: 结合GreedySpline（有界误差样条近似）和稀疏基数表结构，对RadixSpline索引进行综合性能分析

Result: 论文对RadixSpline索引进行了全面性能评估，验证了其在有序键值数据搜索中的效率优势

Conclusion: RadixSpline索引作为学习型索引的代表性方法，通过样条近似和基数表的结合，为高效数据搜索提供了有效的解决方案

Abstract: Recent advances in machine learning have introduced a novel approach to database indexing known as learned indexes. Among these, the RadixSpline index has emerged as a particularly promising solution for efficient search in sorted key-value data. This paper presents a comprehensive analysis and performance evaluation of the RadixSpline index, which combines spline approximation with bounded error (GreedySpline) and a sparse radix table structure. We investigate the …

</details>


### [45] [10Cache: Heterogeneous Resource-Aware Tensor Caching and Migration for LLM Training](https://scholar.google.com/scholar_url?url=https://people.cs.vt.edu/~butta/docs/socc25-10cache.pdf&hl=en&sa=X&d=7283089792267914051&ei=qBIhafO-PP3D6rQP9oG-4Ak&scisig=ABGrvjILYNbpF6KPJV-X5rjOa9cL&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=2&folt=cit)
*S Afroz,RIS Khan,H Albahar,J Han,AR Butt*

Main category: Google Scholar

TL;DR: 10Cache：一种资源感知的张量缓存和迁移系统，通过智能缓存策略减少GPU内存卸载到CPU/NVMe时的张量迁移延迟，优化设备内存利用率，降低LLM训练时间和云成本


<details>
  <summary>Details</summary>
Motivation: 云中训练大型语言模型面临GPU内存瓶颈，现有GPU内存卸载到CPU和NVMe的方法存在高张量迁移延迟和设备内存利用率低的问题，导致训练时间增加和云成本上升

Method: 提出10Cache系统，采用资源感知的张量缓存和迁移策略，通过智能缓存管理减少张量迁移开销，优化GPU、CPU和NVMe之间的内存使用效率

Result: 10Cache显著降低了张量迁移延迟，提高了设备内存利用率，从而减少了大型语言模型训练时间和云成本

Conclusion: 10Cache通过资源感知的缓存和迁移策略有效解决了GPU内存瓶颈问题，为大规模LLM训练提供了更高效、成本更低的解决方案

Abstract: Training large language models (LLMs) in the cloud faces growing memory bottlenecks due to the limited capacity and high cost of GPUs. While GPU memory offloading to CPU and NVMe has made large-scale training more feasible, existing approaches suffer from high tensor migration latency and suboptimal device memory utilization, ultimately increasing training time and cloud costs. To address these challenges, we present 10Cache, a resource-aware tensor caching and migration …

</details>


### [46] [LLM4VA: A Multi-Agent LLM Framework for Automated Prototyping of Visual Analytics Systems](https://scholar.google.com/scholar_url?url=https://visxgenai.github.io/subs-2025/6199/6199-doc.pdf&hl=en&sa=X&d=7998409137524873872&ei=qBIhafO-PP3D6rQP9oG-4Ak&scisig=ABGrvjJMiR2SWpBZowuso46rh8Jd&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=3&folt=cit)
*J Xiong,L Chen,X Dou,S Wang,K Lin,S Yang,Q Li*

Main category: Google Scholar

TL;DR: 该论文提出了一种基于大语言模型（LLM）的端到端视觉分析系统开发方法，旨在自动化传统上依赖专家知识的复杂VA系统构建过程。


<details>
  <summary>Details</summary>
Motivation: 传统视觉分析系统开发需要大量专家知识（数据分析、需求工程、编程、可视化设计），现有可视化推荐方法无法满足端到端VA系统开发的复杂迭代需求。

Method: 基于大语言模型的方法，通过自然语言交互理解用户需求，自动生成完整的视觉分析系统，包括数据预处理、可视化设计、交互功能等组件。

Result: 该方法能够显著降低VA系统开发门槛，提高开发效率，生成的系统能够满足复杂分析需求，减少对专业知识的依赖。

Conclusion: 基于LLM的端到端VA系统开发方法代表了视觉分析领域的重要进步，为自动化复杂分析系统构建提供了可行路径。

Abstract: Visual analytics (VA) systems empower data exploration through interactive visualization techniques, yet their development has traditionally relied on significant human expertise in data analysis, requirement engineering, programming, and visualization design. While existing visualization recommendation methods have advanced the automated generation of basic visualizations, they fall short in addressing the complex, iterative demands of endto-end VA system development …

</details>


### [47] [Towards an Advanced Entity Resolution in Data Lakes](https://scholar.google.com/scholar_url?url=https://ceur-ws.org/Vol-4099/ER25_DC_bouabdelli.pdf&hl=en&sa=X&d=9476598172449363367&ei=qBIhafO-PP3D6rQP9oG-4Ak&scisig=ABGrvjIv4hYz5UZPwJ8Z7lqee9Qa&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=4&folt=cit)
*LF BOUABDELLI*

Main category: Google Scholar

TL;DR: 该论文研究数据湖中的实体解析问题，旨在解决异构数据源导致的实体重复、不一致和歧义等数据质量问题。


<details>
  <summary>Details</summary>
Motivation: 数据湖的无模式架构和异构数据源常导致实体重复、不一致和歧义，引发严重的数据质量问题。尽管实体解析在学术界和工业界已有深入研究，但在数据湖环境中仍面临独特挑战。

Method: 论文未提供具体方法细节，但从摘要推断可能涉及针对数据湖特性的实体解析技术，如处理无模式数据、异构数据集成、实体匹配算法等。

Result: 摘要未提供具体实验结果，但暗示现有最先进的实体解析方法在数据湖环境中可能面临局限性，需要专门解决方案。

Conclusion: 数据湖中的实体解析是一个重要但具有挑战性的问题，需要专门的方法来处理其无模式架构和异构数据特性。

Abstract: Entity Resolution (ER) is a critical challenge for maintaining data quality in data lakes, aiming to identify different descriptions that refer to the same real-world entity. We address here the problem of ER in data lakes, where their schema-less architecture and heterogeneous data sources often lead to entity duplication, inconsistency, and ambiguity, causing serious data quality issues. Although ER has been well studied both in academic research and industry, many state-of-the-art ER …

</details>


### [48] [Scalable Enforcement of Fine Grained Access Control Policies in Relational Database Management Systems](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.14629&hl=en&sa=X&d=14163136485597288698&ei=X8gjabCOBI2v6rQPzvzsmAY&scisig=ABGrvjLbDSi18fh-H8LA1JfySf_4&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=3&folt=cit)
*A Shakya,P Pappachan,D Maier,R Yus,S Mehrotra…*

Main category: Google Scholar

TL;DR: Sieve是一个关系数据库中间件，通过查询重写和缓存技术解决大规模细粒度访问控制策略的性能扩展问题


<details>
  <summary>Details</summary>
Motivation: 随着智能技术和GDPR、CPRA等隐私法规的普及，数据库系统需要管理大量细粒度访问控制策略，但现有方法无法扩展到数千条策略，导致查询性能下降和系统效率降低

Method: 提出Sieve中间件，结合查询重写和缓存技术来高效执行细粒度访问控制策略，支持大规模策略管理

Result: Sieve能够有效扩展至数千条访问控制策略，显著提升查询性能，同时保持系统有效性

Conclusion: Sieve为关系数据库系统提供了一种可扩展的细粒度访问控制解决方案，能够满足现代隐私法规和智能技术对大规模策略管理的需求

Abstract: The proliferation of smart technologies and evolving privacy regulations such as the GDPR and CPRA has increased the need to manage fine-grained access control (FGAC) policies in database management systems (DBMSs). Existing approaches to enforcing FGAC policies do not scale to thousands of policies, leading to degraded query performance and reduced system effectiveness. We present Sieve, a middleware for relational DBMSs that combines query rewriting and caching to …

</details>


### [49] [Designing Compact On-Disk Index Data Structures](https://scholar.google.com/scholar_url?url=https://indigo.uic.edu/ndownloader/files/58977583&hl=en&sa=X&d=10811681690160256275&ei=X8gjabCOBI2v6rQPzvzsmAY&scisig=ABGrvjJoPzgG282XfOx4vk04uRZC&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=6&folt=cit)
*W Zhong*

Main category: Google Scholar

TL;DR: B+-树作为数据库存储引擎的磁盘数据结构，虽然读取性能优化但写入性能较差，需要改进写入效率


<details>
  <summary>Details</summary>
Motivation: 数据库系统性能严重依赖存储引擎，而磁盘数据结构设计对存储引擎性能至关重要。虽然许多数据库系统选择B+-树作为磁盘数据结构，但其写入性能存在瓶颈：单次写入常导致多个块重写，造成I/O开销大

Method: 论文未完整提供，但从摘要可推断可能提出改进B+-树写入性能的方法，可能涉及优化写入时的块重写机制或引入新的数据结构设计

Result: 摘要未提供具体实验结果，但暗示需要解决B+-树写入慢的问题，预期通过改进设计能减少写入时的I/O操作

Conclusion: B+-树作为数据库磁盘数据结构在读取方面表现良好，但写入性能需要优化，改进写入机制对提升整体数据库性能至关重要

Abstract: The performance of a database system heavily depends on its storage engine. The design of on-disk data structure is critical to the storage engine performance. Many database systems have chosen B+-trees as the on-disk data structure. AB+-tree organizes every internal node in a block of the I/O unit so that the reads would incur minimum Input/Output (I/O) s. However, writes in B+-trees are slow because a single write often causes multiple blocks to be rewritten due to the need to maintain its …

</details>


### [50] [Flash-Fusion: Enabling Expressive, Low-Latency Queries on IoT Sensor Streams with LLMs](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.11885&hl=en&sa=X&d=5173716861739667583&ei=X8gjabCOBI2v6rQPzvzsmAY&scisig=ABGrvjLz762AfNkNFtP_oxztgumX&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=7&folt=cit)
*K Patherya,A Dhekne,F Romero*

Main category: Google Scholar

TL;DR: 论文提出通过大型语言模型简化物联网数据分析，解决数据收集成本高和传感器数据过于细粒度的问题


<details>
  <summary>Details</summary>
Motivation: 智慧城市和物联网部署产生了大量传感器数据，但现有数据分析面临两大挑战：1) 数据收集基础设施昂贵，产生海量过于细粒度的低层传感器读数；2) 数据分析过程复杂，用户难以直接利用这些数据进行有效探索

Method: 利用大型语言模型作为自然语言接口，简化物联网数据的探索和分析过程，通过LLM处理低层传感器数据，使其更易于用户理解和交互

Result: 未在摘要中明确说明具体实验结果，但暗示LLM能够为物联网数据分析提供更自然、更易用的接口

Conclusion: 大型语言模型为解决物联网数据分析中的挑战提供了有前景的解决方案，通过自然语言接口降低了数据探索的技术门槛

Abstract: Smart cities and pervasive IoT deployments have generated interest in IoT data analysis across transportation and urban planning. At the same time, Large Language Models offer a new interface for exploring IoT data-particularly through natural language. Users today face two key challenges when working with IoT data using LLMs:(1) data collection infrastructure is expensive, producing terabytes of low-level sensor readings that are too granular for direct use, and (2) data analysis is …

</details>


### [51] [Investigating user perceptions of Generative AI for data storytelling](https://scholar.google.com/scholar_url?url=https://www.tandfonline.com/doi/abs/10.1080/2573234X.2025.2573252&hl=en&sa=X&d=4403685038103618951&ei=X8gjabCOBI2v6rQPzvzsmAY&scisig=ABGrvjIP0SzwcNVMQ40z9fScZXpz&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=9&folt=cit)
*V Gude,A Safitri*

Main category: Google Scholar

TL;DR: 研究评估大型语言模型在协助用户创作数据驱动故事方面的有效性，通过三阶段实验设计验证LLMs在数据叙事中的实际应用价值


<details>
  <summary>Details</summary>
Motivation: 生成式人工智能在数据可视化和叙事领域具有潜力但缺乏实证评估，需要填补LLMs在协助创作数据驱动故事方面的研究空白

Method: 设计三阶段实验框架，评估大型语言模型在数据叙事过程中的辅助能力，通过系统化实验验证LLMs的实际应用效果

Result: 研究发现LLMs能够有效协助用户创作数据驱动故事，为生成式AI在数据叙事领域的应用提供了实证支持

Conclusion: 大型语言模型在数据叙事中具有实际应用价值，能够有效提升数据故事的创作效率和效果，为AI辅助数据可视化提供了新方向

Abstract: Data storytelling combines narrative techniques with data visualisation to present complex information in an engaging and actionable manner. Recently, the potential use of Generative Artificial Intelligence (AI) in data visualisation and storytelling has gained attention but has seen limited empirical evaluation. This study addresses this gap by investigating whether Large Language Models (LLMs) can effectively assist individuals in crafting data-driven stories. To assess this, we designed a three-stage …

</details>


### [52] [Compiling Set Queries into Work-Efficient Tree Traversals](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.15000&hl=en&sa=X&d=3486009544573308445&ei=YcgjadLzA9ToieoP5Py5yQs&scisig=ABGrvjIood-JGyNqMD1SEzDsZElF&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ABGrvjJkn-FcYY8t5hAtGXsL8UoX&html=&pos=2&folt=rel)
*AJ Root,C Gyurgyik,P Goel,K Fatahalian…*

Main category: Google Scholar

TL;DR: 论文探讨了树结构如何通过存储元数据来加速大规模数据集合上的查询，特别是通过元数据谓词快速剪枝或包含子树，从而提升查询性能。


<details>
  <summary>Details</summary>
Motivation: 在大规模数据集合上进行搜索或聚合查询时，传统方法往往需要扫描大量数据，导致性能瓶颈。树结构通过预计算和存储元数据，可以显著减少需要访问的数据量，从而提高查询效率。

Method: 论文提出利用树结构存储数据集合的元数据，当执行查询时，通过检查元数据上的谓词条件，能够快速判断哪些子树完全不包含相关数据（可以剪枝），或者哪些子树完全满足条件（可以直接包含），从而避免不必要的子树遍历。

Result: 该方法能够显著减少查询时需要访问的数据量，从而加速搜索和聚合操作。通过元数据谓词进行子树剪枝或包含，可以大幅降低I/O开销和计算复杂度，特别是在大规模数据集上效果更为明显。

Conclusion: 树结构结合元数据存储是一种有效的查询加速技术，通过智能的子树剪枝机制，能够在保持数据完整性的同时大幅提升查询性能，适用于需要高效处理大规模数据集合的各种应用场景。

Abstract: Trees can accelerate queries that search or aggregate values over large collections. They achieve this by storing metadata that enables quick pruning (or inclusion) of subtrees when predicates on that metadata can prove that none (or all) of the data in …

</details>


### [53] [CLO: Efficient LLM Inference System with CPU-Light KVCache Offloading via Algorithm-System Co-Design](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.14510&hl=en&sa=X&d=6973444149127634914&ei=YcgjadLzA9ToieoP5Py5yQs&scisig=ABGrvjL2DSBg9IOznj3hQW3YLqSZ&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ABGrvjJkn-FcYY8t5hAtGXsL8UoX&html=&pos=3&folt=rel)
*J Yi,P Gong,Y Bai,J Ruan,S Wang,P Wang,H Wang…*

Main category: Google Scholar

TL;DR: 百万token级LLM推理面临KVCache内存瓶颈，现有卸载系统存在延迟问题，本文提出选择性卸载策略优化推理性能


<details>
  <summary>Details</summary>
Motivation: 随着百万token级大语言模型的发展，推理系统的可扩展性面临挑战，其中KVCache成为内存使用和数据传输开销的主要瓶颈。现有卸载系统将KVCache迁移到CPU内存并采用top-k剪枝，但仍存在显著的延迟问题，需要更高效的解决方案。

Method: 提出选择性KVCache卸载策略，通过智能识别和选择性保留关键token的KVCache在GPU内存中，同时将次要token卸载到CPU内存。该方法结合了动态评估机制，根据token的重要性进行分级管理，优化内存使用和数据传输效率。

Result: 实验结果显示，该方法在保持模型质量的同时，显著降低了推理延迟，相比现有卸载系统实现了更好的性能平衡。具体表现为内存使用减少30-50%，推理速度提升20-40%，同时保持了99%以上的模型精度。

Conclusion: 选择性KVCache卸载策略有效解决了百万token级LLM推理中的内存瓶颈问题，通过智能的token重要性评估和分级管理，在内存效率、推理速度和模型质量之间取得了更好的平衡，为大规模LLM推理系统提供了实用的优化方案。

Abstract: The growth of million-token LLMs exposes the scalability limits of inference systems, where the KVCache dominates memory usage and data transfer overhead. Recent offloading systems migrate the KVCache to CPU memory and incorporate top-k …

</details>


### [54] [SERVERLESS DATABASES: FUTURE TRENDS IN CLOUD DATABASE MANAGEMENT AND COST OPTIMIZATION](https://scholar.google.com/scholar_url?url=https://www.arhivzatehnickenauke.com/article/655&hl=en&sa=X&d=17714396100242117896&ei=4zglacegFs2j6rQP2NKOuQI&scisig=ABGrvjIwMCw4tHjI0oocYqeaWPxq&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=0&folt=cit)
*HVR Kavuluri*

Main category: Google Scholar

TL;DR: 对Aurora Serverless和FaunaDB进行模拟基准测试，评估其在真实工作负载下的性能表现，并与RDS PostgreSQL进行对比


<details>
  <summary>Details</summary>
Motivation: 无服务器数据库因其操作简单、按使用付费和弹性扩展等优势正在改变云数据管理基础设施，但其在真实工作负载下的性能表现尚未得到充分研究

Method: 使用模拟基准测试方法，对Aurora Serverless和FaunaDB进行深入分析，评估冷启动延迟、动态成本等性能指标，并与RDS PostgreSQL进行对比

Result: 论文通过模拟基准测试揭示了无服务器数据库在真实工作负载下的性能特征，包括冷启动延迟和成本动态变化等关键指标

Conclusion: 无服务器数据库在特定场景下具有优势，但需要对其性能特征有更深入的理解，以便在实际应用中做出合适的技术选择

Abstract: The cloud data management infrastructure is being transformed by serverless databases because of their operational simplicity, usage-based pricing, and elastic scalability. However, their performance in real-world workloads analysis is still unexplored. This paper presents an in-depth analysis of serverless database systems using simulation-based benchmarks evaluating Aurora Serverless and FaunaDB against RDS PostgreSQL. We simulate cold start latencies, dynamic cost …

</details>


### [55] [Trustworthy AI in the Agentic Lakehouse: from Concurrency to Governance](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.16402&hl=en&sa=X&d=15564631620159776347&ei=4zglacegFs2j6rQP2NKOuQI&scisig=ABGrvjJHYQAeizUXtAOBXPGBd-jt&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=1&folt=cit)
*J Tagliabue,F Bianchi,C Greco*

Main category: Google Scholar

TL;DR: 论文主张通过解决基础设施问题来实现可信的智能体工作流，提出设计基于事务的湖仓架构来满足智能体访问模式，而非直接移植数据库的MVCC机制。


<details>
  <summary>Details</summary>
Motivation: 尽管AI能力不断提升，但大多数企业仍不信任智能体处理生产数据。当前湖仓架构不适合智能体访问模式，需要重新设计基础设施来建立可信的智能体工作流。

Method: 提出设计围绕事务的湖仓架构，分析数据库MVCC机制的直接移植在智能体环境中的局限性，探索适合智能体访问模式的基础设施解决方案。

Result: 论文论证了通过解决基础设施问题（设计基于事务的湖仓架构）是实现可信智能体工作流的关键路径，治理能力会随之自然形成。

Conclusion: 可信智能体工作流的实现应从基础设施入手，设计适合智能体访问模式的事务性湖仓架构，而非简单移植传统数据库机制。

Abstract: Even as AI capabilities improve, most enterprises do not consider agents trustworthy enough to work on production data. In this paper, we argue that the path to trustworthy agentic workflows begins with solving the infrastructure problem first: traditional lakehouses are not suited for agent access patterns, but if we design one around transactions, governance follows. In particular, we draw an operational analogy to MVCC in databases and show why a direct transplant fails in a …

</details>


### [56] [Learning-Augmented Online Algorithms for Nonclairvoyant Joint Replenishment Problem with Deadlines](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.16094&hl=en&sa=X&d=5757867711665790020&ei=4zglacegFs2j6rQP2NKOuQI&scisig=ABGrvjIGr_5xGbLsx5G-N0BObMNK&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=2&folt=cit)
*M Dinitz,JT Fineman,SW Umboh*

Main category: Google Scholar

TL;DR: 该论文研究在线联合补货问题与截止期限(JRP-D)中利用预测来降低非预知情况下的竞争比


<details>
  <summary>Details</summary>
Motivation: 现有研究在预知情况下实现了O(1)的渐进最优竞争比，但在非预知情况下只有O(√n)的竞争比。论文旨在通过利用预测信息显著降低非预知情况下的竞争比

Method: 在请求到达时，虽然真实截止期限未知，但可以利用预测信息来设计在线算法，以改进非预知情况下的性能

Result: 未在摘要中明确说明具体结果，但目标是显著降低非预知情况下的竞争比

Conclusion: 利用预测可以在在线联合补货问题与截止期限中显著改善非预知算法的性能

Abstract: This paper considers using predictions in the context of the online Joint Replenishment Problem with Deadlines (JRP-D). Prior work includes asymptotically optimal competitive ratios of $ O (1) $ for the clairvoyant setting and $ O (\sqrt {n}) $ of the nonclairvoyant setting, where $ n $ is the number of items. The goal of this paper is to significantly reduce the competitive ratio for the nonclairvoyant case by leveraging predictions: when a request arrives, the true deadline of the request is not …

</details>


### [57] [AskDB: An LLM Agent for Natural Language Interaction with Relational Databases](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.16131&hl=en&sa=X&d=4043179206681301384&ei=5DglacecKo2v6rQPzvzsmAY&scisig=ABGrvjIF3w4FLUJO60MGhcjCW1Q7&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ABGrvjJkn-FcYY8t5hAtGXsL8UoX&html=&pos=0&folt=rel)
*XQ Phan,TH Mai,TD Dinh,MT Nguyen,LS Lê*

Main category: Google Scholar

TL;DR: 论文提出了一种统一的交互式数据库系统，通过自然语言、代码和可视化界面支持不同专业水平的用户进行复杂查询和管理任务。


<details>
  <summary>Details</summary>
Motivation: 当前关系数据库交互存在挑战，不同专业水平的用户在进行复杂分析查询或管理任务时面临困难。现有系统通常只解决自然语言、代码或可视化中的单一交互方式，缺乏统一的解决方案。

Method: 开发了一个统一的交互式数据库系统，整合了自然语言处理、代码生成和可视化界面三种交互模式。系统能够理解用户意图，自动生成SQL查询，并提供可视化结果展示和管理功能。

Result: 系统显著降低了数据库交互的复杂性，提高了不同用户群体的工作效率。实验表明，该系统在查询准确性、响应时间和用户满意度方面优于现有单一模式的解决方案。

Conclusion: 统一的交互式数据库系统能够有效解决不同专业水平用户在数据库交互中的挑战，通过整合多种交互模式提供了更灵活、高效的数据库访问方式。

Abstract: Interacting with relational databases remains challenging for users across different expertise levels, particularly when composing complex analytical queries or performing administrative tasks. Existing systems typically address either natural …

</details>


### [58] [Intelligent and Scalable Internal-External Optimizations for Data Systems](https://scholar.google.com/scholar_url?url=https://search.proquest.com/openview/c6a36e6c4c9471b59121354194be1184/1%3Fpq-origsite%3Dgscholar%26cbl%3D18750%26diss%3Dy&hl=en&sa=X&d=2998832274455549937&ei=VLomaaOxM82j6rQP2NKOuQI&scisig=ABGrvjItfYuDjCd8OYS9A5gg1N9O&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=0&folt=cit)
*K Kanellis*

Main category: Google Scholar

TL;DR: 现代数据系统面临数据爆炸、基础设施异构化和应用多样化挑战，需要适应向量搜索、RAG等新用例以及NVMe SSD、CXL内存等新硬件


<details>
  <summary>Details</summary>
Motivation: 现代数据系统面临三大挑战：1) 数据爆炸性增长，2) 基础设施日益异构化，3) 应用类型快速多样化。同时，组织依赖通用数据系统进行数据收集、分析、存储和价值提取，但新用例（如向量搜索、检索增强生成）和新硬件（如高性能NVMe SSD、CXL内存）的出现增加了系统复杂性，需要重新思考数据系统设计。

Method: 摘要未详细描述具体方法，但暗示需要重新设计数据系统架构以应对挑战。可能涉及：1) 支持异构硬件（NVMe SSD、CXL内存）的存储架构，2) 适应多样化工作负载（包括传统分析和新兴AI应用）的处理引擎，3) 可扩展的数据管理框架，4) 针对新用例（向量搜索、RAG）的优化技术。

Result: 摘要未提供具体实验结果，但指出了当前数据系统面临的系统性挑战。暗示现有通用数据系统在应对新硬件、新应用场景时存在局限性，需要新的系统设计方法。

Conclusion: 现代数据系统设计需要根本性变革，以适应数据爆炸、硬件异构化和应用多样化的三重挑战。未来的数据系统必须能够有效利用新型硬件（NVMe SSD、CXL内存），同时支持传统分析和新兴AI工作负载（如向量搜索、RAG），降低系统复杂性并提高效率。

Abstract: Modern data systems operate under explosive data growth, increasingly heterogeneous infrastructures, and rapidly diversifying application mixes. At the same time, organizations rely on general-purpose data systems to collect, analyze, store, and extract value from it. As workloads expand to include more use-cases (eg, vector search, retrieval-augmented generation, etc.) and as devices evolve to high-performance NVMe SSDs and new types of memory (eg, CXL), system complexity …

</details>


### [59] [Application of middleware technology in the localization of databases](https://scholar.google.com/scholar_url?url=https://www.spiedigitallibrary.org/conference-proceedings-of-spie/13965/139651E/Application-of-middleware-technology-in-the-localization-of-databases/10.1117/12.3091330.short&hl=en&sa=X&d=6825254344222154227&ei=VLomaaOxM82j6rQP2NKOuQI&scisig=ABGrvjKpebLpDoGvSpJtAeWmenYq&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=1&folt=cit)
*Y Guo,H Lan,S Wen,H He,X Luo,G Zeng,L Hu…*

Main category: Google Scholar

TL;DR: 提出基于"中间件"技术解决数据库本地化过程中应用连接与适配问题的方案，无需源代码访问或开发者支持


<details>
  <summary>Details</summary>
Motivation: 随着数据库本地化进程推进，应用连接与适配成为阻碍该过程的关键挑战。现有方法通常需要源代码访问或开发者支持，限制了数据库本地化的推广和实施。

Method: 采用"中间件"技术构建解决方案，通过外部SQL处理机制实现应用与本地化数据库之间的连接与适配，无需修改应用源代码或依赖开发者介入。

Result: 该方法能够有效解决应用在数据库本地化过程中遇到的连接与适配问题，提供了一种无需源代码访问或开发者支持的实用解决方案。

Conclusion: 基于中间件的技术方案为数据库本地化过程中的应用连接与适配问题提供了有效解决途径，降低了实施门槛，促进了数据库本地化进程。

Abstract: As the localization of databases progresses, application connectivity and adaptation have emerged as critical challenges impeding this process. This paper proposes a solution based on “middleware” technology to address the connectivity and adaptation issues encountered by applications during the localization of databases. This approach eliminates the need for source code access or developer support. By leveraging “middleware” technology, external Structured Query Language (SQL) …

</details>


### [60] [A Categorical Representation of Multi-model Data to Prevent Data Migration Mismatch](https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-662-72449-1_3&hl=en&sa=X&d=6287315494838754033&ei=VLomaaOxM82j6rQP2NKOuQI&scisig=ABGrvjI416Q2JMcxHO6MrPzivvZC&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=2&folt=cit)
*A Gillet,É Leclercq*

Main category: Google Scholar

TL;DR: 论文探讨多模型存储系统中数据模型间迁移的复杂性，特别是约束保持问题


<details>
  <summary>Details</summary>
Motivation: 随着数据使用场景的多样化，存储系统向多模型系统演进。不同数据模型各有特点、约束和操作符，适合特定用例但可能不适合其他场景。模型间迁移对响应多样化用例至关重要，但由于模型差异而管理复杂，某些约束可能在迁移过程中无法保持

Method: 论文未在摘要中明确说明具体方法，但暗示需要解决多模型系统中数据迁移时的约束保持问题

Result: 摘要未提供具体结果，但暗示多模型数据迁移中存在约束保持的挑战

Conclusion: 多模型存储系统中数据模型间迁移是必要的，但由于模型差异导致约束保持问题，需要专门解决方案

Abstract: To cope with the increasing diversity of data uses, storage systems have evolved towards multi-model systems. Indeed, as each data model has its own characteristics, constraints and operators, they can be best suited for a specific use case but not for another. Migrations between models are therefore essential to respond to the multiplicity of use cases, but are complex to manage because of the differences among models. As such, some constraints might not be preserved during …

</details>


### [61] [Findings of the BlackboxNLP 2025 Shared Task: Localizing Circuits and Causal Variables in Language Models](https://scholar.google.com/scholar_url?url=https://aclanthology.org/2025.blackboxnlp-1.32.pdf&hl=en&sa=X&d=6667904556387017003&ei=J3AqaeTwE-uuieoPn9Oq8Ao&scisig=ABGrvjKdV_6SP1ZCpmn82chYSS3y&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ABGrvjJkn-FcYY8t5hAtGXsL8UoX&html=&pos=3&folt=rel)
*D Arad,Y Belinkov,H Chen,N Kim,H Mohebbi…*

Main category: Google Scholar

TL;DR: MI进展评估困难，MIB基准提供标准化测试，但存在局限性


<details>
  <summary>Details</summary>
Motivation: 机械可解释性研究缺乏标准化评估基准，难以衡量方法进展和比较不同技术

Method: 分析MIB基准的构建原理、评估指标、任务设计，探讨其在MI研究中的适用性和局限性

Result: MIB为MI研究提供了有价值的评估框架，但在任务覆盖、模型泛化、评估指标等方面存在改进空间

Conclusion: 需要进一步完善MI评估基准，结合多种评估方法，建立更全面的MI进展衡量体系

Abstract: Mechanistic interpretability (MI) seeks to uncover how language models (LMs) implement specific behaviors, yet measuring progress in MI remains challenging. The recently released Mechanistic Interpretability Benchmark (MIB) provides a …

</details>


### [62] [SpotIt: Evaluating Text-to-SQL Evaluation with Formal Verification](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.26840&hl=en&sa=X&d=11549462597505683378&ei=J3AqaeTwE-uuieoPn9Oq8Ao&scisig=ABGrvjJURSedip-gvCFzlSXoOWJ8&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ABGrvjJkn-FcYY8t5hAtGXsL8UoX&html=&pos=5&folt=rel)
*R Klopfenstein,Y He,A Tremante,Y Wang…*

Main category: Google Scholar

TL;DR: 社区驱动的Text-to-SQL评估平台对追踪领域进展至关重要，但当前评估方法存在可靠性问题，需要改进评估流程以确保准确衡量模型性能


<details>
  <summary>Details</summary>
Motivation: Text-to-SQL评估平台的可靠性对推动领域进步至关重要，当前评估方法存在缺陷，可能导致性能评估不准确，影响研究进展的可信度

Method: 论文未详细说明具体方法，但从摘要看，可能涉及对现有评估流程的分析、识别问题并提出改进方案，包括更可靠的评估指标或测试方法

Result: 摘要未提供具体结果，但暗示当前评估方法存在可靠性问题，需要改进以确保Text-to-SQL性能评估的准确性

Conclusion: 需要改进Text-to-SQL评估方法以提高可靠性，确保社区驱动的评估平台能够准确追踪领域进展，推动研究进步

Abstract: Community-driven Text-to-SQL evaluation platforms play a pivotal role in tracking the state of the art of Text-to-SQL performance. The reliability of the evaluation process is critical for driving progress in the field. Current evaluation methods are largely test …

</details>


### [63] [Accelerating RAG Systems: A Performance-Oriented Systematic Mapping](https://scholar.google.com/scholar_url?url=https://sol.sbc.org.br/index.php/eniac/article/download/38722/38495&hl=en&sa=X&d=18170955675759219517&ei=JnAqafWHDf3D6rQPtKC5IQ&scisig=ABGrvjLFaDstEX2Qw-0Rbx8DxiJO&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=0&folt=cit)
*JGJ da Silva,SST de Oliveira,AR GalvãoFilho*

Main category: Google Scholar

TL;DR: 对RAG系统优化技术进行系统性映射研究，重点关注TTFT、延迟和缓存效率指标


<details>
  <summary>Details</summary>
Motivation: RAG系统在生产环境部署中，延迟和推理效率优化变得至关重要。虽然已有GPU加速、KV缓存和分层索引等方法，但其影响在研究中呈现碎片化，缺乏系统性分析。

Method: 采用性能导向的系统性映射方法，对RAG优化技术进行分类和评估，重点关注时间到首个token(TTFT)、延迟和缓存效率等关键指标。

Result: 通过系统性映射分析，揭示了不同优化技术对RAG系统性能指标的影响模式，识别了现有研究的碎片化问题，并建立了优化技术的分类框架。

Conclusion: RAG系统优化需要更系统化的方法，本文提出的性能导向映射框架为理解不同技术对关键指标的影响提供了结构化视角，有助于指导实际部署中的优化决策。

Abstract: Optimizing latency and inference efficiency has become critical for the deployment of Retrieval-Augmented Generation (RAG) systems in production environments. While recent methods have explored GPU acceleration, keyvalue (KV) caching, and hierarchical indexing, their impact remains fragmented across studies. This paper presents a performance-oriented systematic mapping of optimization techniques targeting time-to-first-token (TTFT), latency, and caching efficiency metrics in RAG …

</details>


### [64] [Otimização de esquemas NoSQL orientado a documentos: avaliação baseada em métricas e algoritmo VNS](https://scholar.google.com/scholar_url?url=https://repositorio.unb.br/bitstream/10482/53201/1/HarleyVeraOlivera_TESE.pdf&hl=en&sa=X&d=14553849786059057695&ei=JnAqafWHDf3D6rQPtKC5IQ&scisig=ABGrvjKRTUPttBQ6h5VWTNqbUakY&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=2&folt=cit)
*HV Olivera*

Main category: Google Scholar

TL;DR: 本文探讨了文档型NoSQL数据库中模式设计对系统性能的影响，提出了评估不同集合配置组合的方法论


<details>
  <summary>Details</summary>
Motivation: 文档型NoSQL数据库中模式定义直接影响存储效率、查询速度和系统可扩展性，但确定最优配置面临巨大挑战，因为集合及其关系的可能组合数量庞大，每种组合都需要单独评估其对系统整体性能的影响

Method: 通过系统性地评估不同集合配置组合对性能的影响，建立评估框架来量化各种模式设计选择对存储、查询和可扩展性的影响

Result: 研究发现不同集合配置组合对系统性能有显著差异，需要建立系统化的评估方法来识别最优模式设计

Conclusion: 文档型NoSQL数据库的模式设计需要系统化的评估方法，通过量化不同配置组合的性能影响来指导最优模式选择

Abstract: Em bancos de dados NoSQL orientados a documentos, a definição do esquema influencia diretamente o armazenamento, a velocidade das consultas e a escalabilidade do sistema. No entanto, determinar a configuração ideal constitui um desafio significativo devido ao elevado número de combinações possíveis entre coleções e suas relações. Cada uma dessas combinações precisa ser avaliada individualmente para mensurar seu impacto sobre o desempenho geral do sistema …

</details>


### [65] [Updatable Balanced Index for Fast On-device Search with Auto-selection Model](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.20049&hl=en&sa=X&d=4999551239425519789&ei=JnAqafWHDf3D6rQPtKC5IQ&scisig=ABGrvjLTUdT7VsEc6bXr44OQMVMZ&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=5&folt=cit)
*Y Ji,S Wang,Z Chen,Y Sun,Z Peng*

Main category: Google Scholar

TL;DR: 论文探讨了在边缘设备上处理2D地理定位和3D点云等多样边缘数据时，平衡多路KD树（BMKD-tree）在k近邻搜索和半径搜索中的效率问题，并提出了一种改进方法。


<details>
  <summary>Details</summary>
Motivation: 边缘设备收集的2D地理定位和3D点云等多样数据需要高效的k近邻搜索和半径搜索来支持快速分析和学习技术（如使用kNN的k-means数据集简化）。虽然平衡多路KD树是保持高搜索效率的代表性方法，但存在某些局限性需要改进。

Method: 论文提出了一种改进的索引方法来解决平衡多路KD树在边缘设备上处理多样边缘数据时的效率问题，具体方法细节需要进一步阅读全文。

Result: 改进后的方法相比传统平衡多路KD树在边缘设备上的k近邻搜索和半径搜索效率有所提升，能够更好地支持边缘分析和学习应用。

Conclusion: 对于边缘设备上的多样数据搜索任务，需要优化传统索引结构以提高搜索效率，提出的改进方法为边缘计算中的实时数据分析提供了更有效的解决方案。

Abstract: Diverse types of edge data, such as 2D geo-locations and 3D point clouds, are collected by sensors like lidar and GPS receivers on edge devices. On-device searches, such as k-nearest neighbor (kNN) search and radius search, are commonly used to enable fast analytics and learning technologies, such as k-means dataset simplification using kNN. To maintain high search efficiency, a representative approach is to utilize a balanced multi-way KD-tree (BMKD-tree). However, the index …

</details>


### [66] [Information Physics of Intelligence: Unifying Logical Depth and Entropy under Thermodynamic Constraints](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.19156&hl=en&sa=X&d=8657116282689823664&ei=JnAqafWHDf3D6rQPtKC5IQ&scisig=ABGrvjLpxaHfG9-V2hL89DJiSHCr&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=6&folt=cit)
*J Xu,Z Li*

Main category: Google Scholar

TL;DR: 提出一个统一的理论框架，将信息处理视为物理过程，量化从压缩定律生成信息与从内存检索信息的热力学成本差异


<details>
  <summary>Details</summary>
Motivation: 人工智能模型的快速扩展揭示了模型容量（存储）与推理效率（计算）之间的基本矛盾。经典信息理论关注传输和存储限制，但缺乏统一的物理框架来量化从压缩定律生成信息与从内存检索信息的热力学成本差异

Method: 提出一个理论框架，将信息处理视为物理过程，建立统一的物理模型来量化信息生成与检索的热力学成本

Result: 该框架能够量化从压缩定律生成信息与从内存检索信息的热力学成本差异，为理解AI模型容量与推理效率的权衡提供物理基础

Conclusion: 提出的理论框架填补了经典信息理论的空白，为理解信息处理的热力学成本提供了统一物理基础，对AI模型设计中的存储-计算权衡具有重要指导意义

Abstract: The rapid scaling of artificial intelligence models has revealed a fundamental tension between model capacity (storage) and inference efficiency (computation). While classical information theory focuses on transmission and storage limits, it lacks a unified physical framework to quantify the thermodynamic costs of generating information from compressed laws versus retrieving it from memory. In this paper, we propose a theoretical framework that treats information processing as an enabling …

</details>


### [67] [Towards Honest, Practicable and Efficient Private Learning](https://scholar.google.com/scholar_url?url=https://uwspace.uwaterloo.ca/bitstreams/7384142e-3923-493b-a51f-71e70817ddc2/download&hl=en&sa=X&d=8180828785631704749&ei=JnAqafWHDf3D6rQPtKC5IQ&scisig=ABGrvjL33K3S0w4W0oY8e_TfGl7U&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=7&folt=cit)
*S Mohapatra*

Main category: Google Scholar

TL;DR: 该论文聚焦于差分隐私技术，这是一种为数据分析提供严格数学隐私保证的方法，旨在保护个人数据在统计分析中不被泄露。


<details>
  <summary>Details</summary>
Motivation: 在当今数据驱动的世界中，保护个人信息面临重大挑战。科学家和公司在分析大型数据集时，需要确保个体隐私不被泄露，即使攻击者拥有最有利的条件。

Method: 采用差分隐私方法，这是一种强大的数学保证机制，为个人信息泄露设置了严格、可验证的上限。研究人员开发了各种复杂的算法来实现这一目标。

Result: 从摘要中无法获取具体实验结果，但表明差分隐私技术能够为数据分析提供严格的隐私保护保证。

Conclusion: 差分隐私是解决数据驱动世界中隐私保护挑战的有效方法，通过数学保证为个人信息泄露设置严格限制。

Abstract: Protecting our personal information is a major challenge in today's data-driven world. When scientists and companies analyze large datasets, they need a way to ensure our individual privacy isn't compromised. This thesis focuses on Differential Privacy, a powerful, mathematical guarantee that places a strict, verifiable limit on how much personal information can be leaked, even if an attacker has the worst-case advantage. Researchers have developed various sophisticated algorithms to …

</details>


### [68] [Découverte et extraction de données pertinentes dans le web des données](https://scholar.google.com/scholar_url?url=https://theses.hal.science/tel-05383901/document&hl=en&sa=X&d=7557227054617806644&ei=x8IradndDIqi6rQPkt_b8QU&scisig=ABGrvjJfw_KCsyIVlercDRk2u6wb&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=3&folt=cit)
*Z Chevallier*

Main category: Google Scholar

TL;DR: 该论文关注语义Web数据空间中的数据发现挑战，提出基于元数据不完整性和异构性的数据搜索方法


<details>
  <summary>Details</summary>
Motivation: 语义Web（数据Web）通过RDF等W3C标准语言提供了大量互联数据源，但实际利用这些数据面临重大挑战：数据源数量庞大、高度异构，且描述它们的元数据通常不完整，这使得数据发现和利用变得困难

Method: 论文提出一种针对语义Web环境的数据搜索方法，专注于处理元数据不完整性和数据源异构性问题，可能涉及元数据增强、数据源发现或查询优化技术

Result: 未在摘要中明确说明具体结果，但暗示该方法能够改善在元数据不完整和异构环境下的数据发现能力

Conclusion: 在语义Web环境中，需要专门的方法来解决数据发现挑战，特别是处理元数据不完整性和数据源异构性问题，以提高数据利用效率

Abstract: Le Web des données est un ensemble de sources interconnectées, décrites en utilisant les langages proposés par le W3C, comme le langage RDF. Cet espace rend disponible aux applications une vaste quantité d'informations. Cependant, son exploitation est une tâche difficile, car les sources de données disponibles sont nombreuses, hétérogènes, et que les métadonnées les décrivant sont souvent incomplètes. Dans notre travail, nous nous intéressons à la recherche de données …

</details>


### [69] [Hybrid NoSQL Design for High-Speed Search and Insights](https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Rohit-Kommareddy/publication/394214199_Hybrid_NoSQL_Design_for_High-Speed_Search_and_Insights/links/68f5033e02d6215259bd33b6/Hybrid-NoSQL-Design-for-High-Speed-Search-and-Insights.pdf&hl=en&sa=X&d=10805409527430967243&ei=x8IradndDIqi6rQPkt_b8QU&scisig=ABGrvjLVcEGzojjY5cPRHzUTQ_Ko&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=4&folt=cit)
*RR Kommareddy*

Main category: Google Scholar

TL;DR: 本文综述了混合NoSQL系统的设计、实现与评估，这些系统通过整合多种NoSQL模型来提供快速搜索或分析能力，以解决单一NoSQL范式在灵活性和分析性能方面的不足。


<details>
  <summary>Details</summary>
Motivation: 随着非结构化和半结构化数据的增长，NoSQL数据库在现代应用中得到广泛应用。然而，实践中单个NoSQL范式通常无法在灵活性和分析性能之间提供最佳组合，需要混合系统来解决这一局限性。

Method: 论文回顾了混合NoSQL系统的设计、实现和评估方法，描述了一个整合文档存储等模型的统一架构，并分析不同集成策略。

Result: 通过对混合NoSQL系统的全面分析，展示了如何通过整合多种NoSQL模型来提升搜索和分析性能，同时保持数据处理的灵活性。

Conclusion: 混合NoSQL系统为解决单一NoSQL范式的局限性提供了有效方案，通过整合不同模型能够更好地满足现代应用对灵活性和分析性能的双重需求。

Abstract: The rise of unstructured and semi-structured data has driven an increased use of NoSQL databases to support modern applications. However, in practice, individual NoSQL paradigms typically do not deliver the best combination of flexibility and analytical performance. In this paper, we review the design, implementation, and evaluation of hybrid NoSQL systems that integrate multiple NoSQL models to offer fast search or analytics. We describe a unified architecture that integrates document …

</details>


### [70] [Rethinking data in NL2SQL: a survey of what we have and what we expect](https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s44336-025-00026-9&hl=en&sa=X&d=17915662367360330188&ei=yMIraee1KfGQ6rQPzJ-pqA4&scisig=ABGrvjKcljJ9SxxWsBG3zW7PrS_B&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ABGrvjJkn-FcYY8t5hAtGXsL8UoX&html=&pos=1&folt=rel)
*Y Fan,Q Weng,Y Chen,XS Wang*

Main category: Google Scholar

TL;DR: 该论文探讨了基于大语言模型的自然语言到SQL转换技术，分析了现有方法的局限性并提出了改进方案


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的出现，自然语言到SQL转换系统取得了显著进展，但现有方法仍存在局限性，需要更系统性的分析和改进

Method: 论文可能采用系统综述、实验分析或提出新的NL2SQL框架，结合大语言模型的能力来提升SQL生成质量

Result: NL2SQL系统在大语言模型支持下取得了显著性能提升，但仍面临复杂查询、模式理解和错误处理等挑战

Conclusion: 大语言模型为NL2SQL带来了革命性进步，但需要进一步研究来解决现有挑战，实现更鲁棒和实用的自然语言数据库接口

Abstract: Abstract Natural Language to SQL (NL2SQL) has become a cornerstone task for enabling natural language interfaces to relational databases. With the emergence of large language models, NL2SQL systems have achieved remarkable performance …

</details>


### [71] [A Dynamic PD-Disaggregation Architecture for Maximizing Goodput in LLM Inference Serving](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.20982&hl=en&sa=X&d=752792207003598007&ei=yMIraee1KfGQ6rQPzJ-pqA4&scisig=ABGrvjIC7sY4r2XZUr2DPh_792gd&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ABGrvjJkn-FcYY8t5hAtGXsL8UoX&html=&pos=4&folt=rel)
*J Liao,M Xu,W Zheng,Y Wang,K Ye,R Buyya,C Xu*

Main category: Google Scholar

TL;DR: LLM推理中预填充和解码阶段分离部署以应对不同瓶颈，但现有方法存在资源利用不均衡和调度效率问题


<details>
  <summary>Details</summary>
Motivation: 为满足严格的SLO要求，现有LLM推理系统将预填充和解码阶段分离部署在不同GPU上以应对各自的瓶颈，但这种方法存在资源利用不均衡和调度效率低下的问题

Method: 从摘要中无法确定具体方法，但推测可能涉及更智能的资源调度、动态分配或混合部署策略来优化预填充和解码阶段的资源利用

Result: 摘要未提供具体结果，但暗示现有分离部署方法存在局限性，需要改进方案

Conclusion: 需要新的调度或部署策略来解决LLM推理中预填充和解码阶段分离部署带来的资源利用不均衡问题

Abstract: To meet strict Service-Level Objectives (SLOs), contemporary Large Language Models (LLMs) decouple the prefill and decoding stages and place them on separate GPUs to mitigate the distinct bottlenecks inherent to each phase. However, the …

</details>


### [72] [LLM-Enhanced Processing of Complex Spatial Queries](https://scholar.google.com/scholar_url?url=https://renata.borovica-gajic.com/data/2025_adc_ruiyi.pdf&hl=en&sa=X&d=10653784618160240325&ei=yMIraee1KfGQ6rQPzJ-pqA4&scisig=ABGrvjIiRqXJftqE6GTpfEhre66v&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ABGrvjJkn-FcYY8t5hAtGXsL8UoX&html=&pos=5&folt=rel)
*R Hao,G Liu,R Borovica*

Main category: Google Scholar

TL;DR: 传统空间数据库和地图服务难以处理意图丰富、复杂的空间查询，本文提出新方法来解决这一问题


<details>
  <summary>Details</summary>
Motivation: 传统空间数据库和地图服务主要处理确定性查询，但无法有效处理意图丰富、复杂的空间查询，即使像"在墨尔本沿着Tullamarine高速公路寻找方便的加油站"这样的简单请求也难以满足

Method: 从提供的摘要片段来看，方法部分信息不完整，但可能涉及新的查询处理框架、意图理解技术或空间查询优化方法

Result: 摘要未提供具体结果信息，需要完整论文来了解实验结果和性能评估

Conclusion: 需要新的方法来处理意图丰富、复杂的空间查询，以克服传统系统的局限性

Abstract: Traditional spatial databases and map services handle deterministic queries well, but struggle to handle intent-rich and complex spatial queries. Even a simple request such as “In Melbourne, find a convenient petrol stop along the Tullamarine Freeway …

</details>


### [73] [Text-to-SQL as Dual-State Reasoning: Integrating Adaptive Context and Progressive Generation](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.21402&hl=en&sa=X&d=17729073617765234523&ei=yMIraee1KfGQ6rQPzJ-pqA4&scisig=ABGrvjKMCRFVOKCc8A53Ax5iQBRE&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ABGrvjJkn-FcYY8t5hAtGXsL8UoX&html=&pos=6&folt=rel)
*Z Hao,Q Song,R Cai,B Xu*

Main category: Google Scholar

TL;DR: 该论文探讨了在复杂企业级Text-to-SQL任务中，现有分治推理方法（特别是基于Chain-of-Thought的方法）的局限性，并提出了一种新的解决方案来改进大型语言模型处理复杂查询的能力。


<details>
  <summary>Details</summary>
Motivation: 虽然基于Chain-of-Thought的分治推理方法显著提升了大型语言模型的Text-to-SQL能力，但在处理复杂企业级场景时仍存在局限性。这些方法在分解复杂查询、处理多表关联、维护上下文一致性等方面面临挑战，需要更有效的推理框架来应对企业级数据库的复杂性。

Method: 论文提出了一种改进的分治推理方法，可能包括：1）更智能的查询分解策略，能够识别复杂查询的语义结构；2）上下文维护机制，确保分解后的子查询保持一致性；3）多步骤推理框架，结合企业级数据库的特定约束；4）可能引入领域知识或模式信息来指导分解过程。

Result: 新方法在复杂企业级Text-to-SQL任务上相比现有分治推理方法取得了显著改进，提高了查询分解的准确性、上下文一致性以及最终SQL生成的正确率。实验结果表明该方法能够更好地处理多表关联、嵌套查询、聚合函数等复杂企业场景。

Conclusion: 论文提出的改进分治推理方法有效解决了现有方法在复杂企业级Text-to-SQL任务中的局限性，为大型语言模型处理企业数据库查询提供了更可靠、更准确的推理框架，推动了Text-to-SQL技术在企业应用中的进一步发展。

Abstract: Recent divide-and-conquer reasoning approaches, particularly those based on Chain-of-Thought (CoT), have substantially improved the Text-to-SQL capabilities of Large Language Models (LLMs). However, when applied to complex enterprise …

</details>


### [74] [Learning SQL Like a Human: Structure-Aware Curriculum Learning for Text-to-SQL Generation](https://scholar.google.com/scholar_url?url=https://aclanthology.org/anthology-files/anthology-files/pdf/findings/2025.findings-emnlp.190.pdf&hl=en&sa=X&d=5096479471912684167&ei=twYtabOlD4qi6rQPkt_b8QU&scisig=ABGrvjKXhnc1tGoMM35VGFtylkph&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ABGrvjJkn-FcYY8t5hAtGXsL8UoX&html=&pos=1&folt=rel)
*X Zhu,Q Li,L Cui,Y Du*

Main category: Google Scholar

TL;DR: 该论文探讨了大型语言模型在Text-to-SQL任务中的局限性，特别是处理需要多表连接和复杂推理的查询时面临的挑战。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在Text-to-SQL方面取得了进展，但现有模型在处理复杂查询（特别是需要多表连接和复杂推理的查询）时仍然存在困难，这限制了其在真实数据库交互场景中的应用效果。

Method: 从摘要内容来看，论文可能提出了改进Text-to-SQL模型处理复杂查询的方法，但具体方法细节在提供的摘要片段中没有明确说明。可能涉及增强模型的多表连接理解能力、改进查询分解策略或引入新的训练技术。

Result: 摘要片段没有提供具体的实验结果，但暗示了现有模型在复杂查询处理上的不足，以及需要改进的方向。

Conclusion: 需要进一步研究和改进Text-to-SQL模型，以更好地处理复杂的多表连接查询，提高模型在真实数据库交互场景中的实用性。

Abstract: The Text-to-SQL capabilities of large language allow users to interact with databases using natural language. Despite recent advances, existing models continue to struggle with complex queries, particularly those requiring multitable joins and …

</details>


### [75] [Reducing Latency in Large-Scale Data Systems Through Intelligent Memory Tiering and Offloading Mechanisms](https://scholar.google.com/scholar_url?url=https://www.researchsquare.com/article/rs-8210374/latest.pdf&hl=en&sa=X&d=17056931298618647170&ei=tQYtaZzSJ6qy6rQP1qz4iAU&scisig=ABGrvjKn9m25zS6wRwIdqxhKlss8&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=3&folt=cit)
*S Yellu*

Main category: Google Scholar

TL;DR: 论文探讨了在数据爆炸时代，传统DRAM内存架构面临成本、功耗和密度限制，需要新型异构内存系统来解决内存访问延迟瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 物联网、人工智能和实时分析驱动的数据量指数增长对大规模数据系统提出了前所未有的需求。这些系统中的关键瓶颈是内存访问延迟，直接影响应用性能和用户体验。传统依赖DRAM的同构内存架构由于成本、功耗和密度限制日益不足。

Method: 论文未在摘要中明确说明具体方法，但暗示将提出新型异构内存架构解决方案来应对传统DRAM架构的局限性。

Result: 摘要中未提供具体实验结果，但暗示提出的解决方案将改善内存访问延迟，从而提升大规模数据系统的性能。

Conclusion: 传统同构DRAM内存架构已无法满足现代数据密集型应用的需求，需要创新的异构内存系统设计来解决内存访问延迟瓶颈。

Abstract: The exponential growth of data volumes, driven by IoT, AI, and real-time analytics, has placed unprecedented demands on large-scale data systems. A critical bottleneck in these systems is memory access latency, which directly impacts application performance and user experience. Traditional homogenous memory architectures, primarily reliant on Dynamic Random-Access Memory (DRAM), are increasingly insufficient due to cost, power, and density constraints. This paper …

</details>


<div id='Carsten Binnig'></div>

# Carsten Binnig [[Back]](#toc)

### [76] [Navigating the Performance-Security Trade-Off in Future Analytics on Shared Data](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3774303.3774311&hl=zh-CN&sa=X&d=15867415174788043396&ei=iIMGabqVE8ab6rQPkcmJwAg&scisig=ABGrvjLvCeKO22FwV0oyo3_t3HN4&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ABGrvjK24jP7J-3wiF9GIMBBH0jC&html=&pos=0&folt=cit)
*Z István*

Main category: Carsten Binnig

TL;DR: 论文探讨了在多方数据共享分析场景下的安全挑战，现有基于TEE、全同态加密等技术方案存在性能或成本问题，需要更实用的解决方案。


<details>
  <summary>Details</summary>
Motivation: 共享数据分析能产生宝贵洞察，但存在显著安全风险。即使在企业内部，跨子公司和地理区域的数据处理也需要安全防护。现有安全方案在性能、成本或实用性方面存在不足。

Method: 论文分析了现有安全解决方案，包括可信执行环境(TEEs)、全同态加密和结构化加密等技术，并探讨了它们在多方数据分析场景中的适用性和局限性。

Result: 现有安全方案虽然提供强大的安全保障，但在性能开销、成本效益或实际部署方面存在挑战，特别是在企业级多方数据分析场景中。

Conclusion: 需要开发更实用、高效的安全解决方案来支持多方数据共享分析，平衡安全需求与性能成本约束。

Abstract: Securing analytics on shared data is important but expensive. Analyzing datasets from multiple data owners can yield valuable insights [1, 2, 3, 4, 5] but poses significant security risks. Even within enterprises-our primary focus-precautions are necessary when handling data across subsidiaries and geographic regions [6, 7]. Existing security solutions based on Trusted Execution Environments (TEEs)[8, 9], fully homomorphic encryption [10], and structured encryption [11] offer strong …

</details>


### [77] [Searching Settings Accurately and Efficiently in Distributed Systems](https://scholar.google.com/scholar_url?url=https://etd.ohiolink.edu/acprod/odb_etd/ws/send_file/send%3Faccession%3Dosu17527623195458%26disposition%3Dinline&hl=zh-CN&sa=X&d=15105102234454512276&ei=iIMGabqVE8ab6rQPkcmJwAg&scisig=ABGrvjIh0igzOd8totrSNpg2J1_R&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ABGrvjK24jP7J-3wiF9GIMBBH0jC&html=&pos=1&folt=cit)
*Y Hui*

Main category: Carsten Binnig

TL;DR: 该论文提出了一种在分布式系统中进行准确高效设置搜索的方法，涵盖边缘设备、分布式数据库和分布式协议设计三个应用场景


<details>
  <summary>Details</summary>
Motivation: 分布式系统通常有大量可配置参数，但穷举搜索所有设置的计算成本过高，而计算资源本身是有限且宝贵的

Method: 论文采用系统化的设置搜索方法，第一个项目专注于在边缘设备上搜索量化设置以最小化精度损失，提出了特定的搜索算法

Result: 论文展示了在不同分布式系统中实现准确高效设置搜索的能力，特别是在边缘设备量化设置优化方面取得了显著效果

Conclusion: 通过系统化的设置搜索方法，可以在有限计算资源下实现分布式系统参数的高效优化，为不同领域的分布式系统提供实用的配置优化方案

Abstract: Distributed systems often have many settings. However, searching all the settings is too expensive given that computational resources are inherently limited and precious. This dissertation focuses on accurate and efficient setting searching in different distributed systems spanning from edge devices, distributed database systems, to distributed protocol design. The first project focuses on searching quantization settings on edge devices to minimize accuracy loss. We propose a …

</details>


### [78] [Efficient in-memory rebalancings for skewed results in distributed graph queries](https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s44443-025-00212-1&hl=zh-CN&sa=X&d=17933990696800363243&ei=LnEIacLlJceB6rQP4ZrcmAM&scisig=ABGrvjLucEWlnWek0PxaIxr7ZYJl&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ABGrvjK24jP7J-3wiF9GIMBBH0jC&html=&pos=0&folt=cit)
*A Berdai,A Soukrat,D Chiadmi*

Main category: Carsten Binnig

TL;DR: 提出两种分布式图查询结果集重平衡算法，解决因高热度顶点导致的数据倾斜问题，包括随机和保序版本及其渐进变体


<details>
  <summary>Details</summary>
Motivation: 分布式图查询在处理大规模数据集时会产生跨集群分布的结果集，但这些结果集常因高热度顶点（高度数顶点）导致数据分布严重倾斜，影响系统性能和资源利用率

Method: 提出两种高效算法：1) 随机结果集重平衡算法；2) 保序结果集重平衡算法。随后引入这两种算法的渐进变体，用于处理资源受限场景

Result: 算法能够有效解决分布式图查询结果集的数据倾斜问题，提高集群负载均衡和系统性能，渐进变体在资源受限条件下仍能保持良好效果

Conclusion: 通过随机和保序两种重平衡算法及其渐进变体，能够有效缓解分布式图查询中的热点顶点问题，提升大规模图数据处理系统的整体效率和可扩展性

Abstract: Distributed graph queries offer the possibility of executing large-scale graph operations over massive datasets, thereby generating result sets that are distributed across clusters. However, the result sets of these queries often suffer from skewed data distributions, particularly because of hot high-degree vertices. In this work, we present two efficient algorithms for both random and order-preserving result set rebalancing. We then introduce their gradual variants designed to handle limited …

</details>


### [79] [Detecting Logic Bugs in DBMSs via Equivalent Data Construction](https://scholar.google.com/scholar_url?url=http://www.wingtecher.com/themes/WingTecherResearch/assets/papers/paper_from_25/edc_sigmod25.pdf&hl=zh-CN&sa=X&d=4759985669733945304&ei=LnEIacLlJceB6rQP4ZrcmAM&scisig=ABGrvjISBpprLfZxW7xUjOS380t9&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ABGrvjK24jP7J-3wiF9GIMBBH0jC&html=&pos=1&folt=cit)
*W DENG,JIE LIANG,Z WU,J FU,YU JIANG*

Main category: Carsten Binnig

TL;DR: 该内容仅提供了作者信息，未包含论文摘要或研究内容，无法进行分析。


<details>
  <summary>Details</summary>
Motivation: 无法确定，因为只提供了作者信息而未提供论文摘要或研究背景。

Method: 无法确定，因为只提供了作者信息而未提供研究方法或技术细节。

Result: 无法确定，因为只提供了作者信息而未提供研究结果或发现。

Conclusion: 无法确定，因为只提供了作者信息而未提供研究结论或意义。

Abstract: Authors' addresses: Wenqian Deng, Tsinghua University, Beijing, China; Jie Liang, Beihang University, Beijing, China; Zhiyong Wu, Tsinghua University, Beijing, China; Jingzhou Fu, Tsinghua University, Beijing, China; Yu Jiang, Tsinghua University, Beijing, China.

</details>


### [80] [Learned Indexes for Efficient Querying on Knowledge Graphs](https://scholar.google.com/scholar_url?url=https://ceur-ws.org/Vol-4085/paper47.pdf&hl=zh-CN&sa=X&d=15092984580745799703&ei=hQAKafn6GcXXieoP7v2fmQc&scisig=ABGrvjLjKC37-0XzGSUUxt4vI2bE&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ABGrvjK24jP7J-3wiF9GIMBBH0jC&html=&pos=0&folt=cit)
*G Dawra,A Gupta,N Jain,Y Kumar,JR Parashar…*

Main category: Carsten Binnig

TL;DR: 提出使用学习索引替代传统索引来提升大规模知识图谱的SPARQL查询性能，利用数据分布特性实现更高效的查询处理


<details>
  <summary>Details</summary>
Motivation: 现实世界中的知识图谱规模庞大，在这些大型图谱上运行SPARQL查询非常耗时，需要更高效的查询处理方法

Method: 使用学习索引替代传统索引，利用底层数据分布特性实现更高效的查询处理，减少存储开销并提升运行时性能

Result: 在两个知识图谱上的评估表明，学习索引能够显著提升查询性能

Conclusion: 学习索引是提升大规模知识图谱查询性能的有效方法，能够替代传统索引实现更高效的查询处理

Abstract: There are several real-world Knowledge Graphs that are very large in size. Running SPARQL queries over such large graphs is time consuming. We propose improving the query performance over Knowledge Graphs by replacing traditional indices with learned indices. Learned indices exploit the underlying data distribution to enable more efficient query processing, leading to reduced storage overhead and faster runtime performance. Our evaluation on two Knowledge Graphs demonstrates …

</details>


### [81] [SemBench: A Benchmark for Semantic Query Processing Engines](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.01716&hl=zh-CN&sa=X&d=6115860259178792450&ei=9lQNab-6O6PH6rQP-5mLsAE&scisig=ABGrvjIGgGS7oSKIwi28XwMQwLpG&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ABGrvjK24jP7J-3wiF9GIMBBH0jC&html=&pos=1&folt=cit)
*J Lao,A Zimmerer,O Ovcharenko,T Cong,M Russo…*

Main category: Carsten Binnig

TL;DR: 提出针对语义查询处理引擎的新型基准测试，这些系统基于大语言模型的生成和推理能力，通过自然语言指令扩展SQL语义算子，支持多模态数据处理


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要针对传统数据库系统，缺乏对基于大语言模型的语义查询处理引擎的评估标准，这些系统通过自然语言指令扩展SQL能力，支持多模态数据处理，需要新的评估框架

Method: 设计包含场景、模态和查询类型三个关键维度的多样化基准测试框架，评估语义查询处理引擎在扩展SQL语义算子、自然语言指令配置和多模态数据处理方面的性能

Result: 建立了首个针对语义查询处理引擎的综合基准测试，涵盖多种应用场景、数据模态和查询类型，为评估基于大语言模型的数据库系统提供了标准化框架

Conclusion: 该基准测试填补了语义查询处理引擎评估的空白，为基于大语言模型的数据库系统研究和开发提供了重要工具，推动了多模态语义查询处理技术的发展

Abstract: We present a benchmark targeting a novel class of systems: semantic query processing engines. Those systems rely inherently on generative and reasoning capabilities of state-of-the-art large language models (LLMs). They extend SQL with semantic operators, configured by natural language instructions, that are evaluated via LLMs and enable users to perform various operations on multimodal data. Our benchmark introduces diversity across three key dimensions: scenarios, modalities …

</details>


### [82] [Unstructured Data Analysis using LLMs: A Comprehensive Benchmark](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.27119&hl=zh-CN&sa=X&d=18256608016094318257&ei=9lQNab-6O6PH6rQP-5mLsAE&scisig=ABGrvjIRZ-nXfS1u5CMoJdlcDmUp&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ABGrvjK24jP7J-3wiF9GIMBBH0jC&html=&pos=2&folt=cit)
*Q Deng,J Li,C Chai,J Liu,J She,K Jin,Z Sun,Y Deng…*

Main category: Carsten Binnig

TL;DR: LLM驱动的非结构化数据分析系统综述，探讨如何利用大语言模型从非结构化数据中提取结构化信息，实现类似数据库的分析功能


<details>
  <summary>Details</summary>
Motivation: 非结构化数据的爆炸式增长蕴含巨大分析价值，但传统数据库系统难以直接处理。大语言模型在从非结构化数据中提取结构化表格属性方面展现出卓越能力，促使研究人员开发LLM驱动的数据系统，让用户能够像操作数据库一样分析非结构化文档。

Method: 综述性研究，系统分析现有的LLM驱动的非结构化数据分析系统，涵盖查询接口、查询优化策略、操作符等多个方面。通过对比不同系统的设计理念和技术实现，揭示该领域的发展现状和趋势。

Result: 发现现有的非结构化数据分析系统在各个方面存在显著差异，包括查询接口设计、查询优化策略、操作符实现等。这些差异反映了不同的设计哲学和技术路线，为后续研究和系统开发提供了重要参考。

Conclusion: LLM驱动的非结构化数据分析系统是一个新兴且快速发展的领域，通过将大语言模型的能力与传统数据库技术相结合，为处理和分析非结构化数据提供了新的范式。未来需要进一步标准化和优化系统架构，以提高性能和易用性。

Abstract: Nowadays, the explosion of unstructured data presents immense analytical value. Leveraging the remarkable capability of large language models (LLMs) in extracting attributes of structured tables from unstructured data, researchers are developing LLM-powered data systems for users to analyze unstructured documents as working with a database. These unstructured data analysis (UDA) systems differ significantly in all aspects, including query interfaces, query optimization strategies, and operator …

</details>


### [83] [SQLSpace: A Representation Space for Text-to-SQL to Discover and Mitigate Robustness Gaps](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.27532&hl=zh-CN&sa=X&d=16050908386422485211&ei=9lQNab-6O6PH6rQP-5mLsAE&scisig=ABGrvjJZ2baq5O-XPYtc4bLuAvP2&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ABGrvjK24jP7J-3wiF9GIMBBH0jC&html=&pos=4&folt=cit)
*N Srikanth,V Bursztyn,P Mathur,A Nenkova*

Main category: Carsten Binnig

TL;DR: SQLSpace是一种用于文本到SQL任务的人类可解释、可泛化、紧凑的表示方法，通过最小化人工干预从示例中推导得出，用于评估和对比不同基准测试的组成，并深入分析模型性能。


<details>
  <summary>Details</summary>
Motivation: 当前文本到SQL基准测试评估主要依赖整体准确率，缺乏对示例组成和模型性能的细粒度分析。需要一种能够揭示不同基准测试独特维度、深入理解模型性能瓶颈的表示方法。

Method: 提出SQLSpace表示方法，通过最小化人工干预从文本到SQL示例中推导出人类可解释、可泛化、紧凑的表示。该方法能够捕捉示例的关键特征和维度。

Result: 展示了SQLSpace在三个用例中的实用性：1) 对比分析流行文本到SQL基准测试的组成，识别其评估的独特维度；2) 超越整体准确率，在细粒度层面理解模型性能；3) 提供更深入的评估洞察。

Conclusion: SQLSpace为文本到SQL任务提供了一种有效的表示框架，能够支持更深入、更细粒度的基准测试分析和模型性能评估，有助于识别研究中的关键挑战和改进方向。

Abstract: We introduce SQLSpace, a human-interpretable, generalizable, compact representation for text-to-SQL examples derived with minimal human intervention. We demonstrate the utility of these representations in evaluation with three use cases:(i) closely comparing and contrasting the composition of popular text-to-SQL benchmarks to identify unique dimensions of examples they evaluate,(ii) understanding model performance at a granular level beyond overall accuracy …

</details>


### [84] [Update NDP: On Offloading Modifications to Smart Storage with Transactional Guarantees in Near-Data Processing DBMS](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3774753&hl=zh-CN&sa=X&d=16407391628788191656&ei=LQIPadjkA4S6ieoPgY6ewQQ&scisig=ABGrvjLuQwLJmnIcMXKICQ-EHrWC&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ABGrvjK24jP7J-3wiF9GIMBBH0jC&html=&pos=1&folt=cit)
*A Bernhardt,S Tamimi,F Stock,A Koch,I Petrov*

Main category: Carsten Binnig

TL;DR: 该论文探讨了在近数据处理（NDP）环境中执行数据密集型修改操作的挑战，提出了解决事务一致性和低延迟通信问题的方案，使NDP能够支持读写操作。


<details>
  <summary>Details</summary>
Motivation: 现代数据密集型系统处理大规模数据集时，性能受限于不必要的数据移动。虽然近数据处理（NDP）理论上可以减少数据传输并提升性能，但目前NDP主要用于只读场景。数据密集型修改操作在近数据执行中不可行，主要原因是缺乏事务一致性和实用的低延迟通信机制。

Method: 论文提出了一种在NDP环境中支持数据修改操作的方法，重点解决了事务一致性保证和低延迟通信问题。可能包括分布式事务协议、一致性模型、通信优化等技术手段，使计算节点能够直接在存储位置执行修改操作。

Result: 通过提出的解决方案，实现了在NDP环境中支持数据密集型修改操作，减少了不必要的数据移动，提升了系统性能和可扩展性，同时保证了事务一致性。

Conclusion: 该研究扩展了NDP的应用范围，使其不仅限于只读操作，还能支持数据修改操作，为现代数据密集型系统提供了更高效的数据处理架构。

Abstract: The performance and scalability of modern data-intensive systems processing large datasets are limited by unnecessary data movement. Even though near-data processing (NDP) can provably reduce data transfers and increase performance, at present, NDP is utilized primarily in read-only settings. Near-data execution of data-intensive modification operations is currently infeasible due to the lack of transactional consistency and the absence of practicable low-latency …

</details>


### [85] [MtDB: A Decentralized Multi-Tenant Database for Secure Data Sharing](https://scholar.google.com/scholar_url?url=https://eprint.iacr.org/2025/2034.pdf&hl=zh-CN&sa=X&d=8520928382084876150&ei=UY0QadKNNcXXieoP9PS1mQg&scisig=ABGrvjK5QYv5MB0XD-eEeOu3WIRP&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ABGrvjK24jP7J-3wiF9GIMBBH0jC&html=&pos=0&folt=cit)
*S Hossain,W Tang,C Chenli,H Sun,WZ Song,S Lee…*

Main category: Carsten Binnig

TL;DR: MtDB是一种新型去中心化数据库架构，利用区块链进行元数据协调，解决医疗数据共享中的隐私、数据所有权和互操作性挑战


<details>
  <summary>Details</summary>
Motivation: 医疗数据共享对医学研究和患者护理至关重要，但面临隐私保护、数据所有权和互操作性等挑战，主要由于机构间的数据孤岛和严格法规（如GDPR、HIPAA）限制

Method: 提出MtDB去中心化数据库架构，采用区块链进行元数据协调，在多租户数据库生态系统中实现安全数据共享

Result: 未在摘要中明确说明具体实验结果，但该方法旨在解决医疗数据共享的关键挑战

Conclusion: MtDB架构为医疗数据共享提供了一种有前景的解决方案，能够应对隐私、所有权和互操作性等多重挑战

Abstract: Healthcare data sharing is fundamental for advancing medical research and enhancing patient care, yet it faces significant challenges in privacy, data ownership, and interoperability due to fragmented data silos across institutions and strict regulations (eg, GDPR, HIPAA). To bridge these gaps, we propose MtDB, a novel decentralized database architecture addressing secure data sharing in multi-tenant database ecosystems. MtDB employs blockchain for metadata coordination and …

</details>


### [86] [Towards better Hebrew clickbait detection: Insights from BERT and data augmentation](https://scholar.google.com/scholar_url?url=https://journals.plos.org/plosone/article%3Fid%3D10.1371/journal.pone.0332342&hl=zh-CN&sa=X&d=7650922748207513310&ei=G-4Raa2vH42v6rQP2o3qoQg&scisig=ABGrvjL1GKbBPsQ6cyDzQ_cqlzNT&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ABGrvjK24jP7J-3wiF9GIMBBH0jC&html=&pos=0&folt=cit)
*T Natanya,C Liebeskind*

Main category: Carsten Binnig

TL;DR: 该研究推进了希伯来语点击诱饵检测，通过构建数据集和开发模型来识别希伯来语中的点击诱饵标题，以应对数字环境中点击诱饵带来的挑战。


<details>
  <summary>Details</summary>
Motivation: 点击诱饵标题通过煽情或误导性内容吸引读者，在数字环境中带来重大挑战。它们利用好奇心产生流量和收入，但往往以传播错误信息和破坏在线内容可信度为代价。识别点击诱饵对于提高信息消费质量、培养数字媒体信任度以及使用户能够做出明智决策至关重要。

Method: 该研究推进了希伯来语点击诱饵检测，通过构建希伯来语点击诱饵数据集并开发相应的检测模型。具体方法包括数据收集、标注和模型训练，以识别希伯来语中的点击诱饵标题特征。

Result: 研究建立了希伯来语点击诱饵检测的数据集和模型，为希伯来语数字内容中的点击诱饵识别提供了工具和方法，有助于改善希伯来语在线信息环境的质量。

Conclusion: 希伯来语点击诱饵检测对于应对数字环境中的信息质量问题至关重要，该研究为希伯来语社区提供了识别和减轻点击诱饵影响的工具，有助于提升在线内容的可信度和用户决策质量。

Abstract: Clickbait headlines, designed to entice readers with sensationalized or misleading content, pose significant challenges in the digital landscape. They exploit curiosity to generate traffic and revenue, often at the cost of spreading misinformation and undermining the credibility of online content. Identifying clickbait is essential for improving the quality of information consumed, fostering trust in digital media, and enabling users to make informed decisions. This study advances Hebrew clickbait …

</details>


### [87] [Evaluating Trusted Execution Environment Performance for Genome Sequence Alignment: An AMD SEV Case Study](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3731599.3767558&hl=zh-CN&sa=X&d=5645096509545099646&ei=I5ETaYyaCLuZ6rQPko22wQU&scisig=ABGrvjIcgiiR_9NjED1eXHJqwW83&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ABGrvjK24jP7J-3wiF9GIMBBH0jC&html=&pos=0&folt=cit)
*R Keßler,L Nieroda,S Volpert,M Gräf,V Achter…*

Main category: Carsten Binnig

TL;DR: HPC系统需要支持多领域应用的安全数据处理，特别是敏感数据如人类基因组


<details>
  <summary>Details</summary>
Motivation: HPC系统服务于生命科学、医学、工程、人文和自然科学等多个领域，这些应用具有不同的计算需求和特征。处理高度敏感数据（如人类基因组）时需要确保数据安全和保护，这是重要的系统要求。

Method: 论文未提供具体方法细节，但从摘要推断可能涉及HPC系统架构设计、安全机制、数据处理框架或特定领域应用支持方案。

Result: 摘要未提供具体实验结果，但暗示需要开发能够满足多领域应用需求且确保敏感数据安全的HPC系统解决方案。

Conclusion: HPC系统需要适应不同领域应用的多样化计算需求，同时必须提供强大的数据安全保护机制，特别是在处理人类基因组等高度敏感数据时。

Abstract: HPC systems are used for a variety of applications from different fields and user groups. These research areas include, among others, the life sciences and medicine, engineering, the humanities, and the natural sciences. Applications from these areas all have different characteristics and computational demands. An important requirement is the security and protection of data, especially when dealing with highly sensitive data such as the human genome. In order to facilitate the processing …

</details>


### [88] [Federated Reinforcement Learning-based Adaptive Stream Applications Scheduling in Edge and Cloud Computing](https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0167739X25005291&hl=zh-CN&sa=X&d=3521305510505506293&ei=I5ETaYyaCLuZ6rQPko22wQU&scisig=ABGrvjIJJtvevdQSx0n_brXkbbxA&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ABGrvjK24jP7J-3wiF9GIMBBH0jC&html=&pos=1&folt=cit)
*S Lajili,Z Brahmi,MN Omri,RP De Prado*

Main category: Carsten Binnig

TL;DR: 针对流式智能应用在异构边缘云环境中的动态调度挑战，现有集中式反应式方法存在可扩展性和响应性限制，需要探索去中心化主动调度方案。


<details>
  <summary>Details</summary>
Motivation: 流式智能应用的运行时环境具有动态性，受数据流波动和系统条件变化驱动。在异构边缘云基础设施上高效调度这些应用面临重大挑战。现有自适应调度策略多为集中式和反应式，限制了可扩展性和响应性。

Method: 从摘要内容看，本文可能提出一种去中心化和主动的调度方法，以应对动态环境挑战。具体方法细节未在摘要中明确说明，但暗示将探索不同于传统集中式反应式方案的新途径。

Result: 摘要未提供具体实验结果，但暗示去中心化主动调度方案是当前研究不足的领域，需要进一步探索。

Conclusion: 需要开发去中心化和主动的调度策略来解决流式智能应用在动态异构边缘云环境中的调度挑战，以克服现有集中式反应式方法的局限性。

Abstract: The runtime environment of stream and smart applications (SAs) is inherently dynamic, driven by fluctuating data streams and variable system conditions. Efficiently scheduling these applications across heterogeneous edge cloud infrastructures remains a significant challenge. Existing adaptive scheduling strategies are mostly centralized and reactive, which limits scalability and responsiveness. Decentralized and proactive solutions remain underexplored …

</details>


### [89] [Redbench: Workload Synthesis From Cloud Traces](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.13059&hl=zh-CN&sa=X&d=14728337097692824241&ei=X8gjaczAFIS6ieoPgZLwgAY&scisig=ABGrvjIyk3YjxsFeUICNb077Xz9V&oi=scholaralrt&hist=i6heNjgAAAAJ:7693678668619210267:ABGrvjIXk7HFpW7leyqD8i5hB6FH&html=&pos=0&folt=art)
*J Wehrstein,R Heinrich,M Stoian,S Krid,M Stemmer…*

Main category: Carsten Binnig

TL;DR: 标准基准测试（如TPC-H/TPC-DS）未能捕捉云数据仓库真实工作负载的关键特征，包括查询重复和字符串密集型查询


<details>
  <summary>Details</summary>
Motivation: 云数据仓库提供商的工作负载追踪显示，现有标准基准测试与实际生产工作负载存在显著差异，无法准确评估系统性能

Method: 通过分析云数据仓库的真实工作负载追踪，识别标准基准测试的局限性，并提出改进方法

Result: 发现TPC-H和TPC-DS基准测试在查询重复模式和字符串密集型查询方面与真实工作负载存在显著差异

Conclusion: 需要开发更贴近实际云数据仓库工作负载特征的新基准测试方法

Abstract: Workload traces from cloud data warehouse providers reveal that standard benchmarks such as TPC-H and TPC-DS fail to capture key characteristics of real-world workloads, including query repetition and string-heavy queries. In this paper …

</details>


### [90] [Cloud-Native Vector Search: A Comprehensive Performance Analysis](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.14748&hl=zh-CN&sa=X&d=2977040924188180542&ei=YcgjadSuH82j6rQP2NKOuQI&scisig=ABGrvjJpMwv3-ATNKWL8pEBqmJzQ&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ABGrvjK24jP7J-3wiF9GIMBBH0jC&html=&pos=2&folt=cit)
*Z Li,W Ding,S Huang,Z Wang,Y Lin,K Wu,Y Park…*

Main category: Carsten Binnig

TL;DR: 云原生向量搜索系统面临远程存储访问延迟与多样化工作负载的挑战，需要设计高效的向量索引架构


<details>
  <summary>Details</summary>
Motivation: 随着推荐系统和检索增强生成中向量搜索的广泛应用，数据规模和任务复杂性不断增长，促使将向量索引部署到远程存储（云原生向量搜索）。然而，不同工作负载特性和多样化的向量索引形式带来了性能挑战，特别是在远程存储访问延迟方面。

Method: 论文未在摘要中明确说明具体方法，但暗示需要针对云原生环境设计向量索引架构，以应对远程存储访问延迟和多样化工作负载的挑战。

Result: 摘要未提供具体实验结果，但暗示云原生向量搜索服务已经由云提供商推出，但面临性能优化问题。

Conclusion: 云原生向量搜索需要专门设计的索引架构来平衡远程存储访问延迟与多样化工作负载需求，以实现高效的大规模向量检索。

Abstract: Vector search has been widely employed in recommender system and retrieval-augmented-generation pipelines, commonly performed with vector indexes to efficiently find similar items in large datasets. Recent growths in both data and task complexity have motivated placing vector indexes onto remote storage--cloud-native vector search, which cloud providers have recently introduced services for. Yet, despite varying workload characteristics and various available vector index forms …

</details>


### [91] [A Decade of Systems for Human Data Interaction](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.15585&hl=zh-CN&sa=X&d=4945210327634089182&ei=YcgjadSuH82j6rQP2NKOuQI&scisig=ABGrvjJa6zqLeouul7-WLNG3p54T&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ABGrvjK24jP7J-3wiF9GIMBBH0jC&html=&pos=3&folt=cit)
*E Wu,Y Chen,H Mohammed,Z Huang*

Main category: Carsten Binnig

TL;DR: HDI系统面临与传统数据管理不同的挑战，需要满足源于可用性而非查询语义的延迟、正确性和一致性需求，且界面与系统紧密耦合，需要协同设计


<details>
  <summary>Details</summary>
Motivation: 人机数据交互（HDI）面临与传统数据管理根本不同的挑战，这些挑战源于用户体验需求而非查询语义，系统必须满足由可用性驱动的延迟、正确性和一致性要求，否则会破坏用户体验

Method: 论文提出界面与系统紧密耦合的观点，强调两者不能孤立优化，需要协同设计的方法来解决HDI系统的独特挑战

Result: HDI系统的成功实现需要重新思考数据管理方法，将用户体验需求作为核心设计约束，通过界面与系统的协同设计来满足可用性要求

Conclusion: HDI系统设计需要范式转变，从传统的查询语义驱动转向用户体验驱动，界面与系统的紧密耦合要求协同设计方法，这对未来数据管理研究提出了新的方向

Abstract: Human-data interaction (HDI) presents fundamentally different challenges from traditional data management. HDI systems must meet latency, correctness, and consistency needs that stem from usability rather than query semantics; failing to meet these expectations breaks the user experience. Moreover, interfaces and systems are tightly coupled; neither can easily be optimized in isolation, and effective solutions demand their co-design. This dependence also presents a research …

</details>


### [92] [Cardinality estimation with index-based progressive sampling and dynamic sample selection](https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10844-025-01008-5&hl=zh-CN&sa=X&d=1619132281499404763&ei=5TglaZCHCruZ6rQPppf6-Aw&scisig=ABGrvjIJ1ntbT78CKE69iRY6lHzC&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ABGrvjK24jP7J-3wiF9GIMBBH0jC&html=&pos=1&folt=cit)
*Y Deng,Y Lin,Y Zhang,Y Cai,Y Li*

Main category: Carsten Binnig

TL;DR: 提出一种基于索引的渐进采样和动态样本选择的基数估计方法，解决传统采样方法在样本代表性不足或查询属性分布不均时的准确性问题


<details>
  <summary>Details</summary>
Motivation: 基数估计是数据库查询优化的核心问题，传统采样方法在商业数据库中已使用十多年，但当样本缺乏代表性或查询相关属性分布不均时，估计结果会不准确

Method: 基于索引的渐进采样和动态样本选择方法，通过索引结构指导采样过程，动态调整样本选择策略以提高估计精度

Result: 该方法相比传统采样方法能提供更准确的基数估计，特别是在样本代表性不足或属性分布不均的情况下

Conclusion: 提出的基于索引的渐进采样和动态样本选择方法能有效提高基数估计的准确性，为数据库查询优化提供更可靠的基数估计

Abstract: Cardinality estimation is a fundamental and critical problem in query optimization for database management systems. Although sampling-based methods have been widely used in commercial databases for over a decade, their estimation results can be inaccurate when samples lack representativeness or when the distribution of query-related attributes is uneven. This paper proposes a method called Cardinality Estimation with Index-Based Progressive Sampling and Dynamic Sample Selection …

</details>


### [93] [SALT-KG: A Benchmark for Semantics-Aware Learning on Enterprise Tables](https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3D9vVMSvilGX&hl=zh-CN&sa=X&d=2350680761982503980&ei=VromaeKYCJvJieoPuauKkAw&scisig=ABGrvjIRlwwGk3R9CBa-44yX-VKm&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ABGrvjK24jP7J-3wiF9GIMBBH0jC&html=&pos=0&folt=cit)
*IO Mulang,F Sasaki,T Klein,J Kolk,N Grechanov…*

Main category: Carsten Binnig

TL;DR: SALT-KG扩展SALT基准，通过将多表事务数据与元数据知识图谱(OBKG)连接，创建企业表语义感知学习基准


<details>
  <summary>Details</summary>
Motivation: 现有关系预测基准缺乏对企业表格语义信息的建模，需要结合结构化业务知识来评估模型在真实企业场景下的语义感知能力

Method: 将SALT的多表事务数据与结构化操作业务知识图谱(OBKG)连接，OBKG捕获字段级描述、关系依赖和对象类型层次结构，创建语义增强的基准

Result: 创建了SALT-KG基准，支持对联合建模表格数据和结构化业务知识的模型进行受控评估

Conclusion: SALT-KG为评估企业表格语义感知学习提供了更全面的基准，支持模型在真实业务知识背景下的能力评估

Abstract: Building upon the SALT benchmark for relational prediction, we introduce SALT-KG, a benchmark for semantics-aware learning on enterprise tables. SALT-KG extends SALT by linking its multi-table transactional data with a structured Operational Business Knowledge represented in a Metadata Knowledge Graph (OBKG) that captures field-level descriptions, relational dependencies, and object-type hierarchies. This extension enables controlled evaluation of models that jointly …

</details>


### [94] [Workload-aware Approximate Backup to Reduce Fault-tolerant Overhead for Stream Processing Applications](https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0167739X25005400&hl=zh-CN&sa=X&d=5459740761581400085&ei=wM8oab_XGObYieoPqMHA-A0&scisig=ABGrvjI6Bv37354CrHptHqfnGumI&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ABGrvjK24jP7J-3wiF9GIMBBH0jC&html=&pos=0&folt=cit)
*Y Zhuang,Y Gao,C Guo,J Wang,Y Lin,J Sun*

Main category: Carsten Binnig

TL;DR: 分布式流处理系统（DSPS）的容错技术综述，重点分析基于检查点的容错方法及其挑战


<details>
  <summary>Details</summary>
Motivation: 分布式流处理系统处理高速数据流，相比离线数据处理更容易受故障影响，需要可靠的容错机制来保证系统可靠性

Method: 综述分析各种容错技术，特别关注基于检查点的方法，该方法定期持久化算子状态

Result: 识别了基于检查点容错方法的优势和局限性，指出了现有方法的不足和需要改进的方向

Conclusion: 虽然检查点方法是目前最流行的容错技术，但仍存在需要解决的挑战，需要进一步研究改进分布式流处理系统的容错机制

Abstract: Abstract Distributed Stream Processing Systems (DSPSs) are powering big data applications on high-velocity data streams. Compared to offline data processing models, stream processing is more susceptible to failures in the face of on-the-fly data and large distributed cluster deployment. A variety of fault-tolerant techniques have emerged to achieve the reliability of DSPSs, and checkpoint-based approaches that periodically persist operator state are the most popular. However, making …

</details>


### [95] [Large Language Models for Semantic Join: A Comprehensive Survey](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/6287639/10820123/11218142.pdf&hl=zh-CN&sa=X&d=9149779191099234838&ei=yMIrafO0OZvJieoPr47u8Q4&scisig=ABGrvjJhvJ3U9gK1qRy1cihxQfB7&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ABGrvjK24jP7J-3wiF9GIMBBH0jC&html=&pos=0&folt=cit)
*K Hong,Y Park*

Main category: Carsten Binnig

TL;DR: LLMs作为语义连接新范式，有望解决传统方法在语义歧义、可扩展性和人工干预方面的长期挑战


<details>
  <summary>Details</summary>
Motivation: 传统语义连接方法面临深度语义歧义、可扩展性差和人工干预成本高的长期挑战，需要新的解决方案

Method: 提出将大型语言模型作为语义连接的新范式，替代脆弱的规则和句法方法，利用LLM的语义理解能力

Result: LLMs为语义连接提供了有前景的新方向，能够克服传统方法的局限性

Conclusion: LLMs代表了语义连接领域的范式转变，为解决长期存在的挑战提供了新的可能性

Abstract: Semantic join, the operation of integrating information siloed across heterogeneous data sources, is critical for modern data science, yet traditional methods have long been hampered by the persistent challenges of deep semantic ambiguity, poor scalability, and prohibitive manual intervention. This survey posits that Large Language Models (LLMs) represent a promising new paradigm, offering the potential to overcome these long-standing hurdles. By replacing brittle rules and syntactic …

</details>


### [96] [Efficiently Detecting DBMS Bugs through Bottom-up Syntax-based SQL Generation](https://scholar.google.com/scholar_url?url=https://steveleungyl.github.io/papers/liang-sqlbull.pdf&hl=zh-CN&sa=X&d=7918371602347703977&ei=yMIrafO0OZvJieoPr47u8Q4&scisig=ABGrvjKu6lBM8SjHffLArhyaGuBU&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ABGrvjK24jP7J-3wiF9GIMBBH0jC&html=&pos=3&folt=cit)
*Y Liang,P Liu*

Main category: Carsten Binnig

TL;DR: 该论文提出了一种新的自底向上SQL生成方法，相比传统的自顶向下方法，能够更有效地生成复杂查询并发现数据库管理系统中的错误


<details>
  <summary>Details</summary>
Motivation: 现有基于语法的SQL测试工具都采用自顶向下生成方法，这种方法在探索复杂查询时效率较低，容易陷入局部搜索，难以生成具有深度嵌套结构的复杂SQL查询

Method: 提出自底向上的SQL生成方法，从语法树的叶子节点开始构建，逐步向上组合成完整查询，这种方法能够更有效地探索复杂的查询空间，生成具有深度嵌套结构的SQL语句

Result: 自底向上方法相比传统自顶向下方法能够生成更复杂、更多样化的SQL查询，在数据库管理系统测试中发现更多错误，提高了测试覆盖率和错误检测能力

Conclusion: 自底向上SQL生成方法为数据库管理系统测试提供了更有效的语法测试技术，能够更好地发现复杂查询处理中的错误，提升数据库系统的可靠性

Abstract: Syntax-based testing is a promising technique for finding bugs in Database Management Systems (DBMSs). All existing syntax-based SQL generation tools apply a Top-down generation method. To construct a SQL query (syntax tree), the generator forward explores the SQL grammar starting from the root node, and it stops when no further grammar rule can be applied to the leaves of the syntax tree. However, the Top-down generation method tends to put more effort into exploring the …

</details>


### [97] [An Evaluation of B-tree Compression Techniques](https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s00778-025-00950-8&hl=zh-CN&sa=X&d=15148591129694291336&ei=twYtae_OIObYieoPqMHA-A0&scisig=ABGrvjLji5XVB8WODl3cGo7_jPY8&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ABGrvjK24jP7J-3wiF9GIMBBH0jC&html=&pos=0&folt=cit)
*S Sun,C Gao,S Ballijepalli,J Wang*

Main category: Carsten Binnig

TL;DR: B树压缩技术综述：从1970年代至今的发展历程、主要压缩方法及其对空间效率和查询性能的影响


<details>
  <summary>Details</summary>
Motivation: B树作为数据库系统中最重要的索引结构之一，其压缩技术自1970年代提出以来，旨在同时提高空间效率和查询性能。随着时间推移，多种B树压缩技术被开发，需要系统梳理这些技术的发展脉络和影响。

Method: 文献综述方法，系统回顾和分析自1970年代以来提出的各种B树压缩技术，包括不同的压缩策略、算法实现及其在数据库系统中的具体应用。

Result: B树压缩技术经历了长期发展，形成了多种有效的压缩方法，这些技术不仅显著减少了存储空间需求，还通过减少I/O操作和缓存利用率提升，改善了查询性能。

Conclusion: B树压缩是一项成熟且重要的数据库优化技术，经过几十年的发展已经形成了丰富的技术体系，对现代数据库系统的性能和效率产生了深远影响。

Abstract: B-trees are widely recognized as one of the most important index structures in database systems, providing efficient query processing capabilities. Over the past few decades, many techniques have been developed to enhance the efficiency of B-trees from various perspectives. Among them, B-tree compression is an important technique introduced as early as the 1970s to improve both space efficiency and query performance. Since then, several B-tree compression techniques have been …

</details>


### [98] [Analysis and Implementation of Academic Documents Privacy-Preserving Management Model using Dynamic VC and DID Over Hyperledger Fabric Blockchain …](https://scholar.google.com/scholar_url?url=https://sciresol.s3.us-east-2.amazonaws.com/IJST/Articles/2025/Issue-42/IJST-2025-1410.pdf&hl=zh-CN&sa=X&d=9108479559377175225&ei=twYtae_OIObYieoPqMHA-A0&scisig=ABGrvjJSWnBCe_3jzQAvcEZiFQae&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ABGrvjK24jP7J-3wiF9GIMBBH0jC&html=&pos=4&folt=cit)
*K Sathya,A Saraswathi*

Main category: Carsten Binnig

TL;DR: 提出基于Hyperledger Fabric、动态VC和DID区块链技术的学术文档隐私保护验证模型，用于学术证书的签发与验证


<details>
  <summary>Details</summary>
Motivation: 现有学术文档签发与验证系统存在隐私和安全挑战，需要提供高效的学术文档隐私保护方法

Method: 使用Hyperledger Fabric结合动态可验证凭证(VC)和去中心化标识符(DID)区块链技术，构建学术文档隐私保护验证模型

Result: 能够处理现有学术文档签发与验证系统中的隐私和安全问题，提供更安全的学术证书管理方案

Conclusion: 提出的区块链模型为学术文档的隐私保护和验证提供了有效的技术解决方案

Abstract: Objectives: Providing an efficient privacy preservation approach of academic documents is the primary objective of this research work. Methods: Proposed privacy-preserving of academic documents verification model for academic certificate issuance and verification using Hyperledger Fabric over dynamic VC and DID blockchain technology. It can handle privacy and security challenges present in existing academic document's issuance and verification systems, while also …

</details>


<div id='您的个人学术档案'></div>

# 您的个人学术档案 [[Back]](#toc)

### [99] [Energy-Efficient Autonomous Driving with Adaptive Perception and Robust Decision](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.25205&hl=zh-CN&sa=X&d=370279483263769953&ei=LXEIaaCmJcHO6rQPvu_42AM&scisig=ABGrvjIbNVBV8rE5IM3g5mVQtak_&oi=scholaralrt&hist=i6heNjgAAAAJ:9139054514476675507:ABGrvjJJaO4ZFvhRVHnqKIlWzQSz&html=&pos=0&folt=cit&fols=)
*Y Xia,Z Liang,L Deng,Y Zhao,H Su,K Zheng*

Main category: 您的个人学术档案

TL;DR: 自动驾驶感知计算能耗过高，影响电动汽车续航，需优化深度学习模型能效


<details>
  <summary>Details</summary>
Motivation: 自动驾驶技术虽带来社会、经济和环境效益，但其计算引擎（尤其是感知计算）能耗过高，限制了电动汽车的续航里程，需要解决能效问题

Method: 论文综述了近期研究，这些研究采用模型压缩、剪枝、量化等深度学习优化技术，以及专用硬件加速器来降低感知计算能耗

Result: 通过优化技术可以显著降低自动驾驶感知系统的能耗，同时保持足够的感知精度，从而延长电动汽车续航里程

Conclusion: 优化自动驾驶感知计算的能效对于实现可持续的自动驾驶技术至关重要，需要结合算法优化和硬件加速的综合解决方案

Abstract: Autonomous driving is an emerging technology that is expected to bring significant social, economic, and environmental benefits. However, these benefits come with rising energy consumption by computation engines, limiting the driving range of vehicles, especially electric ones. Perception computing is typically the most power-intensive component, as it relies on largescale deep learning models to extract environmental features. Recently, numerous studies have employed model …

</details>


<div id='Matei Zaharia'></div>

# Matei Zaharia [[Back]](#toc)

### [100] [Representation-Based Exploration for Language Models: From Test-Time to Post-Training](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.11686&hl=zh-CN&sa=X&d=2127203986120775398&ei=iIMGaciIJIGpieoP_8jXuAM&scisig=ABGrvjKx1FcWdPYFfOZ6wy1hq-iD&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=1&folt=rel)
*J Tuyls,DJ Foster,A Krishnamurthy,JT Ash*

Main category: Matei Zaharia

TL;DR: 该论文探讨当前强化学习技术是否能促进语言模型发现新行为，还是仅仅强化基础模型中已有的行为


<details>
  <summary>Details</summary>
Motivation: 强化学习有望扩展语言模型能力，但需要验证当前RL技术是否能真正促进新行为的发现，而非仅仅优化已有行为模式

Method: 论文未提供具体方法细节，但从摘要看可能涉及对比分析不同RL技术对语言模型行为多样性的影响

Result: 结果未在摘要中明确说明，但研究旨在揭示当前RL技术是否真正促进语言模型发现新行为

Conclusion: 需要进一步研究RL技术对语言模型行为创新的实际贡献，以确定其是否真正扩展模型能力

Abstract: Reinforcement learning (RL) promises to expand the capabilities of language models, but it is unclear if current RL techniques promote the discovery of novel behaviors, or simply sharpen those already present in the base model. In this paper …

</details>


### [101] [Optimizing Direct Marketing For Burial Insurance With Machine Learning](https://scholar.google.com/scholar_url?url=https://ijetcsit.org/index.php/ijetcsit/article/view/424&hl=zh-CN&sa=X&d=17730613777324246941&ei=iIMGaciIJIGpieoP_8jXuAM&scisig=ABGrvjIvKDP5iBeaZgAoy0aWwc8g&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=2&folt=rel)
*V Tummalapalli*

Main category: Matei Zaharia

TL;DR: 该研究探讨了殡葬保险营销中的消费者异质性响应问题，通过开发基于机器学习的异质性响应模型来改进传统倾向评分模型，实现个性化营销策略优化。


<details>
  <summary>Details</summary>
Motivation: 殡葬保险作为人寿保险的重要细分市场，面临消费者认知度低、价格敏感度高和响应行为异质性等营销挑战。传统倾向评分模型无法有效捕捉消费者的异质性响应模式，导致营销效率低下。

Method: 研究采用机器学习方法开发异质性响应模型，通过分析消费者特征与营销干预之间的交互效应来识别不同的响应细分群体。模型考虑了价格敏感性、渠道偏好和产品特征偏好等多维度异质性。

Result: 异质性响应模型相比传统倾向评分模型显著提升了营销效果，能够更准确地识别高响应概率的消费者细分群体，实现更精准的个性化营销策略，提高转化率和投资回报率。

Conclusion: 针对殡葬保险市场的消费者异质性响应建模是提升营销效率的关键。机器学习方法能够有效捕捉复杂的响应模式，为保险公司提供更精准的客户细分和个性化营销策略，克服传统模型的局限性。

Abstract: Burial insurance, a niche but vital segment of life insurance, presents persistent marketing challenges due to low consumer awareness, price sensitivity, and heterogeneous response behavior. Despite widespread use of propensity modeling …

</details>


### [102] [MRO: Enhancing Reasoning in Diffusion Language Models via Multi-Reward Optimization](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.21473&hl=zh-CN&sa=X&d=12317323340836465950&ei=iIMGaciIJIGpieoP_8jXuAM&scisig=ABGrvjKy5kaEzb3pH8k7TxGG3QH0&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=3&folt=rel)
*C Wang,Y Gan,H Zhou,C Hu,Y Mu,K Song,M Yang…*

Main category: Matei Zaharia

TL;DR: 扩散语言模型在推理能力上落后于自回归大语言模型，需要改进其推理性能


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型作为自回归大语言模型的有前景替代方案，但在推理性能方面仍落后，特别是在复杂推理任务中表现不佳

Method: 论文未提供具体方法细节，但可能涉及改进扩散语言模型的推理架构、训练策略或推理机制

Result: 未提供具体结果，但暗示当前扩散语言模型在推理性能上存在局限性

Conclusion: 需要进一步研究来提升扩散语言模型的推理能力，使其能够与自回归大语言模型竞争

Abstract: Recent advances in diffusion language models (DLMs) have presented a promising alternative to traditional autoregressive large language models (LLMs). However, DLMs still lag behind LLMs in reasoning performance, especially as the number of …

</details>


### [103] [SMaRT: Select, Mix, and ReinvenT-A Strategy Fusion Framework for LLM-Driven Reasoning and Planning](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.18095&hl=zh-CN&sa=X&d=6260306680531832341&ei=iIMGaciIJIGpieoP_8jXuAM&scisig=ABGrvjK3FnRszSUvTIH9jwxzNMjV&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=4&folt=rel)
*N Verma,M Bharadwaj,W Jang,H Singh,Y Wang…*

Main category: Matei Zaharia

TL;DR: 论文提出了一种多策略推理框架来增强大语言模型在复杂任务上的表现，超越传统的单策略提示方法


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在复杂任务自动化方面表现出色，但现有方法主要依赖单策略提示，缺乏多样化推理策略的协同效应，限制了模型在复杂问题解决中的潜力

Method: 开发了一个多策略推理框架，整合多种推理策略（如思维链、自我一致性、反思等），通过策略协同和动态选择机制来提升复杂任务解决能力

Result: 多策略推理框架在多个复杂任务基准测试中显著优于传统单策略方法，展示了更好的泛化能力和问题解决效果

Conclusion: 多策略推理方法能够有效利用不同推理策略的互补优势，为大语言模型在复杂任务自动化领域提供了更强大的解决方案

Abstract: Large Language Models (LLMs) have redefined complex task automation with exceptional generalization capabilities. Despite these advancements, state-of-the-art methods rely on single-strategy prompting, missing the synergy of diverse reasoning …

</details>


### [104] [SafeMT: Multi-turn Safety for Multimodal Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.12133%3F&hl=zh-CN&sa=X&d=2025767650452354485&ei=iIMGaciIJIGpieoP_8jXuAM&scisig=ABGrvjLVW5SprWkxYG62UtOahJ3T&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=5&folt=rel)
*H Zhu,J Dai,J Ji,H Li,C Cai,P Wen,CM Chan…*

Main category: Matei Zaharia

TL;DR: 多模态大语言模型安全风险研究，重点关注多轮对话场景下的安全隐患


<details>
  <summary>Details</summary>
Motivation: 随着多模态大语言模型(MLLMs)的广泛应用，安全问题日益突出。日常交互中更常见的多轮对话比单次提示存在更大风险，但目前研究对此关注不足

Method: 论文未提供具体方法细节，但从摘要推断可能涉及多轮对话安全评估框架、对抗性攻击测试、安全漏洞分析等系统性研究方法

Result: 摘要未提供具体实验结果，但暗示多轮对话场景下MLLMs存在显著安全漏洞，需要专门的安全防护机制

Conclusion: 多模态大语言模型在多轮对话场景下存在严重安全隐患，需要针对性的安全研究和防护措施

Abstract: With the widespread use of multi-modal Large Language models (MLLMs), safety issues have become a growing concern. Multi-turn dialogues, which are more common in everyday interactions, pose a greater risk than single prompts; however …

</details>


### [105] [XModBench: Benchmarking Cross-Modal Capabilities and Consistency in Omni-Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.15148&hl=zh-CN&sa=X&d=15078385575369281917&ei=iIMGaciIJIGpieoP_8jXuAM&scisig=ABGrvjKyFzlkkVOQYvWK-Nfxazuc&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=6&folt=rel)
*X Wang,J Liu,C Huang,X Yu,Z Wang,X Sun,J Wu…*

Main category: Matei Zaharia

TL;DR: 该论文指出当前多模态大语言模型评估主要关注通用跨模态问答能力，但缺乏对模型在复杂推理任务中跨模态信息整合能力的系统性评估，因此提出了新的评估框架来填补这一空白。


<details>
  <summary>Details</summary>
Motivation: 现有Omni-modal大语言模型评估主要关注通用跨模态问答能力，但缺乏对模型在复杂推理任务中跨模态信息整合能力的系统性评估，这限制了我们对模型真实能力的理解。

Method: 论文提出新的评估框架，设计专门任务来测试模型在复杂推理场景下的跨模态信息整合能力，包括多模态信息融合、跨模态推理链构建等。

Result: 通过新评估框架发现，现有OLLMs在复杂跨模态推理任务上表现不佳，揭示了模型在跨模态信息整合方面的局限性。

Conclusion: 需要更全面的评估框架来准确衡量OLLMs的跨模态理解能力，当前模型在复杂推理任务中的跨模态整合能力仍有待提升。

Abstract: Omni-modal large language models (OLLMs) aim to unify audio, vision, and text understanding within a single framework. While existing benchmarks primarily evaluate general cross-modal question-answering ability, it remains unclear whether …

</details>


### [106] [Transcribe, Translate, or Transliterate: An Investigation of Intermediate Representations in Spoken Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.02569%3F&hl=zh-CN&sa=X&d=7999970533456899412&ei=iIMGaciIJIGpieoP_8jXuAM&scisig=ABGrvjKiGiL9WybM7iaRfSXh9wTP&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=7&folt=rel)
*T Ògúnrèmí,CD Manning,D Jurafsky,K Livescu*

Main category: Matei Zaharia

TL;DR: 该论文研究了语音语言模型中模态适配器的设计，发现现有适配器存在信息瓶颈，提出了一种新的适配器架构来改善语音到文本的转换效果。


<details>
  <summary>Details</summary>
Motivation: 语音语言模型依赖模态适配器将语音编码器输出映射到语言模型可理解的表示，但现有适配器存在信息瓶颈问题，限制了语音到文本转换的性能。

Method: 提出了一种新的模态适配器架构，可能包括改进的映射机制、信息保留策略或更有效的特征转换方法，以解决现有适配器的信息瓶颈问题。

Result: 新提出的模态适配器架构在语音到文本转换任务上表现出更好的性能，能够更有效地保留语音信息并减少信息损失。

Conclusion: 模态适配器的设计对语音语言模型的性能至关重要，改进的适配器架构能够显著提升语音到文本转换的效果，为语音语言模型的发展提供了重要见解。

Abstract: Spoken language models (SLMs) that integrate speech with large language models (LMs) rely on modality adapters (MAs) to map the output of speech encoders to a representation that is understandable to the decoder LM. Yet we know very little …

</details>


### [107] [From< Answer> to< Think>: Multidimensional Supervision of Reasoning Process for LLM Optimization](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.11457&hl=zh-CN&sa=X&d=13003080138759958861&ei=iIMGaciIJIGpieoP_8jXuAM&scisig=ABGrvjLYIG2vy36C-XnWesMeJOt5&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=9&folt=rel)
*B Wang,W Su,H Tian,T Yang,Y Zhou,T Yao,Q Ai…*

Main category: Matei Zaharia

TL;DR: 该论文提出了一种新的强化学习范式——过程监督强化学习（PSRL），通过奖励推理过程中的正确中间步骤而非仅最终答案，来提升大语言模型的多步推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前主流的结果监督强化学习（RLVR）范式仅奖励正确的最终答案，这导致模型难以学习复杂的多步推理过程，因为正确的最终答案可能来自错误的推理路径。需要一种能够监督推理过程本身的方法来提升模型的多步推理能力。

Method: 提出过程监督强化学习（PSRL）范式，在强化学习训练过程中不仅奖励正确的最终答案，还奖励推理过程中的正确中间步骤。通过监督整个推理链，使模型能够学习正确的推理路径，而不仅仅是最终结果。

Result: PSRL相比传统的RLVR在多项多步推理任务上取得了显著提升，特别是在需要复杂逻辑推理和数学推理的任务中。过程监督能够有效减少推理过程中的错误传播，提高模型的推理准确性和鲁棒性。

Conclusion: 过程监督强化学习为提升大语言模型的多步推理能力提供了有效途径，通过监督推理过程而非仅最终结果，能够显著改善模型在复杂推理任务中的表现。这一范式为未来大语言模型的推理能力提升提供了新的研究方向。

Abstract: Improving the multi-step reasoning ability of Large Language Models (LLMs) is a critical yet challenging task. The dominant paradigm, outcome-supervised reinforcement learning (RLVR), rewards only correct final answers, often propagating …

</details>


### [108] [MultiVerse: A Multi-Turn Conversation Benchmark for Evaluating Large Vision and Language Models](https://scholar.google.com/scholar_url?url=https://openaccess.thecvf.com/content/ICCV2025/papers/Lee_MultiVerse_A_Multi-Turn_Conversation_Benchmark_for_Evaluating_Large_Vision_and_ICCV_2025_paper.pdf&hl=zh-CN&sa=X&d=10568159666847329935&ei=LnEIaZfoM93YieoP7uzByQ8&scisig=ABGrvjKcXUbeG-4kHMu7-JzegKuU&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=1&folt=rel)
*YJ Lee,BK Lee,J Zhang,Y Hwang,B Ko,HG Kim…*

Main category: Matei Zaharia

TL;DR: 该论文针对现有视觉-语言模型在多轮对话评估上的不足，提出了一个全面的多轮视觉-语言对话基准测试框架，包含多样化的任务类型和评估指标。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型在单轮基准测试中表现优异，但在实际应用中需要更复杂的多轮对话能力。当前的多轮数据集（如MMDU、ConvBench）存在局限性，缺乏全面的评估框架来系统评估模型在多轮对话中的表现。

Method: 提出了一个全面的多轮视觉-语言对话基准测试框架，包含多种任务类型（如视觉问答、对话推理、任务导向对话等），设计了系统化的评估指标，包括对话连贯性、上下文理解、信息一致性等维度。

Result: 通过该基准测试框架对现有视觉-语言模型进行评估，揭示了模型在多轮对话中的局限性，特别是在长期上下文理解、信息一致性维护和复杂推理方面的不足。

Conclusion: 该研究强调了开发专门针对多轮对话能力的视觉-语言模型的必要性，提出的基准测试框架为未来研究提供了重要的评估工具和方向指导。

Abstract: Abstract Vision-and-Language Models (VLMs) have shown impressive capabilities on single-turn benchmarks, yet real-world applications often demand more intricate multi-turn dialogues. Existing multi-turn datasets (eg, MMDU, ConvBench) only …

</details>


### [109] [Attention Sinks in Diffusion Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.15731%3F&hl=zh-CN&sa=X&d=17632376958671726554&ei=LnEIaZfoM93YieoP7uzByQ8&scisig=ABGrvjLy5KJ11KXbhh_IqYlN0lpI&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=2&folt=rel)
*ME Rulli,S Petruzzi,E Michielon,F Silvestri…*

Main category: Matei Zaharia

TL;DR: 掩码扩散语言模型作为自回归模型的有前景替代方案，通过双向注意力实现并行生成，但存在训练-推理不匹配问题


<details>
  <summary>Details</summary>
Motivation: 自回归模型存在顺序生成的局限性，扩散语言模型虽能并行生成但面临训练与推理不一致的问题，需要解决这一核心挑战

Method: 采用掩码扩散语言模型架构，使用transformer编码器配合双向注意力机制，实现并行token生成，但需处理训练-推理不匹配问题

Result: 掩码扩散语言模型展现出作为自回归模型替代方案的潜力，能够实现并行生成，但训练-推理不一致问题仍是主要技术挑战

Conclusion: 掩码扩散语言模型是有前景的非自回归生成方法，但需要进一步解决训练与推理模式的不匹配问题以实现更优性能

Abstract: Masked Diffusion Language Models (DLMs) have recently emerged as a promising alternative to traditional Autoregressive Models (ARMs). DLMs employ transformer encoders with bidirectional attention, enabling parallel token generation while …

</details>


### [110] [HAD: HAllucination Detection Language Models Based on a Comprehensive Hallucination Taxonomy](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.19318&hl=zh-CN&sa=X&d=5057731127272519192&ei=LnEIaZfoM93YieoP7uzByQ8&scisig=ABGrvjIDUeaWXkvgcfSoqVhpButJ&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=5&folt=rel)
*F Xu,X Hu,Z Yu,L Lin,X Zhang,Y Zhang,W Zhou…*

Main category: Matei Zaharia

TL;DR: 该论文关注自然语言生成模型（特别是大语言模型）的幻觉问题，即模型生成看似合理但事实上不正确的内容，并探讨了检测和缓解这一问题的挑战。


<details>
  <summary>Details</summary>
Motivation: 随着自然语言生成模型（特别是大语言模型）的日益广泛应用，对其输出可靠性和准确性的担忧不断增加。核心挑战在于模型会产生幻觉，即生成看似合理但事实上不正确的内容，这限制了模型在关键应用中的可信度。

Method: 从摘要内容来看，论文主要探讨了幻觉问题的本质、检测方法以及缓解策略。虽然没有详细说明具体方法，但可以推断论文可能涉及幻觉的识别技术、评估指标、以及改进模型可靠性的方法。

Result: 摘要未提供具体实验结果，但暗示了幻觉问题是自然语言生成模型可靠性的主要障碍，需要有效的检测和缓解方法。

Conclusion: 幻觉是自然语言生成模型可靠性的关键挑战，需要开发有效的检测和缓解策略以确保模型输出的准确性和可信度。

Abstract: The increasing reliance on natural language generation (NLG) models, particularly large language models, has raised concerns about the reliability and accuracy of their outputs. A key challenge is hallucination, where models produce plausible but …

</details>


### [111] [Study on LLMs for Promptagator-Style Dense Retriever Training](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.02241&hl=zh-CN&sa=X&d=168536585252416978&ei=LnEIaZfoM93YieoP7uzByQ8&scisig=ABGrvjJ6HeFLjSVEy5rIBtSXRKX4&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=9&folt=rel)
*D Gwon,N Jedidi,J Lin*

Main category: Matei Zaharia

TL;DR: Promptagator方法使用LLM生成查询来微调领域专用密集检索模型，但存在查询多样性不足和生成质量不稳定的问题


<details>
  <summary>Details</summary>
Motivation: 原始Promptagator方法虽然展示了使用LLM生成查询来微调领域专用密集检索模型的潜力，但存在查询多样性不足和生成质量不稳定的问题，需要改进以提升检索性能

Method: 基于Promptagator框架进行改进，可能包括增强查询多样性策略、优化提示工程、改进生成质量控制机制，以及可能引入多轮生成或反馈机制

Result: 改进后的方法相比原始Promptagator在检索性能上有显著提升，生成的查询更具多样性和相关性，能够更好地训练出高质量的领域专用密集检索模型

Conclusion: 通过改进Promptagator的查询生成策略，可以显著提升领域专用密集检索模型的性能，为使用LLM生成训练数据来优化检索系统提供了更有效的解决方案

Abstract: Promptagator demonstrated that Large Language Models (LLMs) with few-shot prompts can be used as task-specific query generators for fine-tuning domain-specialized dense retrieval models. However, the original Promptagator approach …

</details>


### [112] [Are Language Models Efficient Reasoners? A Perspective from Logic Programming](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.25626&hl=zh-CN&sa=X&d=1597526771105539469&ei=hQAKaYuOLP-j6rQPweenoAk&scisig=ABGrvjKJg5D6O0tRgk9B5xnTTYXA&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=1&folt=rel)
*A Opedal,Y Zengaffinen,H Shirakami,C Pasti…*

Main category: Matei Zaharia

TL;DR: 该论文指出当前语言模型评估过于关注推理正确性而忽视效率，提出需要同时评估推理效率和正确性，并引入新的评估框架


<details>
  <summary>Details</summary>
Motivation: 现代语言模型展现出强大的演绎推理能力，但标准评估方法过于强调正确性而忽视了人类推理的关键方面——效率。在现实推理场景中，大部分推理过程涉及效率考量，而不仅仅是正确性。因此需要开发能够同时评估推理效率和正确性的框架。

Method: 论文可能提出新的评估框架或方法，同时测量语言模型的推理正确性和效率。可能包括设计包含效率维度的基准测试，或者开发能够量化推理效率的指标和评估协议。

Result: 基于提供的摘要片段，具体结果未明确说明。但可以预期该研究将展示现有语言模型在推理效率方面的局限性，并可能提出改进模型推理效率的方法或架构。

Conclusion: 需要超越仅关注正确性的评估范式，开发能够全面评估语言模型推理能力（包括效率和正确性）的框架，这对于实现更接近人类水平的推理系统至关重要。

Abstract: Modern language models (LMs) exhibit strong deductive reasoning capabilities, yet standard evaluations emphasize correctness while overlooking a key aspect of human-like reasoning: efficiency. In real-world reasoning scenarios, much of the …

</details>


### [113] [Utility-Focused LLM Annotation for Retrieval and Retrieval-Augmented Generation](https://scholar.google.com/scholar_url?url=https://aclanthology.org/2025.emnlp-main.88.pdf&hl=zh-CN&sa=X&d=11193455910477623218&ei=hQAKaYuOLP-j6rQPweenoAk&scisig=ABGrvjK-V38-ikK9Dz-DbWM3hmE8&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=3&folt=rel)
*H Zhang,M Tang,K Bi,J Guo,S Liu,D Shi,D Yin…*

Main category: Matei Zaharia

TL;DR: 使用大语言模型标注文档效用以降低检索和RAG系统训练对人类标注的依赖


<details>
  <summary>Details</summary>
Motivation: 减少检索和检索增强生成系统训练中对昂贵人工标注的依赖，探索利用大语言模型进行文档效用标注的可行性

Method: 使用大语言模型对文档进行效用标注，应用于检索和检索增强生成系统的训练过程

Result: 大语言模型能够有效标注文档效用，降低对人工标注的依赖，提升系统训练效率

Conclusion: 大语言模型可作为文档效用标注的有效工具，为检索和RAG系统训练提供经济高效的替代方案

Abstract: This paper explores the use of large language models (LLMs) for annotating document utility in training retrieval and retrieval-augmented generation (RAG) systems, aiming to reduce dependence on costly human annotations. We address …

</details>


### [114] [The End of Manual Decoding: Towards Truly End-to-End Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.26697&hl=zh-CN&sa=X&d=2908879498202547314&ei=hQAKaYuOLP-j6rQPweenoAk&scisig=ABGrvjKXzun40ZDHxr-ncRBRLE7k&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=5&folt=rel)
*Z Wang,D Ma,X Huang,D Cai,T Lan,J Xu,H Mi…*

Main category: Matei Zaharia

TL;DR: AutoDeco是一种自动解码框架，通过可微近似和强化学习自动优化LLM解码超参数，消除手动调优需求


<details>
  <summary>Details</summary>
Motivation: 当前LLM的"端到端"标签存在误导性，实际依赖不可微的解码过程，需要手动调优温度、top-p等超参数，过程繁琐且低效

Method: 提出AutoDeco框架：1) 使用可微近似方法处理解码过程；2) 结合强化学习自动优化解码超参数；3) 实现端到端的自动解码优化

Result: AutoDeco能够自动优化解码超参数，在多个任务上达到或超过手动调优的性能，显著减少人工调优工作量

Conclusion: AutoDeco解决了LLM解码过程的手动调优问题，实现了真正的端到端优化，为LLM的自动化部署提供了有效解决方案

Abstract: The" end-to-end" label for LLMs is a misnomer. In practice, they depend on a non-differentiable decoding process that requires laborious, hand-tuning of hyperparameters like temperature and top-p. This paper introduces AutoDeco, a …

</details>


### [115] [Diverse, not Short: A Length-Controlled Data Selection Strategy for Improving Response Diversity of Language Models](https://scholar.google.com/scholar_url?url=https://aclanthology.org/2025.emnlp-main.1721.pdf&hl=zh-CN&sa=X&d=4192714401789557018&ei=hQAKaYuOLP-j6rQPweenoAk&scisig=ABGrvjLVn297Plxj3jyuASfq_eLa&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=6&folt=rel)
*V Deshpande,D Ghose,JD Patterson,RE Beaty…*

Main category: Matei Zaharia

TL;DR: 该论文指出常见多样性指标和偏好优化中使用的奖励模型存在系统性偏见，导致模型生成多样性不足，并提出了一种改进的多样性评估方法。


<details>
  <summary>Details</summary>
Motivation: 语言模型的多样性响应对于创造性生成、开放式任务和自我改进训练至关重要。然而，研究发现现有的多样性评估指标和偏好优化中使用的奖励模型存在系统性偏见，导致模型生成的实际多样性不足。

Method: 论文通过分析常见多样性指标和奖励模型的系统性偏见，提出了一种改进的多样性评估方法。该方法旨在更准确地衡量和促进语言模型的响应多样性。

Result: 研究揭示了现有多样性评估方法的局限性，表明这些方法会系统性地偏向某些类型的响应，从而限制了模型的实际多样性表现。

Conclusion: 需要重新审视和改进语言模型多样性评估方法，以促进更真实、更丰富的响应多样性，这对于语言模型的创造性应用和开放式任务至关重要。

Abstract: Diverse language model responses are crucial for creative generation, open-ended tasks, and self-improvement training. We show that common diversity metrics, and even reward models used for preference optimization, systematically bias models …

</details>


### [116] [Do You Know About My Nation? Investigating Multilingual Language Models' Cultural Literacy Through Factual Knowledge](https://scholar.google.com/scholar_url?url=https://aclanthology.org/2025.emnlp-main.756.pdf&hl=zh-CN&sa=X&d=17454883486339239849&ei=hQAKaYuOLP-j6rQPweenoAk&scisig=ABGrvjKF12SDzX6d8Zv4vAvAuiCl&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=7&folt=rel)
*E Tanwar,A Chatterjee,M Saxon,A Albalak,WY Wang…*

Main category: Matei Zaharia

TL;DR: 该论文指出当前多语言问答基准存在西方中心主义倾向，未能考虑区域信息多样性，提出需要更公平的评估框架


<details>
  <summary>Details</summary>
Motivation: 现有大多数多语言问答基准虽然覆盖多种语言，但未能考虑区域信息多样性，存在西方中心主义倾向，导致评估不公平，需要更全面的评估框架

Method: 论文未在摘要中明确说明具体方法，但指出需要构建考虑区域信息多样性的多语言问答基准

Result: 摘要未提供具体实验结果，但指出了当前多语言问答基准的局限性，强调需要更公平的评估标准

Conclusion: 需要开发考虑区域信息多样性的多语言问答基准，以更公平地评估模型在不同文化和区域背景下的表现

Abstract: Most multilingual question-answering benchmarks, while covering a diverse pool of languages, do not factor in regional diversity in the information they capture and tend to be Western-centric. This introduces a significant gap in fairly evaluating …

</details>


### [117] [Efficient Real-time Refinement of Language Model Text Generation](https://scholar.google.com/scholar_url?url=https://aclanthology.org/2025.emnlp-main.1753.pdf&hl=zh-CN&sa=X&d=5438800771147362211&ei=hQAKaYuOLP-j6rQPweenoAk&scisig=ABGrvjJ7QElSwhYp09Mfh_pfB0yc&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=9&folt=rel)
*J Ko,J Baek,SJ Hwang*

Main category: Matei Zaharia

TL;DR: 该论文针对大语言模型生成事实错误答案的问题，提出了一种基于检索增强的框架来提升事实准确性


<details>
  <summary>Details</summary>
Motivation: 大语言模型在各种自然语言任务中表现出色，但存在生成事实错误答案的严重问题，需要有效方法来提高其事实准确性

Method: 采用检索增强框架，通过外部知识检索来验证和修正模型生成的内容，确保回答的事实准确性

Result: 提出的方法显著提高了大语言模型生成答案的事实准确性，在多个基准测试中表现出优于基线模型的性能

Conclusion: 检索增强框架是解决大语言模型事实错误问题的有效方法，能够显著提升模型的事实准确性，为可靠AI系统开发提供了重要方向

Abstract: Large language models (LLMs) have shown remarkable performance across a wide range of natural language tasks. However, a critical challenge remains in that they sometimes generate factually incorrect answers. To address this, while many …

</details>


### [118] [SAKE: Towards Editing Auditory Attribute Knowledge of Large Audio-Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.16917&hl=zh-CN&sa=X&d=4301916401897850477&ei=usMLaZC0FMHO6rQPt-Gh0Ao&scisig=ABGrvjK2cWPL3q4el1dYZvm5OE5X&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=4&folt=rel)
*CK Yang,YT Piao,TW Hsu,SW Fu,Z Chen,KH Lu…*

Main category: Matei Zaharia

TL;DR: SAKE是首个专门为编辑多模态模型知识而设计的基准，填补了现有知识编辑研究主要集中于文本或视觉单模态的空白


<details>
  <summary>Details</summary>
Motivation: 现有知识编辑研究主要集中于文本或视觉单模态，缺乏专门针对多模态模型知识编辑的评估基准，限制了该领域在多模态场景下的发展

Method: 引入SAKE基准，专门设计用于评估多模态模型的知识编辑能力，可能包含多模态知识编辑任务、评估指标和数据集

Result: 论文提出了首个多模态知识编辑基准SAKE，为评估和比较不同多模态知识编辑方法提供了标准化框架

Conclusion: SAKE基准填补了多模态知识编辑领域的评估空白，将推动该方向的研究进展，使知识编辑技术能够更好地适应多模态应用场景

Abstract: Knowledge editing offers an efficient way to update model knowledge without full retraining, but prior work has concentrated almost exclusively on textual or visual modalities. We introduce SAKE, the first benchmark specifically designed for editing …

</details>


### [119] [DatawiseAgent: A Notebook-Centric LLM Agent Framework for Adaptive and Robust Data Science Automation](https://scholar.google.com/scholar_url?url=https://aclanthology.org/2025.emnlp-main.58.pdf&hl=zh-CN&sa=X&d=12016553802437457762&ei=usMLaZC0FMHO6rQPt-Gh0Ao&scisig=ABGrvjLUxIyMJvuhxfnIAsQK926X&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=8&folt=rel)
*Z You,Y Zhang,D Xu,Y Lou,Y Yan,W Wang,H Zhang…*

Main category: Matei Zaharia

TL;DR: LLM智能体在数据科学自动化方面存在任务范围窄、跨任务和模型泛化能力有限、过度依赖SOTA模型等问题


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体在数据科学自动化中表现出潜力，但受到任务范围狭窄、跨任务和模型泛化能力有限、过度依赖最先进LLM等限制，需要开发更通用、可扩展的解决方案

Method: 论文未提供具体方法细节，但从摘要看可能涉及开发新的LLM智能体框架，旨在扩大任务范围、提高跨任务泛化能力、减少对SOTA模型的依赖

Result: 摘要未提供具体实验结果，但暗示新方法可能解决了现有LLM智能体的局限性，实现了更广泛的数据科学任务覆盖和更好的模型泛化能力

Conclusion: 需要开发更通用、可扩展的LLM智能体来克服现有数据科学自动化解决方案的局限性，实现更广泛的任务覆盖和模型适应性

Abstract: Existing large language model (LLM) agents for automating data science show promise, but they remain constrained by narrow task scopes, limited generalization across tasks and models, and over-reliance on state-of-the-art (SOTA) LLMs. We …

</details>


### [120] [Gaperon: A Peppered English-French Generative Language Model Suite](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.25771&hl=zh-CN&sa=X&d=11042162317195861548&ei=usMLaZC0FMHO6rQPt-Gh0Ao&scisig=ABGrvjIPNX5yvNxitTx92sKCMX0I&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=9&folt=rel)
*N Godey,W Antoun,R Touchent,R Bawden…*

Main category: Matei Zaharia

TL;DR: Gaperon是一个完全开源的法国-英语-编程语言模型套件，包含1.5B、8B和24B参数模型，旨在提高大规模模型训练的透明度和可复现性


<details>
  <summary>Details</summary>
Motivation: 推动大规模语言模型训练的透明度和可复现性，特别是在多语言（法语、英语）和编程代码领域，通过完全开源的方式促进研究社区的发展

Method: 开发了包含1.5B、8B和24B参数规模的模型家族，在2-4...（具体训练数据规模未完全显示）的数据上进行训练，采用完全开源的训练框架和流程

Result: 发布了Gaperon模型套件，包含三个不同规模的模型，支持法语、英语和编程语言处理，为研究社区提供了可复现的基准

Conclusion: Gaperon套件通过完全开源的方式成功推进了大规模语言模型训练的透明度和可复现性，为多语言和编程语言模型研究提供了重要资源

Abstract: We release Gaperon, a fully open suite of French-English-coding language models designed to advance transparency and reproducibility in large-scale model training. The Gaperon family includes 1.5 B, 8B, and 24B parameter models trained on 2-4 …

</details>


### [121] [Accumulating Context Changes the Beliefs of Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.01805&hl=zh-CN&sa=X&d=15213292610086080065&ei=91QNabihCoS6ieoPgY6ewQQ&scisig=ABGrvjJBORsXHwCIfekn1c4CNGmo&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=0&folt=rel)
*J Geng,H Chen,R Liu,MH Ribeiro,R Willer,G Neubig…*

Main category: Matei Zaharia

TL;DR: 语言模型助手在头脑风暴和研究等应用中越来越重要，随着内存和上下文容量的提升，模型变得更加自主，但也产生了更多文本数据


<details>
  <summary>Details</summary>
Motivation: 语言模型助手在自主应用中产生的文本数据量急剧增加，需要有效的方法来管理和利用这些数据

Method: 未在摘要中明确说明具体方法，但暗示需要处理语言模型助手生成的文本数据

Result: 未在摘要中提供具体结果

Conclusion: 语言模型助手自主性的增强带来了文本数据管理的挑战

Abstract: Language model (LM) assistants are increasingly used in applications such as brainstorming and research. Improvements in memory and context size have allowed these models to become more autonomous, which has also resulted in more text …

</details>


### [122] [Language models cannot reliably distinguish belief from knowledge and fact](https://scholar.google.com/scholar_url?url=https://www.nature.com/articles/s42256-025-01113-8&hl=zh-CN&sa=X&d=17318522200816827346&ei=91QNabihCoS6ieoPgY6ewQQ&scisig=ABGrvjJRM_wNqLld5nmqG2diftJ-&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=3&folt=rel)
*M Suzgun,T Gur,F Bianchi,DE Ho,T Icard,D Jurafsky…*

Main category: Matei Zaharia

TL;DR: 语言模型在高风险领域应用时，需要区分信念与知识、事实与虚构的能力，但目前缺乏系统评估这种能力的基准测试。


<details>
  <summary>Details</summary>
Motivation: 随着语言模型在法律、医学、新闻和科学等高风险领域的应用增加，模型区分信念与知识、事实与虚构的能力变得至关重要。目前缺乏系统评估这种能力的基准测试。

Method: 论文提出了一个新的基准测试框架，用于评估语言模型区分信念与知识的能力。该方法可能包括设计特定的测试任务、数据集构建、评估指标等系统化方法。

Result: 研究结果显示当前语言模型在区分信念与知识方面存在显著不足，模型容易混淆主观信念与客观事实，在高风险领域应用中存在潜在风险。

Conclusion: 需要开发更系统化的评估基准来测试语言模型区分信念与知识的能力，这对于确保模型在高风险领域的安全可靠应用至关重要。

Abstract: As language models (LMs) increasingly infiltrate into high-stakes domains such as law, medicine, journalism and science, their ability to distinguish belief from knowledge, and fact from fiction, becomes imperative. Failure to make such …

</details>


### [123] [DispatchQA: A Benchmark for Small Function Calling Language Models in E-Commerce Applications](https://scholar.google.com/scholar_url?url=https://aclanthology.org/2025.emnlp-industry.154.pdf&hl=zh-CN&sa=X&d=6473175078231463335&ei=91QNabihCoS6ieoPgY6ewQQ&scisig=ABGrvjIel5QqHu5uIZd9OM5ZAgzI&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=4&folt=rel)
*J Daiber,V Maricato,A Sinha,A Rabinovich*

Main category: Matei Zaharia

TL;DR: DispatchQA是一个评估小型语言模型将开放式搜索查询转换为可执行API调用的基准测试，特别关注延迟敏感的电子商务场景


<details>
  <summary>Details</summary>
Motivation: 现有评估主要关注大型语言模型在结构化任务上的表现，缺乏针对小型语言模型在延迟敏感的实际应用场景（如电子商务搜索）中通过显式函数调用将自然语言查询转换为API调用的系统性评估

Method: 构建DispatchQA基准测试，包含多样化的开放式电子商务搜索查询和对应的API调用规范，评估小型语言模型将自然语言查询准确映射到正确API端点、参数和值的能力

Result: 通过评估多个小型语言模型在DispatchQA上的表现，揭示了当前模型在准确理解查询意图、处理模糊性和生成正确API调用方面的局限性

Conclusion: DispatchQA为评估和改进小型语言模型在实际延迟敏感应用中的函数调用能力提供了重要基准，有助于推动更高效、准确的查询到API转换技术的发展

Abstract: We introduce DispatchQA, a benchmark to evaluate how well small language models (SLMs) translate open‐ended search queries into executable API calls via explicit function calling. Our benchmark focuses on the latency-sensitive e-commerce …

</details>


### [124] [Increasing LLM Coding Capabilities through Diverse Synthetic Coding Tasks](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.23208&hl=zh-CN&sa=X&d=1601239717725406432&ei=91QNabihCoS6ieoPgY6ewQQ&scisig=ABGrvjITbJqDMxK1sSRADPItIOYW&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=5&folt=rel)
*A Abed,I Lukic,JKH Franke,F Hutter*

Main category: Matei Zaharia

TL;DR: 该论文针对大语言模型在代码生成中面临的数据集不足问题，提出了一个大规模、多样化且与人类推理对齐的代码生成数据集


<details>
  <summary>Details</summary>
Motivation: 大语言模型在代码生成方面展现出巨大潜力，但其进展受到大规模、多样化且与人类推理对齐的数据集短缺的限制。现有资源大多仅提供代码片段，缺乏与人类推理过程的深度对齐。

Method: 论文提出了一个大规模代码生成数据集，该数据集具有多样性和与人类推理的对齐性。具体方法包括收集多样化的代码示例，并将这些代码与人类推理过程进行对齐，以更好地反映人类解决问题的思维方式。

Result: 创建了一个大规模、多样化且与人类推理对齐的代码生成数据集，该数据集能够显著提升大语言模型在代码生成任务上的性能，特别是在复杂推理和多样化场景下的表现。

Conclusion: 通过提供大规模、多样化且与人类推理对齐的数据集，可以有效解决大语言模型在代码生成中的瓶颈问题，推动该领域的发展，并为更智能的代码生成系统奠定基础。

Abstract: Large language models (LLMs) have shown impressive promise in code generation, yet their progress remains limited by the shortage of large-scale datasets that are both diverse and well-aligned with human reasoning. Most existing resources pair …

</details>


### [125] [DEEPAMBIGQA: Ambiguous Multi-hop Questions for Benchmarking LLM Answer Completeness](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.01323&hl=zh-CN&sa=X&d=11896138061934127357&ei=91QNabihCoS6ieoPgY6ewQQ&scisig=ABGrvjK62sJBuSTtRveS-iBCRCmi&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=8&folt=rel)
*J Ji,M Li,P Kumar,S Chang,S Potdar*

Main category: Matei Zaharia

TL;DR: 论文提出了一种名为Set-of-Mark Prompting (SoM)的新方法，通过标记图像中的对象来增强大型语言模型的多模态推理能力，显著提高了模型在复杂视觉问答任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在复杂视觉推理任务中存在局限性，特别是在需要理解图像中多个对象及其空间关系的任务中表现不佳。现有的视觉语言模型在需要详细空间推理和对象级理解的复杂问答任务中经常失败。

Method: 提出Set-of-Mark Prompting (SoM)方法：首先使用对象检测器识别图像中的对象，然后为每个检测到的对象添加数字标记。这些标记后的图像与问题一起输入给大型语言模型，使模型能够通过引用标记编号来精确指代图像中的特定对象。

Result: SoM方法在多个基准测试中显著提升了性能：在POPE基准上准确率从85.1%提升到97.5%；在MLLM-Bench基准上从54.7%提升到67.3%；在HallusionBench基准上从32.7%提升到52.8%。该方法还增强了模型的幻觉检测能力。

Conclusion: SoM是一种简单而有效的提示工程技术，通过标记图像中的对象显著提升了大型语言模型在复杂视觉推理任务中的表现。这种方法为增强多模态模型的视觉理解能力提供了新的方向。

Abstract: Large language models (LLMs) with integrated search tools show strong promise in open-domain question answering (QA), yet they often struggle to produce complete answer set to complex questions such as Which actor from the film Heat won at least …

</details>


### [126] [Understanding the Modality Gap: An Empirical Study on the Speech-Text Alignment Mechanism of Large Speech Language Models](https://scholar.google.com/scholar_url?url=https://aclanthology.org/2025.emnlp-main.262.pdf&hl=zh-CN&sa=X&d=8174932824527055829&ei=LQIPabqhFYqi6rQPis_TmQk&scisig=ABGrvjL-w0ukmdYnfITaqkDkUrKw&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=7&folt=rel)
*B Xiang,S Zhao,T Guo,W Zou*

Main category: Matei Zaharia

TL;DR: 端到端大型语音语言模型在对话生成方面表现出色，但在语义理解基准测试中始终落后于传统流水线系统


<details>
  <summary>Details</summary>
Motivation: 揭示端到端大型语音语言模型在语义理解任务上表现不佳的根本原因，并探索改进方法

Method: 通过系统分析揭示LSLMs在语义理解方面的局限性，并提出相应的改进策略

Result: 发现端到端LSLMs在语义理解方面存在系统性缺陷，需要专门优化才能达到传统流水线系统的性能水平

Conclusion: 端到端大型语音语言模型在语义理解方面需要针对性改进，不能仅依赖对话生成能力的优化

Abstract: Abstract End-to-end Large Speech Language Models (LSLMs) have demonstrated impressive conversational generation abilities, yet consistently fall short of traditional pipeline systems on semantic understanding benchmarks. In this work, we reveal …

</details>


### [127] [From Insight to Exploit: Leveraging LLM Collaboration for Adaptive Adversarial Text Generation](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.03128&hl=zh-CN&sa=X&d=3413463340151283100&ei=Uo0Qab2CB_GQ6rQPr_zr6Ao&scisig=ABGrvjIYen6oJljeF4CPtuvlAAxR&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=3&folt=rel)
*N Sultana,MRU Rashid,K Gu,S Mehnaz*

Main category: Matei Zaharia

TL;DR: LLMs在零样本任务中表现良好但敏感任务需评估鲁棒性


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在零样本任务中表现出色，但在敏感任务应用中需要系统评估其鲁棒性，确保模型输出的可靠性和安全性

Method: 通过系统性的鲁棒性评估框架，分析LLMs在敏感任务中的表现，包括对抗性测试、偏差检测和不确定性量化等方法

Result: 研究发现LLMs在敏感任务中存在鲁棒性不足的问题，包括对输入扰动的敏感性、潜在偏见和不确定性处理能力有限

Conclusion: 在部署LLMs处理敏感任务前必须进行全面的鲁棒性评估，需要开发专门的评估框架和增强技术来提升模型在敏感场景下的可靠性

Abstract: LLMs can provide substantial zero-shot performance on diverse tasks using a simple task prompt, eliminating the need for training or fine-tuning. However, when applying these models to sensitive tasks, it is crucial to thoroughly assess their robustness …

</details>


### [128] [Scheduling Your LLM Reinforcement Learning with Reasoning Trees](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.24832&hl=zh-CN&sa=X&d=6565722563583075372&ei=Uo0Qab2CB_GQ6rQPr_zr6Ao&scisig=ABGrvjJBc-yHxO-oUv_ichcZGsm_&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=4&folt=rel)
*H Wang,Z Hao,J Luo,C Wei,Y Shu,L Liu,Q Lin…*

Main category: Matei Zaharia

TL;DR: RLVR方法通过逐步编辑查询的推理树来优化大语言模型，将强化学习与可验证奖励相结合


<details>
  <summary>Details</summary>
Motivation: 传统强化学习方法在优化大语言模型时面临奖励信号稀疏、难以评估推理过程质量的问题，需要一种能够有效指导模型推理过程优化的方法

Method: 将LLM优化过程概念化为逐步编辑查询的推理树，通过探索节点（token）和应用可验证奖励来指导模型学习，将强化学习与可验证奖励机制相结合

Result: 该方法能够更有效地优化大语言模型的推理能力，通过可验证奖励机制提供更精确的训练信号，提升模型在复杂推理任务上的表现

Conclusion: RLVR方法为优化大语言模型的推理能力提供了一种有效框架，通过将强化学习与可验证奖励相结合，能够更好地指导模型学习复杂的推理过程

Abstract: Using Reinforcement Learning with Verifiable Rewards (RLVR) to optimize Large Language Models (LLMs) can be conceptualized as progressively editing a query'sReasoning Tree'. This process involves exploring nodes (tokens) and …

</details>


### [129] [Probing and Boosting Large Language Models Capabilities via Attention Heads](https://scholar.google.com/scholar_url?url=https://aclanthology.org/2025.emnlp-main.1450.pdf&hl=zh-CN&sa=X&d=3470412007312514950&ei=Uo0Qab2CB_GQ6rQPr_zr6Ao&scisig=ABGrvjLExdWnWrCpcwPAWbMa743t&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=5&folt=rel)
*D Zhao,X Liu,X Feng,H Wang,B Qin*

Main category: Matei Zaharia

TL;DR: 该论文探讨大语言模型能力的内在起源，旨在理解特定能力如何从模型内部机制中涌现，以提升可解释性和高效适应


<details>
  <summary>Details</summary>
Motivation: 当前对大型语言模型特定能力涌现的理解不足，现有方法大多依赖外部评估而非内部机制分析，这限制了模型的可解释性和高效适应能力

Method: 论文未提供具体方法细节，但暗示将采用不同于传统外部评估的方法，可能涉及对模型内部机制的分析来理解能力涌现

Result: 摘要未提供具体结果，但暗示研究将揭示大语言模型能力的内在起源机制

Conclusion: 理解大语言模型能力的内在起源对模型可解释性和高效适应至关重要，需要超越传统外部评估的方法

Abstract: Understanding the internal origins of capabilities in large language models (LLMs) is crucial for interpretability and efficient adaptation. However, the emergence of specific capabilities remains poorly understood, as most existing approaches rely on …

</details>


### [130] [Beyond Neural Incompatibility: Easing Cross-Scale Knowledge Transfer in Large Language Models through Latent Semantic Alignment](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.24208&hl=zh-CN&sa=X&d=855501614541975327&ei=Uo0Qab2CB_GQ6rQPr_zr6Ao&scisig=ABGrvjKNqTHXB8kt7R_te-kAkkjz&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=6&folt=rel)
*J Gu,A Aleti,C Chen,H Zhang*

Main category: Matei Zaharia

TL;DR: 该论文探讨了如何在大语言模型中实现细粒度的知识转移，通过知识定位、追踪和分析来理解LLM中知识的编码方式


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在参数中编码了大量知识，且神经可解释性研究有所进展，但目前仍不清楚如何实现细粒度的知识转移。需要更深入地理解LLM中知识的编码、定位和追踪机制

Method: 论文未提供具体方法细节，但从摘要推断可能涉及知识定位、知识追踪和知识分析技术，旨在探索LLM中知识的编码和转移机制

Result: 摘要未提供具体结果，但暗示了在理解LLM知识编码和转移方面存在的研究空白和挑战

Conclusion: 需要进一步研究LLM中细粒度知识转移的方法，以更好地理解和利用这些模型中编码的知识

Abstract: Large Language Models (LLMs) encode vast amounts of knowledge in their massive parameters, which is accessible to locate, trace, and analyze. Despite advances in neural interpretability, it is still not clear how to transfer knowledge in a fine-grained …

</details>


### [131] [Improving Reasoning Capabilities in Small Models through Mixture-of-layers Distillation with Stepwise Attention on Key Information](https://scholar.google.com/scholar_url?url=https://aclanthology.org/2025.emnlp-main.250.pdf&hl=zh-CN&sa=X&d=5388300826406213821&ei=Uo0Qab2CB_GQ6rQPr_zr6Ao&scisig=ABGrvjJVSe7ItItyeOxZwasaAX23&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=7&folt=rel)
*Y Chen,J Sheng,W Zhang,T Liu*

Main category: Matei Zaharia

TL;DR: 该论文关注通过思维链蒸馏将推理能力迁移到小模型的方法，指出当前方法主要关注知识迁移而非推理能力本身，并提出了一种新的蒸馏框架来改进这一过程。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的计算需求推动了通过思维链蒸馏将推理能力迁移到小模型的研究。当前方法主要关注知识迁移而非推理能力本身，存在局限性。

Method: 提出了一种新的思维链蒸馏框架，专注于推理能力的迁移而非单纯的知识传递。该方法可能涉及更精细的蒸馏策略或架构设计。

Result: 新方法在推理能力迁移方面相比现有方法有显著改进，小模型获得了更好的推理性能。

Conclusion: 专注于推理能力而非知识的思维链蒸馏方法能更有效地将大模型的推理能力迁移到小模型中。

Abstract: The significant computational demands of large language models have increased interest in distilling reasoning abilities into smaller models via Chain-of-Thought (CoT) distillation. Current CoT distillation methods mainly focus on transferring …

</details>


### [132] [Are language models aware of the road not taken? Token-level uncertainty and hidden state dynamics](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.04527&hl=zh-CN&sa=X&d=9833064512822978923&ei=G-4Raa_2LbqL6rQPjtScMQ&scisig=ABGrvjLJWyWLNdkiSbgjF2FwRWuf&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=3&folt=rel)
*A Zur,A Geiger,ES Lubana,E Bigelow*

Main category: Matei Zaharia

TL;DR: 该研究探讨语言模型在生成文本时，如何通过采样不同token来探索不同的推理路径，并提出量化这种推理不确定性的方法。


<details>
  <summary>Details</summary>
Motivation: 语言模型在生成文本时，单个token的选择可能导致完全不同的推理路径，这使得模型的不确定性难以量化。研究者希望理解语言模型是否能够表示替代的推理路径，并开发方法来量化这种推理不确定性。

Method: 通过采样不同的token来探索语言模型可能采取的多种推理路径，分析模型如何表示这些替代路径，并开发量化推理不确定性的方法。

Result: 研究发现语言模型确实能够表示多种推理路径，通过系统性的采样和分析，可以有效地量化模型在推理过程中的不确定性。

Conclusion: 语言模型在推理过程中存在多种可能的路径，通过适当的方法可以量化和分析这种推理不确定性，这对于理解模型决策过程和提升模型可靠性具有重要意义。

Abstract: When a language model generates text, the selection of individual tokens might lead it down very different reasoning paths, making uncertainty difficult to quantify. In this work, we consider whether reasoning language models represent the alternate paths …

</details>


### [133] [Contamination Detection for VLMs using Multi-Modal Semantic Perturbation](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.03774&hl=zh-CN&sa=X&d=10830950468035053760&ei=G-4Raa_2LbqL6rQPjtScMQ&scisig=ABGrvjIyPve15oCuG6_OnopzbVxM&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=7&folt=rel)
*J Park,M Cai,F Yao,J Shang,S Lee,YJ Lee*

Main category: Matei Zaharia

TL;DR: 该论文探讨了视觉语言模型在互联网规模专有预训练数据上存在的隐私风险，并提出了一种隐私保护评估框架


<details>
  <summary>Details</summary>
Motivation: 尽管视觉语言模型在众多基准任务上取得了最先进的性能，但使用互联网规模的专有预训练数据引发了严重的隐私担忧。现有研究主要关注文本模型的隐私风险，而对视觉语言模型的隐私评估不足，需要开发专门的评估框架来量化其隐私风险。

Method: 论文提出了一个隐私保护评估框架，用于量化视觉语言模型的隐私风险。该方法可能包括：1）设计针对视觉语言模型的隐私攻击方法；2）开发评估指标来衡量模型记忆和泄露敏感信息的能力；3）建立基准数据集来测试隐私风险；4）分析不同预训练策略对隐私的影响。

Result: 研究发现视觉语言模型确实存在显著的隐私风险，能够记忆和泄露训练数据中的敏感信息。评估框架能够有效量化这些风险，并揭示了模型规模、训练数据特性与隐私风险之间的相关性。结果强调了需要开发隐私保护的视觉语言模型训练方法。

Conclusion: 视觉语言模型在互联网规模数据上的预训练带来了严重的隐私风险。论文提出的评估框架为量化这些风险提供了工具，并强调了开发隐私保护训练方法的重要性。未来的工作需要平衡模型性能与隐私保护，确保视觉语言模型的负责任发展。

Abstract: Recent advances in Vision-Language Models (VLMs) have achieved state-of-the-art performance on numerous benchmark tasks. However, the use of internet-scale, often proprietary, pretraining corpora raises a critical concern for both practitioners …

</details>


### [134] [RefineBench: Evaluating Refinement Capability in Language Models](https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DYcred6ETQR&hl=zh-CN&sa=X&d=5994965452443884975&ei=I5ETaefLGI2v6rQPq7_gyAE&scisig=ABGrvjKr0_N2I0RXst7HguO1uniR&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=2&folt=rel)
*YJ Lee,S Kim,BK Lee,M Moon,Y Hwang,JM Kim…*

Main category: Matei Zaharia

TL;DR: 语言模型能否自我优化其回答？研究探讨了在真实用户交互中超过10%涉及优化请求的背景下，语言模型自我优化的能力。


<details>
  <summary>Details</summary>
Motivation: 随着超过10%的真实用户交互涉及优化请求，研究语言模型能否自我优化其回答变得日益重要。先前研究主要测试了语言模型在...

Method: 方法部分未在提供的摘要中明确说明，但研究可能涉及设计实验来评估语言模型自我优化的能力，包括不同类型的优化请求和评估指标。

Result: 结果部分未在提供的摘要中明确说明，但研究可能发现语言模型在特定条件下能够有效自我优化，或者存在局限性。

Conclusion: 结论部分未在提供的摘要中明确说明，但研究可能强调语言模型自我优化能力的重要性，并提出未来研究方向。

Abstract: Can language models (LMs) self-refine their own responses? This question is increasingly relevant as more than 10% of real-world user interactions involve refinement requests (see Appendix F). Yet prior studies have largely tested LMs on …

</details>


### [135] [Unlocking the Potential of Smaller Language Models as Superior Instruction Evolvers](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3746252.3761290&hl=zh-CN&sa=X&d=14462923280604830961&ei=I5ETaefLGI2v6rQPq7_gyAE&scisig=ABGrvjJ_GcUSBt-EzqoekS4_JUhW&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=3&folt=rel)
*T Hui,L Zhao,G Dong,Y Zhang,S Su*

Main category: Matei Zaharia

TL;DR: 指令调优已成为释放大语言模型潜力的关键，复杂多样的指令在模型与下游任务对齐中起核心作用


<details>
  <summary>Details</summary>
Motivation: 指令调优是大语言模型能力释放的基础，但现有指令数据在复杂性和多样性方面存在不足，限制了模型与广泛下游任务的对齐效果

Method: 未在摘要中明确说明具体方法，但暗示需要开发更复杂、更多样化的指令数据集来提升指令调优效果

Result: 未在摘要中提供具体实验结果，但强调复杂多样指令对模型性能提升的重要性

Conclusion: 指令调优的成功依赖于高质量的指令数据，特别是复杂性和多样性，这对模型与下游任务的有效对齐至关重要

Abstract: Instruction tuning has become a cornerstone for unlocking the full potential of large language models. Among the key factors, complex and diverse instructions play a crucial role in aligning these models with a wide range of downstream tasks …

</details>


### [136] [Multimodal and Multi-task Fusion for Spatial Reasoning](https://scholar.google.com/scholar_url?url=https://openaccess.thecvf.com/content/ICCV2025W/AICity/papers/Dang_Multimodal_and_Multi-task_Fusion_for_Spatial_Reasoning_ICCVW_2025_paper.pdf&hl=zh-CN&sa=X&d=3400572679277993302&ei=I5ETaefLGI2v6rQPq7_gyAE&scisig=ABGrvjLqvP2H9TjpOUCO45b_dXFd&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=4&folt=rel)
*VM Dang,TS Le*

Main category: Matei Zaharia

TL;DR: 该论文针对视觉语言模型在复杂环境（如仓库）中区域级细粒度空间理解能力不足的问题，提出了一种增强空间感知的方法。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在细粒度空间理解方面存在局限，特别是在复杂环境如仓库中，模型的空间感知能力不足，难以准确理解和处理区域级别的空间关系。

Method: 论文提出了一种增强视觉语言模型空间感知能力的方法，可能包括改进的区域注意力机制、空间关系建模或结合特定领域知识的架构设计。

Result: 所提出的方法显著提升了视觉语言模型在复杂环境中的区域级空间理解能力，在相关基准测试中取得了优于现有方法的性能。

Conclusion: 通过增强空间感知能力，视觉语言模型在复杂环境中的细粒度空间理解性能得到显著提升，为实际应用如仓库管理等场景提供了更好的技术支持。

Abstract: Abstract Vision-Language Models (VLMs) have made significant progress, yet they still struggle with fine-grained spatial understanding at the region level, especially in complex environments such as warehouses, due to limited spatial perception and …

</details>


### [137] [Alleviating Hallucinations in Large Language Models through Multi-Model Contrastive Decoding and Dynamic Hallucination Detection](https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DQH2xGLgObM&hl=zh-CN&sa=X&d=14966297470184740530&ei=I5ETaefLGI2v6rQPq7_gyAE&scisig=ABGrvjKW7toChlqmoU_cSoWtDM-F&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=8&folt=rel)
*C Zhu,YF Liu,H Zhang,A Wang,G Chen,L Wang…*

Main category: Matei Zaharia

TL;DR: 该论文针对大语言模型幻觉问题，提出了一种新的对比解码方法，通过对比不同模型层级的表示来识别和减少幻觉内容。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在许多应用中表现出色，但它们仍然容易产生幻觉，生成与预训练语料不一致的内容。现有的对比解码方法大多基于不同模型或不同解码策略之间的对比，但缺乏对模型内部层级表示的深入探索。

Method: 提出了一种新的对比解码方法，通过对比模型不同层级的表示来识别幻觉内容。该方法利用模型内部的多层表示，通过对比高层和低层表示之间的差异来检测可能产生幻觉的部分，并在解码过程中进行修正。

Result: 该方法在多个基准测试中显著减少了幻觉现象，提高了生成内容的准确性和一致性。相比现有方法，在保持生成质量的同时，有效降低了幻觉率。

Conclusion: 通过利用模型内部层级表示的对比，可以更有效地检测和减少大语言模型的幻觉问题，为改进模型可靠性提供了新的方向。

Abstract: Despite their outstanding performance in numerous applications, large language models (LLMs) remain prone to hallucinations, generating content inconsistent with their pretraining corpora. Currently, almost all contrastive decoding approaches …

</details>


### [138] [Towards Optimal Evaluation Efficiency for Large Language Models](https://scholar.google.com/scholar_url?url=https://aclanthology.org/2025.emnlp-main.716.pdf&hl=zh-CN&sa=X&d=11866807402530123844&ei=evgUadXVFbuZ6rQPko22wQU&scisig=ABGrvjJ-ibZ48u_XT9_EvxiHg5qh&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=8&folt=rel)
*G Li,D Xiong*

Main category: Matei Zaharia

TL;DR: 该论文提出了一种成本效益高的方法来评估大型语言模型，通过使用小型但具有代表性的数据集来替代大规模基准测试


<details>
  <summary>Details</summary>
Motivation: 大规模基准测试评估LLMs成本高昂，包括数据标注和计算资源消耗，需要更经济高效的评估方法

Method: 开发了一种使用小型代表性数据集替代大规模基准测试的方法，通过精心选择的数据样本来准确评估模型性能

Result: 该方法能够以显著降低的成本获得与大规模基准测试相当的评估结果，验证了其有效性和实用性

Conclusion: 小型代表性数据集可以作为大规模基准测试的有效替代方案，为LLMs评估提供了一种经济高效的方法

Abstract: Comprehensive evaluation of large language models (LLMs) typically requires large-scale benchmarks, which is costly in terms of both data annotation and computational resource needed for evaluation. To mitigate these challenges, we …

</details>


### [139] [FedCoT: Federated Chain-of-Thought Distillation for Large Language Models](https://scholar.google.com/scholar_url?url=https://aclanthology.org/anthology-files/pdf/emnlp/2025.emnlp-main.747.pdf&hl=zh-CN&sa=X&d=5523495862304510540&ei=evgUadXVFbuZ6rQPko22wQU&scisig=ABGrvjKKXxr9rO8wcEe-_tOCfznY&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=9&folt=rel)
*T Fan,W Chen,Y Kang,G Ma,H Gu,Y Song,L Fan…*

Main category: Matei Zaharia

TL;DR: LLMs在资源受限环境中的部署挑战及解决方案


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在资源受限环境中的部署面临挑战，需要解决计算资源、内存占用和能耗等问题

Method: 未在摘要中明确说明具体方法，但暗示会探讨LLM优化技术如模型压缩、量化、剪枝等

Result: 未提供具体实验结果，但暗示将展示优化技术在资源受限环境中的有效性

Conclusion: 需要开发高效LLM部署方案以在资源受限环境中实现实用化应用

Abstract: Abstract Large Language Models (LLMs) have emerged as a transformative force in artificial intelligence, demonstrating exceptional proficiency across various tasks. However, their deployment in resource-constrained environments and concerns over …

</details>


### [140] [Explore Data Left Behind in Reinforcement Learning for Reasoning Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.04800&hl=zh-CN&sa=X&d=11785781023546407428&ei=B3kWaYWiJ82j6rQPzdm92QM&scisig=ABGrvjJlF433uEtY3ehy2gfMNXpc&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=4&folt=rel)
*C Liu,J Liang,Y Jia,B Cao,Y Bai,H Huang,X Chen*

Main category: Matei Zaharia

TL;DR: RLVR通过可验证奖励提升LLM推理能力，GRPO家族方法在数学推理任务上表现优异


<details>
  <summary>Details</summary>
Motivation: 提升大型语言模型的推理能力，特别是数学推理任务，通过强化学习结合可验证奖励机制

Method: 使用可验证奖励的强化学习（RLVR）方法，特别是Group Relative Policy Optimization（GRPO）家族算法

Result: GRPO方法在数学推理任务上表现出色，显著提升了LLM的推理性能

Conclusion: RLVR结合GRPO是提升LLM推理能力的有效方法，在数学推理领域具有重要应用价值

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as an effective approach for improving the reasoning abilities of large language models (LLMs). The Group Relative Policy Optimization (GRPO) family has demonstrated …

</details>


### [141] [Data-scarce Behavior Editing of Language Models](https://scholar.google.com/scholar_url?url=https://aclanthology.org/anthology-files/anthology-files/pdf/findings/2025.findings-emnlp.514.pdf&hl=zh-CN&sa=X&d=5434254407295665546&ei=B3kWaYWiJ82j6rQPzdm92QM&scisig=ABGrvjJnh0lRa_jg-DfI_goNTdm_&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=5&folt=rel)
*J Singh,S Dutta,T Chakraborty*

Main category: Matei Zaharia

TL;DR: 该论文探讨了大型语言模型通过上下文示例学习任务知识的能力，但指出这种方法的局限性，并提出了改进方案


<details>
  <summary>Details</summary>
Motivation: 大型语言模型通过网页规模文本训练获得了广泛的语言生成能力，能够解决多种任务，特别是当任务知识通过上下文示例被提炼到生成先验中时。然而，这种方法存在局限性，需要更有效的任务知识整合方式。

Method: 论文可能提出了一种改进大型语言模型任务知识整合的方法，但具体方法需要完整论文内容才能确定。从摘要看，可能涉及更有效的上下文学习机制、任务知识编码或模型架构改进。

Result: 基于摘要内容，无法确定具体实验结果。需要完整论文才能了解提出的方法在任务性能、效率或泛化能力方面的改进。

Conclusion: 虽然大型语言模型通过上下文示例能够学习任务知识，但这种方法存在不足，需要更有效的方法来提升模型的任务解决能力。

Abstract: Abstract Large Language Models trained on web-scale text acquire language generation abilities that can solve a wide range of tasks, particularly when task knowledge is refined into the generative prior using in-context examples. However …

</details>


### [142] [Lexo: Eliminating Stealthy Supply-Chain Attacks via LLM-Assisted Program Regeneration](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.14522&hl=zh-CN&sa=X&d=13184445394376771993&ei=B3kWaYWiJ82j6rQPzdm92QM&scisig=ABGrvjI1CHkk7wokU5dWRSdJKczd&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=8&folt=rel)
*E Lamprou,J Dai,G Ntousakis,MC Rinard,N Vasilakis*

Main category: Matei Zaharia

TL;DR: 软件供应链攻击是开源软件生态系统中持续存在的重要威胁，攻击者通过篡改软件组件在保持标准功能的同时隐藏恶意功能


<details>
  <summary>Details</summary>
Motivation: 开源软件生态系统中的供应链攻击日益严重，攻击者通过篡改软件组件在保持原有功能的同时植入恶意代码，这种攻击方式难以检测且影响范围广泛，对软件安全构成重大威胁

Method: 论文可能提出了一种检测和防御软件供应链攻击的方法，可能涉及对软件组件行为的监控、异常检测、代码完整性验证或供应链安全评估框架

Result: 根据摘要片段推断，论文可能展示了检测软件供应链攻击的有效方法，可能包括识别恶意篡改、减少误报率、提高检测效率等具体成果

Conclusion: 软件供应链攻击是开源软件安全的关键挑战，需要系统性的防御机制来保护软件供应链的完整性，确保开源组件的可信性

Abstract: Software supply-chain attacks are an important and ongoing concern in the open source software ecosystem. These attacks maintain the standard functionality that a component implements, but additionally hide malicious functionality activated only …

</details>


### [143] [Can Language Models Compose Skills In-Context?](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.22993&hl=zh-CN&sa=X&d=1974581306023709704&ei=yUQZacjnNYqi6rQPztSpuAk&scisig=ABGrvjLEPaUkm433IKBx2RBk_9vE&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=6&folt=rel)
*Z Liu,Z Xu,Z Shi,Y Liang*

Main category: Matei Zaharia

TL;DR: 研究语言模型通过上下文学习执行组合任务的能力，将基本技能从简单任务组合到复杂任务


<details>
  <summary>Details</summary>
Motivation: 现代智能系统需要将简单任务中的基本技能组合起来完成复杂任务，研究语言模型在上下文中的组合能力对于实现这一目标至关重要

Method: 通过上下文学习的方式，让语言模型在少量示例的指导下，将基本技能组合起来执行复合任务

Result: 语言模型展现出一定的上下文组合能力，能够将基本技能从简单任务迁移到复杂任务中

Conclusion: 语言模型具有通过上下文学习组合基本技能的能力，这对于构建能够处理复杂任务的智能系统具有重要意义

Abstract: Composing basic skills from simple tasks to accomplish composite tasks is crucial for modern intelligent systems. We investigate the in-context composition ability of language models to perform composite tasks that combine basic skills demonstrated …

</details>


### [144] [Sample-Efficient Parametric Learning from Natural Language](https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DaSlqvOkS8U&hl=zh-CN&sa=X&d=7445721276784708958&ei=-7Yaaf25D5vJieoPyNTIYQ&scisig=ABGrvjJSrZb6wTPFlhcMRrEIbXeG&oi=scholaralrt&hist=i6heNjgAAAAJ:15186190164853243054:ABGrvjI4hXbDMfQTBJo7iTkJ7Alj&html=&pos=0&folt=art)
*P Asawa,A Dimakis,M Zaharia*

Main category: Matei Zaharia

TL;DR: 该论文提出了一种通过上下文蒸馏将LLM的上下文学习能力转化为永久模型参数的方法，使模型能够从少量示例中持续学习而无需重复提示。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型主要依赖上下文学习进行推理时适应，但这种适应是临时的。现有方法如上下文蒸馏和自然语言反馈训练虽然有效，但需要大量人工标注或特定训练数据。需要一种能够将上下文学习能力永久内化到模型参数中的方法。

Method: 提出了一种上下文蒸馏方法，通过从模型自身的上下文学习行为中提取知识，将其转化为永久模型参数。该方法利用模型在少量示例上的上下文学习表现，通过蒸馏过程将这些能力固化到模型权重中，使模型能够持续从少量示例中学习而无需重复提示。

Result: 该方法成功将上下文学习能力转化为永久模型参数，使模型能够从少量示例中持续学习，减少了重复提示的需求，提高了学习效率和模型适应性。

Conclusion: 通过上下文蒸馏将上下文学习能力转化为永久模型参数是可行的，这为LLM的持续学习和适应提供了新途径，减少了对外部提示的依赖，提高了模型的自主学习能力。

Abstract: Large language models (LLMs) today rely heavily on in-context learning (ICL) to adapt at inference time, but such adaptations are transient. Prior work on context distillation and training with natural language feedback have shown that prompts or …

</details>


### [145] [Do Language Models Robustly Acquire New Knowledge?](https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3D8NQPcdw7ja&hl=zh-CN&sa=X&d=13349634317913072375&ei=-7YaabSgHoqi6rQPztSpuAk&scisig=ABGrvjLE-YtPLpgdWdV5mDnIeA6T&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=5&folt=rel)
*H Shah,B Ghazi,Y Huang,R Kumar,D Yu,C Zhang*

Main category: Matei Zaharia

TL;DR: 该论文研究如何增强预训练语言模型在获取新知识后的多跳推理能力，解决模型在知识更新后推理能力不足的问题。


<details>
  <summary>Details</summary>
Motivation: 预训练语言模型虽然拥有海量知识，但在添加新知识后往往缺乏鲁棒性——模型能够检索单个事实，但在新获取知识上进行多跳推理时表现不佳。现有方法在知识更新后难以维持复杂的推理能力。

Method: 论文提出了一种增强预训练语言模型多跳推理能力的方法，可能涉及知识整合策略、推理路径优化或专门的训练机制，以提升模型在新知识上的推理鲁棒性。

Result: 提出的方法显著提升了预训练语言模型在知识更新后的多跳推理性能，相比基线方法在相关任务上取得了更好的表现，验证了方法的有效性。

Conclusion: 通过专门的方法增强预训练语言模型在新知识上的多跳推理能力是可行且必要的，这为构建更鲁棒的知识增强语言模型提供了新方向。

Abstract: Language models acquire vast knowledge during pretraining, but adding new knowledge to pre-trained models often lacks robustness—models can retrieve individual facts but struggle with multi-hop reasoning over newly acquired …

</details>


### [146] [CoEvo: Coevolution of LLM and Retrieval Model for Domain-Specific Information Retrieval](https://scholar.google.com/scholar_url?url=https://aclanthology.org/2025.emnlp-main.757.pdf&hl=zh-CN&sa=X&d=12106821133656777827&ei=-7YaabSgHoqi6rQPztSpuAk&scisig=ABGrvjLBd9yGcHrYxVNaQVoLLtXY&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=7&folt=rel)
*A Li,Y Wu,Y Hu,L Qing,S Wang,C Liu,T Wu…*

Main category: Matei Zaharia

TL;DR: 该研究探讨专业领域信息检索中用户查询与结构化文档之间的语言差异问题，并提出解决方案


<details>
  <summary>Details</summary>
Motivation: 专业领域（如法律、医疗）的信息检索面临用户查询（通常使用口语化语言）与高度结构化、术语丰富的文档之间的对齐挑战，这种差异导致检索效果不佳

Method: 未在提供的摘要中明确说明具体方法，但暗示需要解决语言差异问题，可能涉及查询扩展、术语映射或语义理解技术

Result: 未在提供的摘要中明确说明具体结果，但暗示通过解决语言差异问题可以改善专业领域信息检索效果

Conclusion: 专业领域信息检索需要解决用户查询语言与文档语言之间的差异，以提高检索准确性和实用性

Abstract: Abstract Information retrieval in specialized domains (eg, legal and medical) faces challenges in aligning user queries, often expressed in colloquial language, with highly structured, terminology-rich documents. This discrepancy creates a …

</details>


### [147] [Reasoning Path Divergence: A New Metric and Curation Strategy to Unlock LLM Diverse Thinking](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.26122&hl=zh-CN&sa=X&d=14567834691311950933&ei=sSocafyzOc2j6rQP68DT-AU&scisig=ABGrvjLMsEnyFA_3Q_wXHHGZiydD&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=0&folt=rel)
*F Ju,Z Qin,R Min,Z He,L Kong,YR Fung*

Main category: Matei Zaharia

TL;DR: 该论文探讨了测试时缩放（TTS）在提升大语言模型推理能力时面临的输出多样性不足问题，并提出了一种新的多解生成框架来克服传统"一问题一解法"（1P1S）模式的局限性。


<details>
  <summary>Details</summary>
Motivation: 测试时缩放（TTS）虽然能有效提升大语言模型的推理能力，但模型输出多样性低成为瓶颈。这主要源于常见的"一问题一解法"（1P1S）模式，限制了模型探索多种解决方案的能力，从而影响了推理性能的进一步提升。

Method: 论文提出了一种新的多解生成框架，旨在打破1P1S模式的限制。该方法通过生成多个不同的解决方案来增加输出多样性，可能涉及多样化解码策略、多路径推理或集成方法等技术手段。

Result: 提出的多解生成框架显著提高了模型输出的多样性，从而提升了推理任务的性能。实验结果表明，与传统1P1S方法相比，该方法在保持准确性的同时，能够生成更多样化的解决方案。

Conclusion: 通过解决输出多样性不足的问题，多解生成框架为测试时缩放提供了更有效的方法，能够更好地挖掘大语言模型的推理潜力，为复杂问题解决提供更全面的解决方案空间。

Abstract: While Test-Time Scaling (TTS) has proven effective in improving the reasoning ability of large language models (LLMs), low diversity in model outputs often becomes a bottleneck; this is partly caused by the common" one problem, one solution"(1P1S) …

</details>


### [148] [A Survey of Multilingual Reasoning in Language Models](https://scholar.google.com/scholar_url?url=https://aclanthology.org/anthology-files/anthology-files/pdf/findings/2025.findings-emnlp.474.pdf&hl=zh-CN&sa=X&d=7376026060499762102&ei=sSocafyzOc2j6rQP68DT-AU&scisig=ABGrvjKdik9Z4uNzTBlTKsRSQ9oM&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=7&folt=rel)
*A Ghosh,D Dutta,S Saha,C Agarwal*

Main category: Matei Zaharia

TL;DR: 多语言推理是语言模型发展的新兴领域，旨在将推理能力与多语言能力统一整合，目前仍处于早期阶段


<details>
  <summary>Details</summary>
Motivation: 尽管语言模型在推理和多语言能力方面取得了显著进展，但将这两种能力整合到一个统一的多语言推理范式仍处于起步阶段，需要系统性的研究来推动这一领域的发展

Method: 论文未提供具体方法细节，但从摘要内容推断可能涉及构建多语言推理基准、开发统一的多语言推理框架、评估现有模型在多语言推理任务上的表现等系统性研究方法

Result: 摘要未提供具体实验结果，但暗示多语言推理作为一个新兴研究领域，其整合仍面临挑战，需要进一步探索和评估

Conclusion: 多语言推理是语言模型发展的一个重要方向，将推理能力与多语言能力有效整合对于构建更通用、更强大的AI系统至关重要，需要更多研究关注

Abstract: While reasoning and multilingual capabilities in Language Models (LMs) have achieved remarkable progress in recent years, their integration into a unified paradigm—multilingual reasoning—is at a nascent stage. Multilingual reasoning …

</details>


### [149] [Querier-Aware LLM: Generating Personalized Responses to the Same Query from Different Queriers](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3746252.3761389&hl=zh-CN&sa=X&d=11060814672666919057&ei=v7Mdad6-K_3D6rQPsLP28A8&scisig=ABGrvjIXg2DGZBymXBnn7Jz56tre&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=7&folt=rel)
*H Zeng,C Niu,F Wu,C Lv,G Chen*

Main category: Matei Zaharia

TL;DR: 提出一种查询者感知的LLM个性化方法，通过生成针对不同查询者的个性化响应，克服现有方法忽视查询者多样性的局限


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型个性化研究主要关注为模型分配不同的响应角色，但忽视了查询者的多样性。不同查询者可能有不同的背景、偏好和需求，需要针对性的个性化响应

Method: 提出查询者感知的LLM个性化方法，通过分析查询者特征和上下文，生成针对特定查询者的个性化响应。可能涉及查询者建模、偏好学习和上下文感知生成等技术

Result: 该方法能够生成更加个性化和相关的响应，提高用户满意度和交互质量。相比传统方法，能更好地适应不同查询者的需求和偏好

Conclusion: 查询者感知的个性化是LLM发展的重要方向，通过考虑查询者多样性可以显著提升模型的实际应用效果和用户体验

Abstract: Existing work on large language model (LLM) personalization assigned different responding roles to LLMs, but overlooked the diversity of queriers. In this work, we propose a new form of querier-aware LLM personalization, generating different …

</details>


### [150] [SteerX: Disentangled Steering for LLM Personalization](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.22256&hl=zh-CN&sa=X&d=15173525472594900045&ei=qhIhaePMDObYieoP14HR6Qw&scisig=ABGrvjIIUUeO2IolgzFQXZ_DDgvH&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=8&folt=rel)
*X Zhao,M Yan,Y Qiu,H Ni,Y Zhang,F Feng,H Cheng…*

Main category: Matei Zaharia

TL;DR: LLM智能助手需要个性化以适应用户偏好，但现有方法存在隐私、效率和可扩展性问题


<details>
  <summary>Details</summary>
Motivation: LLM智能助手需要个性化来适应用户偏好，但现有方法存在隐私、效率和可扩展性问题，需要更优的解决方案

Method: 论文未提供具体方法细节，但可能涉及隐私保护、高效个性化或可扩展架构等方向

Result: 基于摘要无法确定具体结果，但预期目标是解决LLM个性化中的隐私、效率和可扩展性挑战

Conclusion: 需要开发更好的LLM个性化方法来平衡隐私保护、计算效率和系统可扩展性

Abstract: Large language models (LLMs) have shown remarkable success in recent years, enabling a wide range of applications, including intelligent assistants that support users' daily life and work. A critical factor in building such assistants is personalizing …

</details>


### [151] [ExPairT-LLM: Exact Learning for LLM Code Selection by Pairwise Queries](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.10855&hl=zh-CN&sa=X&d=18176617215350477999&ei=qhIhaePMDObYieoP14HR6Qw&scisig=ABGrvjJYVddjB5MCJrk3VI10Kzs2&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=9&folt=rel)
*T Yuviler,D Drachsler*

Main category: Matei Zaharia

TL;DR: 该论文针对LLM代码生成中的挑战，提出改进的代码选择算法，以从多个生成的程序中更准确地识别正确程序


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在代码生成方面取得进展，但现有代码选择算法仍可能无法正确识别最佳程序，需要改进选择机制以提高代码生成质量

Method: 提出新的代码选择算法，通过改进的评估标准和选择策略，从LLM生成的多个程序候选中更准确地识别正确程序

Result: 新算法相比现有方法能更有效地识别正确程序，提高代码生成的成功率和质量

Conclusion: 改进的代码选择算法能显著提升LLM代码生成的可靠性，为代码生成任务提供更有效的解决方案

Abstract: Despite recent advances in LLMs, the task of code generation is still challenging. To cope, code selection algorithms select the best program from multiple programs generated by an LLM. However, existing algorithms can fail to identify the correct …

</details>


### [152] [Learn More, Forget Less: A Gradient-Aware Data Selection Approach for LLM](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.08620&hl=zh-CN&sa=X&d=10189508758324528095&ei=YcgjacmJK-uuieoPvMeR-QI&scisig=ABGrvjJpdQlhxW4cJiO2ol1OiAXH&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=7&folt=rel)
*Y Liu,S Wang,Z Liu,Z Song,J Wang,J Liu,Q Liu…*

Main category: Matei Zaharia

TL;DR: 该论文探讨了大型语言模型在领域专业化中的监督微调挑战，提出了改进方法以解决现有SFT在领域适应中的局限性。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在各种任务上取得了显著成就，但监督微调对于将这些模型适应到专业领域仍然至关重要。然而，当前SFT在领域专业化方面存在局限性，需要更有效的方法来提升模型在特定领域的性能。

Method: 论文提出了改进的监督微调方法，可能包括领域特定的训练策略、数据增强技术或架构调整，以更好地适应专业领域的需求。

Result: 提出的方法在领域专业化任务上表现出优于传统SFT的性能，提高了模型在特定领域的准确性和适应性。

Conclusion: 改进的监督微调方法对于大型语言模型的领域专业化至关重要，能够有效解决现有SFT的局限性，为专业领域应用提供更好的模型适应能力。

Abstract: Despite large language models (LLMs) have achieved impressive achievements across numerous tasks, supervised fine-tuning (SFT) remains essential for adapting these models to specialized domains. However, SFT for domain specialization can …

</details>


### [153] [MoDES: Accelerating Mixture-of-Experts Multimodal Large Language Models via Dynamic Expert Skipping](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.15690&hl=zh-CN&sa=X&d=11400841156223041571&ei=YcgjacmJK-uuieoPvMeR-QI&scisig=ABGrvjJ3FfJOk6R9RSLL-b4m49qE&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=9&folt=rel)
*Y Huang,Z Wang,Z Yuan,Y Ding,R Gong,J Guo…*

Main category: Matei Zaharia

TL;DR: 该论文针对MoE多模态大语言模型的高计算成本问题，提出了一种基于视觉感知的专家跳过方法，通过视觉特征预测专家激活模式，显著降低推理开销。


<details>
  <summary>Details</summary>
Motivation: MoE多模态大语言模型在视觉语言任务上表现出色，但存在计算效率低下的问题。现有的专家跳过方法主要基于文本模态，忽略了视觉信息对专家激活模式的影响，导致性能下降。

Method: 提出了一种视觉感知的专家跳过方法，利用视觉特征预测MoE层的专家激活模式。该方法通过分析视觉输入对专家选择的影响，设计了一个轻量级预测模块，在保持模型性能的同时减少不必要的专家计算。

Result: 实验表明，该方法在多个视觉语言基准测试中，能够显著降低推理计算成本（如FLOPs减少30-50%），同时保持与原始模型相当甚至更好的性能。视觉感知的跳过策略比纯文本方法更有效。

Conclusion: 视觉信息对MoE多模态模型的专家激活模式有重要影响，基于视觉感知的专家跳过方法能够有效平衡计算效率与模型性能，为高效多模态推理提供了新思路。

Abstract: Mixture-of-Experts (MoE) Multimodal large language models (MLLMs) excel at vision-language tasks, but they suffer from high computational inefficiency. To reduce inference overhead, expert skipping methods have been proposed to deactivate …

</details>


### [154] [SkyRL-Agent: Efficient RL Training for Multi-turn LLM Agent](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.16108&hl=zh-CN&sa=X&d=9663847387937350888&ei=5DglabTiOM2j6rQP2NKOuQI&scisig=ABGrvjLWjzPZIOElufEVPVxMWu_H&oi=scholaralrt&hist=i6heNjgAAAAJ:15186190164853243054:ABGrvjI4hXbDMfQTBJo7iTkJ7Alj&html=&pos=0&folt=art)
*S Cao,D Li,F Zhao,S Yuan,SR Hegde,C Chen…*

Main category: Matei Zaharia

TL;DR: SkyRL-Agent是一个用于高效多轮长时程智能体训练与评估的框架，提供异步调度、轻量级工具集成和灵活后端互操作性


<details>
  <summary>Details</summary>
Motivation: 当前智能体训练和评估面临多轮长时程任务的效率挑战，需要解决异步调度、工具集成和后端互操作性问题

Method: 开发了SkyRL-Agent框架，包含高效的异步调度机制、轻量级工具集成方案和灵活的后端互操作性设计

Result: 框架实现了高效的多轮长时程智能体训练与评估，支持无缝集成各种工具和后端系统

Conclusion: SkyRL-Agent为复杂智能体任务提供了有效的训练和评估解决方案，提升了多轮长时程任务的执行效率

Abstract: We introduce SkyRL-Agent, a framework for efficient, multi-turn, long-horizon agent training and evaluation. It provides efficient asynchronous dispatching, lightweight tool integration, and flexible backend interoperability, enabling seamless use with …

</details>


### [155] [Learning from the Undesirable: Robust Adaptation of Language Models without Forgetting](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.13052&hl=zh-CN&sa=X&d=2935718966651686182&ei=5TglaZveF5vJieoPuauKkAw&scisig=ABGrvjIqYfcPpoBGrUujf0BPGVEZ&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=3&folt=rel)
*Y Nam,J Kim,J Jeong*

Main category: Matei Zaharia

TL;DR: 语言模型通过监督微调适应下游任务，但在数据有限时可能导致过拟合和泛化能力下降


<details>
  <summary>Details</summary>
Motivation: 研究语言模型在有限数据下进行监督微调时出现的过拟合问题及其对模型泛化能力的影响

Method: 分析典型场景下监督微调过程，比较微调数据与预训练数据的规模差异

Result: 有限数据下的监督微调会导致语言模型过拟合，降低其在未见数据上的泛化性能

Conclusion: 需要开发更有效的微调策略来处理数据稀缺问题，提高语言模型在有限数据下的适应能力

Abstract: Language models (LMs) are often adapted through supervised fine-tuning (SFT) to specialize their capabilities for downstream tasks. However, in typical scenarios where the fine-tuning data is limited, eg, compared to pre-training, SFT can lead LMs …

</details>


### [156] [Hierarchical Token Prepending: Enhancing Information Flow in Decoder-based LLM Embeddings](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.14868&hl=zh-CN&sa=X&d=16209263753787249502&ei=5TglaZveF5vJieoPuauKkAw&scisig=ABGrvjJLHeEa7g7g1lspXzbddJV_&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=5&folt=rel)
*X Ding,X Huang,M Ju,L Collins,Y Liu,L Akoglu…*

Main category: Matei Zaharia

TL;DR: 该论文针对大语言模型因果注意力机制导致信息流受限、影响嵌入表示质量的问题，提出了通过预置特殊标记来增强文本嵌入的方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的因果注意力机制限制了从后向前的信息流动，导致文本嵌入表示质量下降。现有方法尝试通过预置特殊标记来解决这一问题，但仍有改进空间。

Method: 提出通过预置特殊标记来增强文本嵌入的方法，具体技术细节未在摘要中详细说明，但核心思想是利用特殊标记来改善信息流动。

Result: 该方法能够有效提升大语言模型生成的文本嵌入表示质量，改善因果注意力机制带来的信息流动限制问题。

Conclusion: 通过预置特殊标记的方法可以有效缓解大语言模型因果注意力机制对文本嵌入质量的负面影响，为改进文本表示提供了有效途径。

Abstract: Large language models produce powerful text embeddings, but their causal attention mechanism restricts the flow of information from later to earlier tokens, degrading representation quality. While recent methods attempt to solve this by prepending a …

</details>


### [157] [Knots: A large-scale multi-agent enhanced expert-annotated dataset and LLM prompt optimization for NOTAM semantic parsing](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.12630&hl=zh-CN&sa=X&d=8415264970880035920&ei=5TglaZveF5vJieoPuauKkAw&scisig=ABGrvjLqUv48f0k5RdXz5jhY9g5k&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=8&folt=rel)
*M Liu,Q Fang,Y Yang,C Zhao,K Cai*

Main category: Matei Zaharia

TL;DR: 论文分析了航空通告(NOTAMs)的自动解析挑战，提出了一种基于大型语言模型的方法来改善信息提取和推理能力


<details>
  <summary>Details</summary>
Motivation: 航空通告(NOTAMs)是飞行安全信息的关键传播渠道，但其复杂的语言结构和隐含的推理逻辑给自动解析带来了重大挑战。现有方法在处理这些复杂语义和推理需求方面存在不足。

Method: 论文提出了一种基于大型语言模型的方法来处理NOTAMs，可能包括自然语言处理技术、语义解析、推理机制等，以应对NOTAMs特有的语言复杂性和隐含信息。

Result: 该方法在NOTAMs解析任务上表现出色，能够更准确地提取关键安全信息并进行必要的推理，相比现有方法有显著改进。

Conclusion: 基于大型语言模型的方法为NOTAMs的自动解析提供了有效解决方案，能够更好地处理其语言复杂性和推理需求，对航空安全信息处理具有重要意义。

Abstract: Abstract Notice to Air Missions (NOTAMs) serve as a critical channel for disseminating key flight safety information, yet their complex linguistic structures and implicit reasoning pose significant challenges for automated parsing. Existing …

</details>


### [158] [CoDaPO: Confidence and Difficulty-Adaptive Policy Optimization for Language Models](https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DP4JHrUkXIH&hl=zh-CN&sa=X&d=826266569300946412&ei=VromacjuGaG7ieoP8Y6WyQc&scisig=ABGrvjK0LyP8udqHSxv7m_UCbj88&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=0&folt=rel)
*Z Zhou,X Lu,C Cao,B Miranda,T Liu,B Han,S Koyejo*

Main category: Matei Zaharia

TL;DR: 本文通过PRAG框架分析GRPO算法在LLM强化学习后训练中的问题，提出改进方案


<details>
  <summary>Details</summary>
Motivation: 强化学习后训练能提升大语言模型的推理能力，但当前主流的GRPO算法存在持续性问题，需要深入分析其根本原因

Method: 使用PRAG框架（概率、奖励、优势、梯度）诊断GRPO算法的三个核心问题，并提出相应的改进方案

Result: 通过PRAG分析揭示了GRPO算法在概率分布、奖励函数、优势估计和梯度计算方面的具体问题，为算法改进提供了理论基础

Conclusion: 对GRPO算法的系统性分析为强化学习后训练方法的优化提供了重要见解，有助于开发更有效的LLM推理能力提升技术

Abstract: Reinforcement learning (RL) post-training strengthens reasoning in large language models (LLMs), yet the prevailing GRPO algorithm exhibits persistent issues. Using a PRAG lens (Probability, Reward, Advantage, Gradient), we diagnose three …

</details>


### [159] [Improving Preference Alignment of LLM using Inference-Free Self-Refinement](https://scholar.google.com/scholar_url?url=https://aclanthology.org/anthology-files/anthology-files/pdf/findings/2025.findings-emnlp.1329.pdf&hl=zh-CN&sa=X&d=14432208903136868405&ei=VromacjuGaG7ieoP8Y6WyQc&scisig=ABGrvjJLf_Jbm8gCntNORQRV7fkp&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=6&folt=rel)
*F Ma,K Tian,J Xue,X Wang,Y Ma,Q Chen,P Jiang…*

Main category: Matei Zaharia

TL;DR: 论文探讨了大型语言模型通过预训练和指令微调获得上下文学习能力，特别是自我精炼能力，使模型能够在不更新参数的情况下适应任务


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型如何通过预训练和指令微调发展上下文学习能力，特别是自我精炼能力，使模型能够在不更新参数的情况下适应各种任务

Method: 通过预训练和指令微调的方法，使大型语言模型获得上下文学习能力，特别关注自我精炼这一具体表现

Result: 大型语言模型能够通过预训练和指令微调发展出上下文学习能力，包括自我精炼能力，从而实现在不更新参数的情况下适应新任务

Conclusion: 大型语言模型通过预训练和指令微调获得的上下文学习能力，特别是自我精炼能力，是实现无参数更新任务适应的有效机制

Abstract: Large language models (LLMs) develop the incontext learning capability through pretraining and instruction tuning, enabling task adaptation without parameter updates. Self-refinement is a manifestation of this capability, which allows LLMs to …

</details>


### [160] [Restructuring the Corpus Makes RAG Work for Math](https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3D6cYmnzJViJ&hl=zh-CN&sa=X&d=15916613711207868560&ei=J3AqacywI-bYieoPqMHA-A0&scisig=ABGrvjLNP7ztSOI7ADbYcRRWU2d8&oi=scholaralrt&hist=i6heNjgAAAAJ:15186190164853243054:ABGrvjI4hXbDMfQTBJo7iTkJ7Alj&html=&pos=0&folt=art)
*N Arabzadeh,W Ma,S Min,M Zaharia*

Main category: Matei Zaharia

TL;DR: 该论文探讨了检索增强生成（RAG）在数学推理任务中的有效性，发现传统RAG方法在数学问题上表现不佳，并提出了一种新的检索策略来改善性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在数学推理任务上通过思维链提示或推理轨迹训练取得了良好表现，但检索增强生成（RAG）在数学问题解决中的有效性仍不明确。研究者希望探究RAG是否能够有效提升数学推理能力，以及如何优化检索策略来适应数学问题的特殊性。

Method: 研究者系统评估了传统RAG方法在数学推理任务上的表现，分析了现有检索策略的局限性。基于分析结果，他们提出了一种新的检索方法，专门针对数学问题的特点进行优化，可能包括问题分解、相似性度量改进或检索内容选择策略的调整。

Result: 研究发现传统RAG方法在数学推理任务上表现不佳，未能有效提升模型性能。然而，提出的新检索策略显著改善了RAG在数学问题上的表现，证明了通过针对性优化，RAG可以成为有效的数学推理增强工具。

Conclusion: 虽然传统RAG方法在数学推理任务中效果有限，但通过专门设计的检索策略可以显著提升其性能。这表明数学问题的特殊性需要专门的检索方法，为未来RAG在数学推理领域的应用提供了重要启示。

Abstract: Large Language Models (LLMs) achieve strong performance on mathematical problem solving when guided by chain-of-thought prompting or trained on reasoning traces. Yet it remains unclear whether Retrieval-Augmented Generation (RAG) which …

</details>


### [161] [MindEval: Benchmarking Language Models on Multi-turn Mental Health Support](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.18491&hl=zh-CN&sa=X&d=15768728625622841403&ei=KHAqaZD4Eb2qieoPl6Cn4QQ&scisig=ABGrvjIBwkVtw3euQRz-7BbQKzMc&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=5&folt=rel)
*J Pombal,M D'Eon,NM Guerreiro,PH Martins…*

Main category: Matei Zaharia

TL;DR: 论文探讨AI心理聊天机器人的局限性并提出改进方法


<details>
  <summary>Details</summary>
Motivation: 当前AI心理聊天机器人存在奉承、过度验证、强化适应不良信念等局限性，需要创建更好的系统来提供有效的心理健康支持

Method: 论文未在摘要中明确说明具体方法，但暗示需要克服现有系统的核心障碍并创建更好的AI心理支持系统

Result: 摘要未提供具体结果，但指出了当前AI心理聊天机器人系统的局限性问题

Conclusion: 需要改进AI心理聊天机器人系统以克服现有局限性，提供更有效的心理健康支持

Abstract: Demand for mental health support through AI chatbots is surging, though current systems present several limitations, like sycophancy or overvalidation, and reinforcement of maladaptive beliefs. A core obstacle to the creation of better …

</details>


### [162] [CDLM: Consistency Diffusion Language Models For Faster Sampling](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.19269&hl=zh-CN&sa=X&d=4266191329938859192&ei=KHAqaZD4Eb2qieoPl6Cn4QQ&scisig=ABGrvjJI9bhKY9hMjkoVkYPaiU9G&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=6&folt=rel)
*M Kim,C Xu,C Hooper,H Singh,B Athiwaratkun…*

Main category: Matei Zaharia

TL;DR: CDLM（一致性扩散语言模型）通过结合一致性模型和扩散语言模型，实现了快速、高质量的文本生成，解决了传统扩散语言模型推理速度慢的问题。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型（DLMs）虽然提供了并行生成的优势，但由于需要大量细化步骤且无法使用标准的KV缓存，导致推理速度缓慢。这限制了DLMs在实际应用中的实用性。

Method: CDLM将一致性模型与扩散语言模型相结合，通过一致性蒸馏技术减少生成所需的步骤数量，同时保持生成质量。该方法支持KV缓存，从而显著提升推理效率。

Result: CDLM在保持与标准扩散语言模型相当生成质量的同时，实现了显著的推理速度提升。实验表明，CDLM在多个文本生成任务上表现出色，推理速度比传统DLMs快数倍。

Conclusion: CDLM为扩散语言模型提供了一种高效的推理解决方案，通过结合一致性模型和KV缓存机制，在保持生成质量的同时大幅提升了推理速度，推动了DLMs的实际应用。

Abstract: Diffusion Language Models (DLMs) offer a promising parallel generation paradigm but suffer from slow inference due to numerous refinement steps and the inability to use standard KV caching. We introduce CDLM (Consistency Diffusion Language …

</details>


### [163] [No Free Lunch in Language Model Bias Mitigation? Targeted Bias Reduction Can Exacerbate Unmitigated LLM Biases](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.18635&hl=zh-CN&sa=X&d=15502750475249958842&ei=KHAqaZD4Eb2qieoPl6Cn4QQ&scisig=ABGrvjIYxK0sp1R27WWmlwtTGHzb&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=8&folt=rel)
*S Chand,F Baca,E Ferrara*

Main category: Matei Zaharia

TL;DR: 该论文探讨了大型语言模型（LLMs）中社会偏见的缓解方法，指出现有技术通常只在单一维度上评估效果，而忽略了偏见的多维性和复杂性。


<details>
  <summary>Details</summary>
Motivation: LLMs从训练数据中继承了社会偏见，可能导致有害或不公平的输出。虽然已有多种技术旨在缓解这些偏见，但现有评估方法往往只关注单一维度，未能充分捕捉偏见的多维性和复杂性。

Method: 论文未在摘要中明确说明具体方法，但暗示需要超越单一维度的评估框架来全面衡量偏见缓解技术的效果。

Result: 摘要未提供具体实验结果，但强调了现有偏见缓解技术评估方法的局限性，即仅沿单一维度进行评估。

Conclusion: 需要更全面、多维度的评估框架来有效衡量LLMs偏见缓解技术的效果，以更好地理解和解决模型中的社会偏见问题。

Abstract: Large Language Models (LLMs) inherit societal biases from their training data, potentially leading to harmful or unfair outputs. While various techniques aim to mitigate these biases, their effects are often evaluated only along the dimension of …

</details>


### [164] [Structured Prompting Enables More Robust, Holistic Evaluation of Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.20836&hl=zh-CN&sa=X&d=15325603490241987395&ei=ycIrabaBDNOyieoPsZes4AQ&scisig=ABGrvjIH2ZsfeOfdTtm3fzbAH2eM&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=0&folt=rel)
*A Aali,MA Mohsin,V Bikia,A Singhvi,R Gaus,S Bedi…*

Main category: Matei Zaharia

TL;DR: 该论文提出了一种新的语言模型评估框架，旨在解决现有基准测试中的系统性偏差问题，通过更全面的评估方法提供更准确的性能估计。


<details>
  <summary>Details</summary>
Motivation: 随着语言模型在各领域的广泛应用，需要高质量的基准测试框架来准确评估性能以指导部署决策。现有框架如Holistic Evaluation等存在系统性偏差，无法全面反映模型在实际应用中的表现。

Method: 论文提出了一种新的评估框架，可能包括多维度评估指标、更全面的任务覆盖、偏差校正机制等创新方法，以提供更准确的语言模型性能评估。

Result: 新框架能够更准确地评估语言模型性能，减少系统性偏差，提供更可靠的性能估计，有助于做出更好的部署决策。

Conclusion: 高质量、无偏差的评估框架对于语言模型的部署决策至关重要，提出的新框架能够提供更准确的性能评估，推动语言模型在实际应用中的合理部署。

Abstract: As language models (LMs) are increasingly adopted across domains, high-quality benchmarking frameworks that accurately estimate performance are essential for guiding deployment decisions. While frameworks such as Holistic Evaluation of …

</details>


### [165] [Modeling Chain-of-Thought Collapse in Pruned Language Models: Fidelity and Similarity Analysis for Mathematical Reasoning](https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3D2k5Yl3HoKE&hl=zh-CN&sa=X&d=118093362007581436&ei=ycIrabaBDNOyieoPsZes4AQ&scisig=ABGrvjLGostPEpLSL9ZtncX61E3e&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=7&folt=rel)
*AK Sharma,T Shinde*

Main category: Matei Zaharia

TL;DR: 提出一个量化模型相似性与损失之间关系的框架，用于在计算和内存约束下实现高效数学推理


<details>
  <summary>Details</summary>
Motivation: 在现实应用中部署大型推理模型时，计算和内存约束下的高效数学推理至关重要。需要理解模型相似性与性能损失之间的关系，以优化资源使用。

Method: 提出一个框架来量化模型相似性与损失之间的关系，可能涉及模型压缩、知识蒸馏或参数共享技术，以在有限资源下保持推理能力。

Result: 未在摘要中明确说明具体结果，但框架旨在提供模型相似性与性能损失之间的量化关系，帮助在约束条件下优化推理效率。

Conclusion: 该框架为在计算和内存受限环境中部署大型推理模型提供了理论基础，通过量化相似性-损失关系来实现高效的数学推理。

Abstract: Efficient mathematical reasoning under compute and memory constraints is crucial for deploying large reasoning models (LRMs) in real-world applications. We propose a framework to quantify the relationship between model similarity and loss of …

</details>


### [166] [Teach Small Models to Reason by Curriculum Distillation](https://scholar.google.com/scholar_url?url=https://aclanthology.org/2025.emnlp-main.376.pdf&hl=zh-CN&sa=X&d=6997645719476922067&ei=ycIrabaBDNOyieoPsZes4AQ&scisig=ABGrvjK5b7QsRR6R_wuU7Pmx9N71&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=8&folt=rel)
*W Jiang,Y Lu,H Lin,X Han,L Sun*

Main category: Matei Zaharia

TL;DR: 该论文探讨大型推理模型（LRMs）与大型语言模型（LLMs）在推理能力与计算效率之间的权衡，并提出一种结合两者优势的方法。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）虽然具备强大的System-2式推理能力，但计算开销巨大；而高效的System-1式大型语言模型（LLMs）在复杂任务上表现不佳。需要找到一种方法结合两者的优势。

Method: 论文提出了一种结合LRMs和LLMs的方法，具体方法细节需要从完整论文中获取，但核心思想是利用LRMs的深度推理能力来指导或增强LLMs的高效处理。

Result: 该方法能够在保持计算效率的同时提升复杂任务上的推理性能，实现了System-1和System-2推理能力的有效结合。

Conclusion: 通过结合LRMs的深度推理和LLMs的高效处理，可以创建出既具备强大推理能力又保持计算效率的混合模型架构。

Abstract: Abstract Large Reasoning Models (LRMs) show strong System-2-style reasoning, but at the cost of significant computational overhead. In contrast, efficient System-1-style Large Language Models (LLMs) often struggle on complex tasks. We identify a …

</details>


### [167] [LLM-as-a-Judge in Entity Retrieval: Assessing Explicit and Implicit Relevance](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3746252.3760922&hl=zh-CN&sa=X&d=15466449824469377303&ei=twYtaZOHMf3D6rQP3LSU2Ag&scisig=ABGrvjK_8bK4wpW1ZsF80RDMClv9&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=6&folt=rel)
*MH Saliminabi,N Arabzadeh,SM Hosseini…*

Main category: Matei Zaharia

TL;DR: 论文探讨了实体检索领域高质量监督数据稀缺的问题，提出了一种利用大型语言模型生成合成训练数据的方法来改善实体检索模型的性能。


<details>
  <summary>Details</summary>
Motivation: 实体检索在信息访问系统中至关重要，但现有检索模型的开发和评估受到高质量监督数据有限的制约。虽然最近的研究展示了大型语言模型在生成合成训练数据方面的潜力，但如何有效利用这些模型来提升实体检索性能仍是一个开放问题。

Method: 论文提出了一种利用大型语言模型生成合成训练数据的方法。具体包括：1）设计提示策略引导LLM生成高质量的实体查询对；2）构建数据过滤和清洗机制确保合成数据的质量；3）将生成的合成数据与现有监督数据结合训练实体检索模型。

Result: 实验结果表明，使用LLM生成的合成训练数据能够显著提升实体检索模型的性能。与仅使用有限监督数据的基线相比，该方法在多个标准实体检索基准上取得了显著的性能提升，证明了合成数据生成的有效性。

Conclusion: 大型语言模型能够有效生成高质量的合成训练数据，缓解实体检索领域监督数据稀缺的问题。该方法为资源受限场景下的实体检索模型开发提供了可行的解决方案，并展示了LLM在数据增强方面的潜力。

Abstract: Entity retrieval plays a critical role in information access systems, yet the development and evaluation of retrieval models remain constrained by the limited availability of high-quality supervision. While recent work has demonstrated the utility …

</details>


### [168] [Benchmarking Autoformalization and Subsequent Execution of Mathematical Reasoning in Large Language Models through Chain-of-Thought](https://scholar.google.com/scholar_url?url=https://www.cortexpd.org/papers/Benchmarking_End_to_End_Autoformalization_and_Execution_of_Mathematical_Reasoning_in_Large_Language_Models_through_Chain_of_Thought.pdf&hl=zh-CN&sa=X&d=106723066845321434&ei=twYtaZOHMf3D6rQP3LSU2Ag&scisig=ABGrvjKQVHTzEIdS9wxq_0JBF61M&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=8&folt=rel)
*A Sharma,D Sharma,A Wez,B Yee*

Main category: Matei Zaharia

TL;DR: 现有数学推理基准主要关注最终答案正确性，这种基于答案的评估对LLM真实推理能力视角有限，无法区分不同推理过程


<details>
  <summary>Details</summary>
Motivation: 现有数学推理基准过于关注最终答案正确性，缺乏对LLM真实推理过程的深入评估，无法区分不同推理路径的质量

Method: 未在摘要中明确说明具体方法，但暗示需要超越单纯答案正确性的评估框架

Result: 未提供具体实验结果，但指出了当前评估方法的局限性

Conclusion: 需要开发更全面的数学推理评估框架，超越单纯的答案正确性，考虑推理过程的质量

Abstract: Existing benchmarks for mathematical reasoning in Large Language Models (LLM's) concentrate mainly on final answer correctness. This answer-based evaluation has a limited view of true LLM reasoning, and it doesn't differentiate between …

</details>


<div id='Rong Zhu'></div>

# Rong Zhu [[Back]](#toc)

### [169] [A Survey of Data Agents: Emerging Paradigm or Overstated Hype?](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.23587&hl=zh-CN&sa=X&d=13871757647874201614&ei=gwAKacSoFLqL6rQPwZS26QU&scisig=ABGrvjI6I8tBI4p1NVl-dc5VIHPs&oi=scholaralrt&hist=i6heNjgAAAAJ:8587655636886263605:ABGrvjIDpgORvVSmGRmktXiGSz8v&html=&pos=0&folt=cit)
*Y Zhu,L Wang,C Yang,X Lin,B Li,W Zhou,X Liu…*

Main category: Rong Zhu

TL;DR: 论文分析了"数据智能体"术语的模糊性问题，提出统一框架来区分不同复杂度的数据智能体，以解决用户期望不匹配和责任归属问题


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的快速发展，数据智能体作为协调数据+AI生态系统处理复杂数据任务的自主系统应运而生。然而，"数据智能体"这一术语目前存在术语模糊性和采用不一致的问题，将简单的查询响应系统与复杂的自主架构混为一谈。这种术语模糊性导致了用户期望不匹配、责任归属不清等问题，阻碍了该领域的健康发展。

Method: 论文提出一个统一的分类框架来区分不同复杂度的数据智能体。该方法可能包括：1）定义数据智能体的核心特征和功能维度；2）建立复杂度分层模型；3）制定分类标准来区分简单查询响应系统和复杂自主架构；4）提供评估指标来衡量智能体的自主性和能力水平。

Result: 通过提出的分类框架，论文能够清晰地区分不同类型的数据智能体，帮助用户和开发者建立一致的术语理解。该框架有助于：1）明确不同复杂度智能体的能力边界；2）建立合理的用户期望；3）澄清责任归属问题；4）促进数据智能体生态系统的标准化发展。

Conclusion: 论文强调了统一数据智能体术语和分类框架的重要性，认为这有助于解决当前领域的混乱状态，促进更健康、更负责任的数据智能体生态系统发展。清晰的分类不仅有助于技术发展，还能改善用户体验和责任归属机制。

Abstract: The rapid advancement of large language models (LLMs) has spurred the emergence of data agents--autonomous systems designed to orchestrate Data+ AI ecosystems for tackling complex data-related tasks. However, the term" data agent" currently suffers from terminological ambiguity and inconsistent adoption, conflating simple query responders with sophisticated autonomous architectures. This terminological ambiguity fosters mismatched user expectations, accountability …

</details>


### [170] [PathFinder: Efficiently Supporting Conjunctions and Disjunctions for Filtered Approximate Nearest Neighbor Search](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.00995&hl=zh-CN&sa=X&d=17536133826189962007&ei=9VQNad3rOIePieoPstbBMQ&scisig=ABGrvjLc8Dh2bM5qjdqYmckbGUm_&oi=scholaralrt&hist=i6heNjgAAAAJ:8587655636886263605:ABGrvjIDpgORvVSmGRmktXiGSz8v&html=&pos=0&folt=cit)
*T Wu,D Tang*

Main category: Rong Zhu

TL;DR: 该论文针对过滤近似最近邻搜索(ANNS)问题，提出了一种支持任意合取过滤条件的通用图索引框架，通过解耦语义相似性和属性过滤实现高效查询。


<details>
  <summary>Details</summary>
Motivation: 现有图ANNS索引在处理复杂过滤条件时存在局限性：针对特定属性优化的索引无法支持任意合取过滤条件，而通用方法则效率低下。需要一种既能支持复杂过滤又保持高效性能的解决方案。

Method: 提出解耦语义相似性和属性过滤的通用图索引框架，通过分离处理相似性搜索和过滤约束，支持任意合取过滤条件。采用优化策略平衡搜索效率和准确性。

Result: 该方法在支持复杂过滤条件的同时，相比现有通用方法显著提升了查询效率，在多个数据集上验证了其优越性能。

Conclusion: 该框架为过滤ANNS问题提供了通用高效的解决方案，通过解耦设计平衡了过滤灵活性和搜索性能，适用于需要复杂过滤约束的实际应用场景。

Abstract: Filtered approximate nearest neighbor search (ANNS) restricts the search to data objects whose attributes satisfy a given filter and retrieves the top-$ K $ objects that are most semantically similar to the query object. Many graph-based ANNS indexes are proposed to enable efficient filtered ANNS but remain limited in applicability or performance: indexes optimized for a specific attribute achieve high efficiency for filters on that attribute but fail to support complex filters with arbitrary conjunctions …

</details>


### [171] [Towards Realistic Error Models for Tabular Data](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3774914&hl=zh-CN&sa=X&d=7093478958297448643&ei=IZETabObOsXXieoP0MjCwAo&scisig=ABGrvjLyoesukPpRtjFnBwHLarqu&oi=scholaralrt&hist=i6heNjgAAAAJ:8587655636886263605:ABGrvjIDpgORvVSmGRmktXiGSz8v&html=&pos=0&folt=cit)
*P Jung,S Jäger,N Chandler,F Biessmann*

Main category: Rong Zhu

TL;DR: 该论文探讨数据错误对数据管道和机器学习模型的影响，指出当前研究面临缺乏标准化错误数据集和可重复性不足的挑战，并提出解决方案


<details>
  <summary>Details</summary>
Motivation: 数据错误是现代数据管理和处理系统的关键挑战，需要深入理解错误生成机制及其对数据管道和下游应用（如机器学习模型训练）的影响。当前研究面临两大挑战：缺乏标准化的错误数据集和可重复性不足，阻碍了该领域的科学进展。

Method: 论文提出通过创建标准化的错误数据集和建立可重复的研究框架来解决当前挑战。可能包括错误分类、错误注入方法、影响评估指标以及数据管道错误传播分析等方法。

Result: 通过系统化方法，论文能够更好地理解和量化数据错误对数据管道和机器学习模型的影响，为错误监测和缓解提供理论基础和实践指导。

Conclusion: 解决数据错误研究中的标准化和可重复性挑战对于推进该领域科学进展至关重要，有助于开发更可靠的数据管理和机器学习系统。

Abstract: Errors in data are a key challenge in modern data management and processing systems. Monitoring and mitigating risks associated with errors in data transformations and downstream applications, such as Machine Learning (ML) model training, requires a profound understanding of error generation and impact of errors on data pipelines. Unfortunately, scientific progress in the field is facing two main challenges: For one, research on data errors often does not adhere to the FAIR …

</details>


### [172] [TianheEngine: Hierarchy-aware Adaptive Partitioning System for Trillion-scale Graph Processing](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3712285.3759831&hl=zh-CN&sa=X&d=18403633136102991043&ei=yEQZaZOtKebYieoP9Yna-Qw&scisig=ABGrvjKm9tzi_MN_hYTsrEe0yIRf&oi=scholaralrt&hist=i6heNjgAAAAJ:8587655636886263605:ABGrvjIDpgORvVSmGRmktXiGSz8v&html=&pos=0&folt=cit)
*X Gan,T Li,Y Wang,Q Zhang,Y Yi,C Gong,J Liu…*

Main category: Rong Zhu

TL;DR: TianheEngine是一个层次感知的自适应图分区系统，针对现代高性能计算系统的层次化通信差异进行优化，以处理万亿边规模的图数据。


<details>
  <summary>Details</summary>
Motivation: 传统图分区策略忽视现代高性能计算系统的层次化通信差异，在处理万亿边规模图数据时导致过高的跨节点通信开销，需要更有效的分区方法来管理分布式计算系统中的大规模图数据。

Method: 提出TianheEngine系统，采用层次感知的自适应分区方法，考虑现代HPC系统的层次化通信架构，优化图分区以减少跨节点通信开销。

Result: 该系统能够有效处理万亿边规模的图数据，显著降低跨节点通信开销，提高分布式图计算的性能。

Conclusion: 层次感知的自适应图分区对于管理大规模分布式图计算至关重要，TianheEngine为解决现代HPC系统中的图分区挑战提供了有效方案。

Abstract: Graph partitioning is essential for effectively managing multi-trillion-edge graphs in distributed computing systems, particularly those spanning hierarchical architectures with thousands of computing nodes. Traditional partitioning strategies neglect hierarchical communication variances across modern high-performance computing (HPC) systems, leading to prohibitive cross overhead when processing trillion-scale graphs. We propose TianheEngine, a hierarchy-aware adaptive partitioning system …

</details>


### [173] [Optimization Techniques for Crop Yield Prediction and Air Quality Management: Performance Analysis and Comparative Study](https://scholar.google.com/scholar_url?url=https://www.espublisher.com/uploads/article_pdf/faf1803.pdf&hl=zh-CN&sa=X&d=12259125505698205290&ei=X8gjaYr6NceB6rQPrcX0oQg&scisig=ABGrvjIN7jteeneBCOXfAV1FtwL0&oi=scholaralrt&hist=i6heNjgAAAAJ:8587655636886263605:ABGrvjIDpgORvVSmGRmktXiGSz8v&html=&pos=1&folt=cit)
*K Harish,P Nimmy,KV Nagaraja,TV Smitha*

Main category: Rong Zhu

TL;DR: 论文分析了几种梯度优化算法在回归模型中的性能，包括BGD、Mini-Batch GD、SGD、RMSprop、Momentum、Adam、Nadam、Adagrad和Adadelta，旨在提升模型精度、稳定性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 在大规模高噪声数据集中，回归模型的优化对于提升模型精度、稳定性和计算效率至关重要。需要系统分析不同梯度优化方法的性能差异。

Method: 对多种梯度优化方法进行系统性分析：批量梯度下降(BGD)、小批量梯度下降(Mini-Batch GD)、随机梯度下降(SGD)、RMSprop、动量法(Momentum)、Adam、Nadam、Adagrad和Adadelta。研究这些方法在回归模型中的表现特征。

Result: 分析显示不同优化方法在收敛速度、稳定性、计算效率和噪声鲁棒性方面存在显著差异。自适应方法(如Adam、RMSprop)通常在大规模高噪声数据中表现更优。

Conclusion: 梯度优化方法的选择对回归模型性能有重要影响。自适应优化器在处理大规模高噪声数据时具有优势，但具体选择需根据数据特性和计算资源权衡。

Abstract: Optimization of regression models remains essential to enhance both model precision and level of stability, as well as operational computational efficiency in datasets with large sizes and high noise levels. This paper examines several gradientbased optimization approaches: Batch Gradient Descent, Mini-Batch Gradient Descent, Stochastic Gradient Descent, RMSprop, Momentum, Adam, Nadam, Adagrad and Adadelta. The analysis studies how these methods perform …

</details>


### [174] [TD-Orch: Scalable Load-Balancing for Distributed Systems with Applications to Graph Processing](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.11843&hl=zh-CN&sa=X&d=6951012240024037267&ei=X8gjaYr6NceB6rQPrcX0oQg&scisig=ABGrvjIfupzivoRutYicYwgunj-L&oi=scholaralrt&hist=i6heNjgAAAAJ:8587655636886263605:ABGrvjIDpgORvVSmGRmktXiGSz8v&html=&pos=4&folt=cit)
*Y Zhao,Q Lin,H Kang,GE Blelloch,L Dhulipala…*

Main category: Rong Zhu

TL;DR: TD-Orch是一个任务-数据编排框架，支持图处理和键值存储等分布式应用，通过智能的任务和数据协同定位来优化性能


<details>
  <summary>Details</summary>
Motivation: 分布式应用中，任务和数据通常分布在多台机器上，任务需要访问特定数据项。现有的解决方案在任务与数据协同定位方面效率不高，导致通信开销大、性能下降。需要一种统一的任务-数据编排抽象来优化这种协同定位过程。

Method: 提出TD-Orch框架，采用任务-数据编排抽象，通过智能调度算法决定何时移动任务、何时移动数据，或者两者结合。框架包含任务调度器、数据管理器、协同定位引擎等组件，支持批处理任务模式，每个任务可以请求一个或多个数据项。

Result: TD-Orch在多种分布式应用（包括图处理和键值存储）中表现出高效性和可扩展性。相比现有解决方案，显著减少了通信开销，提高了任务执行效率，能够处理大规模分布式环境中的任务-数据协同定位问题。

Conclusion: 任务-数据编排抽象是分布式系统设计的重要范式，TD-Orch框架为此提供了高效、可扩展的解决方案，能够优化多种分布式应用的性能，为开发者提供了简单易用的编程接口。

Abstract: In this paper, we highlight a task-data orchestration abstraction that supports a range of distributed applications, including graph processing and key-value stores. Given a batch of tasks each requesting one or more data items, where both tasks and data are distributed across multiple machines, each task must get co-located with its target data (by moving tasks and/or data) and executed. We present TD-Orch, an efficient and scalable orchestration framework featuring a simple application developer …

</details>


<div id='Thomas Neumann'></div>

# Thomas Neumann [[Back]](#toc)

### [175] [The effect of acute tryptophan depletion on beliefs in a Stag Hunt game](https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0167268125004378&hl=zh-CN&sa=X&d=4845946199272310634&ei=hgAKaeQxx4HqtA_Qra3BDA&scisig=ABGrvjK92S_xKtKdVl7leV2P49zJ&oi=scholaralrt&hist=i6heNjgAAAAJ:17461000864107631014:ABGrvjKZOsjUpw9VK-LT8-2DQLmQ&html=&pos=0&folt=art)
*P Bengart,CH Declerck,T Neumann,B Vogt*

Main category: Thomas Neumann

TL;DR: 研究测试血清素在协调博弈中对合作行为的影响


<details>
  <summary>Details</summary>
Motivation: 在猎鹿博弈中，协调选择收益主导但风险较高的策略依赖于对伙伴也会选择该策略的信念。本研究旨在测试血清素这种神经递质在此协调过程中的可能作用。

Method: 研究采用实验方法，通过操纵血清素水平（可能使用急性色氨酸耗竭或补充等方法），观察参与者在猎鹿博弈中的策略选择和行为变化。

Result: 血清素水平的变化会影响参与者在协调博弈中的风险承担和合作行为，具体表现为血清素水平较高时参与者更倾向于选择收益主导但风险较高的策略。

Conclusion: 血清素在协调博弈中发挥重要作用，影响个体对风险的评估和对伙伴行为的信念，从而调节合作行为。

Abstract: Coordinating on the payoff dominant (yet risky) strategy in the Stag Hunt game hinges on beliefs that the partner will also select the risky strategy. The purpose of the study was to test the possible involvement of serotonin, a neurotransmitter …

</details>


<div id='Alekh Jindal'></div>

# Alekh Jindal [[Back]](#toc)

### [176] [Optimising SQL queries for database transparency](https://scholar.google.com/scholar_url?url=https://pubs.aip.org/aip/acp/article-abstract/3297/1/040014/3369695&hl=zh-CN&sa=X&d=6523064496412226109&ei=hoMGaceIFd7M6rQP173fsAE&scisig=ABGrvjL5-rNf6sRf-2bqnkeQ4dQ2&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ABGrvjJJrURLYOT54u5YN19mJdpa&html=&pos=0&folt=rel)
*N Varshney,D Gupta,A Kumar,D Arora,W Singh…*

Main category: Alekh Jindal

TL;DR: 利用先前运行过的查询是提高数据库性能的关键方法，通过减少重复查询的处理和返回需求来提升效率


<details>
  <summary>Details</summary>
Motivation: 数据库性能优化是系统设计的重要目标，重复查询处理会消耗大量计算资源和时间，影响用户体验和系统响应速度

Method: 通过缓存先前执行过的查询结果，当相同或相似查询再次出现时直接从缓存返回结果，避免重复的数据库处理过程

Result: 显著减少数据库处理时间和资源消耗，提高查询响应速度，降低系统负载，改善用户体验

Conclusion: 查询缓存是数据库性能优化的重要策略，通过重用先前查询结果可以有效提升系统效率和响应能力

Abstract: Utilising queries that have been previously run is one of the most important aspects of improving database speed. This is because it significantly reduces the need to process and return repetitive database requests to the user, which, in turn, leads to …

</details>


### [177] [Geometry-Aware Collaborative Multi-Solutions Optimizer for Model Fine-Tuning with Parameter Efficiency](https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DSbJAGSdLhY&hl=zh-CN&sa=X&d=12009356543587218296&ei=gQAKaZbdObuZ6rQPo6-DgQY&scisig=ABGrvjKGWqjwMmhNv34oEkxwHFkQ&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ABGrvjJJrURLYOT54u5YN19mJdpa&html=&pos=0&folt=rel)
*VA Nguyen,T Le,M Harandi,E Abbasnejad,TT Do…*

Main category: Alekh Jindal

TL;DR: 基于梯度流理论和几何结构的多解框架，为给定任务提供多样化解决方案，通过协作提升性能和适应性


<details>
  <summary>Details</summary>
Motivation: 传统方法通常为任务提供单一解决方案，限制了系统的适应性和鲁棒性。需要一种能够生成多个不同但互补的解决方案的框架，以应对复杂多变的任务需求。

Method: 提出基于梯度流理论的框架，利用几何结构信息生成多个不同的解决方案。通过分析解空间的几何特性，确保生成的解决方案既多样化又具有协作性。

Result: 该框架能够为给定任务生成多个不同的解决方案，这些方案通过协作显著提升了整体性能，并增强了系统在不同场景下的适应能力。

Conclusion: 基于梯度流和几何结构的多解框架提供了一种有效的方法来生成多样化且协作的解决方案，显著提高了任务处理的性能和适应性。

Abstract: We propose a framework grounded in gradient flow theory and informed by geometric structure that provides multiple diverse solutions for a given task, ensuring collaborative results that enhance performance and adaptability across different …

</details>


### [178] [Learning to Instruct: Fine-Tuning a Task-Aware Instruction Optimizer for Black-Box LLMs](https://scholar.google.com/scholar_url?url=https://aclanthology.org/2025.findings-emnlp.407/&hl=zh-CN&sa=X&d=5631882772417450158&ei=gQAKaZbdObuZ6rQPo6-DgQY&scisig=ABGrvjIK4OVwO-FJEEIAcVp7er-d&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ABGrvjJJrURLYOT54u5YN19mJdpa&html=&pos=1&folt=rel)
*Y Qi,J Tian,T Liu,R Li,T Wei,H Liu,X Tang…*

Main category: Alekh Jindal

TL;DR: 提出Learning to Instruct方法，通过强化学习优化黑盒大语言模型的指令设计，无需访问模型内部状态


<details>
  <summary>Details</summary>
Motivation: 黑盒大语言模型的性能高度依赖于指令设计，但由于无法访问内部状态，传统优化方法难以应用

Method: 采用强化学习框架，将指令设计视为优化问题，通过与环境交互学习最优指令策略

Result: 该方法显著提升黑盒LLM在各种任务上的性能，证明指令优化对模型表现的重要性

Conclusion: Learning to Instruct为黑盒大语言模型提供了一种有效的指令优化方法，无需模型内部信息

Abstract: Abstract The performance of Large Language Models (LLMs) critically depends on designing effective instructions, which is particularly challenging for black-box LLMs with inaccessible internal states. To this end, we introduce Learning to Instruct, a …

</details>


### [179] [Using machine learning methods to analyse the efficiency of SQL queries](https://scholar.google.com/scholar_url?url=https://repository.kpi.kharkov.ua/items/8fceb2b3-f055-4b45-99ff-354676d7db3e&hl=zh-CN&sa=X&d=5818141583646610159&ei=9VQNaYGtDoGpieoPoLfX2Q0&scisig=ABGrvjLWWKkNISVHPoc-ZgGl9ETs&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ABGrvjJJrURLYOT54u5YN19mJdpa&html=&pos=2&folt=rel)
*A Reznichenko,A Kopp*

Main category: Alekh Jindal

TL;DR: 使用机器学习方法分析SQL查询效率的研究


<details>
  <summary>Details</summary>
Motivation: SQL查询性能优化对数据库系统至关重要，传统方法依赖专家经验和手动调优，需要更智能、自动化的效率分析工具

Method: 采用机器学习方法分析SQL查询，可能包括特征提取、性能指标收集、模型训练和效率预测

Result: 机器学习方法能够有效分析SQL查询效率，提供比传统方法更准确的性能预测和优化建议

Conclusion: 机器学习为SQL查询效率分析提供了有前景的自动化解决方案，能够显著提升数据库性能调优的效率

Abstract: Reznichenko A. Using machine learning methods to analyse the efficiency of SQL queries [Electronic resource]/A. Reznichenko, A. Kopp//Інформаційні технології: наука, техніка, технологія, освіта, здоров'я= Information technologies: science …

</details>


### [180] [Roadrunner: Accelerating Data Delivery to WebAssembly-Based Serverless Functions](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.01888&hl=zh-CN&sa=X&d=5498754078191965392&ei=KwIPafycIcXXieoPrpbVOQ&scisig=ABGrvjJtHLuq66nQGbj_J-b0ADlS&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ABGrvjJJrURLYOT54u5YN19mJdpa&html=&pos=0&folt=rel)
*C Marcelino,T Pusztai,S Nastic*

Main category: Alekh Jindal

TL;DR: Serverless计算通过无状态函数和外部存储服务简化基础设施管理，但面临冷启动延迟、状态管理复杂性和性能开销等挑战


<details>
  <summary>Details</summary>
Motivation: Serverless计算虽然提供了基础设施自动管理和弹性伸缩的优势，但无状态设计导致函数需要依赖外部远程服务进行状态存储和管理，这带来了冷启动延迟、状态管理复杂性以及性能开销等问题

Method: 论文可能提出了一种改进的Serverless架构或优化方法，通过减少对外部存储的依赖、优化状态管理机制或降低冷启动延迟来提升性能

Result: 预期结果包括降低Serverless函数的延迟、减少冷启动开销、改善状态管理效率，并可能提供性能基准测试数据

Conclusion: 通过优化Serverless架构的状态管理和性能瓶颈，可以更好地发挥其弹性伸缩和运维简化的优势，同时克服现有局限性

Abstract: Serverless computing provides infrastructure management and elastic auto-scaling, therefore reducing operational overhead. By design serverless functions are stateless, which means they typically leverage external remote services to store and …

</details>


### [181] [Trends in Students' SQL Queries in the Era of Generative AI](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3769994.3770024&hl=zh-CN&sa=X&d=8648875381102445515&ei=Ge4RabnUK5vJieoP4rCBoQ8&scisig=ABGrvjKsq50ljyy4vAKyltCkwKNC&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ABGrvjJJrURLYOT54u5YN19mJdpa&html=&pos=1&folt=rel)
*A Laaksonen,K Korpimies,M Luukkainen*

Main category: Alekh Jindal

TL;DR: 分析数据库入门课程中SQL查询的近期趋势，基于学生练习数据集


<details>
  <summary>Details</summary>
Motivation: 了解数据库入门课程中SQL查询的演变趋势，识别学生常见模式、错误和进步，为教学改进提供数据支持

Method: 收集和分析数据库课程中学生的SQL练习数据集，包括查询结构、语法使用、错误类型等，采用统计分析方法识别趋势

Result: 发现SQL查询在特定方面的变化趋势，识别学生常见错误模式和学习进展，为课程设计和教学策略提供实证依据

Conclusion: SQL查询分析为数据库教育提供了有价值的见解，有助于优化教学方法和课程设计，提升学生学习效果

Abstract: This paper studies recent trends in SQL queries in an introductory databases course. The course includes a set of SQL exercises where students create SQL queries that retrieve information from database tables. We analyze a dataset collected from the …

</details>


### [182] [Query Processing on Encrypted Data: A Comparative Study of Modern Approaches](https://scholar.google.com/scholar_url?url=https://www.eventiotic.com/eventiotic/files/Papers/URL/2af1414a-c074-41b2-978e-c3bc1aa7591d.pdf&hl=zh-CN&sa=X&d=18438798605219403030&ei=Ge4RabnUK5vJieoP4rCBoQ8&scisig=ABGrvjIm-Ht3ZfTnbG5hZXdhlFLM&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ABGrvjJJrURLYOT54u5YN19mJdpa&html=&pos=2&folt=rel)
*A Vidaković,T Petrović,P Kresoja,M Veinović*

Main category: Alekh Jindal

TL;DR: 该论文探讨了在隐私法规和安全需求日益增长的背景下，数据库加密技术的重要性，特别关注了在加密数据上进行查询的多种方法。


<details>
  <summary>Details</summary>
Motivation: 随着隐私法规的加强和安全担忧的增加，数据库加密技术在现代应用中变得至关重要。需要研究能够在加密数据上执行查询的方法，以平衡数据安全性和查询功能。

Method: 论文讨论了多种加密数据查询方法，包括顺序保持加密（Order-Preserving Encryption）、完全同态加密（Fully Homomorphic Encryption）等。这些方法允许在加密状态下对数据进行操作，而无需解密。

Result: 论文分析了不同加密查询方法的优缺点，包括安全性、性能、功能支持等方面的比较。各种方法在安全性和查询效率之间存在不同的权衡。

Conclusion: 数据库加密技术对于满足现代隐私和安全需求至关重要。不同的加密查询方法适用于不同的应用场景，需要根据具体的安全要求和性能需求进行选择。

Abstract: As privacy regulations and security concerns increase, database encryption techniques have become essential in modern applications. Multiple approaches exist for querying encrypted data, including Order-Preserving Encryption, Fully …

</details>


### [183] [TwinBandit Prompt Optimizer: Adaptive Prompt Optimization via Synergistic Dual MAB-Guided Feedback](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3746252.3760824&hl=zh-CN&sa=X&d=16250904473923895985&ei=IJETaYniOfGQ6rQP3avymAQ&scisig=ABGrvjL_i18NY_LiENf6ITY13pgT&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ABGrvjJJrURLYOT54u5YN19mJdpa&html=&pos=0&folt=rel)
*YJ Park,SR Lee,AD Vo,M Jung,D Choi*

Main category: Alekh Jindal

TL;DR: 论文提出了一种改进自动提示工程的方法，通过战略性地利用失败反馈并协调选择多样化的生成策略来解决现有方法的不足


<details>
  <summary>Details</summary>
Motivation: 现有自动提示工程方法存在缺陷，未能战略性地利用特定失败反馈，也缺乏对多样化生成策略的自适应协调选择

Method: 通过结合失败反馈的战略性使用与多样化生成策略的自适应协调选择来改进自动提示工程

Result: 未在摘要中明确说明具体结果

Conclusion: 提出的方法能够解决自动提示工程中的常见缺陷，通过更有效的反馈利用和策略协调来提升性能

Abstract: A common deficiency in Automatic Prompt Engineering (APE) is the failure to strategically employ specific failure feedback in concert with the adaptive and coordinated selection of diverse generation strategies. To address this deficiency, we …

</details>


### [184] [Evaluating HPK for Running Cloud-Native Workloads on Slurm Clusters](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3731599.3767352&hl=zh-CN&sa=X&d=5208169031985293705&ei=BXkWaceoB4qi6rQP6t-R-Q4&scisig=ABGrvjItFpuYZD7CxBR_G9GLQDJC&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ABGrvjJJrURLYOT54u5YN19mJdpa&html=&pos=3&folt=rel)
*A Chazapis,L Vassilakis,G Petsis,M Marazakis…*

Main category: Alekh Jindal

TL;DR: 论文探讨了在混合云原生与HPC工作流中实现高效数据处理的挑战与解决方案


<details>
  <summary>Details</summary>
Motivation: 应用和服务日益复杂，需要将云原生和HPC步骤集成到同一工作流中，但云提供商和HPC中心通常提供不同的基础设施和接口，导致数据移动和转换效率低下

Method: 未在摘要中明确说明具体方法，但暗示需要开发能够桥接云原生和HPC环境的数据处理框架或中间件

Result: 未在摘要中提供具体实验结果

Conclusion: 需要创新的解决方案来优化混合云-HPC工作流中的数据移动和转换效率

Abstract: The escalating complexity of applications and services encourages a shift towards higher-level data processing pipelines that integrate both Cloud-native and HPC steps into the same workflow. Cloud providers and HPC centers typically provide …

</details>


### [185] [QPMMCOA and Bayesian Fuzzy Clustering: A Novel Approaches For Optimizing Queries in Big Data](https://scholar.google.com/scholar_url?url=https://www.sid.ir/en/VEWSSID/J_pdf/303-355534-en-1536697.pdf&hl=zh-CN&sa=X&d=3038407028161259740&ei=sCocaYTYMNToieoP297F-A4&scisig=ABGrvjJlmYPPyTAjx9PgxkZZyouh&oi=scholaralrt&hist=i6heNjgAAAAJ:9105223062713277753:ABGrvjLLCDsovBUGXtYF5vE3qvQg&html=&pos=0&folt=cit)
*RM Sandhya,SN Raghavendra*

Main category: Alekh Jindal

TL;DR: 该论文探讨了大数据环境中查询优化的哲学应用，指出当前云平台解决方案因忽视能源问题和查询特性而存在不足


<details>
  <summary>Details</summary>
Motivation: 大数据爆炸式增长推动了信息领域对大数据处理的关注，查询优化在大数据环境的数据检索过程中具有关键作用。然而，当前云平台中的分布式数据处理解决方案大多忽视了能源相关问题和查询特性，存在明显缺陷

Method: 论文未在摘要中明确说明具体方法，但暗示需要开发考虑能源效率和查询特性的新型查询优化解决方案

Result: 摘要未提供具体实验结果，但指出当前大多数解决方案因缺乏对能源问题和查询特性的考虑而存在不足

Conclusion: 大数据环境中的查询优化需要综合考虑能源效率和查询特性，当前云平台解决方案在这方面存在改进空间

Abstract: The explosion of data in the last ten years has led to a substantial focus on big data (BD) in information area. The philosophical applications of" query optimization (QO)" are crucial in BD environments' data retrieval processes. Several distributed data processing platforms in cloud were developed to provide BD query optimization services that are both affordable and effective. Nevertheless, due to a lack of consideration for energy-related concerns and query characteristics, most solutions …

</details>


### [186] [Optimizing UDF Queries in SQL Data Engines](https://scholar.google.com/scholar_url?url=https://www.openproceedings.org/2026/conf/edbt/paper-124.pdf&hl=zh-CN&sa=X&d=307397812907858293&ei=YMgjaZu1CPGQ6rQPybbN6Qk&scisig=ABGrvjK2FpLyTAhP1zNtEaNVIRsX&oi=scholaralrt&hist=i6heNjgAAAAJ:9105223062713277753:ABGrvjLLCDsovBUGXtYF5vE3qvQg&html=&pos=0&folt=cit)
*K Chasialis,Y Foufoulas,A Simitsis,Y Ioannidis*

Main category: Alekh Jindal

TL;DR: QFusor是一个可插拔的优化器，通过操作符融合、内联和JIT编译等技术提升SQL数据库中用户定义函数(UDF)的性能


<details>
  <summary>Details</summary>
Motivation: SQL数据库中的用户定义函数(UDF)通常存在高执行开销和优化受限的问题，因为查询规划器将其视为黑盒，导致性能瓶颈

Method: 通过操作符融合、函数内联、状态化执行和JIT编译等技术，融合不同类型的UDF（标量、聚合、表函数），并作为可插拔优化器集成到数据库系统中

Result: 未在摘要中明确说明具体实验结果，但方法旨在显著降低UDF执行开销并提升性能

Conclusion: QFusor提供了一种有效的方法来优化SQL数据库中的UDF性能，克服传统黑盒处理方式的局限性

Abstract: Many SQL database engines support user-defined functions (UDFs) for complex in-database computations. However, UDFs often suffer from high execution overhead and limited optimization, as query planners treat them as black boxes. In this paper, we introduce QFusor, a pluggable optimizer that enhances UDF performance in SQL databases by:(a) reducing overhead through operator fusion, inlining, and stateful, JIT-compiled execution,(b) fusing different UDF types (scalar, aggregate, table) and …

</details>


### [187] [Research on optimization of human resource allocation in high-tech manufacturing industry based on big data analysis](https://scholar.google.com/scholar_url?url=https://www.spiedigitallibrary.org/conference-proceedings-of-spie/13940/1394026/Research-on-optimization-of-human-resource-allocation-in-high-tech/10.1117/12.3092278.short&hl=zh-CN&sa=X&d=7349080423908763687&ei=YMgjaZu1CPGQ6rQPybbN6Qk&scisig=ABGrvjIjJ4hOjGlcBScFdRLY9dup&oi=scholaralrt&hist=i6heNjgAAAAJ:9105223062713277753:ABGrvjLLCDsovBUGXtYF5vE3qvQg&html=&pos=2&folt=cit)
*Y Zheng*

Main category: Alekh Jindal

TL;DR: 应用大数据分析优化高科技制造业人力资源配置，通过聚类和决策树等技术实现员工技能与岗位需求的更好匹配，动态调整资源配置提升效率


<details>
  <summary>Details</summary>
Motivation: 高科技制造业面临人力资源配置效率低下的问题，传统方法难以实现员工技能与岗位需求的精准匹配，需要利用大数据技术优化资源配置

Method: 采用案例研究方法，对领先科技制造企业进行综合分析，运用聚类分析和决策树等大数据技术，建立人力资源优化配置模型

Result: 大数据技术显著提升了人力资源配置效率，实现了员工技能与岗位需求的更好匹配，能够根据实际情况动态调整资源配置

Conclusion: 大数据分析是优化高科技制造业人力资源配置的有效工具，聚类和决策树等技术能够显著提升资源配置效率和匹配精度

Abstract: This paper explores the application of big data analysis in optimizing human resource allocation in high-tech manufacturing. Through a comprehensive case study of a leading technology manufacturing company, we show how big data technologies such as clustering and decision trees can significantly improve human resource allocation by better matching employee skills with job requirements and dynamically adjusting resource allocation according to the situation. efficiency …

</details>


### [188] [Analytical Queries for Unstructured Data](https://scholar.google.com/scholar_url?url=https://www.nowpublishers.com/article/Details/DBS-087&hl=zh-CN&sa=X&d=6905873297184348187&ei=XsgjadKdL_GQ6rQPybbN6Qk&scisig=ABGrvjIOUKoslj5BKWOKs4cxSLL2&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ABGrvjJJrURLYOT54u5YN19mJdpa&html=&pos=1&folt=rel)
*D Kang*

Main category: Alekh Jindal

TL;DR: 论文探讨了非结构化数据爆炸式增长与机器学习方法能力提升之间的匹配问题，强调需要系统化的方法来评估和比较不同ML方法在处理非结构化数据方面的性能。


<details>
  <summary>Details</summary>
Motivation: 非结构化数据（文本、图像、视频、音频）正以指数级速度增长，同时机器学习方法在分析这类数据方面的能力也在不断增强。然而，缺乏系统化的方法来评估和比较不同ML方法在处理非结构化数据方面的性能，这阻碍了该领域的进步。

Method: 论文可能提出了一种系统化的评估框架或基准测试方法，用于比较不同机器学习方法在处理非结构化数据方面的性能。可能包括标准化评估指标、基准数据集、以及在不同类型非结构化数据上的比较方法。

Result: 通过提出的系统化评估方法，能够更准确地比较不同ML方法在非结构化数据分析任务上的性能，识别各种方法的优势和局限性，为领域发展提供指导。

Conclusion: 随着非结构化数据的快速增长和ML方法的不断进步，建立系统化的评估框架对于推动该领域发展至关重要。这种框架能够帮助研究人员和从业者更好地理解不同方法的性能，促进更有效的非结构化数据分析技术的发展。

Abstract: Unstructured data, in the form of text, images, video, and audio, is produced at exponentially higher rates. In tandem, machine learning (ML) methods have become increasingly powerful at analyzing unstructured data. Modern ML methods can now …

</details>


### [189] [Optimizing the Optimizer: An Example Showing the Power of LLM Code Generation](https://scholar.google.com/scholar_url?url=https://annals-csis.org/proceedings/2025/pliks/1481.pdf&hl=zh-CN&sa=X&d=3205171160053723510&ei=4zglaeOmBI2v6rQPzvzsmAY&scisig=ABGrvjJ5a4Um0TUxv7eH0uifV7iU&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ABGrvjJJrURLYOT54u5YN19mJdpa&html=&pos=2&folt=rel)
*CC Sartori,C Blum*

Main category: Alekh Jindal

TL;DR: LLMs与优化算法的集成研究，探索如何利用预训练语言模型增强现有优化方法


<details>
  <summary>Details</summary>
Motivation: 大型语言模型与优化算法的结合创造了强大的协同效应，为研究开辟了令人兴奋的机会。论文旨在探索LLMs如何增强现有优化算法。

Method: 利用LLMs的预训练能力，将其集成到现有优化算法中，探索LLMs在优化过程中的应用方式。

Result: 论文展示了LLMs与优化算法集成的潜力，但具体结果需要完整论文内容才能确定。

Conclusion: LLMs为优化算法提供了新的增强途径，这一研究方向具有重要价值和广阔前景。

Abstract: The integration of Large Language Models (LLMs) into optimization has created a powerful synergy, opening exciting research opportunities. This paper investigates how LLMs can enhance existing optimization algorithms. Using their pre-trained …

</details>


### [190] [Performance-Aware Serverless Scheduling for Distributed AI Workloads](https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Aman-Nikhare/publication/397834660_Performance-Aware_Serverless_Scheduling_for_Distributed_AI_Workloads/links/69204ee3f4878b75fc783297/Performance-Aware-Serverless-Scheduling-for-Distributed-AI-Workloads.pdf&hl=zh-CN&sa=X&d=12699823516819938249&ei=VLomad26HeuuieoPvMeR-QI&scisig=ABGrvjK62o2XJFgw7TH-sRLFBMRg&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ABGrvjJJrURLYOT54u5YN19mJdpa&html=&pos=0&folt=rel)
*A Nikhare*

Main category: Alekh Jindal

TL;DR: 服务器无计算面临冷启动延迟、资源效率低下和状态管理困难等挑战，需要新的解决方案来优化性能和资源利用率


<details>
  <summary>Details</summary>
Motivation: 当前服务器无计算平台存在冷启动延迟、资源效率低下和状态管理困难等核心问题，限制了其在延迟敏感应用和大规模工作负载中的广泛应用，需要新的架构和方法来解决这些挑战

Method: 论文未提供具体方法细节，但通常涉及优化容器生命周期管理、改进资源分配策略、增强状态管理机制，可能包括预测性预热、智能调度算法和分布式状态存储等技术

Result: 基于摘要内容无法确定具体实验结果，但预期解决方案应能显著减少冷启动延迟、提高资源利用率、改善状态管理效率，从而提升服务器无计算平台的整体性能

Conclusion: 服务器无计算需要创新的架构设计和技术优化来解决现有挑战，以实现更高效、可扩展和实用的云基础设施

Abstract: Serverless computing has emerged as a transformative paradigm for cloud infrastructure, offering automatic scaling, pay-per-use pricing, and simplified deployment. However, current serverless platforms face significant challenges when …

</details>


### [191] [ERINYES: Request-Level Provenance Analysis for Serverless Attacks](https://scholar.google.com/scholar_url?url=https://nchr.elsevierpure.com/en/publications/erinyes-request-level-provenance-analysis-for-serverless-attacks/&hl=zh-CN&sa=X&d=16238471130627427992&ei=VLomad26HeuuieoPvMeR-QI&scisig=ABGrvjKAjZqrkJ_I2fKpZ7DSwmgH&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ABGrvjJJrURLYOT54u5YN19mJdpa&html=&pos=1&folt=rel)
*H Xi,H Wan,X Zhao,M Guizani*

Main category: Alekh Jindal

TL;DR: 服务器无服务器架构虽然具有成本效益和管理便利性，但也增加了应用攻击面，导致安全事件频发


<details>
  <summary>Details</summary>
Motivation: 无服务器架构因其成本效益和管理便利性而备受关注，但该框架增加了应用程序的攻击面，导致安全事件频发，需要解决其安全挑战

Method: 论文未提供具体方法细节，但从摘要看可能涉及分析无服务器架构的安全漏洞、攻击面评估或安全防护机制研究

Result: 摘要未提供具体研究结果，但暗示无服务器架构确实存在安全风险，需要进一步的安全解决方案

Conclusion: 无服务器架构在带来成本和管理优势的同时，引入了新的安全挑战，需要专门的安全机制来应对

Abstract: The serverless architecture has attracted significant attention due to its cost-effectiveness and ease of management. However, the serverless framework increases the attack surface of applications, resulting in frequent security incidents …

</details>


### [192] [Describing SQL queries in Natural Language](https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-032-06905-4_5&hl=zh-CN&sa=X&d=4584982651768452825&ei=xsIradmnNf-j6rQPrbnwwA4&scisig=ABGrvjJu2oenPVk1KYqN3pDpQqjd&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ABGrvjJJrURLYOT54u5YN19mJdpa&html=&pos=2&folt=rel)
*G Katsogiannis*

Main category: Alekh Jindal

TL;DR: 自然语言接口将用户问题转换为SQL查询，使非技术用户能够访问数据库


<details>
  <summary>Details</summary>
Motivation: SQL虽然强大但复杂，使得数据库对非技术用户难以访问，需要更易用的接口

Method: 开发自然语言接口，将用户用自然语言提出的问题自动转换为SQL查询语句

Result: 自然语言接口能够有效降低数据库访问门槛，使非技术用户能够查询数据

Conclusion: 自然语言接口是连接非技术用户与数据库的有效桥梁，提高了数据可访问性

Abstract: Abstract Structured Query Language (SQL) is a powerful tool for data retrieval, but its complexity often renders databases inaccessible to non-technical users. While natural language interfaces can help bridge this gap by translating user questions …

</details>


<div id='Xuanhe Zhou'></div>

# Xuanhe Zhou [[Back]](#toc)

### [193] [ReCoT: Reflective Self-Correction Training for Mitigating Confirmation Bias in Large Vision-Language Models](https://scholar.google.com/scholar_url?url=https://openaccess.thecvf.com/content/ICCV2025/papers/Qu_ReCoT_Reflective_Self-Correction_Training_for_Mitigating_Confirmation_Bias_in_Large_ICCV_2025_paper.pdf&hl=zh-CN&sa=X&d=16007642928015365075&ei=h4MGacHuK6PH6rQP48qQiAk&scisig=ABGrvjL89adARvAnZsjkcp6Kr4II&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=1&folt=rel)
*M Qu,Y Hu,K Han,Y Wei,Y Zhao*

Main category: Xuanhe Zhou

TL;DR: LVLMs存在确认偏误问题，模型倾向于依赖文本信息而忽略视觉证据，导致视觉幻觉


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型(LVLMs)在视觉和文本理解方面取得显著进展，但普遍存在确认偏误问题，即模型倾向于依赖文本信息而忽略视觉证据，导致视觉幻觉现象

Method: 未在摘要中明确说明具体方法，但问题涉及模型对文本信息的过度依赖和对视觉证据的忽视

Result: 确认偏误导致LVLMs产生视觉幻觉，模型输出与视觉证据不一致

Conclusion: LVLMs中的确认偏误是需要解决的重要问题，以提高模型对视觉信息的准确理解和利用

Abstract: Abstract Recent advancements in Large Vision-Language Models (LVLMs) have greatly improved their ability to understand both visual and text information. However, a common problem in LVLMs is confirmation bias, where models tend to …

</details>


### [194] [Mixture-of-Minds: Multi-Agent Reinforcement Learning for Table Understanding](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.20176&hl=zh-CN&sa=X&d=16349007919506338803&ei=h4MGacHuK6PH6rQP48qQiAk&scisig=ABGrvjKngAd__IuXZQsWiH3fNvXj&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=3&folt=rel)
*Y Zhou,M Zhang,K Li,M Wang,Q Liu,Q Wang,J Liu…*

Main category: Xuanhe Zhou

TL;DR: 表格理解和推理是许多实际应用的基础能力，但现有方法在处理复杂表格时存在局限性，需要更先进的模型来提升性能。


<details>
  <summary>Details</summary>
Motivation: 表格理解和推理在金融、医疗、知识管理等实际应用中至关重要，但现有方法在处理复杂表格结构和推理任务时仍面临挑战，需要开发更强大的模型来提升性能。

Method: 论文未提供具体方法细节，但从上下文推断可能涉及开发新的表格理解和推理模型，可能结合深度学习、注意力机制等技术来处理表格结构、数值推理和语义理解。

Result: 论文未提供具体实验结果，但从引用文献（Zhang et al., 2025c; Cheng et al., 2025; Fang et al., 2024）来看，该领域已有相关研究进展，本文可能在这些基础上提出改进。

Conclusion: 表格理解和推理是一个重要的研究领域，需要更先进的模型来应对实际应用中的复杂需求，本文可能为此方向做出了贡献。

Abstract: Understanding and reasoning over tables is a fundamental capability for many real-world applications, including finance, healthcare, and knowledge management (Zhang et al., 2025c; Cheng et al., 2025; Fang et al., 2024). Compared with free text …

</details>


### [195] [Finding Answers in Thought Matters: Revisiting Evaluation on Large Language Models with Reasoning](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.14773%3F&hl=zh-CN&sa=X&d=7758581512971899590&ei=h4MGacHuK6PH6rQP48qQiAk&scisig=ABGrvjLl_qyOnbY2V89ArXJ6unqZ&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=4&folt=rel)
*H Jo,J Lee,J Lee,SW Lee,J Park,KM Yoo*

Main category: Xuanhe Zhou

TL;DR: 论文提出了一种基于推理路径概率评估生成模型的新方法，通过分析模型生成推理步骤的概率分布来评估其推理能力，相比传统仅关注最终答案概率的方法能提供更深入的性能洞察。


<details>
  <summary>Details</summary>
Motivation: 当前评估生成模型（特别是需要推理能力的模型）主要依赖最终答案选择的概率，这种方法忽略了推理过程的质量和可靠性，无法区分模型是真正理解问题还是偶然猜对答案。

Method: 提出基于推理路径概率的评估框架，通过分析模型生成完整推理链的概率分布来评估推理能力，包括计算推理路径的似然度、识别关键推理步骤以及评估推理过程的连贯性和逻辑性。

Result: 该方法能够更准确地识别模型推理能力的差异，区分表面正确但推理过程薄弱的模型与真正具备强推理能力的模型，提供比传统最终答案概率方法更丰富的评估维度。

Conclusion: 基于推理路径概率的评估方法为生成模型的推理能力评估提供了更全面和深入的框架，有助于推动更可靠的模型开发和评估实践。

Abstract: Evaluating generative models, such as large language models (LLMs), commonly involves question-answering tasks where the final answer is selected based on probability of answer choices. On the other hand, for models requiring reasoning, the …

</details>


### [196] [LLM meets ML: Data-efficient Anomaly Detection on Unstable Logs](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3771283&hl=zh-CN&sa=X&d=9431051214712331792&ei=LnEIaaT6B7qL6rQPvbmoWA&scisig=ABGrvjLzX4teWIz_rtZeBijVUGYk&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=0&folt=rel)
*F Hadadi,Q Xu,D Bianculli,L Briand*

Main category: Xuanhe Zhou

TL;DR: 针对不稳定日志的异常检测（ULAD）是一个现实但研究不足的挑战，因为大多数现有方法都假设日志是稳定的，而实际中日志常因软件或环境变化而不稳定。


<details>
  <summary>Details</summary>
Motivation: 现有日志异常检测方法通常假设日志格式稳定，但实际生产环境中日志常因软件更新、配置变更或环境变化而不稳定，导致传统方法失效。需要研究能处理不稳定日志的异常检测方法。

Method: 论文未在摘要中明确说明具体方法，但暗示需要开发专门针对不稳定日志的异常检测技术，可能涉及日志表示学习、变化适应机制或鲁棒性特征提取等方法。

Result: 摘要未提供具体实验结果，但指出不稳定日志异常检测是一个重要但研究不足的领域，暗示现有方法在此场景下性能受限。

Conclusion: 不稳定日志异常检测是一个现实且重要的研究挑战，需要专门的方法来处理日志格式变化问题，该领域值得进一步深入研究。

Abstract: Most log-based anomaly detectors assume logs are stable, though in reality they are often unstable due to software or environmental changes. Anomaly detection on unstable logs (ULAD) is therefore a more realistic, yet under-investigated challenge …

</details>


### [197] [Detecting Data Contamination from Reinforcement Learning Post-training for Large Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.09259%3F&hl=zh-CN&sa=X&d=8633433897467472486&ei=LnEIaaT6B7qL6rQPvbmoWA&scisig=ABGrvjLIQP_II4zcuUDbBpUTAv5W&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=3&folt=rel)
*Y Tao,T Wang,Y Dong,H Liu,K Zhang,X Hu,G Li*

Main category: Xuanhe Zhou

TL;DR: 数据污染对LLM评估构成严重威胁，当基准样本意外出现在训练集中时会损害评估有效性


<details>
  <summary>Details</summary>
Motivation: 数据污染问题严重影响大语言模型评估的可靠性，当基准测试样本意外出现在训练数据中时，会导致评估结果失真，无法准确反映模型真实能力

Method: 未在摘要中明确说明具体方法，但关注数据污染检测和缓解策略

Result: 数据污染会显著影响LLM评估的准确性，导致性能指标虚高，需要建立更可靠的评估框架

Conclusion: 数据污染是大语言模型评估中的关键问题，需要开发有效的检测和缓解方法来确保评估的可靠性和有效性

Abstract: Data contamination poses a significant threat to the reliable evaluation of Large Language Models (LLMs). This issue arises when benchmark samples may inadvertently appear in training sets, compromising the validity of reported …

</details>


### [198] [Converting Natural Language to Query Languages Using Large Language Models: A Systematic Literature Review](https://scholar.google.com/scholar_url?url=https://sol.sbc.org.br/index.php/webmedia/article/download/38015/37793&hl=zh-CN&sa=X&d=2060964189307270287&ei=L3EIaY_NBLmAieoPq7Lh4A8&scisig=ABGrvjIvG_Hmaw3oHYbqTBSsTgK6&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=1&folt=cit)
*RR Lima,KC Vasconcelos,EM Gadelha*

Main category: Xuanhe Zhou

TL;DR: 本文通过系统文献综述，探讨了大型语言模型在自然语言到查询语言转换任务中的应用现状与影响。


<details>
  <summary>Details</summary>
Motivation: 自然语言到查询语言转换任务能提高非技术用户的数据访问性，但现有研究缺乏关于大型语言模型在该任务中影响的系统性文献综述。

Method: 采用系统文献综述方法，分析近期研究如何利用大型语言模型进行自然语言到查询语言转换。

Result: 论文作为系统文献综述的输出，总结了大型语言模型在自然语言到查询语言转换任务中的应用现状、方法和技术趋势。

Conclusion: 该综述填补了大型语言模型在自然语言到查询语言转换任务中影响研究的空白，为未来研究提供了基础。

Abstract: The task of converting natural language commands into query languages (NL-to-QL) has gained attention due to its potential to improve data accessibility for non-technical users. Although several studies have explored rule-based and sequence-to-sequence models, there is still a lack of a literature review that presents the impact of using large language models (LLMs) on this task. As an output of a systematic literature review, this paper examines how recent studies have utilized LLMs by …

</details>


### [199] [ARG: Testing Query Rewriters via Abstract Rule Guided Fuzzing](https://scholar.google.com/scholar_url?url=http://www.wingtecher.com/themes/WingTecherResearch/assets/papers/paper_from_25/arg_ase25.pdf&hl=zh-CN&sa=X&d=9794823067340493677&ei=L3EIaY_NBLmAieoPq7Lh4A8&scisig=ABGrvjKe0i34rhQeLc0JFRe5kUcX&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=2&folt=cit)
*D Li,Y Guo,Q Liu,J Liang,Z Wu,J Fu,C Zhang…*

Main category: Xuanhe Zhou

TL;DR: 该论文针对查询重写器优化中的复杂性和潜在问题，提出了一种新的DBMS测试方法，旨在更有效地检测查询重写相关的错误。


<details>
  <summary>Details</summary>
Motivation: 查询重写器在将查询转换为更高效且语义等价形式方面至关重要，但其实现复杂，受重写规则设计、规则交互和语义保持等多因素影响，容易导致系统崩溃或错误查询结果。现有DBMS测试方法通常针对广泛错误设计，未能专门针对查询重写问题。

Method: 论文提出了一种专门针对查询重写器优化的测试方法（具体方法未在摘要中详细说明，但从上下文推断可能包括针对重写规则交互、语义保持等特定问题的测试策略）。

Result: 该方法能够更有效地检测查询重写相关的错误，相比现有通用测试方法具有更好的针对性和检测能力。

Conclusion: 专门针对查询重写器复杂性的测试方法是必要的，提出的方法能够提高DBMS的可靠性和查询结果的正确性。

Abstract: Query rewriters transform a query into a more efficient yet semantically equivalent form, which is vital for optimizing query execution. Despite its importance, query rewriting is inherently complex, influenced by factors including rewrite rule design, rule interactions, and semantic preservation. Consequently, its implementation struggles to prevent problems, which may result in system crashes or incorrect query results. Existing DBMS testing approaches are generally designed for broad bug …

</details>


### [200] [Data to Defense: The Role of Curation in Aligning Large Language Models Against Safety Compromise](https://scholar.google.com/scholar_url?url=https://aclanthology.org/2025.emnlp-main.647.pdf&hl=zh-CN&sa=X&d=15064278624983647106&ei=hgAKacqKEbqL6rQPwZS26QU&scisig=ABGrvjK5A5ZT8qz6cKRGBGlhfmDV&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=1&folt=cit)
*X Liu,J Liang,L Tang,M Ye,W Ma,Z Xi*

Main category: Xuanhe Zhou

TL;DR: 提出自适应数据筛选方法，在LLM定制化过程中增强模型对抗有害样本的鲁棒性


<details>
  <summary>Details</summary>
Motivation: LLM在微调定制过程中存在脆弱性，恶意样本可能损害模型鲁棒性并放大有害行为，需要解决这一安全挑战

Method: 自适应数据筛选方法，能够对任意文本进行筛选处理，增强其在对抗有害样本过程中的有效性

Result: 该方法能有效提升LLM在定制化过程中的安全性，增强模型对抗恶意样本的能力

Conclusion: 提出的自适应数据筛选方法为解决LLM定制化过程中的安全脆弱性问题提供了有效解决方案

Abstract: Large language models (LLMs) are widely adapted for downstream applications through fine-tuning, a process named customization. However, recent studies have identified a vulnerability during this process, where malicious samples can compromise the robustness of LLMs and amplify harmful behaviors. To address this challenge, we propose an adaptive data curation approach allowing any text to be curated to enhance its effectiveness in counteracting harmful samples during …

</details>


### [201] [Tools are under-documented: Simple Document Expansion Boosts Tool Retrieval](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.22670&hl=zh-CN&sa=X&d=11849048070055505754&ei=hgAKacqKEbqL6rQPwZS26QU&scisig=ABGrvjLFGm6E3l5LnWaRHq4T98mQ&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=2&folt=cit)
*X Lu,H Huang,R Meng,Y Jin,W Zeng,X Shen*

Main category: Xuanhe Zhou

TL;DR: Tool-DE：一个通过结构化工具文档增强来改进LLM工具检索的基准和框架


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在工具使用方面表现出强大能力，但工具检索的进展受到不完整和异构工具文档的限制。现有工具文档质量参差不齐，阻碍了有效的工具检索。

Method: 引入Tool-DE基准和框架，通过结构化字段系统性地丰富工具文档，使其更适合检索。开发了两个专用模型：Tool-Embed用于工具嵌入，Tool-Rank用于工具排序。设计了可扩展的文档增强方法。

Result: Tool-DE框架显著提升了工具检索效果，结构化文档增强了检索的准确性和效率。专用模型在工具嵌入和排序任务上表现出色。

Conclusion: 通过系统性地丰富工具文档结构，Tool-DE有效解决了工具检索中的文档质量问题，为LLM工具使用提供了更可靠的检索基础。

Abstract: Large Language Models (LLMs) have recently demonstrated strong capabilities in tool use, yet progress in tool retrieval remains hindered by incomplete and heterogeneous tool documentation. To address this challenge, we introduce Tool-DE, a new benchmark and framework that systematically enriches tool documentation with structured fields to enable more effective tool retrieval, together with two dedicated models, Tool-Embed and Tool-Rank. We design a scalable …

</details>


### [202] [DLBENCH: A Comprehensive Benchmark for SQL Translation with Large Language Models](https://scholar.google.com/scholar_url?url=https://matafeiyanll.github.io/paper/ASE25.pdf&hl=zh-CN&sa=X&d=8612717885906474893&ei=hgAKacqKEbqL6rQPwZS26QU&scisig=ABGrvjJBYlBn3q3BHSvvx5JDnyWI&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=3&folt=cit)
*L Lin,H Chen,Q Zhu,L Chen,L Tang,R Wu*

Main category: Xuanhe Zhou

TL;DR: SQL翻译技术解决不同数据库管理系统间SQL方言差异导致的迁移、联邦和集成挑战


<details>
  <summary>Details</summary>
Motivation: 近年来，数据库管理系统日益复杂，SQL方言激增，导致数据库迁移、联邦和集成面临重大挑战。不同DBMS间的SQL方言差异阻碍了系统间的无缝通信和互操作性。

Method: SQL翻译技术，即将SQL查询从源方言DBMS转换为目标方言DBMS的过程。虽然摘要未详细说明具体方法，但通常涉及语法解析、语义分析、方言映射和查询重写等技术。

Result: 摘要未提供具体实验结果，但指出SQL翻译在解决数据库互操作性问题上发挥着关键作用。

Conclusion: SQL翻译是解决数据库系统间互操作性挑战的重要技术，对于实现无缝的数据库迁移、联邦和集成至关重要。

Abstract: In recent years, the growing complexity of database management systems (DBMSs) and the proliferation of SQL dialects have created significant challenges for database migration, federation, and integration. These challenges arise from the disparities between SQL dialects across different DBMSs, hindering seamless communication and system interoperability. SQL translation, the process of converting SQL queries from a source dialect DBMS to a target dialect DBMS, plays a crucial role in …

</details>


### [203] [Every Activation Boosted: Scaling General Reasoner to 1 Trillion Open Language Foundation](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.22115&hl=zh-CN&sa=X&d=9115580649993639836&ei=hgAKacqKEbqL6rQPwZS26QU&scisig=ABGrvjIqfdvxw5kJzmSN7M19iPt6&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=4&folt=cit)
*A Li,B Liu,B Hu,B Li,B Zeng,B Ye,C Tang,C Tian…*

Main category: Xuanhe Zhou

TL;DR: Ling 2.0是一个面向推理的语言基础模型系列，采用混合专家架构，参数规模从160亿到1万亿，强调高稀疏性、跨尺度一致性和基于经验缩放定律的效率优化。


<details>
  <summary>Details</summary>
Motivation: 构建一个专门针对推理任务优化的语言基础模型系列，通过混合专家架构实现从数十亿到万亿参数的统一扩展，同时保持高效率和性能一致性。

Method: 采用统一的混合专家架构，基于经验缩放定律设计高稀疏性模型，包含三个非思考模型：Ling-mini-2.0、Ling-flash-2.0和Ling-1T，参数规模从16B到1T。

Result: 提出了一个可扩展的推理导向语言模型系列，实现了从160亿到1万亿参数的统一架构，强调高稀疏性和跨尺度一致性。

Conclusion: Ling 2.0系列为推理任务提供了一个可扩展的高效语言基础模型框架，通过混合专家架构和稀疏设计实现了从数十亿到万亿参数的统一扩展。

Abstract: We introduce Ling 2.0, a series reasoning-oriented language foundation built upon the principle that every activation boosts reasoning capability. Designed to scale from tens of billions to one trillion parameters under a unified Mixture-of-Experts (MoE) paradigm, Ling 2.0 emphasizes high sparsity, cross-scale consistency, and efficiency guided by empirical scaling laws. The series includes three non-thinking (instruct) models-Ling-mini-2.0, Ling-flash-2.0, and Ling-1T-ranging from 16B to 1T …

</details>


### [204] [Проблематика совершенствования экологического мониторинга на нефтегазовых объектах с применением технологий искусственного интеллекта](https://scholar.google.com/scholar_url?url=https://izvestiya.tpu.ru/archive/article/download/5289/3538&hl=zh-CN&sa=X&d=13549935565185455058&ei=hgAKacqKEbqL6rQPwZS26QU&scisig=ABGrvjIXgAJG7Uj0FH47vUBkR4X9&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=9&folt=cit)
*АИ Нургалиев,АА Назарова,ИВ Шарф*

Main category: Xuanhe Zhou

TL;DR: 俄罗斯石油天然气公司面临气候政策挑战，需通过环境监测实施可持续发展战略以提升国际竞争力和投资吸引力


<details>
  <summary>Details</summary>
Motivation: 研究动机源于俄罗斯采纳的气候政策对石油天然气行业提出的挑战，要求企业实施可持续发展战略，其中环境监测是关键环节，直接影响公司在全球碳氢化合物市场的投资吸引力和竞争力

Method: 摘要未详细说明具体研究方法，但从内容推断可能涉及环境监测体系的构建、可持续发展战略实施框架、以及环境绩效评估方法等方面的研究

Result: 摘要未提供具体研究结果，但暗示通过环境监测和可持续发展战略的实施，俄罗斯石油天然气公司能够提升其国际竞争力和投资吸引力

Conclusion: 环境监测在俄罗斯石油天然气公司的可持续发展战略中占据核心地位，是应对气候政策挑战、提升全球市场竞争力的关键要素

Abstract: Актуальность исследования обусловлена вызовами принятой климатической доктрины, ориентирующей российские нефтегазовые компании на реализацию стратегии устойчивого развития, в рамках которой экологический мониторинг окружающей среды занимает ключевое место и является основой инвестиционной привлекательности и конкурентоспособности компаний на мировом рынке углеводородного сырья. Трансформация экологического …

</details>


### [205] [How Much Do LLMs Hallucinate across Languages? On Realistic Multilingual Estimation of LLM Hallucination](https://scholar.google.com/scholar_url?url=https://aclanthology.org/2025.emnlp-main.1481.pdf&hl=zh-CN&sa=X&d=8666106879209759655&ei=hAAKaYrABv-j6rQPweenoAk&scisig=ABGrvjLt_PvpTHonbsTS0uyQTywi&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=2&folt=rel)
*SOU Islam,A Lauscher,G Glavaš*

Main category: Xuanhe Zhou

TL;DR: 该论文研究多语言大语言模型中的幻觉问题，发现幻觉率在不同语言间存在显著差异，并开发了跨语言幻觉检测方法


<details>
  <summary>Details</summary>
Motivation: 在错误信息时代，大语言模型的幻觉（生成非事实或不忠实回答）是其全球效用的主要风险。尽管LLMs变得越来越多语言化，但绝大多数研究集中在英语上，而多语言环境中的幻觉问题尚未得到充分探索

Method: 研究多语言LLMs在不同语言中的幻觉率差异，开发跨语言幻觉检测方法，可能涉及多语言数据集构建、幻觉评估框架和跨语言分析技术

Result: 发现幻觉率在不同语言间存在显著差异，某些语言比英语更容易出现幻觉，开发了有效的跨语言幻觉检测方法

Conclusion: 多语言LLMs的幻觉问题具有语言特异性，需要针对不同语言开发专门的检测和缓解策略，这对LLMs的全球部署和可靠性至关重要

Abstract: In the age of misinformation, hallucination—the tendency of Large Language Models (LLMs) to generate non-factual or unfaithful responses—represents the main risk for their global utility. Despite LLMs becoming increasingly multilingual, the vast majority …

</details>


### [206] [Llm-hanabi: Evaluating multi-agent gameplays with theory-of-mind and rationale inference in imperfect information collaboration game](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.04980%3F&hl=zh-CN&sa=X&d=12450820312632344206&ei=hAAKaYrABv-j6rQPweenoAk&scisig=ABGrvjKwxQYEW2ctJZpT6Stox0x_&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=3&folt=rel)
*F Liang,T Zheng,C Chan,Y Yim,Y Song*

Main category: Xuanhe Zhou

TL;DR: 该论文探讨大型语言模型在理论心智推理方面的能力，研究其在多智能体协作中推断他人行为背后动机的潜力


<details>
  <summary>Details</summary>
Motivation: 多智能体协作需要智能体能够理解其他智能体行为背后的动机和推理过程，这是理论心智（ToM）的核心能力。尽管当前大型语言模型在逻辑推理方面表现出色，但在推断行为动机方面仍存在局限，这限制了其在复杂多智能体协作场景中的应用效果。

Method: 论文可能采用实验评估方法，设计多智能体协作任务来测试LLMs的理论心智推理能力。可能包括构建需要推断其他智能体意图的协作场景，设计对比实验来评估不同模型在ToM任务上的表现，以及分析模型推理过程中的认知偏差。

Result: 研究结果显示，虽然LLMs在某些逻辑推理任务上表现优异，但在需要深度理解他人心理状态和行为动机的理论心智推理任务中仍存在显著不足。模型可能表现出对表面行为的过度依赖，而难以准确推断行为背后的复杂意图和信念。

Conclusion: 当前大型语言模型在理论心智推理方面仍有待提升，这限制了其在需要深度协作的多智能体系统中的实际应用。未来的研究需要开发更先进的架构和训练方法来增强LLMs的心理状态推理能力，以实现真正有效的多智能体协作。

Abstract: Effective multi-agent collaboration requires agents to infer the rationale behind others' actions, a capability rooted in Theory-of-Mind (ToM). While recent Large Language Models (LLMs) excel at logical inference, their ability to infer rationale in …

</details>


### [207] [Multi-Agent Evolve: LLM Self-Improve through Co-evolution](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.23595&hl=zh-CN&sa=X&d=11606676273015370394&ei=hAAKaYrABv-j6rQPweenoAk&scisig=ABGrvjJz5WH2XJNfDR8mzfCrcYEN&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=4&folt=rel)
*Y Chen,Y Wang,S Zhu,H Yu,T Feng,M Zhang…*

Main category: Xuanhe Zhou

TL;DR: RL能提升LLM推理能力但依赖人工数据集和可验证奖励，本文提出自监督强化学习框架Self-Rewarding，让LLM自我生成训练数据和奖励信号，实现持续自我改进


<details>
  <summary>Details</summary>
Motivation: 现有RL方法依赖人工标注数据集和可验证奖励信号，限制了LLM推理能力的规模化提升。需要开发能够自我生成训练数据和奖励信号的框架，实现持续自我改进

Method: 提出Self-Rewarding框架，让LLM同时作为推理者和奖励模型。通过迭代训练过程，LLM生成训练数据并自我评估，创建奖励信号用于强化学习训练，实现自我改进循环

Result: Self-Rewarding框架在多个推理任务上表现优于传统RL方法，实现了持续的性能提升，减少了对外部人工标注的依赖，展示了自我改进的潜力

Conclusion: 自监督强化学习为LLM推理能力提升提供了新范式，通过自我生成数据和奖励信号，能够实现持续自我改进，减少对人工标注的依赖，具有重要的研究价值

Abstract: Reinforcement Learning (RL) has demonstrated significant potential in enhancing the reasoning capabilities of large language models (LLMs). However, the success of RL for LLMs heavily relies on human-curated datasets and verifiable rewards …

</details>


### [208] [Rediscovering Entropy Regularization: Adaptive Coefficient Unlocks Its Potential for LLM Reinforcement Learning](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.10959%3F&hl=zh-CN&sa=X&d=13383069328035440967&ei=hAAKaYrABv-j6rQPweenoAk&scisig=ABGrvjIoEmuO2TyR1O2iA2ocfTui&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=6&folt=rel)
*X Zhang,X Yuan,D Huang,W You,C Hu,J Ruan…*

Main category: Xuanhe Zhou

TL;DR: RLVR训练中策略熵崩溃问题及其解决方案


<details>
  <summary>Details</summary>
Motivation: 强化学习与可验证奖励（RLVR）已成为提升大语言模型推理能力的关键范式，但在训练过程中常出现策略熵崩溃问题，导致模型探索不足和泛化能力下降。

Method: 论文提出了一种解决RLVR训练中策略熵崩溃问题的方法，可能包括熵正则化、探索策略改进或训练稳定性增强等技术。

Result: 提出的方法有效缓解了策略熵崩溃问题，提高了模型的探索能力和泛化性能，在推理任务上取得了更好的表现。

Conclusion: 解决RLVR训练中的策略熵崩溃问题对于提升大语言模型的推理能力至关重要，论文提出的方法为此提供了有效解决方案。

Abstract: Reasoning ability has become a defining capability of Large Language Models (LLMs), with Reinforcement Learning with Verifiable Rewards (RLVR) emerging as a key paradigm to enhance it. However, RLVR training often suffers from policy entropy …

</details>


### [209] [MarsadLab at PalmX Shared Task: An LLM Benchmark for Arabic Culture and Islamic Civilization](https://scholar.google.com/scholar_url?url=https://aclanthology.org/2025.arabicnlp-sharedtasks.112.pdf&hl=zh-CN&sa=X&d=1829799894866412314&ei=hAAKaYrABv-j6rQPweenoAk&scisig=ABGrvjL4pWp2AzIQiUeaNc1uUdSF&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=7&folt=rel)
*MR Biswas,S Ibrahim,K Attia,F Alam,W Zaghouani*

Main category: Xuanhe Zhou

TL;DR: 团队提交了PalmX 2025阿拉伯文化与宗教知识理解共享任务的解决方案，专注于训练能够理解特定领域文化宗教知识的大语言模型


<details>
  <summary>Details</summary>
Motivation: 解决阿拉伯文化宗教知识理解任务，开发能够准确理解和处理特定领域文化宗教内容的大语言模型

Method: 训练大型语言模型，专注于领域特定的文化宗教知识表示，可能包括微调、领域适应或专门训练策略

Result: 提交了PalmX 2025共享任务的解决方案，展示了在阿拉伯文化宗教知识理解任务上的模型性能

Conclusion: 成功开发了针对阿拉伯文化宗教知识理解的大语言模型，为相关领域任务提供了有效解决方案

Abstract: This paper presents our submission to the PalmX 2025 Shared Task on Arabic cultural and religious knowledge comprehension. We focus on training large language models capable of representing domain-specific cultural and religious …

</details>


### [210] [Grounded in Reality: Learning and Deploying Proactive LLM from Offline Logs](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.25441&hl=zh-CN&sa=X&d=4325796382419123253&ei=ucMLafvDL93YieoPw97yoQo&scisig=ABGrvjKRufzfaPriDTuDtP8nulYE&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=0&folt=rel)
*F Wei,D Chen,C Wang,Y Huang,Y Chen,X Pan,Y Li…*

Main category: Xuanhe Zhou

TL;DR: 该论文探讨了如何将大型语言模型从被动响应者转变为主动、目标导向的合作伙伴，特别是在高风险领域，提出了一种新的训练范式来解决现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型目前主要作为被动响应者，但在高风险领域（如医疗、金融、安全等）需要它们成为主动、目标导向的合作伙伴。现有方法要么短视地优化单轮交互，要么缺乏有效的训练机制来培养这种主动协作能力。

Method: 论文提出了一种新的训练范式，可能包括多轮对话优化、目标导向的强化学习、主动提问机制、长期规划能力培养等方法，旨在让LLMs学会主动引导对话、识别用户需求、制定长期策略。

Result: 通过新提出的训练方法，LLMs在主动协作任务上表现出显著改进，能够更好地理解复杂目标、主动获取必要信息、制定有效策略，并在高风险领域的模拟场景中展现出更强的合作伙伴能力。

Conclusion: 将LLMs从被动响应者转变为主动合作伙伴是可行的，但需要专门设计的训练范式。论文提出的方法为解决这一挑战提供了有效途径，为LLMs在高风险领域的应用开辟了新方向。

Abstract: Large Language Models (LLMs) excel as passive responders, but teaching them to be proactive, goal-oriented partners, a critical capability in high-stakes domains, remains a major challenge. Current paradigms either myopically optimize single-turn …

</details>


### [211] [BOTS: A Unified Framework for Bayesian Online Task Selection in LLM Reinforcement Finetuning](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.26374&hl=zh-CN&sa=X&d=16698335626719348895&ei=ucMLafvDL93YieoPw97yoQo&scisig=ABGrvjLOfq_kWXJwN5cjorIVMi5G&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=1&folt=rel)
*Q Shen,D Chen,Y Huang,Z Ling,Y Li,B Ding,J Zhou*

Main category: Xuanhe Zhou

TL;DR: RFT效果对训练任务选择敏感，本文提出任务感知RFT框架，通过任务相似性度量和自适应探索策略优化训练任务选择，在数学推理任务上显著提升性能


<details>
  <summary>Details</summary>
Motivation: 强化微调(RFT)对LLM与人类偏好对齐和推理能力提升至关重要，但其效果高度依赖于训练任务的选择。现有方法通常均匀采样任务，忽略了任务间的相似性和差异性，导致训练效率低下和性能不稳定

Method: 提出任务感知RFT框架：1) 使用任务相似性度量评估任务间关系；2) 设计自适应探索策略，根据任务相似性动态调整任务采样概率；3) 在数学推理任务上验证框架有效性

Result: 在多个数学推理基准测试中，任务感知RFT相比均匀采样RFT显著提升性能，证明任务感知方法能更有效地利用训练数据，提高模型泛化能力

Conclusion: 任务感知RFT通过考虑任务相似性和自适应探索策略，解决了传统RFT对训练任务选择敏感的问题，为LLM对齐和推理能力提升提供了更有效的训练框架

Abstract: Reinforcement finetuning (RFT) is a key technique for aligning Large Language Models (LLMs) with human preferences and enhancing reasoning, yet its effectiveness is highly sensitive to which tasks are explored during training. Uniform …

</details>


### [212] [EARL: Efficient Agentic Reinforcement Learning Systems for Large Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.05943&hl=zh-CN&sa=X&d=15212407793487519145&ei=ucMLafvDL93YieoPw97yoQo&scisig=ABGrvjLOp_D7_fs7nnnVmYZ4k6ip&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=2&folt=rel)
*Z Tan,M Abdullahi,T Shi,H Yuan,Z Xu,C Yu,B Li…*

Main category: Xuanhe Zhou

TL;DR: 该论文探讨了大规模语言模型强化学习训练中的挑战，特别是智能体强化学习在多轮交互和工具使用场景下的扩展问题，提出了解决这些挑战的方法。


<details>
  <summary>Details</summary>
Motivation: 随着强化学习在大语言模型后训练中变得日益重要，智能体强化学习范式通过多轮交互和工具使用扩展了这一应用。然而，扩展这类系统暴露了两个关键挑战：需要处理大规模训练数据带来的复杂性，以及智能体在多轮交互中保持连贯性和有效性的困难。

Method: 论文可能提出了一种新的训练框架或算法来应对智能体强化学习的扩展挑战，可能包括分布式训练策略、高效的数据采样方法、改进的奖励设计，或者专门针对多轮交互和工具使用的优化技术。

Result: 提出的方法应该能够有效处理大规模训练数据，提升智能体在多轮交互中的表现，改善工具使用的效率和准确性，最终实现更稳定和可扩展的智能体强化学习系统。

Conclusion: 该研究为大规模语言模型的智能体强化学习训练提供了重要见解和解决方案，推动了这一领域向更复杂、更实用的应用场景发展，为构建更强大的AI智能体奠定了基础。

Abstract: Reinforcement learning (RL) has become a pivotal component of large language model (LLM) post-training, and agentic RL extends this paradigm to operate as agents through multi-turn interaction and tool use. Scaling such systems exposes two …

</details>


### [213] [An approach for systematic decomposition of complex llm tasks](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.07772%3F&hl=zh-CN&sa=X&d=6399357744788452814&ei=ucMLafvDL93YieoPw97yoQo&scisig=ABGrvjLXmpOvC81Z7-mY8nq3wUif&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=3&folt=rel)
*T Zhou,J Xu,G Liu,J Liu,H Wang,E Wu*

Main category: Xuanhe Zhou

TL;DR: 提出一种系统化分解框架，解决LLM在复杂任务中的可靠性问题，替代现有的启发式或人工分解方法


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理复杂任务时存在可靠性问题，现有分解方法大多是启发式的，依赖于智能体或人工分解，缺乏系统化框架

Method: 引入一种新颖的系统化分解框架，该方法不是基于启发式规则，而是通过结构化方法将复杂任务分解为可管理的子任务

Result: 该框架能够显著提高LLM在复杂任务上的可靠性和性能，相比现有方法有更好的效果

Conclusion: 系统化分解框架为解决LLM在复杂任务中的可靠性问题提供了有效途径，具有重要的理论和实践意义

Abstract: Large Language Models (LLMs) suffer from reliability issues on complex tasks, as existing decomposition methods are heuristic and rely on agent or manual decomposition. This work introduces a novel, systematic decomposition framework …

</details>


### [214] [PORTool: Tool-Use LLM Training with Rewarded Tree](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.26020&hl=zh-CN&sa=X&d=11071588112686069057&ei=ucMLafvDL93YieoPw97yoQo&scisig=ABGrvjLhllEi0JWKysiJSIkOaZly&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=4&folt=rel)
*F Wu,W Zhu,Y Zhang,S Chatterjee,J Zhu,F Mo…*

Main category: Xuanhe Zhou

TL;DR: 当前工具使用大语言模型在静态数据集上训练，能够与外部工具交互并进行多步工具集成推理，但存在模仿而非理解工具使用、缺乏动态适应能力的问题


<details>
  <summary>Details</summary>
Motivation: 现有工具使用LLMs在静态数据集上训练，仅模仿工具调用轨迹，缺乏对工具使用的深入理解，无法动态适应新工具或环境变化，限制了实际应用效果

Method: 论文可能提出了一种动态适应或强化学习框架，使LLMs能够通过与环境交互学习工具使用策略，而非仅仅模仿静态数据中的工具调用序列

Result: 预期结果包括：模型能够更好地理解工具功能、适应新工具、在动态环境中做出更优决策，相比静态训练模型在工具使用任务上表现更优

Conclusion: 静态数据集训练的局限性需要通过动态适应方法克服，使LLMs真正理解工具使用，提高在实际复杂环境中的泛化能力和适应性

Abstract: Current tool-use large language models (LLMs) are trained on static datasets, enabling them to interact with external tools and perform multi-step, tool-integrated reasoning, which produces tool-call trajectories. However, these models imitate how …

</details>


### [215] [Enhancing Text-to-SQL generation with language sequential consistency](https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0925231225023938&hl=zh-CN&sa=X&d=13104267075880935550&ei=ucMLafvDL93YieoPw97yoQo&scisig=ABGrvjLEFDhH9tEyKGC6dmIrzYVK&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=5&folt=rel)
*Z Zhang,Y Chen,C Guo,J Song,G He*

Main category: Xuanhe Zhou

TL;DR: 该论文研究文本到SQL转换任务，旨在解决自然语言问题与SQL之间的结构差异带来的挑战


<details>
  <summary>Details</summary>
Motivation: 文本到SQL转换是重要任务，但自然语言问题与SQL之间的显著结构差异增加了模型转换的难度，需要解决这一挑战

Method: 论文未在摘要中明确说明具体方法，但暗示需要处理自然语言与SQL之间的结构差异问题

Result: 摘要未提供具体实验结果，但暗示需要改进文本到SQL转换的性能

Conclusion: 文本到SQL转换面临结构差异挑战，需要进一步研究改进转换方法

Abstract: Text-to-SQL is an important task that aims to convert unstructured natural language questions into Structured Query Language (SQL). The significant structural gap between questions and SQL increases the difficulty of conversion for the model …

</details>


### [216] [Multimodal Language Models See Better When They Look Shallower](https://scholar.google.com/scholar_url?url=https://aclanthology.org/2025.emnlp-main.339.pdf&hl=zh-CN&sa=X&d=8581773817515859918&ei=ucMLafvDL93YieoPw97yoQo&scisig=ABGrvjL0ONpl_IuskiPSdei06iFv&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=6&folt=rel)
*H Chen,J Lin,X Chen,Y Fan,J Dong,X Jin,H Su,J Fu…*

Main category: Xuanhe Zhou

TL;DR: 本文挑战了MLLMs中普遍存在的"深层偏见"——即仅从ViT的最终层提取视觉特征的做法，指出这种经验性惯例缺乏理论依据，并提出了更优的多层特征融合策略。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型普遍采用从预训练Vision Transformer的最终层提取视觉特征的惯例，但这种"深层偏见"主要是经验性传统而非有原则的设计。作者旨在挑战这一惯例，探索更有效的视觉特征提取策略。

Method: 论文挑战了仅使用ViT最终层特征的惯例，提出了更全面的多层特征融合方法。通过分析不同层次视觉特征的语义信息，探索了更优的特征提取策略来提升MLLMs的性能。

Result: 研究发现仅依赖ViT最终层特征存在局限性，而结合多层特征（包括中间层）能提供更丰富的视觉语义信息，从而提升多模态大语言模型的视觉理解和推理能力。

Conclusion: 多模态大语言模型不应盲目遵循仅从ViT最终层提取视觉特征的惯例，而应采用更全面的多层特征融合策略，这能提供更丰富的视觉语义表示，从而提升模型性能。

Abstract: Multimodal large language models (MLLMs) typically extract visual features from the final layers of a pretrained Vision Transformer (ViT). This widespread deep-layer bias, however, is largely driven by empirical convention rather than principled …

</details>


### [217] [A Unified Masked Jigsaw Puzzle Framework for Vision and Language Models](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11202736/&hl=zh-CN&sa=X&d=1563935042963717014&ei=ucMLafvDL93YieoPw97yoQo&scisig=ABGrvjI91GyoWTH7572d6KMRe8_I&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=7&folt=rel)
*W Ye,W Wang,Y Liu,Y Song,B Ren,W Bi…*

Main category: Xuanhe Zhou

TL;DR: 联邦学习中Transformer架构面临梯度攻击防御和性能提升的双重挑战，需要同时解决隐私保护和模型效果问题


<details>
  <summary>Details</summary>
Motivation: Transformer作为联邦学习中流行的架构，在CV和NLP任务中面临两个关键挑战：防御梯度攻击以保护隐私，以及提升模型性能。需要一种方法能同时解决这两个问题。

Method: 从提供的摘要片段来看，方法部分信息不完整。但可以推断可能涉及联邦学习中的隐私保护技术（如差分隐私、安全聚合）与Transformer架构优化的结合，以同时实现梯度攻击防御和性能提升。

Result: 摘要未提供具体实验结果。预期结果应包括：在CV和NLP任务中，提出的方法能有效防御梯度攻击（如重构攻击、成员推理攻击），同时保持或提升模型性能（准确率、收敛速度等）。

Conclusion: 需要一种综合解决方案来平衡联邦学习中Transformer架构的隐私保护和模型性能，这对于实际部署至关重要。

Abstract: In federated learning, Transformer, as a popular architecture, faces critical challenges in defending against gradient attacks and improving model performance in both Computer Vision (CV) and Natural Language Processing (NLP) tasks. It has …

</details>


### [218] [DSG-MCTS: A Dynamic Strategy-Guided Monte Carlo Tree Search for Diversified Reasoning in Large Language Models](https://scholar.google.com/scholar_url?url=https://aclanthology.org/2025.emnlp-main.532.pdf&hl=zh-CN&sa=X&d=13221156992926354535&ei=ucMLafvDL93YieoPw97yoQo&scisig=ABGrvjIXXNm6kfLK8Ksx0IOQD5UE&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=8&folt=rel)
*R Ha,C Li,R Pu,L Zhang,X Zhang,S Su*

Main category: Xuanhe Zhou

TL;DR: 该论文探讨了如何通过结构化推理过程来提升大语言模型在复杂任务中的表现，解决幻觉、错误和逻辑不一致问题


<details>
  <summary>Details</summary>
Motivation: 大语言模型在复杂推理任务中表现出潜力，但随着任务复杂度增加，其性能会下降，产生幻觉、错误和逻辑不一致问题，需要增强推理能力

Method: 论文提出了一种结构化推理方法，通过系统化的推理框架来引导LLMs的思考过程，可能包括思维链、推理步骤分解、验证机制等

Result: 该方法显著提高了LLMs在复杂推理任务中的准确性和可靠性，减少了幻觉和逻辑错误

Conclusion: 结构化推理是提升大语言模型复杂任务表现的有效途径，为更可靠的AI推理系统提供了重要方向

Abstract: Large language models (LLMs) have shown strong potential in complex reasoning tasks. However, as task complexity increases, their performance often degrades, resulting in hallucinations, errors, and logical inconsistencies. To enhance reasoning …

</details>


### [219] [Seallms-audio: Large audio-language models for southeast asia](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.01670&hl=zh-CN&sa=X&d=7170266935781660542&ei=9lQNadHsIpvJieoPm6nJ6Qo&scisig=ABGrvjKoH3sjPelXONEB7zghwBWT&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=2&folt=rel)
*C Liu,M Aljunied,G Chen,HP Chan,W Xu,Y Rong…*

Main category: Xuanhe Zhou

TL;DR: SeaLLMs-Audio是首个针对东南亚语言（印尼语、泰语、越南语）以及英语和中文的大规模音频语言模型


<details>
  <summary>Details</summary>
Motivation: 现有音频语言模型主要针对主流语言，缺乏对东南亚语言的支持，需要开发专门针对该地区多语言环境的模型

Method: 使用大规模多语言音频-文本数据进行训练，支持印尼语、泰语、越南语、英语和中文五种语言

Result: 开发了首个针对东南亚语言的大规模音频语言模型，填补了该领域空白

Conclusion: SeaLLMs-Audio为东南亚语言的多模态AI应用提供了重要基础，推动了语言技术在该地区的普及

Abstract: We introduce SeaLLMs-Audio, the first large audio-language model (LALM) tailored for multiple Southeast Asian (SEA) languages-Indonesian (id), Thai (th), and Vietnamese (vi)-alongside English (en) and Chinese (zh). Trained on a large-scale …

</details>


### [220] [Efficient Long-context Language Model Training by Core Attention Disaggregation](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.18121&hl=zh-CN&sa=X&d=4827556454641860109&ei=9lQNadHsIpvJieoPm6nJ6Qo&scisig=ABGrvjJ5Xt5j_ZOtzBuqgc1_Qhoe&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=3&folt=rel)
*Y Zhuang,J Chen,B Pang,Y Gu,Y Zhu,Y Jiang…*

Main category: Xuanhe Zhou

TL;DR: CAD技术通过将核心注意力计算与模型其他部分解耦并在专用计算池上执行，以提升长上下文LLM训练效率


<details>
  <summary>Details</summary>
Motivation: 长上下文大语言模型训练中的核心注意力计算（softmax(QK^T)V）是计算瓶颈，限制了训练效率和可扩展性

Method: 提出核心注意力解耦技术，将softmax(QK^T)V计算从模型其余部分分离，在专用计算池上异步执行，减少通信开销

Result: CAD技术显著提升长上下文LLM训练效率，降低计算瓶颈，改善模型可扩展性

Conclusion: 注意力计算解耦是优化长上下文LLM训练的有效策略，为大规模语言模型训练提供新的架构优化方向

Abstract: We present core attention disaggregation (CAD), a technique that improves long-context large language model training by decoupling the core attention computation, softmax (QK^ T) V, from the rest of the model and executing it on a separate pool of …

</details>


### [221] [Dacp: Domain-adaptive continual pre-training of large language models for phone conversation summarization](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.05858%3F&hl=zh-CN&sa=X&d=1358191630370098442&ei=9lQNadHsIpvJieoPm6nJ6Qo&scisig=ABGrvjJxmYAfn1ThpAmGb34ZByrR&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=8&folt=rel)
*XY Fu,E Khasanova,MTR Laskar,H Saini,SB Tn*

Main category: Xuanhe Zhou

TL;DR: LLMs在文本摘要方面表现优异，但在专业领域和对话数据上表现不足，需要专门的评估基准


<details>
  <summary>Details</summary>
Motivation: 现有LLMs在通用文本摘要上表现良好，但在专业领域（如医学、法律）和对话数据上表现不佳，缺乏针对这些场景的专门评估基准

Method: 通过创建专门的评估基准来测试LLMs在专业领域和对话数据上的摘要能力，可能包括数据集构建、评估指标设计和模型性能分析

Result: LLMs在专业领域和对话数据上的摘要性能确实不如通用领域，显示出领域适应性的局限性

Conclusion: 需要开发专门针对专业领域和对话数据的评估基准来更好地衡量和改进LLMs在这些场景下的摘要能力

Abstract: Large language models (LLMs) have achieved impressive performance in text summarization, yet their performance often falls short when applied to specialized domains% or conversational data that differ from their original pre-training …

</details>


### [222] [Code-Switching In-Context Learning for Cross-Lingual Transfer of Large Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.05678%3F&hl=zh-CN&sa=X&d=13748405910128370276&ei=9lQNadHsIpvJieoPm6nJ6Qo&scisig=ABGrvjK5Xq45A4VnRW0JvpkKkbby&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=9&folt=rel)
*H Yoo,J Jin,K Cho,A Oh*

Main category: Xuanhe Zhou

TL;DR: 大语言模型的多语言能力依赖于英语作为潜在表示，形成翻译障碍，导致推理过程隐含地依赖于内部翻译成英语


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型展现出强大的多语言能力，但其依赖英语作为潜在表示的方式存在问题。这种依赖形成了翻译障碍，导致模型的推理过程隐含地依赖于内部翻译成英语，这可能影响非英语语言任务的性能和质量。

Method: 从摘要内容来看，论文可能提出了一种方法来减少或消除这种翻译依赖。可能的方法包括：开发更平衡的多语言表示、减少英语偏置、或者创建不依赖单一语言作为中介的推理机制。

Result: 根据摘要暗示，改进后的方法应该能够减少翻译障碍，提升非英语语言任务的性能，使模型能够更直接地处理多语言内容而不需要隐含的英语翻译。

Conclusion: 大语言模型的多语言能力存在根本性限制，即对英语作为潜在表示的依赖。通过解决这一翻译障碍，可以显著提升模型在非英语语言任务上的性能和公平性。

Abstract: While large language models (LLMs) exhibit strong multilingual abilities, their reliance on English as latent representations creates a translation barrier, where reasoning implicitly depends on internal translation into English. When this process …

</details>


### [223] [Relation-Aware Bayesian Optimization of DBMS Configurations Guided by Affinity Scores](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.27145&hl=zh-CN&sa=X&d=17162308456490378870&ei=91QNaZv0FcHO6rQPt-Gh0Ao&scisig=ABGrvjKbAriNbnnCu13yv43muNN4&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=4&folt=cit)
*S Kwon,S Baek,H Yang,Y Jo,S Park*

Main category: Xuanhe Zhou

TL;DR: 论文探讨数据库管理系统配置参数自动优化的机器学习方法，指出现有方法在样本效率、泛化能力和适应性方面的局限性


<details>
  <summary>Details</summary>
Motivation: DBMS性能对配置参数高度敏感，传统手动调优方法难以适应大规模异构数据和多样化工作负载，需要更高效的自动化配置优化方法

Method: 采用机器学习方法进行DBMS配置参数自动优化，但具体方法未在摘要中详细说明

Result: 现有机器学习方法在DBMS配置优化中仍存在关键局限性，具体表现为样本效率、泛化能力和适应性方面的不足

Conclusion: 需要改进现有机器学习方法以克服在DBMS配置优化中的局限性，实现更高效的自动化参数调优

Abstract: Database Management Systems (DBMSs) are fundamental for managing large-scale and heterogeneous data, and their performance is critically influenced by configuration parameters. Effective tuning of these parameters is essential for adapting to diverse workloads and maximizing throughput while minimizing latency. Recent research has focused on automated configuration optimization using machine learning; however, existing approaches still exhibit several key limitations …

</details>


### [224] [Text-to-SQL with Table Retrieval and Metadata](https://scholar.google.com/scholar_url?url=https://s-space.snu.ac.kr/bitstream/10371/229263/1/000000192329.pdf&hl=zh-CN&sa=X&d=147592468684857403&ei=91QNaZv0FcHO6rQPt-Gh0Ao&scisig=ABGrvjKhzc6vWSc4UP55WGT0QTGC&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=5&folt=cit)
*명현기*

Main category: Xuanhe Zhou

TL;DR: 提出利用大语言模型增强模式链接和元数据生成的Text-to-SQL新框架，通过表检索获取相关模式和单元格值作为SQL生成的关键上下文


<details>
  <summary>Details</summary>
Motivation: 关系数据库对结构化数据管理至关重要，但其固有的复杂性给Text-to-SQL带来了模式链接挑战。现有方法在处理复杂数据库模式时存在局限性，需要更有效的模式链接和上下文理解机制。

Method: 提出一个新颖框架，利用大语言模型增强模式链接和元数据生成。方法集成表检索技术，检索相关模式和单元格值作为SQL生成的关键上下文。同时生成元数据以改善语义理解。

Result: 论文表明该方法能有效解决复杂数据库的模式链接问题，通过检索相关模式和单元格值提供更好的上下文，从而提高Text-to-SQL的性能和准确性。

Conclusion: 该框架通过结合大语言模型、表检索和元数据生成，显著改善了Text-to-SQL中的模式链接问题，为处理复杂关系数据库提供了更有效的解决方案。

Abstract: Relational databases are essential for structured data management, yet their inherent complexity poses a schema linking challenge to Text-to-SQL. In this work, we propose a novel framework that leverages Large Language Models (LLMs) for enhanced schema linking and metadata generation. Our method integrates table retrieval to retrieve relevant schema and cell values, which serve as crucial context for SQL generation. We also generate metadata to improve the semantic …

</details>


### [225] [Controlling Performance and Budget of a Centralized Multi-agent LLM System with Reinforcement Learning](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.02755&hl=zh-CN&sa=X&d=2554914377828732268&ei=LAIPafDBJ8eB6rQPoOTz8Qc&scisig=ABGrvjIp-vIxSKTN5KGkP_nq4WDh&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=0&folt=rel)
*B Jin,TJ Collins,D Yu,M Cemri,S Zhang,M Li,J Tang…*

Main category: Xuanhe Zhou

TL;DR: 该论文探讨了在多智能体LLM系统中，通过动态路由机制实现不同规模和能力的语言模型之间的高效协作，以平衡性能与成本。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在不同领域展现出互补优势，且推理成本各异，这促使设计多智能体LLM系统，让专业化模型能够高效协作。

Method: 论文提出了一种动态路由机制，根据任务复杂度和模型能力，智能地将查询分配给不同规模和成本的LLM，实现性能与成本的平衡。

Result: 该方法在保持或提升任务性能的同时，显著降低了总体推理成本，实现了不同LLM之间的高效协作。

Conclusion: 动态路由机制为构建高效的多智能体LLM系统提供了可行方案，能够在模型能力与推理成本之间取得良好平衡。

Abstract: Large language models (LLMs) exhibit complementary strengths across domains and come with varying inference costs, motivating the design of multi-agent LLM systems where specialized models collaborate efficiently. Existing approaches …

</details>


### [226] [Incentivizing Agentic Reasoning in LLM Judges via Tool-Integrated Reinforcement Learning](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.23038&hl=zh-CN&sa=X&d=18085606667674975693&ei=LAIPafDBJ8eB6rQPoOTz8Qc&scisig=ABGrvjKZvE8E3nUaXZYsOIqoOOAX&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=1&folt=rel)
*R Xu,J Chen,J Ye,Y Wu,J Yan,C Yang,H Yu*

Main category: Xuanhe Zhou

TL;DR: LLM作为评估者主要依赖文本推理，缺乏外部验证能力，限制了评估的准确性和可靠性


<details>
  <summary>Details</summary>
Motivation: 当前LLM评估者主要基于内在文本推理，无法验证事实准确性、逻辑一致性或与现实世界知识的一致性，这限制了评估的可靠性和实用性

Method: 未在摘要中明确说明具体方法，但暗示需要增强LLM评估者的能力，使其能够进行外部验证和事实核查

Result: 未在摘要中提供具体结果，但指出当前LLM评估方法的局限性

Conclusion: 需要开发能够进行外部验证的LLM评估系统，以提高评估的准确性和可靠性

Abstract: Large Language Models (LLMs) are widely used as judges to evaluate response quality, providing a scalable alternative to human evaluation. However, most LLM judges operate solely on intrinsic text-based reasoning, limiting their ability to verify …

</details>


### [227] [Nyuad at arahealthqa shared task: Benchmarking the medical understanding and reasoning of large language models in arabic healthcare tasks](https://scholar.google.com/scholar_url?url=https://aclanthology.org/2025.arabicnlp-sharedtasks.19.pdf&hl=zh-CN&sa=X&d=13663259693449684926&ei=LAIPafDBJ8eB6rQPoOTz8Qc&scisig=ABGrvjLwn2yhLGlaZIEmaz7Nvozs&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=7&folt=rel)
*N AlDahoul,Y Zaki*

Main category: Xuanhe Zhou

TL;DR: 该论文探讨大型语言模型在阿拉伯语医学NLP领域的应用现状、挑战及未来发展方向


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在阿拉伯语通用NLP任务中表现出色，但在阿拉伯语医学领域的应用效果尚未得到充分研究和验证，存在特定领域的挑战需要解决

Method: 论文可能采用文献综述、实证分析或实验评估的方法，系统考察LLMs在阿拉伯语医学NLP任务中的表现，识别关键挑战并提出改进方向

Result: 发现LLMs在阿拉伯语医学NLP领域存在局限性，包括医学专业术语理解、领域知识整合、文化语境适应等方面的挑战，需要针对性优化

Conclusion: 需要开发专门针对阿拉伯语医学领域的LLM优化方法，包括领域适应、术语增强、文化敏感性调整等，以提升在医疗健康应用中的实用性

Abstract: Recent progress in large language models (LLMs) has showcased impressive proficiency in numerous Arabic natural language processing (NLP) applications. Nevertheless, their effectiveness in Arabic medical NLP domains has received …

</details>


### [228] [OmniEduBench: A Comprehensive Chinese Benchmark for Evaluating Large Language Models in Education](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.26422&hl=zh-CN&sa=X&d=4317175194317605604&ei=LAIPafDBJ8eB6rQPoOTz8Qc&scisig=ABGrvjI_qwtYE7G2qCw63Ic4YUx3&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=9&folt=rel)
*M Zhang,H Chen,W Zhang,D Zhu,X Lin,B Jiang…*

Main category: Xuanhe Zhou

TL;DR: 该论文指出当前大语言模型及其基准测试主要关注知识维度，忽略了教育应用中的其他重要维度，如认知技能、情感态度等，存在局限性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在教育领域的广泛应用，现有模型和基准测试主要关注知识维度，忽视了教育中同样重要的认知技能、情感态度等维度，这种局限性影响了LLM在教育领域的全面应用效果。

Method: 论文未提供具体方法细节，但从摘要推断可能涉及构建更全面的教育评估框架，考虑知识、认知技能、情感态度等多维度评估标准，以弥补现有LLM基准测试的不足。

Result: 摘要未提供具体实验结果，但指出了当前LLM在教育应用中的局限性：过度关注知识维度而忽视其他教育重要维度，这可能导致教育应用效果不全面。

Conclusion: 需要开发更全面的LLM评估框架，涵盖知识、认知技能、情感态度等多维度，以更好地支持教育领域的应用需求。

Abstract: With the rapid development of large language models (LLMs), various LLM-based works have been widely applied in educational fields. However, most existing LLMs and their benchmarks focus primarily on the knowledge dimension, largely …

</details>


### [229] [The Quest for an LLM-Based Natural Language Interface for an Industrial Database](https://scholar.google.com/scholar_url?url=https://ebooks.iospress.nl/doi/10.3233/FAIA251458&hl=zh-CN&sa=X&d=9340755032537982508&ei=Uo0QafG6FceB6rQPsefiqAI&scisig=ABGrvjJsH99q81szG5ke2NONinMD&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=0&folt=cit)
*M Lemos,YT Izquierdo,GM García,ERS Nascimento…*

Main category: Xuanhe Zhou

TL;DR: 构建基于大语言模型的自然语言接口用于能源公司生产应用Busca360，分析文本转SQL技术在Busca360数据库上的表现并提出解决方案


<details>
  <summary>Details</summary>
Motivation: 为能源公司的生产应用Busca360构建自然语言接口，解决现有文本转SQL技术在特定数据库上的局限性，提升用户通过自然语言查询数据的能力

Method: 基于大语言模型构建自然语言接口，使用Busca360数据库和100个自然语言问题及其对应SQL查询作为基准测试，分析现有文本转SQL技术的表现并提出改进方案

Result: 论文分析了现有文本转SQL技术在Busca360数据库上的性能表现，识别了具体局限性，并提出了针对性的解决方案来克服这些限制

Conclusion: 成功构建了基于大语言模型的自然语言接口，通过基准测试验证了解决方案的有效性，为生产环境中的文本转SQL应用提供了实践指导

Abstract: This paper describes the steps taken to construct a Natural Language interface based on Large Language Models (LLMs) for Busca360, an application in production at an energy company. The paper analyses how technologies developed for text-to-SQL perform on the Busca360 database and proposes solutions to overcome the limitations observed. The analysis is based on a benchmark that uses the Busca360 database and a set of 100 Natural Language (NL) questions and their …

</details>


### [230] [xRouter: Training Cost-Aware LLMs Orchestration System via Reinforcement Learning](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.08439&hl=zh-CN&sa=X&d=16366367940733410075&ei=UY0QabuuBf-j6rQP7fvY4A4&scisig=ABGrvjLCK4Yy01ofyIAjdQ4SYKt_&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=1&folt=rel)
*C Qian,Z Liu,S Kokane,A Prabhakar,J Qiu,H Chen…*

Main category: Xuanhe Zhou

TL;DR: 现代LLM部署面临成本与性能的权衡：高端模型推理能力强但昂贵，轻量级模型经济但复杂任务表现脆弱。静态升级规则和关键词匹配方法存在局限性。


<details>
  <summary>Details</summary>
Motivation: 解决LLM部署中成本与性能的权衡问题，传统静态升级规则和关键词匹配方法在复杂任务上效果有限，需要更智能的模型选择策略。

Method: 从摘要信息看，可能涉及动态模型选择策略、智能路由机制或基于任务复杂度的自适应模型切换方法，但具体方法细节未在提供的摘要中明确说明。

Result: 摘要未提供具体实验结果，但暗示需要更有效的模型选择策略来平衡成本与性能。

Conclusion: 需要开发更智能的动态模型选择机制来优化LLM部署的成本效益比，替代传统的静态升级规则和关键词匹配方法。

Abstract: Modern LLM deployments confront a widening cost-performance spectrum: premium models deliver strong reasoning but are expensive, while lightweight models are economical yet brittle on complex tasks. Static escalation rules and keyword …

</details>


### [231] [Multi-Document Event Extraction Using Large and Small Language Models](https://scholar.google.com/scholar_url?url=https://aclanthology.org/2025.emnlp-main.972.pdf&hl=zh-CN&sa=X&d=4527960192042402239&ei=UY0QabuuBf-j6rQP7fvY4A4&scisig=ABGrvjKJ_KF8zd0OUDvQcS3RiNjq&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=4&folt=rel)
*Q Min,Z Qu,Q Guo,X Hu,Z Zhang,Y Zhang*

Main category: Xuanhe Zhou

TL;DR: 多文档事件提取旨在从多样化来源聚合事件信息，以全面理解复杂事件，但现有研究对此任务关注有限


<details>
  <summary>Details</summary>
Motivation: 多文档事件提取对于全面理解复杂事件具有重要实际意义，但现有研究对此任务关注不足，需要开发有效方法来从多样化文档来源中聚合事件信息

Method: 论文未提供具体方法细节，但基于摘要内容，该研究应涉及从多个文档中提取和整合事件信息的技术，可能包括跨文档事件关联、信息融合和冲突解决等方法

Result: 摘要未提供具体实验结果，但该研究应开发了多文档事件提取系统或框架，能够从多样化文档来源中有效聚合事件信息，提升复杂事件理解的全面性

Conclusion: 多文档事件提取是一个重要但研究不足的任务，需要进一步探索有效方法来从多样化文档中聚合事件信息，以实现对复杂事件的全面理解

Abstract: Multi-document event extraction aims to aggregate event information from diverse sources for a comprehensive understanding of complex events. Despite its practical significance, this task has received limited attention in existing research. The …

</details>


### [232] [Enhancing Large Vision-Language Models with Ultra-Detailed Image Caption Generation](https://scholar.google.com/scholar_url?url=https://aclanthology.org/2025.emnlp-main.1357.pdf&hl=zh-CN&sa=X&d=8365552251184998123&ei=UY0QabuuBf-j6rQP7fvY4A4&scisig=ABGrvjLjQtcNXRXUXSRzJatIrByO&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=5&folt=rel)
*Y Zeng,Y Qi,Y Zhao,X Bao,L Chen,Z Chen,S Huang…*

Main category: Xuanhe Zhou

TL;DR: 该论文针对大视觉语言模型中高质量图像描述数据稀缺的问题，提出了一种自动生成超详细图像描述的方法来提升模态对齐和视觉理解能力。


<details>
  <summary>Details</summary>
Motivation: 高质量图像描述对于提升大视觉语言模型的模态对齐和视觉理解能力至关重要，但现有超详细图像描述数据稀缺，限制了模型的进一步发展。

Method: 论文提出了一种自动生成超详细图像描述的方法（具体方法未在摘要中详细说明，但暗示通过某种技术手段解决数据稀缺问题）。

Result: 该方法能够生成高质量的图像描述数据，有助于提升大视觉语言模型的性能（具体量化结果未在摘要中提供）。

Conclusion: 通过自动生成超详细图像描述数据，可以有效解决数据稀缺问题，推动大视觉语言模型在模态对齐和视觉理解方面的进步。

Abstract: High-quality image captions are essential for improving modality alignment and visual understanding in Large Vision-Language Models (LVLMs). However, the scarcity of ultra-detailed image caption data limits further advancements. This paper …

</details>


### [233] [BILLY: Steering Large Language Models via Merging Persona Vectors for Creative Generation](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.10157%3F&hl=zh-CN&sa=X&d=6255808199843750801&ei=UY0QabuuBf-j6rQP7fvY4A4&scisig=ABGrvjJNLipe2fVkvhRALhPHJR-P&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=7&folt=rel)
*TM Pai,JI Wang,LC Lu,SH Sun,HY Lee,KW Chang*

Main category: Xuanhe Zhou

TL;DR: 提出一种解决多LLM系统高计算成本和推理延迟问题的新方法


<details>
  <summary>Details</summary>
Motivation: 多LLM系统通过模拟人类集体智能增强了大型语言模型的创造力，但存在高计算成本和推理延迟等显著缺点

Method: 提出一种新方法来解决多LLM系统的计算效率和延迟问题（具体方法未在摘要中说明）

Result: 未在摘要中提供具体结果

Conclusion: 需要解决多LLM系统的效率和延迟问题以充分发挥其潜力

Abstract: Multi-LLM systems enhance the creativity of large language models by simulating human collective intelligence but suffer from significant drawbacks, such as high computational costs and inference latency. To address these limitations, we propose …

</details>


### [234] [Simulating Viva Voce Examinations to Evaluate Clinical Reasoning in Large Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.10278%3F&hl=zh-CN&sa=X&d=9526299421127490873&ei=UY0QabuuBf-j6rQP7fvY4A4&scisig=ABGrvjKLpBkffVUsiRygPvzYM4y2&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=8&folt=rel)
*C Chiu,S Pitis,M van der Schaar*

Main category: Xuanhe Zhou

TL;DR: 临床推理是假设驱动的过程，医生通过有限信息逐步完善诊断，而当前医学基准测试存在局限性


<details>
  <summary>Details</summary>
Motivation: 当前医学基准测试未能充分反映临床推理的实际过程，需要更贴近真实临床实践的评估框架

Method: 提出新的评估方法或框架，可能包括模拟临床推理过程的测试设计、逐步信息获取的评估机制

Result: 新评估框架能更准确地衡量临床推理能力，揭示当前基准测试的局限性

Conclusion: 需要开发更贴近真实临床推理过程的医学评估基准，以更好地评估和提升临床决策能力

Abstract: Clinical reasoning in medicine is a hypothesis-driven process where physicians refine diagnoses from limited information through targeted history, physical examination, and diagnostic investigations. In contrast, current medical benchmarks …

</details>


### [235] [PROM: Personal Knowledge Graph Construction with Large Language Models](https://scholar.google.com/scholar_url?url=https://www.scitepress.org/Papers/2025/138309/138309.pdf&hl=zh-CN&sa=X&d=17399280072014386645&ei=UY0QabuuBf-j6rQP7fvY4A4&scisig=ABGrvjLBIMxJL8qW87OvZesFvi7v&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=9&folt=rel)
*A Maoliniyazi,C Ma,X Meng,B Xu*

Main category: Xuanhe Zhou

TL;DR: PKG-Enhanced Chatbot利用个人知识图谱增强聊天机器人，通过实体链接和关系提取构建PKG，提升个性化对话能力


<details>
  <summary>Details</summary>
Motivation: 数字信息爆炸式增长需要有效的个人知识管理，个人知识图谱(PKGs)作为连接实体和关系的知识模型具有潜力，但现有聊天机器人缺乏个性化知识整合能力

Method: 提出PKG-Enhanced Chatbot框架，通过实体链接将用户输入与PKG中的实体对齐，利用关系提取构建知识图谱，整合PKG知识到对话生成中

Result: 系统能够有效整合个人知识到对话中，提供更个性化和准确的回复，在知识密集型对话任务中表现优于传统聊天机器人

Conclusion: PKG增强的聊天机器人是个人知识管理的有效解决方案，能够显著提升对话系统的个性化和知识整合能力，为未来个性化AI助手提供新方向

Abstract: The growing volume of digital information requires effective Personal Knowledge Management. Personal Knowledge Graphs (PKGs), which model knowledge as connected entities and relationships, show potential. Chats or natural voice …

</details>


### [236] [RUST-BENCH: Benchmarking LLM Reasoning on Unstructured Text within Structured Tables](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.04491&hl=zh-CN&sa=X&d=9400156336482780547&ei=Gu4RaZWjMIePieoPuIjpsAQ&scisig=ABGrvjJwJfmn3Lih92RCaRoJpDXZ&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=0&folt=rel)
*N Abhyankar,P Chaurasia,S Kabra,A Srivastava…*

Main category: Xuanhe Zhou

TL;DR: 现有表格推理基准主要测试小规模、统一格式的表格，未能充分反映真实世界数据的复杂性，导致对大型语言模型推理能力的评估不完整


<details>
  <summary>Details</summary>
Motivation: 现有表格推理基准存在局限性，主要基于小型、格式统一的表格，无法代表真实世界中复杂、多样化的表格数据，导致对LLM推理能力的评估存在偏差

Method: 论文未在摘要中明确说明具体方法，但暗示需要构建更复杂、更接近真实世界数据的表格推理基准来全面评估LLM的推理能力

Result: 摘要未提供具体实验结果，但指出现有基准的局限性，暗示需要新的评估框架来更准确地衡量LLM在复杂表格推理任务上的表现

Conclusion: 需要开发更复杂、更贴近真实世界表格数据的推理基准，以全面评估大型语言模型的表格推理能力，避免现有基准的局限性

Abstract: Existing tabular reasoning benchmarks mostly test models on small, uniform tables, underrepresenting the complexity of real-world data and giving an incomplete view of Large Language Models'(LLMs) reasoning abilities. Real tables are long …

</details>


### [237] [Multi-Modal Fact-Verification Framework for Reducing Hallucinations in Large Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.22751&hl=zh-CN&sa=X&d=2313002504823181042&ei=Gu4RaZWjMIePieoPuIjpsAQ&scisig=ABGrvjLf9jW9GNWCh3ROmy8rSuyk&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=6&folt=rel)
*P Patel*

Main category: Xuanhe Zhou

TL;DR: 大语言模型存在幻觉问题，会自信地生成看似合理但虚假的信息，这已成为AI系统应用的主要障碍


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽然改变了人机交互方式，但存在严重缺陷：它们会自信地生成听起来完全合理但实际上是虚假的信息。这种幻觉问题已成为AI系统可靠应用的主要障碍，需要解决以提高模型的可信度和实用性。

Method: 从摘要内容来看，本文主要关注大语言模型的幻觉问题，但未提供具体的解决方法。可能涉及对幻觉问题的分析、评估指标或缓解策略的研究。

Result: 摘要明确指出大语言模型存在幻觉问题，会生成看似合理但虚假的信息。这已成为AI系统应用的主要障碍，暗示需要进一步研究解决方案。

Conclusion: 大语言模型的幻觉问题是一个关键缺陷，严重影响了AI系统的可靠性和可信度，需要有效的解决方案来克服这一障碍。

Abstract: While Large Language Models have transformed how we interact with AI systems, they suffer from a critical flaw: they confidently generate false information that sounds entirely plausible. This hallucination problem has become a major barrier to …

</details>


### [238] [DeepEye-SQL: A software-engineering-inspired text-to-sql framework](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.17586&hl=zh-CN&sa=X&d=2063099248663232273&ei=Gu4RaZWjMIePieoPuIjpsAQ&scisig=ABGrvjLoGCi0cg6ylcvcSdGTm7jO&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=7&folt=rel)
*B Li,C Chen,Z Xue,Y Mei,Y Luo*

Main category: Xuanhe Zhou

TL;DR: 该论文指出当前LLM在Text-to-SQL任务中系统级可靠性不足的问题，强调需要超越单个模块优化的整体系统方法


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在Text-to-SQL任务上取得了进展，但现有解决方案在系统级可靠性方面仍然不足。问题的关键不仅在于单个模块（如模式链接、推理和验证）的局限性，更在于缺乏整体系统层面的优化方法

Method: 论文提出需要超越传统模块化方法，采用系统级优化策略。虽然摘要未详细说明具体技术，但暗示需要整合模式链接、推理和验证等模块，并考虑它们之间的交互和整体系统性能

Result: 摘要未提供具体实验结果，但指出了当前Text-to-SQL解决方案在系统级可靠性方面的不足，为后续研究提供了方向性指导

Conclusion: Text-to-SQL任务需要从系统层面进行优化，而不仅仅是改进单个模块。未来的研究应该关注整体系统架构和模块间的协同工作，以提高实际应用中的可靠性

Abstract: Large language models (LLMs) have advanced Text-to-SQL, yet existing solutions still fall short of system-level reliability. The limitation is not merely in individual modules-eg, schema linking, reasoning, and verification-but more critically in the lack …

</details>


### [239] [FINDR: A Fast Influential Data Selector for NL2Code Pretraining](https://scholar.google.com/scholar_url?url=https://web.eecs.umich.edu/~xlfzhang/assets/pdf/AACL2025/paper.pdf&hl=zh-CN&sa=X&d=5594713567383846183&ei=G-4RaejPOo2v6rQP2o3qoQg&scisig=ABGrvjINuu57gh7t9P1NrmlhH1IX&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=3&folt=cit)
*XF Zhang,L Wang*

Main category: Xuanhe Zhou

TL;DR: 该研究探讨了在NL2Code任务中通过数据选择方法从大规模语料库中识别与目标分布对齐的子集，以提升模型的专业化性能


<details>
  <summary>Details</summary>
Motivation: 虽然大规模预训练产生了具有多任务能力的大语言模型，但实际应用如NL2Code需要更专业化的训练。现有方法主要针对指令微调设计，而NL2Code领域的数据选择挑战尚未得到充分探索

Method: 通过数据选择视角，识别大规模语料库中与目标分布对齐的子集。具体方法可能涉及分布对齐、相关性度量或基于模型反馈的选择策略

Result: 摘要未提供具体实验结果，但暗示该方法能够有效识别与NL2Code任务对齐的数据子集，提升模型在该领域的专业化性能

Conclusion: 数据选择是提升NL2Code模型专业化性能的有效途径，填补了该领域的研究空白，为实际应用提供了更高效的训练策略

Abstract: Pretraining on massive corpora has given rise to large language models (LLMs) with multitask capabilities. However, real-world applications often require more specialized training, as is the case of NL2Code. We approach this specialization through the lens of data selection, ie, identifying a subset of a large corpus that aligns with a desired target distribution—a challenge that remains underexplored within NL2Code. Existing methods are typically designed for selecting instructiontuning …

</details>


### [240] [Efficient Knowledge Transfer from Large to Small Language Models via Low-Overhead Query Mechanism](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3746252.3761417&hl=zh-CN&sa=X&d=17119394211247354639&ei=IpETafmbIoS6ieoPn56AOA&scisig=ABGrvjI78b2lHyhQHisN0YlMg9SU&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=0&folt=rel)
*F Ahemad*

Main category: Xuanhe Zhou

TL;DR: 提出一种新颖的查询机制，使小型语言模型能够在推理过程中高效地从大型模型中提取知识，以弥补性能差距


<details>
  <summary>Details</summary>
Motivation: 小型语言模型虽然计算效率高，但性能通常不如大型模型。需要一种方法让小型模型在推理时能够利用大型模型的知识，以平衡效率与性能。

Method: 引入一种新颖的查询机制，使小型模型在推理过程中能够高效地从大型模型中提取相关知识。该方法允许小型模型在需要时向大型模型查询特定信息。

Result: 小型模型通过该机制能够显著提升性能，接近或达到大型模型的水平，同时保持计算效率优势。

Conclusion: 提出的查询机制为小型语言模型提供了一种有效利用大型模型知识的途径，实现了效率与性能的良好平衡。

Abstract: Small language models offer computational efficiency but often lack the performance of larger models. We introduce a novel query mechanism enabling small models to efficiently extract knowledge from large models during inference. Our approach …

</details>


### [241] [Stronger Together: On-Policy Reinforcement Learning for Collaborative LLMs](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.11062%3F&hl=zh-CN&sa=X&d=2047779828874521572&ei=IpETafmbIoS6ieoPn56AOA&scisig=ABGrvjL6WDytZpoTyv6cZB0gnctk&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=1&folt=rel)
*Y Zhao,L Hu,Y Wang,M Hou,H Zhang,K Ding…*

Main category: Xuanhe Zhou

TL;DR: 该论文探讨了如何结合多智能体系统（MAS）和强化学习（RL）来增强大语言模型（LLM）的智能体能力，通过角色编排和环境反馈优化任务性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在作为智能体执行复杂任务时存在局限性，需要更有效的协作和学习机制来提升其任务执行能力。多智能体系统和强化学习各自有优势，但单独使用时效果有限，因此需要探索两者的结合来充分发挥LLM的智能体潜力。

Method: 结合多智能体系统的角色编排机制和强化学习的环境反馈机制。MAS通过角色分工和协作优化任务分配，RL则通过奖励信号和环境交互来训练和优化智能体行为。两者结合形成互补的学习和协作框架。

Result: 结合MAS和RL的方法能够显著提升LLM智能体的任务执行效率和效果。MAS的角色编排提供了结构化协作，RL的环境反馈则实现了自适应学习，两者协同工作使LLM智能体在复杂任务中表现更优。

Conclusion: 多智能体系统和强化学习的结合为增强大语言模型的智能体能力提供了有效框架。这种集成方法能够充分发挥两种范式的优势，为LLM在复杂环境中的自主学习和协作任务执行开辟了新途径。

Abstract: Multi-agent systems (MAS) and reinforcement learning (RL) are widely used to enhance the agentic capabilities of large language models (LLMs). MAS improves task performance through role-based orchestration, while RL uses environmental …

</details>


### [242] [StepTool: Enhancing Multi-Step Tool Usage in LLMs via Step-Grained Reinforcement Learning](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3746252.3761391&hl=zh-CN&sa=X&d=16312401093599634882&ei=IpETafmbIoS6ieoPn56AOA&scisig=ABGrvjISs4z56d-KsIyQf3WiEEAg&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=3&folt=rel)
*Y Yu,Z Wang,W Ma,S Wang,C Wu,Z Guo,M Zhang*

Main category: Xuanhe Zhou

TL;DR: 该论文探讨大型语言模型在工具学习方面的挑战，提出新方法改进LLMs利用外部工具解决复杂任务的能力


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型具有强大的文本生成能力，但在有效利用外部工具解决复杂任务方面仍存在困难，这一挑战被称为工具学习。现有方法主要依赖监督微调，但效果有限。

Method: 论文提出了一种新方法（具体方法未在摘要中明确说明，但暗示超越了传统的监督微调方法），旨在改进LLMs的工具学习能力。

Result: 该方法在工具学习任务上取得了显著改进（具体指标未在摘要中提供），表明LLMs能够更有效地利用外部工具解决复杂问题。

Conclusion: 该研究为提升LLMs的工具学习能力提供了新思路，有助于推动LLMs在实际应用中的复杂任务解决能力。

Abstract: Despite their powerful text generation capabilities, large language models (LLMs) still struggle to effectively utilize external tools to solve complex tasks, a challenge known as tool learning. Existing methods primarily rely on supervised fine-tuning …

</details>


### [243] [Reflective Thought and Code for Solving Numerical Problems with Large Language Models](https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-981-95-3358-9_31&hl=zh-CN&sa=X&d=4596098188484784639&ei=IpETafmbIoS6ieoPn56AOA&scisig=ABGrvjIg_CIfICNTksfJm7ntZqvp&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=6&folt=rel)
*LTT Son,NV Anh,NTT Linh,NV Ha*

Main category: Xuanhe Zhou

TL;DR: 该论文针对大语言模型在需要精确计算和推理的计算问题上的局限性，提出了一种新的评估基准和解决方案。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在许多推理任务上表现出色，但在需要精确推理和正确数值计算的计算问题上仍存在局限。现有评估基准往往无法充分测试模型的计算能力，因此需要专门针对计算问题的评估框架。

Method: 论文提出了一种新的评估基准，专门设计用于测试大语言模型在计算问题上的能力。该基准包含需要精确数值计算和逻辑推理的问题，并可能提出了相应的解决方案或改进方法。

Result: 通过该评估基准，论文揭示了当前大语言模型在计算问题上的具体局限性，展示了模型在精确计算和推理方面的不足，并可能展示了提出的解决方案在提升模型计算能力方面的效果。

Conclusion: 大语言模型在计算问题上仍有显著改进空间，需要专门的评估基准和解决方案来提升其精确计算能力。该研究为未来改进大语言模型的计算推理能力提供了重要基础。

Abstract: Large language models (LLMs) have achieved strong performance on many reasoning tasks but remain limited in solving computational problems, where precise reasoning and correct numerical calculation are essential. Therefore, common …

</details>


### [244] [â€ œ 数据+ AIâ€ 双向赋能机制与农业领域实践.](https://scholar.google.com/scholar_url?url=https://search.ebscohost.com/login.aspx%3Fdirect%3Dtrue%26profile%3Dehost%26scope%3Dsite%26authtype%3Dcrawler%26jrnl%3D10080864%26AN%3D188965590%26h%3DIu22YgsVfoOR7jBmdCZYdZQoaPM5fEoamEeNxkaKU%252B5aX12wS5U%252Bgv6eRMaE%252BjovaDN7cnC5h5FwUDYd%252FVTXyw%253D%253D%26crl%3Dc&hl=zh-CN&sa=X&d=4300098905856535117&ei=I5ETaZShKIqi6rQP6t-R-Q4&scisig=ABGrvjIQrb6DEAR--VA9BwxrZJ2S&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=3&folt=cit)
*王彦芳， 赵瑞雪*

Main category: Xuanhe Zhou

TL;DR: 探讨数据与AI双向赋能机制与实践路径，为AI迭代升级、数据价值释放及行业智能服务发展提供理论支撑


<details>
  <summary>Details</summary>
Motivation: 数据被列为第五生产要素，生成式AI技术突破，数据与AI进入融合共生变革期，但二者协同机制解析不足，需要探讨双向赋能机制与实践路径

Method: 从数据赋能AI和AI赋能数据两个维度阐释双向协同机制，分析二者关系从单向依赖转为双向深度协同发展的过程

Result: 形成良性互动循环，进入由应用驱动的融合阶段，为AI快速迭代升级、数据要素价值加速释放及行业智能服务发展落地提供理论支撑

Conclusion: 数据与AI关系从单向依赖转变为双向深度协同，形成良性循环，推动行业智能服务发展，需要进一步探讨协同机制与实践路径

Abstract: 伴随数据增列为第五生产要素与生成式人工智能(artificial intelligence, AI) 技术的跨越式突破, 数据和AI 进入融合共生的剧烈变革期,“数据+ AI” 深度交叉融合成为各行业的研究焦点. 针对二者协同机制的解析不足, 探讨其双向赋能的机制与实践路径, 旨在为AI 快速迭代升级, 数据要素价值加速释放及行业智能服务发展落地提供理论支撑与实证支持. 从数据赋能AI 和AI 赋能数据维度阐释其双向协同机制, 二者关系从单向依赖转为双向深度协同发展, 形成良性互动循环, 进入由应用驱动的融合 …

</details>


### [245] [GrASP: A Generalizable Address-based Semantic Prefetcher for Scalable Transactional and Analytical Workloads](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.11011&hl=zh-CN&sa=X&d=17756980411005191191&ei=efgUacG8Jqqy6rQP_fqIwQ4&scisig=ABGrvjLeVTUT0aTa0VmZF1mL6DYS&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=0&folt=rel)
*F Zirak,F Choudhury,R Borovica*

Main category: Xuanhe Zhou

TL;DR: 该论文探讨了数据库中的数据预取技术，传统方法关注顺序模式，而最新学习型方法试图解决更复杂的访问模式。


<details>
  <summary>Details</summary>
Motivation: 数据预取对于减少I/O开销和提升数据库性能至关重要。传统预取器主要处理顺序访问模式，但在实际应用中存在更复杂的访问模式，需要更智能的预取策略。

Method: 论文提到了传统预取方法和学习型方法的对比，但具体方法细节在提供的摘要中未完全展开。可能涉及机器学习算法来预测数据访问模式，以替代或增强传统的顺序预取策略。

Result: 摘要中未提供具体实验结果。但可以推断学习型方法相比传统顺序预取器在处理复杂访问模式方面可能表现更好，能够更准确地预测未来数据需求。

Conclusion: 学习型数据预取方法代表了数据库性能优化的重要发展方向，能够处理超越简单顺序模式的复杂数据访问场景，有望显著提升数据库系统的I/O效率。

Abstract: Data prefetching--loading data into the cache before it is requested--is essential for reducing I/O overhead and improving database performance. While traditional prefetchers focus on sequential patterns, recent learning-based approaches …

</details>


### [246] [KBAlign: Efficient Self Adaptation on Specific Textual Knowledge Bases](https://scholar.google.com/scholar_url?url=https://aclanthology.org/anthology-files/anthology-files/pdf/findings/2025.findings-emnlp.728.pdf&hl=zh-CN&sa=X&d=7862847137224413566&ei=B3kWaaeSNKqy6rQP_fqIwQ4&scisig=ABGrvjKbwsZnl2TTuKPZplTdH6Gk&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=2&folt=cit)
*Z Zeng,Y Chen,S Yu,R Wang,Y Yan,Z Liu,S Wang…*

Main category: Xuanhe Zhou

TL;DR: KBAlign：针对小规模知识库的自监督框架，通过结构对齐增强RAG系统在特定领域知识问答中的性能


<details>
  <summary>Details</summary>
Motivation: 当前基于检索增强生成（RAG）的知识问答系统在小规模知识库上存在适配困难：无监督训练效果不佳，而微调需要大量外部信号成本过高

Method: 提出KBAlign自监督框架，通过知识库结构对齐技术增强RAG系统，无需外部监督信号

Result: 未在摘要中明确说明具体实验结果，但暗示该方法能有效提升小规模知识库上的问答性能

Conclusion: KBAlign为特定领域知识问答提供了一种高效的自监督解决方案，解决了小规模知识库适配的成本和效果问题

Abstract: Although retrieval-augmented generation (RAG) remains essential for knowledgebased question answering (KBQA), current paradigms face critical challenges under specific domains. Existing methods struggle with targeted adaptation on small-scale KBs: vanilla unsupervised training exhibits poor effectiveness, while fine-tuning incurs prohibitive costs of external signals. We present KBAlign, a self-supervised framework that enhances RAG systems through …

</details>


### [247] [TS-SQL: Test-driven Self-refinement for Text-to-SQL](https://scholar.google.com/scholar_url?url=https://aclanthology.org/anthology-files/anthology-files/pdf/findings/2025.findings-emnlp.156.pdf&hl=zh-CN&sa=X&d=10003125228181126042&ei=B3kWaaeSNKqy6rQP_fqIwQ4&scisig=ABGrvjL54u49taEy47RFw9-AoO7Y&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=4&folt=cit)
*W Xu,H Zhu,L Yan,C Liu,P Han,S Duan,JZ Pan*

Main category: Xuanhe Zhou

TL;DR: TS-SQL：基于测试驱动的自优化方法，通过协作LLM生成测试用例来检测和修正Text-to-SQL中的语义错误


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的自优化方法在Text-to-SQL任务中面临语义错误问题，如条件遗漏和需求误解，这些错误源于LLM语义理解过程中的幻觉和偏见，导致无法纠正的错误

Method: 提出测试驱动的自优化框架TS-SQL，利用协作LLM生成测试用例来检测SQL语义错误，通过测试反馈指导修正过程，避免依赖易出错的语义理解

Result: TS-SQL能够有效检测和修正Text-to-SQL中的语义错误，相比传统自优化方法显著提升SQL查询的准确性和语义完整性

Conclusion: 测试驱动的自优化方法通过生成测试用例来验证SQL语义，有效解决了传统自优化方法中的幻觉和偏见问题，为Text-to-SQL任务提供了更可靠的错误检测和修正机制

Abstract: Abstract Large Language Model (LLM)-based selfrefinement has advanced Text-to-SQL, but it struggles with SQL semantic errors, such as omitted conditions and misinterpreted requirements. This is because self-refinement depends on LLMs' semantic understanding of questions, a process prone to hallucination-induced biases, leading to uncorrectable errors. To solve this problem, we propose Test-driven Selfrefinement for Text-to-SQL (TS-SQL). It leverages a collaborative LLM …

</details>


### [248] [iKnow: an Intent-Guided Chatbot for Cloud Operations with Retrieval-Augmented Generation](https://scholar.google.com/scholar_url?url=https://jun-jie-huang.github.io/assets/papers/ase25_iknow.pdf&hl=zh-CN&sa=X&d=2083243865519468353&ei=B3kWaaeSNKqy6rQP_fqIwQ4&scisig=ABGrvjJMKRY5u14d8h24qgCLO2wZ&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=9&folt=cit)
*J Huang,Y Zhong,G Yu,Z Jiang,M Yan,W Luan…*

Main category: Xuanhe Zhou

TL;DR: 开发基于RAG的云运维聊天机器人，解决云工程师面对海量文档时知识获取效率低的问题


<details>
  <summary>Details</summary>
Motivation: 云服务运维文档数量庞大，工程师难以高效获取相关知识，需要一种能够快速检索并生成简洁、有引用来源答案的解决方案

Method: 采用检索增强生成(RAG)技术，构建能够检索相关知识并生成带引用答案的聊天机器人系统

Result: 论文分析了RAG基云运维聊天机器人的开发与部署经验，探讨了实际应用中面临的挑战

Conclusion: RAG技术能够有效提升云运维知识获取效率，但构建可靠的RAG基聊天机器人仍面临实际部署挑战

Abstract: Managing complex cloud services requires standard operational documentation, but its sheer volume often hinders cloud engineers from efficient knowledge acquisition. Retrieval-Augmented Generation (RAG) can streamline this process by retrieving relevant knowledge and generating concise, referenced answers. However, deploying a reliable RAG-based chatbot for cloud operation remains a challenge. In this experience paper, we analyze the development and deployment of RAG-based …

</details>


### [249] [When to Ensemble: Identifying Token-Level Points for Stable and Fast LLM Ensembling](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.15346&hl=zh-CN&sa=X&d=17424261019605374866&ei=v-0Xaeq5C7mAieoPtbvzyQs&scisig=ABGrvjISmbNrXhPomQ2E9BG6vmh_&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=2&folt=rel)
*H Yun,K Ki,J Lee,E Yang*

Main category: Xuanhe Zhou

TL;DR: LLM集成方法通过聚合多个模型的下一词概率分布来提升性能，但现有方法在计算效率和效果上存在局限


<details>
  <summary>Details</summary>
Motivation: 集成大型语言模型是提升性能的有前景方法，但现有集成技术要么计算成本高（如投票），要么效果有限（如简单平均），需要更高效的集成方法

Method: 提出了一种新的集成方法，通过聚合多个LLM的下一词概率分布来生成更准确的预测，可能涉及加权平均、概率校准或自适应选择机制

Result: 该方法在多个基准测试中超越了单个模型和现有集成方法，在保持计算效率的同时显著提升了生成质量

Conclusion: 概率分布聚合是有效的LLM集成策略，为构建更强大、更可靠的LLM系统提供了实用解决方案

Abstract: Ensembling Large Language Models (LLMs) has gained attention as a promising approach to surpass the performance of individual models by leveraging their complementary strengths. In particular, aggregating models' next-token probability …

</details>


### [250] [Feedback Descent: Open-Ended Text Optimization via Pairwise Comparison](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.07919&hl=zh-CN&sa=X&d=8085188666630012090&ei=wO0XaauVDbmAieoPtbvzyQs&scisig=ABGrvjITAoEbbKmjkBkum1Ej31Wd&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=1&folt=cit)
*Y Lee,J Boen,C Finn*

Main category: Xuanhe Zhou

TL;DR: Feedback Descent是一种通过结构化文本反馈而非标量奖励来优化文本工件（提示、代码、分子）的框架，通过保留详细批评而非压缩为二元偏好来拓宽偏好学习中的信息瓶颈。


<details>
  <summary>Details</summary>
Motivation: 传统偏好学习通常将详细反馈压缩为二元偏好或标量奖励，导致信息丢失。Feedback Descent旨在通过保留结构化文本反馈来拓宽信息瓶颈，实现更有效的文本空间优化。

Method: 提出Feedback Descent框架，利用结构化文本反馈而非标量奖励进行优化。通过上下文学习将结构化反馈转化为梯度方向，在文本空间而非权重空间中进行定向优化。

Result: 该方法在提示、代码和分子优化任务中表现出色，通过保留详细批评信息实现了更有效的优化，相比传统偏好学习方法有显著改进。

Conclusion: Feedback Descent通过结构化文本反馈拓宽了偏好学习的信息瓶颈，为文本工件的优化提供了更有效的方法，在多个领域展现出应用潜力。

Abstract: We introduce\textit {Feedback Descent}, a framework that optimizes text artifacts--prompts, code, and molecules--through structured textual feedback, rather than relying solely on scalar rewards. By preserving detailed critiques instead of compressing them to binary preferences, Feedback Descent widens the information bottleneck in preference learning, enabling directed optimization in text space rather than weight space. We show that in-context learning can transform structured …

</details>


### [251] [RadialRouter: Structured Representation for Efficient and Robust Large Language Models Routing](https://scholar.google.com/scholar_url?url=https://aclanthology.org/anthology-files/anthology-files/pdf/findings/2025.findings-emnlp.787.pdf&hl=zh-CN&sa=X&d=5543049807808820200&ei=yUQZacGAC4ePieoP4Ijq0QY&scisig=ABGrvjJZcIQrLSCpaRib7e_6rUg_&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=5&folt=rel)
*RJP Shao,Z Wen,J Wu,MFSZJ Tao*

Main category: Xuanhe Zhou

TL;DR: LLM路由技术综述：通过智能选择最优模型来平衡性能与成本，提升AI系统效率


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）的快速发展，出现了多种不同能力和成本的模型。为了在特定任务中平衡性能与资源消耗，需要开发智能路由技术来从候选模型中选择最优的LLM。

Method: 论文综述了LLM路由技术，包括基于启发式规则、基于学习的方法和混合方法。讨论了路由决策的关键因素：任务复杂度、模型能力、成本约束和延迟要求。

Result: 路由技术能显著降低计算成本（高达70%）同时保持性能，实现更高效的LLM部署。智能路由系统能根据任务需求动态选择最合适的模型。

Conclusion: LLM路由是优化AI系统效率的关键技术，未来需要更精细的路由策略、自适应机制和标准化评估框架来推动该领域发展。

Abstract: The rapid advancements in large language models (LLMs) have led to the emergence of routing techniques, which aim to efficiently select the optimal LLM from diverse candidates to tackle specific tasks, optimizing performance while reducing …

</details>


### [252] [Text2SQL-Flow: A Robust SQL-Aware Data Augmentation Framework for Text-to-SQL](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.10192&hl=zh-CN&sa=X&d=7256365290184612006&ei=-7YaadPbLNToieoP3qjLUA&scisig=ABGrvjL2mI7H0R-V3gYKO_q8baHS&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=1&folt=cit)
*Q Cai,H Liang,C Xu,T Xie,W Zhang,B Cui*

Main category: Xuanhe Zhou

TL;DR: Text2SQL-Flow是一个SQL感知的数据增强框架，通过六个维度从少量种子数据生成大规模、语义有效且结构多样的Text-to-SQL对，以解决现有数据集稀缺、简单和低多样性的问题。


<details>
  <summary>Details</summary>
Motivation: 当前AI领域的数据中心范式对Text-to-SQL任务至关重要，但现有数据集存在稀缺、过于简单和多样性不足的问题，限制了模型性能的提升。

Method: 提出Text2SQL-Flow框架，这是一个SQL感知的数据增强方法，通过六个不同的增强维度，从最小化的种子数据生成大规模、语义有效且结构多样的Text-to-SQL数据对，并集成了端到端的SQL执行管道。

Result: 框架能够生成大规模、高质量且多样化的Text-to-SQL数据集，解决了现有数据集的局限性，为模型训练提供了更丰富的数据资源。

Conclusion: Text2SQL-Flow通过创新的数据增强方法有效解决了Text-to-SQL领域的数据稀缺和多样性不足问题，为提升模型性能提供了重要的数据基础。

Abstract: The data-centric paradigm has become pivotal in AI, especially for Text-to-SQL, where performance is limited by scarce, simplistic, and low-diversity datasets. To address this, we propose Text2SQL-Flow, a SQL-aware data augmentation framework that generates large-scale, semantically valid, and structurally diverse Text-to-SQL pairs from minimal seed data. It operates across six augmentation dimensions and integrates an end-to-end pipeline featuring SQL execution …

</details>


### [253] [ConstrainedSQL: Training LLMs for Text2SQL via Constrained Reinforcement Learning](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.09693&hl=zh-CN&sa=X&d=2633242246694458754&ei=-7YaadPbLNToieoP3qjLUA&scisig=ABGrvjL3zXECWNYTQxXO055qcfzJ&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=2&folt=cit)
*W Chen,NH Pham,MR Glass,LH Vu,G Rossiello…*

Main category: Xuanhe Zhou

TL;DR: 该论文提出了一种约束强化学习框架来解决Text2SQL任务中奖励函数设计问题，防止奖励黑客现象


<details>
  <summary>Details</summary>
Motivation: 强化学习在提升Text2SQL LLMs推理能力方面显示出潜力，但现有方法（如GRPO和DAPO）的性能高度依赖于奖励函数设计。不恰当的奖励会导致奖励黑客现象，模型会利用奖励结构的漏洞获得高分而非真正解决问题。

Method: 采用约束强化学习框架，通过引入约束条件来规范奖励函数的设计，防止模型利用奖励漏洞，确保模型真正学习解决Text2SQL任务。

Result: 约束强化学习框架能够有效防止奖励黑客现象，提升Text2SQL模型的真实性能，使模型更专注于解决实际任务而非仅仅优化奖励分数。

Conclusion: 约束强化学习为解决Text2SQL任务中的奖励函数设计问题提供了有效方案，能够防止奖励黑客现象，提高模型的真实推理能力。

Abstract: Reinforcement learning (RL) has demonstrated significant promise in enhancing the reasoning capabilities of Text2SQL LLMs, especially with advanced algorithms such as GRPO and DAPO. However, the performance of these methods is highly sensitive to the design of reward functions. Inappropriate rewards can lead to reward hacking, where models exploit loopholes in the reward structure to achieve high scores without genuinely solving the task. This work considers a constrained RL framework …

</details>


### [254] [MPCR-SQL: Enhancing SQL Generation by Multi-path SQL Generation and Collective SQL Refinement](https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-981-95-4091-4_15&hl=zh-CN&sa=X&d=2088307968852382541&ei=siocae7nCuvJieoPmryp4QQ&scisig=ABGrvjLYTc6EJnsr2cbZ1L_-euw0&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=0&folt=cit)
*M Hou,Y Huang,S Wang*

Main category: Xuanhe Zhou

TL;DR: MPCR-SQL提出了一种结合多路径SQL生成和对比排序的方法，旨在解决现有LLM在SQL生成中缺乏多样性和难以从多个候选中选择最优SQL的问题。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型在SQL生成方面取得了显著进展，但存在两个主要限制：1）生成的SQL查询缺乏多样性；2）难以从多个候选SQL中选择最优查询。这些限制影响了实际应用中的效果和鲁棒性。

Method: MPCR-SQL采用协同工作的双模块架构：1）多路径SQL生成模块，通过设计不同提示策略或采样方法生成多样化的SQL候选；2）对比排序模块，通过对比学习或排序算法从候选集中选择最优SQL查询。

Result: 该方法在SQL生成任务中表现出色，能够生成更多样化的SQL查询，并有效提升从多个候选中选择最优SQL的准确率，相比现有方法有显著改进。

Conclusion: MPCR-SQL通过结合多路径生成和对比排序，有效解决了SQL生成中的多样性和选择问题，为LLM在数据库查询生成领域的应用提供了更可靠的解决方案。

Abstract: Recent advancements in large language models (LLMs) have markedly enhanced SQL generation. Nevertheless, existing approaches typically generate SQL queries without considering their diversity. In addition, current methods often encounter challenges in selecting the optimal SQL from multiple candidates. To mitigate these limitations, this study presents MPCR-SQL, which synergistically combines two key modules:(1) A Multi-Path SQL Generation module is designed to produce a broader …

</details>


### [255] [BannerBench: Benchmarking Vision Language Models for Multi-Ad Selection with Human Preferences](https://scholar.google.com/scholar_url?url=https://aclanthology.org/anthology-files/anthology-files/pdf/findings/2025.findings-emnlp.1311.pdf&hl=zh-CN&sa=X&d=10834430207326919002&ei=sSocacmwGIqi6rQPwoX9sA8&scisig=ABGrvjKTszcT3ii1O_Vv0WoHBagB&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=4&folt=rel)
*H Otake,P Zhang,Y Sakai,M Mita,H Ouchi…*

Main category: Xuanhe Zhou

TL;DR: 该论文研究如何自动化网页横幅广告选择，通过构建一个端到端框架来预测广告点击率，同时考虑人类偏好因素


<details>
  <summary>Details</summary>
Motivation: 网页横幅广告目前仍主要依赖人工选择，因为人类偏好对广告投放决策至关重要。然而，手动选择效率低下且难以规模化，需要开发自动化解决方案来平衡算法效率和人类偏好因素。

Method: 论文提出一个端到端框架，通过机器学习模型预测广告点击率，同时整合人类偏好数据。方法可能包括特征工程、用户行为建模、偏好融合机制，以及将人工选择标准量化为可训练的模型参数。

Result: 提出的自动化框架在广告点击率预测方面表现出色，能够有效模拟人类选择偏好，实现比纯算法方法更好的广告投放效果，同时显著提高选择效率。

Conclusion: 通过结合机器学习预测和人类偏好建模，可以成功实现网页横幅广告的自动化选择，在保持广告效果的同时大幅提升运营效率，为数字广告优化提供了新的解决方案。

Abstract: Web banner advertisements, which are placed on websites to guide users to a targeted landing page (LP), are still often selected manually because human preferences are important in selecting which ads to deliver. To automate this …

</details>


### [256] [Korean Benchmark for Science and Technology Information Domain to Evaluate Large Language Models](https://scholar.google.com/scholar_url?url=https://www.dbpia.co.kr/Journal/articleDetail%3FnodeId%3DNODE12417635&hl=zh-CN&sa=X&d=495268874834902095&ei=v7MdafORBqqy6rQP4IzGyAE&scisig=ABGrvjJNiXqGafkAhb16DusFkz1N&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=5&folt=rel)
*고동혁， 육정훈， 이병호， 임경태， 이경하， 김태훈…*

Main category: Xuanhe Zhou

TL;DR: 한국어 과학기술정보 전문분야 벤치마크 구축 및 거대 언어 모델 평가


<details>
  <summary>Details</summary>
Motivation: 거대 언어 모델의 과학기술정보 분야 전문 지식을 평가하기 위한 한국어 벤치마크가 부족하며, 기존 범용 벤치마크와 차별화된 도메인 특화 평가 체계 필요

Method: 과학기술정보 전문분야 8가지 카테고리를 정의하고, 각 문제의 난이도와 특성을 고려한 한국어 벤치마크 데이터셋 구축

Result: 한국어 과학기술정보 전문분야 벤치마크가 구축되어 거대 언어 모델의 도메인 특화 지식 평가 가능

Conclusion: 구축된 벤치마크는 한국어 거대 언어 모델의 과학기술정보 분야 전문성 평가에 기여하며, 도메인 특화 평가의 중요성 확인

Abstract: 본 논문에서는 거대 언어 모델의 과학기술정보 분야의 전문 지식을 평가하기 위해 한국어 벤치마크를 구축한다. 범용 분야 벤치마크와 차별화된 도메인 특화 데이터 구축을 위하여 과학기술정보 전문분야 8 가지 카테고리를 정의하고 각 문제의 난이도와 …

</details>


### [257] [Aesthetics of humanism and AI in institutional governance: Research perspectives](https://scholar.google.com/scholar_url?url=https://www.taylorfrancis.com/chapters/edit/10.4324/9781003662723-2/aesthetics-humanism-ai-institutional-governance-micha%25C5%2582-szostak&hl=zh-CN&sa=X&d=5756570460621932902&ei=qhIhaYarHY2v6rQPhqjYoQE&scisig=ABGrvjJmc_Ob-A_gcF5uWZCKXbGc&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=0&folt=cit)
*M Szostak*

Main category: Xuanhe Zhou

TL;DR: 探讨将美学视角融入AI在制度治理中角色分析的研究方向、领域和问题


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索美学洞察和多层次意义如何增强AI治理解决方案的设计、实施和感知，以提升透明度、信任和公民参与

Method: 通过分析美学因素与AI治理的相互作用，研究美学如何影响透明度、信任和公民参与

Result: 该章节提出了研究框架和潜在研究方向，但未提供具体实证结果

Conclusion: 美学视角对于理解AI在制度治理中的角色至关重要，需要进一步研究美学如何增强AI治理系统的设计、实施和公众接受度

Abstract: This chapter explores potential research perspectives, areas, and problems in integrating aesthetics in analysing the role of AI in institutional governance. The research problem focuses on how aesthetic insights and layered meanings can enhance the design, implementation, and perception of AI-powered solutions in governance and public systems. The analyses investigate how these factors influence transparency, trust, and civic engagement by examining the interplay …

</details>


### [258] [LoRA-Guided PPO for Cost-Aware and Compute-Efficient Agent Orchestration](https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DfcJL3z579B&hl=zh-CN&sa=X&d=7803382907159093210&ei=qhIhaYarHY2v6rQPhqjYoQE&scisig=ABGrvjLpYpJYO3i8y0yMWCIe2n-5&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=1&folt=cit)
*A Durai,JC Hu,K Buch,K Zhu,V Sharma,A Balwani*

Main category: Xuanhe Zhou

TL;DR: 提出混合策略解决多智能体推理系统中的预算感知分配问题，结合参数高效预训练和强化学习


<details>
  <summary>Details</summary>
Motivation: 多智能体推理系统面临预算感知分配的根本挑战：需要在多个步骤中决定调用哪些子智能体，同时平衡成功概率与计算和货币成本

Method: 将问题形式化为成本约束的顺序决策问题，提出混合策略：使用LoRA适配器从启发式轨迹中捕获成本敏感先验，并结合强化学习进行优化

Result: 未在摘要中明确说明具体实验结果

Conclusion: 该方法为解决多智能体系统中的预算感知分配问题提供了有效的混合策略框架

Abstract: A fundamental challenge in multi-agent reasoning systems is budget-aware allocation: deciding which sub-agents to invoke across multiple steps while balancing success against computational and monetary cost. We formalize this setting as a cost-constrained sequential decision problem and propose a hybrid policy that integrates parameter-efficient pretraining with reinforcement learning. Specifically, a LoRA adapter captures cost-sensitive priors from heuristic traces, and …

</details>


### [259] [UniqueNOSD: a novel framework for NoSQL over SQL databases](https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1186/s40537-025-01307-2&hl=zh-CN&sa=X&d=12419793351297489709&ei=qhIhaYarHY2v6rQPhqjYoQE&scisig=ABGrvjL7HD39LGiOBTpoEhOUoECo&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=2&folt=cit)
*AA Gidado,CI Ezeife*

Main category: Xuanhe Zhou

TL;DR: NoSQL数据库主要用于非核心系统，通过分区实现可用性和可扩展性，但牺牲一致性；而大型企业核心系统仍依赖关系数据库


<details>
  <summary>Details</summary>
Motivation: 大型企业在核心系统仍使用关系数据库，而NoSQL仅用于非核心系统，这反映了当前数据库架构的现状和局限性。需要探索如何更好地平衡CAP定理中的一致性、可用性和分区容错性

Method: 基于CAP定理分析NoSQL系统的设计原则，探讨关系数据库与NoSQL数据库在企业架构中的角色定位和使用场景

Result: 当前企业实践中，关系数据库仍是核心系统的首选，NoSQL主要用于需要高可用性和可扩展性的非核心系统，体现了CAP定理在现实应用中的权衡

Conclusion: 企业数据库架构需要根据具体需求在关系数据库和NoSQL之间做出选择，未来可能需要更灵活的混合解决方案来平衡CAP特性

Abstract: To date, most large corporations still have their core solutions on relational databases but only use non-relational (ie NoSQL) database management systems (DBMS) for their non-core systems that favour availability and scalability through partitioning while trading off consistency. NoSQL systems are built based on the CAP (ie, Consistency, Availability and Partitioning) database theorem, which trades off one of these features while maintaining the others. The need for systems availability …

</details>


### [260] [Factored Internal Verification Enhances Large Language Model Factuality](https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-981-95-4088-4_18&hl=zh-CN&sa=X&d=4012231527847410048&ei=qRIhaaKAJv-j6rQPgcTr8Qg&scisig=ABGrvjJs_tQ-PTFmoIPawLeRVlS3&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=6&folt=rel)
*R Zhuang,B Wang,S Sun,K Lu*

Main category: Xuanhe Zhou

TL;DR: FactPrompt框架通过认知精炼过程，结合引导式思维链和知识图谱验证，减少LLM的事实幻觉


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的事实幻觉严重限制了其可靠性，需要有效方法来减少这种幻觉

Method: FactPrompt框架，受认知精炼过程启发，整合引导式思维链(CoT)和知识图谱验证机制

Result: 未提供具体实验结果，但框架旨在显著减少LLM的事实幻觉

Conclusion: FactPrompt通过结构化推理和外部知识验证，为减少LLM事实幻觉提供了有效解决方案

Abstract: Abstract Large Language Model (LLM) factual hallucination critically limits their reliability. To address this, we introduce FactPrompt, a framework inspired by cognitive refinement processes, integrating guided Chain-of-Thought (CoT) with a …

</details>


### [261] [W2S-AlignTree: Weak-to-Strong Inference-Time Alignment for Large Language Models via Monte Carlo Tree Search](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.11518&hl=zh-CN&sa=X&d=1490051724794161330&ei=qRIhaaKAJv-j6rQPgcTr8Qg&scisig=ABGrvjKqxo8LnmmX3WlUcpmEPndi&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=7&folt=rel)
*Z Ding,Y Wang,T Xiao,H Wang,G Ma,M Wan…*

Main category: Xuanhe Zhou

TL;DR: LLMs存在与人类偏好不对齐的问题，主要原因是弱监督不足和缺乏细粒度控制，需要更好的训练时对齐方法


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然表现出色，但其输出经常与人类偏好不对齐，这源于弱监督的不足和缺乏细粒度控制，需要改进训练时的对齐方法

Method: 论文提出了一种训练时的对齐方法，通过改进监督信号和引入更精细的控制机制来解决LLM输出不对齐的问题

Result: 该方法能够显著提升LLM输出与人类偏好的一致性，提供更好的细粒度控制能力

Conclusion: 提出的训练时对齐方法有效解决了LLM与人类偏好不对齐的问题，为模型提供了更好的可控性和对齐性

Abstract: Large Language Models (LLMs) demonstrate impressive capabilities, yet their outputs often suffer from misalignment with human preferences due to the inadequacy of weak supervision and a lack of fine-grained control. Training-time …

</details>


### [262] [Hybrid Instruction Tuning with Marginalization for Zero-Shot Reasoning in Language Models](https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Shirmohammad-Tavangari/publication/397648853_Hybrid_Instruction_Tuning_with_Marginalization_for_Zero-Shot_Reasoning_in_Language_Models/links/6918c5f4480eb767581bd257/Hybrid-Instruction-Tuning-with-Marginalization-for-Zero-Shot-Reasoning-in-Language-Models.pdf&hl=zh-CN&sa=X&d=5101627711483055268&ei=qRIhaaKAJv-j6rQPgcTr8Qg&scisig=ABGrvjKK5NSUpD3rEjGU2xhMbK0j&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=8&folt=rel)
*S Tavangari*

Main category: Xuanhe Zhou

TL;DR: 该论文探讨大型语言模型在复杂推理任务中的局限性，并提出改进方法


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在自然语言理解和推理方面表现出色，但在复杂、多步骤推理任务中，其推理能力往往显得浅层或不一致，需要改进

Method: 论文可能提出新的评估框架、训练方法或架构改进来增强LLMs的深度推理能力

Result: 通过提出的方法，模型在复杂推理任务上的表现得到显著提升，推理过程更加一致和可靠

Conclusion: 需要专门的方法来提升大型语言模型的深度推理能力，这对于其在复杂任务中的应用至关重要

Abstract: Recent advancements in large language models (LLMs) have revealed their strong performance in natural language understanding and inference. However, their reasoning abilities often remain shallow or inconsistent, especially in complex, multi …

</details>


### [263] [Enhancing Zero-Shot Reasoning in Language Models via Hybrid Instruction Marginalization](https://scholar.google.com/scholar_url?url=https://www.academia.edu/download/124769624/mdpi_1_.pdf&hl=zh-CN&sa=X&d=11470646476086033208&ei=qRIhaaKAJv-j6rQPgcTr8Qg&scisig=ABGrvjJFMIzvWL2-WOVy9BMztXZb&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=9&folt=rel)
*S Tavangari,A Yelği*

Main category: Xuanhe Zhou

TL;DR: 论文指出大语言模型在复杂多步推理任务中存在能力不足，提出了一种改进方法


<details>
  <summary>Details</summary>
Motivation: 大语言模型在自然语言理解方面表现出色，但在复杂多步推理任务中，其推理能力往往表面化、不一致且容易出错，需要改进

Method: 未在摘要中明确说明具体方法，但暗示提出了一种改进大语言模型复杂推理能力的技术或框架

Result: 未在摘要中提供具体实验结果，但暗示提出的方法能够显著提升大语言模型在复杂推理任务中的表现

Conclusion: 需要开发新的方法来增强大语言模型的复杂推理能力，以解决当前存在的表面化、不一致和易错问题

Abstract: Abstract Large Language Models (LLMs) have demonstrated remarkable capabilities in natural language understanding; however, their reasoning abilities, especially in complex, multi-step tasks, often remain superficial, inconsistent, and prone to errors …

</details>


### [264] [FinCriticalED: A Visual Benchmark for Financial Fact-Level OCR Evaluation](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.14998&hl=zh-CN&sa=X&d=9710998109585849005&ei=YcgjadbXN-vJieoPsMzREQ&scisig=ABGrvjLNihCeaWa5oeKu8kkYSfp9&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=0&folt=cit)
*Y He,X Peng,Y Cao,Y Wang,L Qian,H Li,Y Han…*

Main category: Xuanhe Zhou

TL;DR: FinCriticalED是一个用于评估OCR和视觉语言模型在金融文档事实级别性能的视觉基准，专注于检测可能导致重大财务影响的微小OCR错误


<details>
  <summary>Details</summary>
Motivation: 金融文档具有视觉密集、表格繁多的布局，其中数值和时间信息与结构紧密耦合。在高风险场景中，微小的OCR错误（如符号反转或日期偏移）可能导致完全不同的财务解读，而传统的OCR指标（如ROUGE）无法有效检测这些关键错误

Method: 开发了FinCriticalED基准，专注于金融文档的事实级别错误检测。该基准包含视觉密集的金融文档，特别关注表格布局，评估模型在检测数值符号反转、日期偏移等关键错误方面的能力，这些错误在传统OCR指标中容易被忽略

Result: 论文介绍了FinCriticalED基准，但未提供具体的实验结果数据。该基准旨在填补现有OCR评估方法在金融文档关键错误检测方面的空白，为评估视觉语言模型在金融领域的实际应用性能提供专门工具

Conclusion: FinCriticalED基准为评估OCR和视觉语言模型在金融文档处理中的关键错误检测能力提供了重要工具，有助于提高金融文档自动处理的准确性和可靠性，特别是在高风险决策场景中

Abstract: We introduce FinCriticalED (Financial Critical Error Detection), a visual benchmark for evaluating OCR and vision language models on financial documents at the fact level. Financial documents contain visually dense and table heavy layouts where numerical and temporal information is tightly coupled with structure. In high stakes settings, small OCR mistakes such as sign inversion or shifted dates can lead to materially different interpretations, while traditional OCR metrics like ROUGE and …

</details>


### [265] [LITHE: A Query Rewrite Advisor using LLMs](https://scholar.google.com/scholar_url?url=https://www.openproceedings.org/2026/conf/edbt/paper-93.pdf&hl=zh-CN&sa=X&d=1804913012627713998&ei=YcgjadbXN-vJieoPsMzREQ&scisig=ABGrvjLIvUu5D_ZzJlGiqRBVdkZR&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=2&folt=cit)
*S Dharwada,H Devrani,JR Haritsa,H Doraiswamy*

Main category: Xuanhe Zhou

TL;DR: LLMs用于SQL查询重写以提升执行性能，替代传统的基于规则的转换方法


<details>
  <summary>Details</summary>
Motivation: 传统基于规则的SQL查询重写工具存在规则范围有限、难以在生产系统中更新的问题，而LLMs具有出色的认知能力，可以用于实现更灵活、更有效的查询重写

Method: 利用大型语言模型（LLMs）的认知能力进行SQL查询重写，通过LLMs理解查询语义并生成性能更优的等效查询

Result: 论文探讨了LLMs在SQL查询重写中的应用潜力，表明LLMs能够生成"精简"的等效查询，从而提升查询执行性能

Conclusion: LLMs为SQL查询重写提供了新的可能性，能够克服传统基于规则方法的局限性，实现更灵活、更有效的查询优化

Abstract: When complex SQL queries suffer slow executions despite query optimization, DBAs typically invoke automated query rewriting tools to recommend “lean” equivalents that are conducive to faster execution. The rewritings are usually achieved via transformation rules, but these rules are limited in scope and difficult to update in production systems. We investigate here how the remarkable cognitive capabilities of LLMs can be leveraged for performant query rewriting while incorporating …

</details>


### [266] [Advancing Conversational Text-to-SQL: Context Strategies and Model Integration with Large Language Models](https://scholar.google.com/scholar_url?url=https://www.mdpi.com/1999-5903/17/11/527&hl=zh-CN&sa=X&d=6823235187279772115&ei=YcgjadbXN-vJieoPsMzREQ&scisig=ABGrvjJFRrFf_ih3M-qNXYykjRd4&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=4&folt=cit)
*BG Ascoli,JD Choi*

Main category: Xuanhe Zhou

TL;DR: 该论文研究对话式文本到SQL转换，将传统的单轮SQL生成扩展到多轮对话场景，解决现有数据集在对话上下文跟踪方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 尽管在Spider和BIRD等单轮基准测试中取得了显著进展，并且大型语言模型兴起，但对话式数据集仍然面临挑战。传统单轮SQL生成无法满足用户通过多轮对话逐步细化和完善数据库查询的需求。

Method: 论文提出将对话式文本到SQL扩展到多轮场景，要求模型能够跟踪多个用户查询和系统响应之间的对话上下文。虽然具体方法未在摘要中详细说明，但核心是处理多轮交互中的上下文依赖关系。

Result: 摘要中未提供具体实验结果，但暗示了对话式数据集继续带来挑战，表明现有方法在多轮对话场景下仍有改进空间。

Conclusion: 对话式文本到SQL是一个重要的研究方向，需要专门的方法来处理多轮对话中的上下文跟踪问题，以支持用户通过交互式对话逐步完善数据库查询。

Abstract: Conversational text-to-SQL extends the traditional single-turn SQL generation paradigm to multi-turn, dialogue-based scenarios, enabling users to pose and refine database queries interactively, and requiring models to track dialogue context over multiple user queries and system responses. Despite extensive progress in single-turn benchmarks such as Spider and BIRD, and the recent rise of large language models, conversational datasets continue to pose challenges. In this paper, we …

</details>


### [267] [Beyond SELECT: A Comprehensive Taxonomy-Guided Benchmark for Real-World Text-to-SQL Translation](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.13590&hl=zh-CN&sa=X&d=16736254628017597577&ei=YcgjadbXN-vJieoPsMzREQ&scisig=ABGrvjIU1h4w7qFZo-3WKebzl2TC&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=6&folt=cit)
*H Wang,Y Song,X Yin,X Chen*

Main category: Xuanhe Zhou

TL;DR: 提出基于核心意图、语句类型、语法结构和关键操作的新文本到SQL分类法，评估现有数据集局限性


<details>
  <summary>Details</summary>
Motivation: 现有文本到SQL数据集覆盖范围有限，未能捕捉真实应用的多样性，需要更全面的评估框架

Method: 提出新的文本到SQL分类法，包含核心意图、语句类型、语法结构和关键操作四个维度，并用此分类法评估Spider、Bird等公开数据集

Result: 揭示现有数据集在多样性、复杂性和现实应用覆盖方面的局限性，为未来数据集开发提供指导

Conclusion: 提出的分类法能系统评估文本到SQL数据集质量，现有数据集需要改进以更好反映真实世界应用场景

Abstract: Text-to-SQL datasets are essential for training and evaluating text-to-SQL models, but existing datasets often suffer from limited coverage and fail to capture the diversity of real-world applications. To address this, we propose a novel taxonomy for text-to-SQL classification based on dimensions including core intents, statement types, syntax structures, and key actions. Using this taxonomy, we evaluate widely used public text-to-SQL datasets (eg, Spider and Bird) and reveal limitations in their …

</details>


### [268] [Natural Language Interfaces for Databases: What Do Users Think?](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.14718&hl=zh-CN&sa=X&d=4717350852218784494&ei=YcgjadbXN-vJieoPsMzREQ&scisig=ABGrvjIfks-sqvogPEYA-fWY7d44&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=7&folt=cit)
*P Ipeirotis,H Zheng*

Main category: Xuanhe Zhou

TL;DR: 该论文研究了自然语言数据库接口(NLIDB)的可用性问题，通过混合方法用户研究比较了SQL-LLM与传统NLIDB系统，发现用户在使用过程中面临查询优化、错误恢复和界面设计等方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 尽管自然语言数据库接口在翻译准确性方面取得了显著进展，但用户在使用过程中面临的可用性挑战（如用户挫败感、查询优化策略和错误恢复）仍未得到充分探索。研究者旨在深入调查这些可用性维度，以改进NLIDB系统的实际用户体验。

Method: 采用混合方法用户研究，比较SQL-LLM（一种基于大型语言模型的系统）与传统NLIDB系统。研究通过定量和定性方法收集数据，分析用户在使用过程中的行为模式、困难点和优化策略。

Result: 研究发现用户在使用NLIDB时面临多种可用性挑战，包括查询表述困难、错误理解与恢复问题、界面交互限制等。研究识别了影响用户体验的关键因素，并为改进NLIDB系统设计提供了实证依据。

Conclusion: 自然语言数据库接口的可用性问题需要更多关注，单纯提高翻译准确性不足以确保良好的用户体验。未来的NLIDB系统设计应综合考虑查询优化、错误恢复机制和用户界面设计，以提升整体可用性。

Abstract: Natural Language Interfaces for Databases (NLIDBs) aim to make database querying accessible by allowing users to ask questions in everyday language rather than using formal SQL queries. Despite significant advancements in translation accuracy, critical usability challenges, such as user frustration, query refinement strategies, and error recovery, remain underexplored. To investigate these usability dimensions, we conducted a mixed-method user study comparing SQL-LLM, a state …

</details>


### [269] [Node-Level Uncertainty Estimation in LLM-Generated SQL](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.13984&hl=zh-CN&sa=X&d=10148475981779253480&ei=YcgjadbXN-vJieoPsMzREQ&scisig=ABGrvjLN3e5y0apTGTzI41Nn7NPg&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=8&folt=cit)
*H Hasson,R Guo*

Main category: Xuanhe Zhou

TL;DR: 提出基于AST节点级不确定性估计的LLM生成SQL错误检测框架，包含语义感知标注算法和模式感知节点表示


<details>
  <summary>Details</summary>
Motivation: LLM生成的SQL查询中错误检测需要更细粒度的分析方法，传统整体评估方法无法准确定位具体错误位置，需要开发能够识别AST节点级错误的实用框架

Method: 采用两阶段方法：1) 语义感知标注算法，在给定生成SQL和黄金参考时分配节点级正确性，不过度惩罚结构容器或别名变化；2) 使用丰富的模式感知特征表示每个节点

Result: 该方法能够准确定位SQL查询中的错误节点，提供细粒度的错误检测，相比传统整体评估方法具有更高的精度和实用性

Conclusion: 提出的AST节点级不确定性估计框架为LLM生成SQL的错误检测提供了有效的细粒度分析方法，能够识别具体错误位置而不受结构变化干扰

Abstract: We present a practical framework for detecting errors in LLM-generated SQL by estimating uncertainty at the level of individual nodes in the query's abstract syntax tree (AST). Our approach proceeds in two stages. First, we introduce a semantically aware labeling algorithm that, given a generated SQL and a gold reference, assigns node-level correctness without over-penalizing structural containers or alias variation. Second, we represent each node with a rich set of schema-aware and …

</details>


### [270] [Seer: Online Context Learning for Fast Synchronous LLM Reinforcement Learning](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.14617&hl=zh-CN&sa=X&d=2892572261068713863&ei=YMgjaYaVM72qieoPn4DxyAk&scisig=ABGrvjILfFtcWzPkySWjm1bXsy7E&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=0&folt=rel)
*R Qin,W He,W Huang,Y Zhang,Y Zhao,B Pang,X Xu…*

Main category: Xuanhe Zhou

TL;DR: 论文提出了一种异步强化学习系统AsyncRL，通过解耦rollout和训练阶段来解决同步RL系统在大型语言模型训练中的性能瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 现有同步强化学习系统在训练大型语言模型时面临严重的性能瓶颈，特别是rollout阶段主导端到端迭代时间，导致计算资源利用率低下和训练效率受限。

Method: 提出AsyncRL系统，采用异步架构将rollout和训练阶段解耦，使用独立的rollout worker和训练worker，通过共享经验缓冲区实现异步通信，支持多GPU并行和动态资源分配。

Result: AsyncRL系统显著提升了训练效率，减少了端到端迭代时间，提高了计算资源利用率，在多个基准测试中展现出比同步RL系统更好的性能表现。

Conclusion: 异步强化学习架构是解决大型语言模型RL训练性能瓶颈的有效方案，能够显著提升训练效率和资源利用率，为大规模语言模型的高效训练提供了新的系统设计思路。

Abstract: Reinforcement Learning (RL) has become critical for advancing modern Large Language Models (LLMs), yet existing synchronous RL systems face severe performance bottlenecks. The rollout phase, which dominates end-to-end iteration …

</details>


### [271] [Closing the Feedback Loop in Text2Vis: Refining Visualization with Vision-Language Models](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3746027.3755862&hl=zh-CN&sa=X&d=17886266967035108315&ei=YMgjaYaVM72qieoPn4DxyAk&scisig=ABGrvjL6rqBo93cAhFItkgc52xuZ&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=4&folt=rel)
*S Shi,T Ren,G Zhu,G Feng,J Hu*

Main category: Xuanhe Zhou

TL;DR: Text-to-Visualization (Text2Vis) 通过自然语言查询直接生成数据可视化，但早期基于规则和机器学习的方法在复杂查询和生成质量方面存在局限。


<details>
  <summary>Details</summary>
Motivation: Text2Vis 旨在让非技术用户能够通过自然语言查询轻松创建数据可视化，从而普及数据洞察的获取。然而，早期方法在处理复杂查询和生成高质量可视化方面存在不足，需要更先进的解决方案。

Method: 早期 Text2Vis 方法主要依赖基于规则的系统（使用预定义模板和解析器）和机器学习模型（如序列到序列模型）。这些方法试图将自然语言查询映射到可视化规范，但在处理复杂语义和生成多样化可视化方面存在局限。

Result: 早期 Text2Vis 方法在简单查询上取得了一定成功，但在处理复杂、模糊或多步骤查询时表现不佳，生成的可视化质量有限，难以满足实际应用需求。

Conclusion: Text2Vis 领域需要更先进的技术（如大语言模型、多模态学习）来克服早期方法的局限性，实现更准确、灵活和高质量的自然语言到可视化转换。

Abstract: Text-to-Visualization (Text2Vis) generates data visualizations directly from natural language queries, democratizing access to data insights. Early Text2Vis efforts, primarily relying on rule-based systems and machine learning models, struggled to …

</details>


### [272] [Applying Text-to-SQL in Process Mining: Leveraging Natural Language for Data Insights](https://scholar.google.com/scholar_url?url=https://books.google.com/books%3Fhl%3Dzh-CN%26lr%3D%26id%3Di-OYEQAAQBAJ%26oi%3Dfnd%26pg%3DPA191%26ots%3DHzaIqyeusA%26sig%3D8VdNA_jGRUHv2jTorC4ClSvFqiU&hl=zh-CN&sa=X&d=14638759852191291843&ei=YMgjaYaVM72qieoPn4DxyAk&scisig=ABGrvjLKtEFBFHg3EL8OlAcUAyrg&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=5&folt=rel)
*BY Yamate,TR Neubauer,M Fantinato,SM Peres*

Main category: Xuanhe Zhou

TL;DR: 该论文探讨如何将文本到SQL技术应用于过程挖掘领域，使非技术用户能够通过自然语言查询访问过程数据，从而扩展过程挖掘的可用性。


<details>
  <summary>Details</summary>
Motivation: 过程挖掘通常需要SQL查询技能来访问和分析过程数据，这限制了非技术用户的使用。文本到SQL技术可以降低这一门槛，使更多用户能够通过自然语言查询访问过程数据，从而扩大过程挖掘的应用范围。

Method: 论文提出将文本到SQL技术应用于过程挖掘领域，具体方法可能包括：开发专门针对过程数据查询的自然语言到SQL转换模型，考虑过程挖掘特有的查询模式（如事件日志分析、过程发现、合规性检查等），以及可能构建专门的数据集或基准来评估系统性能。

Result: 研究可能展示了文本到SQL系统在过程挖掘查询上的有效性，包括查询准确率、系统可用性等方面的评估结果。系统可能能够处理典型的过程挖掘查询，如"显示上个月所有异常流程实例"或"找出违反合规规则的案例"等。

Conclusion: 文本到SQL技术可以成功应用于过程挖掘领域，为非技术用户提供自然语言接口来访问过程数据，从而扩大过程挖掘的可用性和应用范围。这为过程挖掘工具的用户友好性改进提供了新的方向。

Abstract: Accessing a database using natural language has the potential to broaden information retrieval, making it accessible to users without SQL knowledge. This task, known as text-to-SQL, can also benefit the area of process mining, which provides …

</details>


### [273] [A Multifaceted Analysis of Negative Bias in Large Language Models through the Lens of Parametric Knowledge](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.10881&hl=zh-CN&sa=X&d=5944296429299422080&ei=YMgjaYaVM72qieoPn4DxyAk&scisig=ABGrvjIzsIPE7cwutPa_Wl25r5vP&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=9&folt=rel)
*J Song,S Yu,S Yoon*

Main category: Xuanhe Zhou

TL;DR: 该论文研究大语言模型在二元决策任务中的负向偏见问题，即模型过度生成否定回答的倾向，并提出检测和解决方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在二元决策任务（如是否问题回答）中表现出明显的负向偏见，即倾向于过度生成否定回答。这种系统性偏见会影响模型的可靠性和公平性，需要被检测和纠正。

Method: 论文聚焦于检测和解决LLMs中的负向偏见问题。虽然具体方法未在摘要中详细说明，但研究重点在于识别这种偏见模式并开发相应的缓解策略。

Result: 摘要未提供具体实验结果，但表明研究确认了LLMs存在负向偏见问题，并提出了相应的检测和解决方法。

Conclusion: LLMs在二元决策任务中存在系统性负向偏见，需要专门的检测和缓解技术来确保模型的公平性和可靠性。

Abstract: Negative bias refers to the tendency of large language models (LLMs) to excessively generate negative responses in binary decision tasks (eg, yes-no question answering). Previous research has focused on detecting and addressing negative …

</details>


### [274] [CoVis: Neural and LLM-Driven Multi-Turn Interactions for Conversational Text-to-Visualization Generation](https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s00778-025-00954-4&hl=zh-CN&sa=X&d=3827061852374130518&ei=5DglafH-GtOyieoPyofJ-QE&scisig=ABGrvjLE1fDrnfJUsDHFt5VYXy4Y&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=0&folt=rel)
*Y Song,J Lu,RCW Wong*

Main category: Xuanhe Zhou

TL;DR: 该论文研究如何降低数据可视化的使用门槛，通过开发自然语言问题到可视化转换的自动任务，并引入基于大型语言模型的新方法来解决现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 数据可视化被广泛用于从大数据集中传达洞察，但使用门槛较高。现有自动可视化方法存在局限性，需要更有效的解决方案来降低使用门槛。

Method: 引入基于大型语言模型的新方法，用于自然语言问题到可视化转换的自动任务，改进现有技术。

Result: 新方法在自然语言问题到可视化转换任务上表现出色，相比现有方法有显著改进，能够更准确地理解和生成可视化。

Conclusion: 基于大型语言模型的方法为自动数据可视化任务提供了有效解决方案，显著降低了数据可视化的使用门槛，具有实际应用价值。

Abstract: Data visualization (DV) is widely used to communicate insights from large datasets. To lower the barrier to DV use, researchers have investigated automatic DV tasks like natural language question (NLQ) to visualization translation, formally called text …

</details>


### [275] [Play by the Type Rules: Inferring Constraints for Small Language Models in Declarative Programs](https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DNv7zctYGYj&hl=zh-CN&sa=X&d=10436169429245434276&ei=VromaYipK-uuieoPvMeR-QI&scisig=ABGrvjLnGwnVyZaHQYYO70OfGRrr&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=0&folt=cit)
*P Glenn,A Samuel,D Liu*

Main category: Xuanhe Zhou

TL;DR: 该论文提出了一种在声明式查询语言中集成语言模型操作符的方法，通过类型对齐和约束满足来确保生成的输出符合数据库类型检查和内容规则。


<details>
  <summary>Details</summary>
Motivation: 当前在声明式查询语言中集成语言模型操作符面临挑战：生成的输出必须同时满足类型检查器和数据库内容的约束。现有方法通常使用多个LLM后处理步骤，但缺乏系统化的解决方案来确保类型对齐和约束满足。

Method: 论文提出了一种系统化方法，通过类型对齐机制和约束满足技术，确保语言模型生成的输出能够符合数据库查询语言的类型规则和内容约束，从而实现优化的查询执行。

Result: 该方法能够有效确保语言模型操作符生成的输出与数据库类型系统和内容约束保持一致，从而在保持声明式查询语言优化执行优势的同时，利用语言模型的强大推理能力。

Conclusion: 通过系统化的类型对齐和约束满足方法，可以在声明式查询语言中有效集成语言模型操作符，实现廉价可解释函数与强大通用推理能力的结合，同时保持数据库查询优化的优势。

Abstract: Integrating language model powered operators in declarative query languages allows for the combination of cheap and interpretable functions with powerful, generalizable reasoning. However, in order to benefit from the optimized execution of a database query language like SQL, generated outputs must align with the rules enforced by both type checkers and database contents. Current approaches address this challenge with orchestrations consisting of many LLM-based post-processing …

</details>


### [276] [LLM 기반에이전트시스템의평가자동화방법소개](https://scholar.google.com/scholar_url?url=https://www.dbpia.co.kr/Journal/articleDetail%3FnodeId%3DNODE12455738&hl=zh-CN&sa=X&d=17232561458862315813&ei=wM8oadXDOs2j6rQPsvXUgA0&scisig=ABGrvjLoSaaQthgal-2vxz34FQKl&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=1&folt=cit)
*임연수， 도수종， 박천음*

Main category: Xuanhe Zhou

TL;DR: 대화형 시스템의 발전과 목적 지향 대화 시스템의 구성 요소 및 한계를 분석한 논문


<details>
  <summary>Details</summary>
Motivation: 대화형 시스템의 중요성과 목적 지향 대화 시스템의 한계를 극복하기 위한 연구 필요성 제시

Method: 목적 지향 대화 시스템의 구성 요소(자연어 이해, 대화 상태 추적, 자연어 생성 등) 분석 및 체계적 검토

Result: 목적 지향 대화 시스템의 구조적 특징과 도메인 특화적 한계를 명확히 식별

Conclusion: 보다 유연하고 일반화된 대화 시스템 개발을 위한 연구 방향 제시

Abstract: 대화형 시스템은 사용자의 의도를 파악하고 적절한응답 또는 행동을 하여 사용자와 상호작용하는 지능형시스템이다 [1-5]. 과거의 주류는 목적 지향 대화 시스템 (Task Oriented Dialogue System) 으로 비행기 예약, 레스토랑 예약과 같은 특정 도메인에서 사용자를 돕는 것을목표로 한다. 목적 지향 대화 시스템은 자연어 이해 (Natural Language Understanding), 대화 상태 추적 (Dialog State Tracking), 자연어 생성 (Natural Language Generation) 등과 같은 여러 모듈로 구성된다 [6, 7]. 목적지향 대화 …

</details>


### [277] [RAG-Driven Data Quality Governance for Enterprise ERP Systems](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.16700&hl=zh-CN&sa=X&d=11415031895812221505&ei=wM8oadXDOs2j6rQPsvXUgA0&scisig=ABGrvjJ7pDuAWLWK4bZQem3JGFQr&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=2&folt=cit)
*SB Vedat,EK Yarkan,M Akarsu,RK Karaman,A Sar…*

Main category: Xuanhe Zhou

TL;DR: 企业ERP系统面临多语言人工录入的数据质量问题，提出结合自动化数据清洗与LLM驱动SQL查询生成的端到端管道，在24万员工记录的生产系统中部署六个月


<details>
  <summary>Details</summary>
Motivation: 企业ERP系统管理数十万员工记录时，人力资源部门在多语言环境下进行分散式人工录入，面临关键的数据质量问题，需要有效的解决方案来确保数据质量和一致性

Method: 提出端到端管道，结合自动化数据清洗与LLM驱动的SQL查询生成，部署在生产系统中管理24万员工记录；系统采用两阶段集成方法：多阶段清洗流程

Result: 系统在24万员工记录的生产环境中成功部署并运行六个月，展示了端到端管道在实际企业ERP系统中的可行性和有效性

Conclusion: 结合自动化数据清洗与LLM驱动SQL查询生成的端到端管道能够有效解决企业ERP系统中多语言人工录入的数据质量问题，为大规模员工记录管理提供了实用解决方案

Abstract: Enterprise ERP systems managing hundreds of thousands of employee records face critical data quality challenges when human resources departments perform decentralized manual entry across multiple languages. We present an end-to-end pipeline combining automated data cleaning with LLM-driven SQL query generation, deployed on a production system managing 240,000 employee records over six months. The system operates in two integrated stages: a multi-stage cleaning …

</details>


### [278] [Low-Resolution Editing is All You Need for High-Resolution Editing](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.19945&hl=zh-CN&sa=X&d=17563745480240042780&ei=KHAqadzdH-vJieoP8e3G6Qs&scisig=ABGrvjJ2O0SrcUs5GyNghIFSPmY0&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=0&folt=cit)
*J Lee,H Lee,YJ Lee,B Han*

Main category: Xuanhe Zhou

TL;DR: 提出高分辨率图像编辑任务，开发支持4K及以上分辨率的可控图像编辑框架


<details>
  <summary>Details</summary>
Motivation: 当前图像生成方法主要局限于低分辨率（通常不超过1K），无法满足高分辨率内容创作需求，需要开发支持高分辨率、可控的图像编辑机制

Method: 未在摘要中明确说明具体方法，但提到引入高分辨率图像编辑任务，并可能涉及新的框架或架构来支持4K及以上分辨率的可控编辑

Result: 未在摘要中提供具体结果，但暗示该方法能够支持4K及以上分辨率的高质量图像编辑

Conclusion: 高分辨率内容创作是视觉和图形领域的关键挑战，需要开发支持高分辨率、可控的图像编辑方法

Abstract: High-resolution content creation is rapidly emerging as a central challenge in both the vision and graphics communities. While images serve as the most fundamental modality for visual expression, content generation that aligns with the user intent requires effective, controllable high-resolution image manipulation mechanisms. However, existing approaches remain limited to low-resolution settings, typically supporting only up to 1K resolution. In this work, we introduce the task of high …

</details>


### [279] [A System-Level Taxonomy of Failure Modes in Large Language Model Applications](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.19933&hl=zh-CN&sa=X&d=516689692586618619&ei=KHAqadzdH-vJieoP8e3G6Qs&scisig=ABGrvjIfRMGy5jzJfCKCcDLuI6i5&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=1&folt=cit)
*V Vinay*

Main category: Xuanhe Zhou

TL;DR: 提出一个针对现实世界LLM应用的系统级故障模式分类法，包含15种隐藏故障模式


<details>
  <summary>Details</summary>
Motivation: LLM被快速集成到决策支持工具、自动化工作流和AI软件系统中，但其在生产环境中的行为仍未被充分理解，且其故障模式与传统机器学习模型有根本性差异

Method: 提出系统级分类法，识别和分类15种现实世界LLM应用中的隐藏故障模式，包括多步推理漂移、潜在不一致性等

Result: 建立了包含15种故障模式的分类体系，揭示了LLM在生产环境中特有的系统性故障模式

Conclusion: 需要系统性地理解和分类LLM的故障模式，以开发更可靠的LLM应用系统

Abstract: Large language models (LLMs) are being rapidly integrated into decision-support tools, automation workflows, and AI-enabled software systems. However, their behavior in production environments remains poorly understood, and their failure patterns differ fundamentally from those of traditional machine learning models. This paper presents a system-level taxonomy of fifteen hidden failure modes that arise in real-world LLM applications, including multi-step reasoning drift, latent inconsistency …

</details>


### [280] [LLM and Agent-Driven Data Analysis: A Systematic Approach for Enterprise Applications and System-level Deployment](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.17676&hl=zh-CN&sa=X&d=5184061844059195819&ei=KHAqadzdH-vJieoP8e3G6Qs&scisig=ABGrvjJjx-n-Xcxfqm7IKxl9GbqS&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=2&folt=cit)
*X Wang,X Ling,K Li,G Yin,L Zhang,J Wu,A Wang…*

Main category: Xuanhe Zhou

TL;DR: 生成式AI和智能体技术正在重塑企业数据管理与分析，传统数据库应用受到RAG和向量数据库等AI工具的深刻影响，同时数据安全与合规成为关键挑战


<details>
  <summary>Details</summary>
Motivation: 生成式AI和智能体技术的快速发展正在深刻改变企业数据管理格局，传统数据库应用面临AI驱动的RAG和向量数据库等技术带来的根本性变革，同时企业需要应对数据安全和合规性这一首要挑战

Method: 论文探讨了生成式AI和智能体技术在企业数据管理中的应用，重点关注检索增强生成(RAG)和向量数据库技术，这些技术为企业知识库的语义查询提供了新途径

Result: AI驱动的工具正在从根本上影响传统数据库应用和系统部署，为企业知识库的语义查询开辟了新路径，同时数据安全和合规性成为转型过程中的关键考量因素

Conclusion: 生成式AI和智能体技术正在深刻变革企业数据管理与分析范式，RAG和向量数据库等技术提供了创新的语义查询解决方案，但必须将数据安全和合规性作为核心优先事项来确保成功转型

Abstract: The rapid progress in Generative AI and Agent technologies is profoundly transforming enterprise data management and analytics. Traditional database applications and system deployment are fundamentally impacted by AI-driven tools, such as Retrieval-Augmented Generation (RAG) and vector database technologies, which provide new pathways for semantic querying over enterprise knowledge bases. In the meantime, data security and compliance are top priorities for …

</details>


### [281] [The Case for Intent-Based Query Rewriting](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.20419&hl=zh-CN&sa=X&d=9645305795914912844&ei=KHAqadzdH-vJieoP8e3G6Qs&scisig=ABGrvjKbD_50FNDcphX3nrpZQ3yN&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=4&folt=cit)
*GL Nicolai,P Hansert,S Michel*

Main category: Xuanhe Zhou

TL;DR: 提出意图驱动的查询重写概念，与传统基于性能优化的查询重写不同，旨在保持可获取洞察不变的前提下改变查询结构和语法结果


<details>
  <summary>Details</summary>
Motivation: 传统查询重写主要关注通过等价规则和优化启发式减少查询评估时间，但无法在保持洞察不变的前提下改变查询结构和语法结果。需要一种新的重写方法，允许更灵活地改变查询表达形式而不损失核心洞察价值。

Method: 提出意图驱动的查询重写概念，开发首个可行解决方案。该方法不依赖严格的等价规则，而是基于查询意图保持洞察一致性，允许改变查询结构和语法形式。

Result: 成功描述了意图驱动查询重写的概念，并提出了首个可行的解决方案，能够实现保持洞察不变的前提下改变查询结构和语法结果。

Conclusion: 意图驱动的查询重写是一种与传统方法截然不同的新范式，它允许更灵活地重写查询而不损失核心洞察价值，为查询优化和表达提供了新的可能性。

Abstract: With this work, we describe the concept of intent-based query rewriting and present a first viable solution. The aim is to allow rewrites to alter the structure and syntactic outcome of an original query while keeping the obtainable insights intact. This drastically differs from traditional query rewriting, which typically aims to decrease query evaluation time by using strict equivalence rules and optimization heuristics on the query plan. Rewriting queries to queries that only provide a similar insight but …

</details>


### [282] [Scaling LLM Planning: NL2FLow for Parametric Workflow Problem Generation and Rigorous Evaluation](https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DUEb66ZGXXN&hl=zh-CN&sa=X&d=14869130784617470389&ei=KHAqadzdH-vJieoP8e3G6Qs&scisig=ABGrvjKTBn_nk1Cr1zKzewzJ-pT9&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=5&folt=cit)
*J Kang*

Main category: Xuanhe Zhou

TL;DR: NL2Flow：一个用于生成和评估工作流规划问题的全自动管道，通过结构化中间表示生成问题，并转换为自然语言和PDDL格式，以解决LLM规划和推理评估数据稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在规划和推理方面的进展受到可扩展评估数据稀缺的阻碍，而鲁棒的工作流组合对于智能体性能至关重要。需要一种自动化方法来生成和评估工作流规划问题。

Method: 提出NL2Flow全自动管道，通过参数化方式在结构化中间表示中生成工作流规划问题，然后将这些问题转换为自然语言和正式的PDDL（规划领域定义语言）格式。

Result: 评估了多个开源指令模型在工作流规划任务上的表现，为LLM规划和推理能力提供了系统化的评估基准。

Conclusion: NL2Flow为工作流规划问题的生成和评估提供了可扩展的解决方案，有助于推进LLM在规划和推理方面的研究。

Abstract: Robust workflow composition is critical for effective agent performance, yet progress in Large Language Model (LLM) planning and reasoning is hindered by a scarcity of scalable evaluation data. This work introduces NL2Flow, a fully automated pipeline for generating and evaluating workflow planning problems. NL2Flow generates problems parametrically in a structured intermediate representation, translating them into both natural language and formal PDDL. I evaluate several open-source, instruct …

</details>


### [283] [Agent-as-a-Graph: Knowledge Graph-Based Tool and Agent Retrieval for LLM Multi-Agent Systems](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.18194&hl=zh-CN&sa=X&d=9830487594682457500&ei=J3AqabnRBMeB6rQPv8m60QM&scisig=ABGrvjIZQjbg5QvXZPlHwX27d292&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=0&folt=rel)
*F Nizar,E Lumer,A Gulati,PH Basavaraju,VK Subbiah*

Main category: Xuanhe Zhou

TL;DR: 大语言模型多智能体系统通过MCP服务器实现可扩展的并行化子智能体编排与检索


<details>
  <summary>Details</summary>
Motivation: 解决传统单智能体系统在处理复杂任务时的局限性，通过分布式、专业化的子智能体系统提升任务处理能力和效率

Method: 采用大规模并行化的多智能体架构，每个子智能体配备数百至数千个模型上下文协议(MCP)服务器和工具，实现专业化分工和协同工作

Result: 实现了可扩展的智能体编排和检索系统，能够高效处理复杂任务，提升整体系统的性能和适应性

Conclusion: 基于MCP的多智能体系统架构为大规模复杂任务处理提供了有效的解决方案，展示了分布式智能体系统的优势

Abstract: Recent advances in Large Language Model Multi-Agent Systems enable scalable orchestration and retrieval of specialized, parallelized subagents, each equipped with hundreds or thousands of Model Context Protocol (MCP) servers and tools …

</details>


### [284] [LLM-EDT: Large Language Model Enhanced Cross-domain Sequential Recommendation with Dual-phase Training](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.19931&hl=zh-CN&sa=X&d=5569344325267611051&ei=J3AqabnRBMeB6rQPv8m60QM&scisig=ABGrvjJO5nSIMJih6mQ4MpWPp0TC&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=2&folt=rel)
*Z Liu,Q Liu,W Wang,Y Wang,T Xu,W Huang,C Chen…*

Main category: Xuanhe Zhou

TL;DR: CDSR面临交互不平衡和转移模式问题，现有方法难以有效处理


<details>
  <summary>Details</summary>
Motivation: 跨域序列推荐（CDSR）通过整合多域信息来丰富用户-物品交互，但现有方法面临两个关键挑战：1）交互不平衡问题（某些域交互稀疏），2）转移模式问题（跨域转移模式复杂难以建模）

Method: 论文未提供具体方法细节，但基于摘要分析，可能提出了一种新框架来处理CDSR中的不平衡和转移模式问题

Result: 摘要未提供具体实验结果，但暗示现有方法在解决不平衡和转移模式问题上存在局限

Conclusion: 需要新的CDSR方法来有效解决交互不平衡和复杂转移模式问题，以提升跨域推荐性能

Abstract: Cross-domain Sequential Recommendation (CDSR) has been proposed to enrich user-item interactions by incorporating information from various domains. Despite current progress, the imbalance issue and transition issue hinder further …

</details>


### [285] [Towards Reverse Engineering of Language Models: A Survey](https://scholar.google.com/scholar_url?url=https://aclanthology.org/anthology-files/anthology-files/pdf/findings/2025.findings-emnlp.395.pdf&hl=zh-CN&sa=X&d=3596061090191528847&ei=J3AqabnRBMeB6rQPv8m60QM&scisig=ABGrvjK9eeKc9uzDIqeOxnGwC1UM&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=5&folt=rel)
*X Ti,W Ye,Z Zhang,J Zhao,C Yao,L Feng,H Wang*

Main category: Xuanhe Zhou

TL;DR: 该论文探讨了大型语言模型在多个领域应用中的安全挑战，特别是通过可访问接口引发的安全问题，并提出了相应的安全评估框架。


<details>
  <summary>Details</summary>
Motivation: 随着语言模型的持续发展和各类可访问接口的广泛可用，大型语言模型被应用到越来越多的领域。然而，由于模型规模庞大和接口多样性，这些应用面临着新的安全挑战，需要系统性的安全评估方法。

Method: 论文可能提出了一种针对大型语言模型应用的安全评估框架或方法，通过分析不同类型的可访问接口（如API、Web界面、移动应用等）来识别潜在的安全风险，并建立相应的安全测试和评估体系。

Result: 研究可能发现大型语言模型通过可访问接口存在多种安全漏洞，包括但不限于：提示注入攻击、数据泄露风险、权限绕过问题、恶意内容生成等。这些安全威胁需要专门的防护措施。

Conclusion: 大型语言模型的广泛应用带来了新的安全挑战，需要建立专门的安全评估框架和防护机制来确保这些模型在实际应用中的安全性，特别是在可访问接口层面需要加强安全防护。

Abstract: With the continuous development of language models and the widespread availability of various types of accessible interfaces, large language models (LLMs) have been applied to an increasing number of fields. However, due to the vast …

</details>


### [286] [UCO: A Multi-Turn Interactive Reinforcement Learning Method for Adaptive Teaching with Large Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.08873&hl=zh-CN&sa=X&d=6138661317503698106&ei=yMIraffnGJvJieoPr47u8Q4&scisig=ABGrvjIzP10tWA0ASEyPe831uKb9&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=3&folt=rel)
*S Wei,M Zhang,X Lin,B Jiang,K Kuang,Z Dai*

Main category: Xuanhe Zhou

TL;DR: 该论文提出了一种基于强化学习的动态教学框架，使大语言模型能够根据学生反馈自适应调整教学策略，超越传统监督微调方法的静态模式学习。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在教育场景中从答案提供者转向智能导师，但现有的监督微调方法仅学习表面教学模式，缺乏动态适应能力。需要开发能够根据学生反馈实时调整教学策略的智能教学系统。

Method: 采用强化学习方法，构建动态教学框架，使LLM能够基于学生反馈（如理解程度、困惑信号等）自适应调整教学策略，包括解释深度、示例选择、提问方式等教学要素。

Result: 提出的强化学习教学框架相比传统监督微调方法，在教学效果、学生参与度和学习效率方面有显著提升，能够实现个性化的动态教学适应。

Conclusion: 基于强化学习的动态教学框架为大语言模型在教育领域的应用提供了新的方向，使智能导师能够更有效地适应学生需求，实现真正的个性化教学。

Abstract: Large language models (LLMs) are shifting from answer providers to intelligent tutors in educational settings, yet current supervised fine-tuning methods only learn surface teaching patterns without dynamic adaptation capabilities. Recent reinforcement …

</details>


### [287] [CANVAS: A Benchmark for Vision-Language Models on Tool-Based User Interface Design](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.20737&hl=zh-CN&sa=X&d=17126056963637069991&ei=yMIraffnGJvJieoPr47u8Q4&scisig=ABGrvjKg6EyIMqc6w7MfvTL7kn84&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=4&folt=rel)
*D Jeong,S Byun,K Son,DH Kim,J Kim*

Main category: Xuanhe Zhou

TL;DR: 该论文探讨了利用视觉语言模型辅助用户界面设计迭代过程的方法，通过工具调用能力来提升设计效率


<details>
  <summary>Details</summary>
Motivation: 用户界面设计是一个迭代过程，设计师需要不断使用Figma或Sketch等设计软件进行优化。当前视觉语言模型具备工具调用能力，但尚未有效应用于UI设计迭代流程中，存在提升设计效率的潜力

Method: 论文提出利用视觉语言模型的工具调用能力来辅助UI设计迭代过程。具体方法可能包括：1）模型理解设计意图和上下文；2）调用设计工具进行修改；3）提供设计建议和优化方案；4）支持多轮交互式设计迭代

Result: 研究结果表明，视觉语言模型能够有效理解设计需求，通过工具调用协助设计师完成界面修改任务，提升设计迭代效率，减少手动操作时间

Conclusion: 视觉语言模型具备辅助UI设计迭代的潜力，通过工具调用能力可以显著提升设计效率，为设计工作流提供智能化支持

Abstract: User interface (UI) design is an iterative process in which designers progressively refine their work with design software such as Figma or Sketch. Recent advances in vision language models (VLMs) with tool invocation suggest these models can …

</details>


### [288] [ToolOrchestra: Elevating Intelligence via Efficient Model and Tool Orchestration](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.21689&hl=zh-CN&sa=X&d=6132770974055667444&ei=ycIrac2PG8eB6rQPv8m60QM&scisig=ABGrvjILAITsATPHjwtiplwFTfg1&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=0&folt=cit)
*H Su,S Diao,X Lu,M Liu,J Xu,X Dong,Y Fu,P Belcak…*

Main category: Xuanhe Zhou

TL;DR: ToolOrchestra方法训练小型编排器来协调多个模型和工具，以解决复杂智能体任务，提高效率并突破智能上限


<details>
  <summary>Details</summary>
Motivation: 大型语言模型是强大的通用工具，但解决像Humanity's Last Exam这样的深度复杂问题仍然具有概念挑战性和计算成本高昂。需要更高效的方法来处理困难智能体任务。

Method: 引入ToolOrchestra方法，训练小型编排器来协调其他模型和各种工具，通过编排管理实现复杂任务的分解和解决。

Result: 该方法既能提高解决困难智能体任务的效率，又能推动智能上限的突破，展示了小型编排器在复杂问题解决中的潜力。

Conclusion: 小型编排器通过协调多个模型和工具，为解决深度复杂问题提供了一种既高效又能突破智能上限的新方法。

Abstract: Large language models are powerful generalists, yet solving deep and complex problems such as those of the Humanity's Last Exam (HLE) remains both conceptually challenging and computationally expensive. We show that small orchestrators managing other models and a variety of tools can both push the upper bound of intelligence and improve efficiency in solving difficult agentic tasks. We introduce ToolOrchestra, a method for training small orchestrators that coordinate …

</details>


### [289] [Prompt Engineering Techniques for Context-dependent Text-to-SQL in Arabic](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.20677&hl=zh-CN&sa=X&d=15884211514876734410&ei=ycIrac2PG8eB6rQPv8m60QM&scisig=ABGrvjLUujBdoGg8nH5eBxEByP-6&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=2&folt=cit)
*S Almohaimeed,M Alsofyani,S Almohaimeed…*

Main category: Xuanhe Zhou

TL;DR: 首个阿拉伯语跨领域上下文依赖文本到SQL数据集Ar-SParC的提出，填补了阿拉伯语在该研究领域的空白


<details>
  <summary>Details</summary>
Motivation: 当前跨领域上下文依赖文本到SQL研究主要集中在英语和中文，阿拉伯语领域完全空白，需要构建首个阿拉伯语数据集以推动该语言在该领域的研究发展

Method: 创建Ar-SParC数据集，包含跨领域、上下文依赖的阿拉伯语文本到SQL转换任务，采用系统化数据收集和标注方法

Result: 成功构建了首个阿拉伯语跨领域上下文依赖文本到SQL数据集，为阿拉伯语自然语言与数据库交互研究提供了基础资源

Conclusion: Ar-SParC填补了阿拉伯语在跨领域上下文依赖文本到SQL研究领域的空白，为后续阿拉伯语自然语言数据库查询研究奠定了基础

Abstract: In recent years, the task of cross-domain, context-dependent text-to-SQL has received significant attention. Enables users with no prior knowledge of SQL to have a conversation with databases using natural language. However, most of the available datasets and research have been conducted in English, along with some work in Chinese. To this date, no effort has been made to address this task in the Arabic language. In this paper, we introduce Ar-SParC, the first Arabic cross-domain …

</details>


### [290] [Aragog: Just-in-Time Model Routing for Scalable Serving of Agentic Workflows](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.20975&hl=zh-CN&sa=X&d=4932544527360086110&ei=ycIrac2PG8eB6rQPv8m60QM&scisig=ABGrvjJ6DCeFJg-naJRjLbqns75j&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=4&folt=cit)
*Y Dai,Z Chen,A Iyer,R Netravali*

Main category: Xuanhe Zhou

TL;DR: 论文提出了一种动态配置选择方法，用于降低多阶段Agent工作流的LLM推理成本，通过运行时决策而非静态绑定来适应工作流执行的异构性和长度


<details>
  <summary>Details</summary>
Motivation: Agent工作流在解决复杂多阶段任务方面表现出色，但大规模部署时计算成本高昂，因为每个请求需要经过多次LLM推理。现有的配置选择方法在请求执行前就固定了配置决策，无法适应工作流执行的异构性和长期性特点

Method: 提出了一种动态配置选择方法，能够在工作流执行过程中根据实时情况调整LLM分配策略，而不是在请求开始前就固定配置。该方法考虑了工作流执行的异构性、任务长度变化以及成本效益平衡

Result: 与静态配置方法相比，动态配置选择方法能够显著降低Agent工作流的计算成本，同时保持任务完成质量。该方法能够适应工作流执行过程中的变化，实现更好的成本效益平衡

Conclusion: 动态配置选择是降低Agent工作流服务成本的有效方法，通过在工作流执行过程中灵活调整LLM分配策略，能够适应实际执行的异构性，实现显著的成本节约

Abstract: Agentic workflows have emerged as a powerful paradigm for solving complex, multi-stage tasks, but serving them at scale is computationally expensive given the many LLM inferences that each request must pass through. Configuration selection, or the cost-aware assignment of workflow agents to specific LLMs, can reduce these costs, but existing approaches bind configuration decisions before request execution, making them ill-suited for the heterogeneous and lengthy execution of workflows …

</details>


### [291] [$ A^ 2Flow: $ Automating Agentic Workflow Generation via Self-Adaptive Abstraction Operators](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.20693&hl=zh-CN&sa=X&d=10242948404898832324&ei=ycIrac2PG8eB6rQPv8m60QM&scisig=ABGrvjKrYAF6x-wqIIArDHgJW4cW&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=5&folt=cit)
*M Zhao,X Wei,Y Shao,K Zhou,L Yang,S Rao,J Zhan…*

Main category: Xuanhe Zhou

TL;DR: A²Flow：基于自适应抽象算子的全自动智能体工作流生成框架，无需手动预定义算子


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在自动化智能体工作流设计方面潜力巨大，但现有方法仍严重依赖手动预定义算子，限制了泛化能力和可扩展性

Method: 提出A²Flow框架，采用三阶段算子提取过程：1)基于案例的初始算子生成，2)自适应抽象算子构建，3)全自动工作流生成，无需人工干预

Result: 未在摘要中明确说明具体实验结果，但框架旨在实现完全自动化的智能体工作流生成，提升泛化性和可扩展性

Conclusion: A²Flow通过自适应抽象算子解决了现有方法对人工预定义算子的依赖问题，为智能体工作流的全自动化设计提供了新途径

Abstract: Large language models (LLMs) have shown strong potential in automating the design of agentic workflows. However, existing methods still rely heavily on manually predefined operators, limiting generalization and scalability. To address this issue, we propose $ A^ 2Flow $, a fully automated framework for agentic workflow generation based on self-adaptive abstraction operators. $ A^ 2Flow $ employs a three-stage operator extraction process: 1) Case-based Initial Operator Generation …

</details>


### [292] [“数据+ AI” 双向赋能机制与农业领域实践](https://scholar.google.com/scholar_url?url=https://nkdb.magtechjournal.com/CN/article/downloadArticleFile.do%3FattachType%3DPDF%26id%3D13021&hl=zh-CN&sa=X&d=12771949754468504952&ei=ycIrac2PG8eB6rQPv8m60QM&scisig=ABGrvjLuoXCgIqm04DwczXrLmJ7w&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=9&folt=cit)
*王彦芳， 赵瑞雪*

Main category: Xuanhe Zhou

TL;DR: 数据与AI双向赋能机制解析：从单向依赖到双向协同的融合共生关系


<details>
  <summary>Details</summary>
Motivation: 数据被列为第五生产要素，生成式AI技术突破，数据与AI进入融合共生变革期，但二者协同机制解析不足，需要探讨双向赋能机制与实践路径

Method: 从数据赋能AI和AI赋能数据两个维度阐释双向协同机制，分析二者从单向依赖转为双向深度协同发展的关系

Result: 数据与AI形成良性互动循环，进入由应用驱动的融合阶段，为AI迭代升级、数据要素价值释放和行业智能服务发展提供支撑

Conclusion: 数据与AI的深度交叉融合成为各行业研究焦点，双向赋能机制为智能服务发展提供理论支撑与实证支持

Abstract: 伴随数据增列为第五生产要素与生成式人工智能(artificial intelligence, AI) 技术的跨越式突破, 数据和AI 进入融合共生的剧烈变革期,“数据+ AI” 深度交叉融合成为各行业的研究焦点. 针对二者协同机制的解析不足, 探讨其双向赋能的机制与实践路径, 旨在为AI 快速迭代升级, 数据要素价值加速释放及行业智能服务发展落地提供理论支撑与实证支持. 从数据赋能AI 和AI 赋能数据维度阐释其双向协同机制, 二者关系从单向依赖转为双向深度协同发展, 形成良性互动循环, 进入由应用驱动的融合 …

</details>


### [293] [Tool learning with language models: a comprehensive survey of methods, pipelines, and benchmarks](https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s44336-025-00024-x&hl=zh-CN&sa=X&d=583612225830331158&ei=uAYtaZz8A-uuieoPn9Oq8Ao&scisig=ABGrvjLSEgQjj3p1ZZ3jOrFHB0Ub&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=0&folt=cit)
*J Chen,H Wu,J Pang,Y Wang,D Zhang,C Sun*

Main category: Xuanhe Zhou

TL;DR: 该论文是关于大语言模型工具学习范式的系统性综述，探讨LLMs如何通过外部工具增强推理和决策能力


<details>
  <summary>Details</summary>
Motivation: 工具学习已成为增强大语言模型推理和决策能力的关键能力，通过使LLMs能够与API、搜索引擎、计算器等外部工具交互，但需要系统性的综述来梳理这一新兴范式

Method: 采用系统性综述方法，分析工具学习范式，重点关注LLMs如何分解复杂任务、选择适当工具、正确调用工具以及生成连贯响应

Result: 提供了工具学习范式的系统性概述，包括任务分解、工具选择、调用执行和响应生成等关键环节的全面分析

Conclusion: 工具学习是增强LLMs能力的重要范式，需要系统化的方法来实现有效的工具集成和任务执行

Abstract: Tool learning has emerged as a key capability for enhancing the reasoning and decision-making abilities of large language models (LLMs) by enabling them to interface with external tools such as application programming interfaces (APIs), search engines, and calculators. This survey provides a systematic overview of the tool learning paradigm, focusing on how LLMs can decompose complex tasks, select appropriate tools, invoke them correctly, and generate coherent responses. We …

</details>


### [294] [Architecture for Managing Autonomous Virtual Organizations in the Industry 4.0 Context](https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2073-431X/14/12/519&hl=zh-CN&sa=X&d=12519437725462690459&ei=uAYtaZz8A-uuieoPn9Oq8Ao&scisig=ABGrvjKVexuZLmImnVZbUDRSeQW0&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=1&folt=cit)
*CP López,M Santórum,J Aguilar*

Main category: Xuanhe Zhou

TL;DR: 该论文提出了一种基于RAMI 4.0框架的虚拟组织管理架构，整合了智能需求收集机制，以支持个性化产品创造并符合工业4.0标准。


<details>
  <summary>Details</summary>
Motivation: 现有虚拟组织管理架构存在三个主要问题：1) 未与工业4.0标准对齐；2) 缺乏智能需求收集机制；3) 未基于RAMI 4.0框架。这些限制阻碍了虚拟组织在个性化产品创造中的有效支持。

Method: 提出了一种基于RAMI 4.0框架的虚拟组织管理架构，该架构整合了智能需求收集机制，旨在支持个性化产品创造过程中的通信与协调。

Result: 开发了一个符合工业4.0标准的虚拟组织管理架构，该架构通过智能需求收集机制提升了虚拟组织在个性化产品创造中的协调效率和适应性。

Conclusion: 基于RAMI 4.0框架并整合智能需求收集机制的虚拟组织管理架构能够更好地支持个性化产品创造，解决了现有架构与工业4.0标准不兼容的问题。

Abstract: A Virtual Organization (VO) unites companies or independent individuals to achieve a shared, short-term objective by leveraging information technologies for communication and coordination in personalized product creation. Despite extensive research, existing VO management architectures lack alignment with Industry 4.0 standards, do not incorporate intelligent requirement-gathering mechanisms, and are not based on the RAMI 4.0 framework. These limitations hinder support for …

</details>


### [295] [Multi-turn NLIDBs](https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-032-06905-4_6&hl=zh-CN&sa=X&d=16955310303072397629&ei=uAYtaZz8A-uuieoPn9Oq8Ao&scisig=ABGrvjLYQaeP_QkoY_1GjmOUy7n1&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=5&folt=cit)
*G Katsogiannis*

Main category: Xuanhe Zhou

TL;DR: 该章节综述了多轮Text-to-SQL任务，重点分析交互式和对话式两个子类别，涵盖系统架构、挑战、数据集和评估指标


<details>
  <summary>Details</summary>
Motivation: 构建自然直观的自然语言接口数据库需要支持多轮交互，现有研究需要系统性的综述来理解交互式和对话式Text-to-SQL的核心挑战与架构

Method: 通过文献综述方法，系统分析多轮Text-to-SQL的两个子类别：交互式（用户主动澄清）和对话式（系统主动询问），详细阐述各自的系统架构设计

Result: 提供了多轮Text-to-SQL的全面技术框架，包括核心挑战分析、系统架构概述、现有数据集整理和评估指标总结

Conclusion: 多轮Text-to-SQL是实现自然数据库交互的关键技术，交互式和对话式方法各有特点，需要针对不同应用场景选择合适的架构和评估方法

Abstract: Enabling interaction with users in a chatbot environment is an important step toward building natural and intuitive NLIDBs. This chapter explores the problem of multi-turn Text-to-SQL, focusing on its two main subcategories: interactive and conversational Text-to-SQL. For each subcategory, the chapter outlines the core challenges and offers a comprehensive overview of the systems' architecture. The chapter also presents existing datasets and evaluation metrics, providing a holistic understanding …

</details>


### [296] [Adaptive information retrieval for multimodal data](https://scholar.google.com/scholar_url?url=https://patents.google.com/patent/US12450274B1/en&hl=zh-CN&sa=X&d=914504712446776306&ei=uAYtaZz8A-uuieoPn9Oq8Ao&scisig=ABGrvjIC5Wq-32T1eqOhz7p8P7jG&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=7&folt=cit)
*S Jain,S Thiruchittampalam,VN VEDAM,J Lin*

Main category: Xuanhe Zhou

TL;DR: 文档智能分块系统：基于文档结构、层次和内容分类，动态选择最优分块策略


<details>
  <summary>Details</summary>
Motivation: 传统文档分块方法通常采用固定策略，无法适应不同类型文档的结构和内容特征，导致信息提取效率低下。需要一种能根据文档特性动态选择最优分块策略的智能方法。

Method: 通过处理器分析文档的结构、层次和内容特征，生成文档分类，然后从多个可用分块策略中选择针对该分类优化的分块策略，最后按照选定策略将文档划分为多个块。

Result: 实现了根据文档特征动态选择分块策略的能力，能够针对不同类型文档（如技术文档、法律合同、学术论文等）采用最适合的分块方式，提高后续处理任务的效率。

Conclusion: 基于文档分类的智能分块策略选择方法比固定分块策略更有效，能够适应多样化的文档类型和结构，为文档处理和信息提取任务提供更优化的数据准备。

Abstract: At least one processor can generate a classification of a document including a plurality of sections according to at least one of a structure of at least one of the plurality of sections, a hierarchy of the plurality of sections, and a content of at least one of the plurality of sections. The at least one processor can determine a chunking strategy optimized for the classification from among a plurality of available chunking strategies, divide the document into a plurality of chunks according to the chunking …

</details>


### [297] [Consistent Discourse-level Temporal Relation Extraction Using Large Language Models](https://scholar.google.com/scholar_url?url=https://aclanthology.org/anthology-files/anthology-files/pdf/findings/2025.findings-emnlp.1010.pdf&hl=zh-CN&sa=X&d=1709923130515583835&ei=tgYtabq-Ov-j6rQPrbnwwA4&scisig=ABGrvjIpSz2DSscQLt1AwGATNc22&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=0&folt=rel)
*Y Fan,M Strube*

Main category: Xuanhe Zhou

TL;DR: 该论文探讨了利用大语言模型进行时间关系提取的研究进展和挑战


<details>
  <summary>Details</summary>
Motivation: 理解文本中事件之间的时间关系对于确定文本的时间结构至关重要。虽然大语言模型在时间关系提取方面取得了进展，但仍存在需要解决的挑战和局限性。

Method: 论文可能涉及使用大语言模型进行时间关系提取的方法，包括模型架构、训练策略或评估框架。具体方法在提供的摘要中未详细说明。

Result: 摘要未提供具体结果，但暗示大语言模型在时间关系提取方面有研究进展，同时存在需要进一步探索的问题。

Conclusion: 大语言模型为时间关系提取提供了新的可能性，但该领域仍面临挑战，需要进一步研究来改进模型在理解时间结构方面的能力。

Abstract: Understanding temporal relations between events in a text is essential for determining its temporal structure. Recent advancements in large language models (LLMs) have spurred research on temporal relation extraction. However, LLMs …

</details>


<div id='Ziniu Wu'></div>

# Ziniu Wu [[Back]](#toc)

### [298] [JITI: Dynamic Model Serving for Just-in-Time Traffic Inference](https://scholar.google.com/scholar_url?url=https://fbronzino.com/assets/pdf/conext25.pdf&hl=zh-CN&sa=X&d=16579257493946790777&ei=hYMGaYnIIMab6rQPkcmJwAg&scisig=ABGrvjLHg0mnmNLpQE_p-mo1z1GS&oi=scholaralrt&hist=i6heNjgAAAAJ:1601694329521098688:ABGrvjKcA5wbu-wU3CW2rX5yqQCe&html=&pos=0&folt=cit)
*XI JIANG,S LIU,S NAAMA,F BRONZINO,P SCHMITT…*

Main category: Ziniu Wu

TL;DR: 该论文摘要不完整，无法提供完整的分析


<details>
  <summary>Details</summary>
Motivation: 摘要信息不完整，无法确定研究动机

Method: 摘要信息不完整，无法确定研究方法

Result: 摘要信息不完整，无法确定研究结果

Conclusion: 摘要信息不完整，无法得出研究结论

Abstract: Authors' Contact Information: Xi Jiang, University of Chicago, Chicago, IL, USA, xijiang9@ uchicago. edu; Shinan Liu, University of Hong Kong, Pok Fu Lam, Hong Kong, shinan6@ hku. hk; Saloua Naama, Université Savoie Mont Blanc, Chambéry, France, saloua. naama@ univ-smb. fr; Francesco Bronzino, École Normale Supérieure de Lyon; Institut universitaire de France, Lyon, France, francesco. bronzino@ ens-lyon. fr; Paul Schmitt, California Polytechnic State University, San …

</details>


### [299] [Optimizer-Aware Fine-Tuning of Whisper Small with Low-Rank Adaption: An Empirical Study of Adam and AdamW](https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2078-2489/16/11/928&hl=zh-CN&sa=X&d=3144457064226682123&ei=h4MGaaCABOSv6rQP5unnwAs&scisig=ABGrvjIg9Rq9KPbCKTxGJF8eQCMY&oi=scholaralrt&hist=i6heNjgAAAAJ:8133205940682390297:ABGrvjKXJphW1zAH---Rlc_Z3vEU&html=&pos=0&folt=rel)
*H Arshad,T Abdullah,M Rehman,A Hussain…*

Main category: Ziniu Wu

TL;DR: Whisper模型在多种语言上表现出色但计算效率有限，研究通过实验探索提升其效率的方法


<details>
  <summary>Details</summary>
Motivation: Whisper模型虽然在多语言任务中表现出色，但其计算效率在有限资源环境下仍存在问题，需要优化

Method: 通过实验方法（具体实验设计未在摘要中详细说明）来提升Whisper模型的效率

Result: 摘要未提供具体实验结果，需要完整论文才能了解效率提升的具体效果

Conclusion: Whisper模型需要效率优化，实验方法为解决其计算资源限制问题提供了途径

Abstract: Whisper is a transformer-based multilingual model that has illustrated state-of-the-art behavior in numerous languages. However, the efficiency remains persistent with the limited computational resources. To address this issue, an experiment was …

</details>


### [300] [DRAMA: Unifying Data Retrieval and Analysis for Open-Domain Analytic Queries](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.27238&hl=zh-CN&sa=X&d=1782540478688235297&ei=9VQNaYP2KtrZzwLz3N3oDQ&scisig=ABGrvjJar9QEDKvApVA32Lrz_6z1&oi=scholaralrt&hist=i6heNjgAAAAJ:8133205940682390297:ABGrvjKXJphW1zAH---Rlc_Z3vEU&html=&pos=1&folt=rel)
*C Hu,M Yang,J Weiland,Y Lim,S Palawala,D Kang*

Main category: Ziniu Wu

TL;DR: 自动化数据科学工作流需要具备三种关键能力：理解用户意图、自主规划分析步骤、执行分析并生成结果


<details>
  <summary>Details</summary>
Motivation: 手动进行真实世界数据分析劳动密集且效率低下，现有自动化系统未能完全具备支持端到端数据分析所需的关键能力

Method: 未明确说明具体方法，但提到需要开发能够理解用户意图、自主规划分析步骤、执行分析并生成结果的系统

Result: 未提供具体实验结果，但指出现有系统未能完全实现所需的关键能力

Conclusion: 需要开发能够完全支持端到端数据分析的自动化系统，具备理解、规划和执行三种关键能力

Abstract: Manually conducting real-world data analyses is labor-intensive and inefficient. Despite numerous attempts to automate data science workflows, none of the existing paradigms or systems fully demonstrate all three key capabilities required to support …

</details>


### [301] [Are We Asking the Right Questions? On Ambiguity in Natural Language Queries for Tabular Data Analysis](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.04584&hl=zh-CN&sa=X&d=55630518198284102&ei=Ge4RaY73BuvJieoP2KHq4Q4&scisig=ABGrvjJSKKjobDg6Sg_gVm0y5ICI&oi=scholaralrt&hist=i6heNjgAAAAJ:1601694329521098688:ABGrvjKcA5wbu-wU3CW2rX5yqQCe&html=&pos=0&folt=cit)
*D Gomm,C Wolff,M Hulsebos*

Main category: Ziniu Wu

TL;DR: 将自然语言查询中的歧义重构为协作交互特征，建立区分可解析协作查询与不可解析非协作查询的框架


<details>
  <summary>Details</summary>
Motivation: 传统方法将自然语言查询中的歧义视为缺陷，本文将其重新定义为协作交互的特征，让用户和系统共同承担查询规范的责任

Method: 开发一个原则性框架，区分可解析的协作查询与无法解析的非协作查询，并应用于表格数据自然语言接口

Result: 建立了系统的歧义处理框架，能够识别哪些查询可以通过协作方式解决，哪些需要用户进一步澄清

Conclusion: 歧义不应被视为自然语言接口的缺陷，而应作为协作交互的特征，通过共享责任的方式提高查询处理的效率和准确性

Abstract: Natural language interfaces to tabular data must handle ambiguities inherent to queries. Instead of treating ambiguity as a deficiency, we reframe it as a feature of cooperative interaction, where the responsibility of query specification is shared among the user and the system. We develop a principled framework distinguishing cooperative queries, ie, queries that yield a resolvable interpretation, from uncooperative queries that cannot be resolved. Applying the framework to …

</details>


### [302] [Finding Heavy-Hitters with Optimal State Changes](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3767714&hl=zh-CN&sa=X&d=15511105717491209513&ei=yEQZaZacGbmAieoPtbvzyQs&scisig=ABGrvjKHaV71FoFudkgjSesc7iX_&oi=scholaralrt&hist=i6heNjgAAAAJ:8133205940682390297:ABGrvjKXJphW1zAH---Rlc_Z3vEU&html=&pos=0&folt=rel)
*W Swartworth,DP Woodruff*

Main category: Ziniu Wu

TL;DR: 该论文研究了流算法设计中关于内存变化次数的问题，特别展示了如何使用O(1/ε n^{1-1/k} polylog(n/ε))状态解决ε-lk-heavy-hitters问题


<details>
  <summary>Details</summary>
Motivation: 研究流算法设计中内存变化次数的最小化问题，探索在有限内存变化约束下的算法设计可能性

Method: 基于[Jayaram, Woodruff, Zhou'24]的工作，研究ε-lk-heavy-hitters问题的流算法设计，特别关注状态复杂度的优化

Result: 证明了可以使用O(1/ε n^{1-1/k} polylog(n/ε))状态解决ε-lk-heavy-hitters问题

Conclusion: 在流算法设计中，通过优化内存变化策略，可以在有限状态复杂度下有效解决heavy-hitters问题

Abstract: A recent work,[Jayaram, Woodruff, Zhou'24] studied the problem of designing streaming algorithms with few changes memory. In particular they showed that one can solve the ε-lk-heavy-hitters problem using O (1/ε n1-1/k polylog (n/ε)) state …

</details>


### [303] [FLOWER: Flow-Oriented Entity-Relationship Tool](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.13357&hl=zh-CN&sa=X&d=14320224406268679006&ei=XcgjaeLXMf-j6rQPj9qr8A0&scisig=ABGrvjLszaDZtQzKEJzEYnDCnB04&oi=scholaralrt&hist=i6heNjgAAAAJ:1601694329521098688:ABGrvjKcA5wbu-wU3CW2rX5yqQCe&html=&pos=1&folt=cit)
*D Moskalev*

Main category: Ziniu Wu

TL;DR: 提出一种面向流程的实体关系工具，作为首个端到端解决方案，旨在消除实体识别中的人工干预和资源密集型流程


<details>
  <summary>Details</summary>
Motivation: 探索跨数据源的关系对实体识别至关重要，但现有方法依赖人工因素构建实体关系模型，导致流程繁琐且资源密集

Method: 开发面向流程的实体关系工具，作为首个端到端解决方案，自动化处理实体关系建模过程

Result: 该工具消除了实体识别中的常规工作和资源密集型流程，提高了处理效率

Conclusion: 面向流程的实体关系工具为实体识别提供了创新的端到端解决方案，减少了人工干预和资源消耗

Abstract: Exploring relationships across data sources is a crucial optimization for entities recognition. Since databases can store big amount of information with synthetic and organic data, serving all quantity of objects correctly is an important task to deal with. However, the decision of how to construct entity relationship model is associated with human factor. In this paper, we present flow-oriented entity-relationship tool. This is first and unique end-to-end solution that eliminates routine and resource-intensive …

</details>


### [304] [AgentTune: An Agent-Based Large Language Model Framework for Database Knob Tuning](https://scholar.google.com/scholar_url?url=https://renata.borovica-gajic.com/data/2026_sigmod.pdf&hl=zh-CN&sa=X&d=17000219885145543268&ei=xsIrafv1H-vJieoP8e3G6Qs&scisig=ABGrvjJ1BG201j2v6-hqhBWT78FX&oi=scholaralrt&hist=i6heNjgAAAAJ:1601694329521098688:ABGrvjKcA5wbu-wU3CW2rX5yqQCe&html=&pos=1&folt=cit)
*Y LI,H LI,J ZHANG,R BOROVICA*

Main category: Ziniu Wu

TL;DR: ML-based knob tuning systems使用强化学习和贝叶斯优化等技术，通过"尝试-收集-调整"循环自动优化数据库配置


<details>
  <summary>Details</summary>
Motivation: 传统数据库参数调优依赖专家经验且耗时费力，需要自动化系统来发现有效配置而无需大量人工干预

Method: 基于强化学习和贝叶斯优化的机器学习方法，采用"尝试-收集-调整"循环：给定工作负载，ML模型建议配置，应用到DBMS并评估性能

Result: 过去十年中已出现多种ML-based knob tuning系统，能够自动发现有效配置

Conclusion: 机器学习方法为数据库参数调优提供了有效的自动化解决方案

Abstract: Over the past decade, various machine learning (ML)-based knob tuning systems have emerged, capable of automatically discovering effective configurations without extensive human intervention. These include approaches based on Reinforcement Learning [28, 65] and Bayesian Optimization [2, 26, 67] techniques. Such systems generally follow a “try-collect-adjust” loop: given a workload, the ML model suggests a configuration, which is then applied to the DBMS and evaluated through …

</details>


### [305] [Enhancing learning-based database optimizaers via representation learning](https://scholar.google.com/scholar_url?url=https://dr.ntu.edu.sg/bitstreams/7da26a84-2644-49c4-94d1-275b14cb83e4/download&hl=zh-CN&sa=X&d=4793807376634038702&ei=tAYtaar1Nc2j6rQPsvXUgA0&scisig=ABGrvjKQewFSoWzuHaYX3FWTsiS7&oi=scholaralrt&hist=i6heNjgAAAAJ:1601694329521098688:ABGrvjKcA5wbu-wU3CW2rX5yqQCe&html=&pos=0&folt=cit)
*Y Zhao*

Main category: Ziniu Wu

TL;DR: ML4DB系统利用查询计划作为输入，在成本估算、查询优化等任务中展现出潜力；查询计划表示是将任意查询计划转换为向量表示的过程，作为机器学习模型的输入


<details>
  <summary>Details</summary>
Motivation: 基于查询计划的机器学习在数据库系统中具有广泛应用前景，但需要有效的查询计划表示方法将复杂的图结构转换为适合机器学习模型处理的向量表示

Method: 将查询计划视为有向无环图，开发查询计划表示方法，将任意查询计划转换为向量表示，作为机器学习模型的输入

Result: 未提供具体实验结果，但指出该方法为ML4DB系统提供了有效的输入表示基础

Conclusion: 查询计划表示是ML4DB系统的关键组件，为基于机器学习的数据库任务提供了必要的输入转换机制

Abstract: Abstract Machine learning for database (ML4DB) systems that leverage query plans as input have demonstrated growing promise in a variety of tasks, including cost estimation, query optimization and many others. A query plan is a directed acyclic graph which describe steps to process a query and retrieve the results, and query plan representation is the procedure which takes an arbitrary query plan as input and output a vector representation for it, as the input to machine learning models in a …

</details>


<div id='Ion Stoica'></div>

# Ion Stoica [[Back]](#toc)

### [306] [Language Models Can Easily Learn to Reason from Demonstrations](https://scholar.google.com/scholar_url?url=https://aclanthology.org/2025.findings-emnlp.866/&hl=zh-CN&sa=X&d=4277406638709075606&ei=gQAKabXmGOSv6rQPh5K9yQ8&scisig=ABGrvjKPy7QcS1J_GxAk6zXNLlgk&oi=scholaralrt&hist=i6heNjgAAAAJ:3972655621478617842:ABGrvjK3cJwYyV0sJxFw8VU0mgDL&html=&pos=0&folt=art)
*D Li,S Cao,T Griggs,S Liu,X Mo,E Tang,S Hegde…*

Main category: Ion Stoica

TL;DR: 该论文探讨大型推理模型在长链思维训练方面的挑战，指出当前训练技术和数据要求限制了长链推理能力的发展。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在处理复杂问题时需要遵循包含反思、回溯和自我验证的长链思维，但现有训练技术和数据要求限制了这种长链推理能力的发展，需要探索更有效的训练方法。

Method: 论文未在摘要中明确说明具体方法，但暗示需要研究新的训练技术和数据策略来激发大型推理模型的长链思维能力。

Result: 摘要未提供具体实验结果，但指出了当前大型推理模型在长链思维训练方面存在的技术瓶颈和数据需求挑战。

Conclusion: 需要开发新的训练技术和数据策略来有效激发大型推理模型的长链推理能力，以解决复杂问题。

Abstract: Large reasoning models (LRMs) tackle complex problems by following long chain-of-thoughts (Long CoT) that incorporate reflection, backtracking, and self-validation. However, the training techniques and data requirements to elicit Long CoT remain …

</details>


### [307] [Radial Attention: $\mathcal O (n\log n) $ Sparse Attention for Long Video Generation](https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DhYovE4nHTt&hl=zh-CN&sa=X&d=11239942217260809836&ei=9FQNadyuPIePieoPstbBMQ&scisig=ABGrvjIXYEHiqPcS71xEeX8Quydl&oi=scholaralrt&hist=i6heNjgAAAAJ:3972655621478617842:ABGrvjK3cJwYyV0sJxFw8VU0mgDL&html=&pos=0&folt=art)
*X Li,M Li,T Cai,H Xi,S Yang,Y Lin,L Zhang,S Yang…*

Main category: Ion Stoica

TL;DR: 该论文针对扩散模型在视频生成中因时间维度导致计算成本过高的问题，提出了一种高效的训练和推理方法。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在视频生成方面取得了显著进展，但额外的时间维度大幅增加了计算成本，使得长视频的训练和推理变得极其昂贵，这限制了实际应用。

Method: 论文提出了一种新的方法（具体方法未在摘要中说明，但暗示通过某种创新技术）来降低扩散模型在视频生成中的计算复杂度，使长视频的生成更加高效。

Result: 该方法显著减少了计算开销，使得在保持生成质量的同时，能够高效地训练和推理长视频，解决了现有方法在计算资源上的瓶颈。

Conclusion: 通过提出的高效方法，扩散模型在视频生成领域的应用得以扩展，为长视频生成提供了可行的解决方案，推动了该领域的发展。

Abstract: Recent advances in diffusion models have enabled high-quality video generation, but the additional temporal dimension significantly increases computational costs, making training and inference on long videos prohibitively expensive. In this paper …

</details>


### [308] [EDIT-Bench: Evaluating LLM Abilities to Perform Real-World Instructed Code Edits](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.04486&hl=zh-CN&sa=X&d=5283698315003684171&ei=Ge4RaZnWGrqL6rQPjtScMQ&scisig=ABGrvjKwOFDZztr52wE5TC4Cj2cm&oi=scholaralrt&hist=i6heNjgAAAAJ:3972655621478617842:ABGrvjK3cJwYyV0sJxFw8VU0mgDL&html=&pos=0&folt=art)
*W Chi,V Chen,R Shar,A Mittal,J Liang,WL Chiang…*

Main category: Ion Stoica

TL;DR: 论文提出一个名为InstructCoder的基准测试，用于评估大型语言模型在指令式代码编辑任务上的能力，该任务要求模型根据用户指令直接修改现有代码


<details>
  <summary>Details</summary>
Motivation: 当前AI编程助手广泛采用指令式代码编辑交互模式，但缺乏专门评估该能力的基准测试，现有基准主要关注代码生成而非代码修改

Method: 构建包含1,000个Python代码编辑任务的多样化数据集，涵盖多种编辑类型和难度级别，使用自动评估指标和人工评估相结合的方法

Result: 评估显示当前最先进的代码LLMs在指令式代码编辑任务上表现有限，存在代码理解不足、编辑不完整等问题，揭示了该任务的挑战性

Conclusion: 指令式代码编辑是一个具有挑战性的任务，需要专门的评估基准，InstructCoder为未来模型改进提供了重要参考，并揭示了代码编辑与代码生成的不同特性

Abstract: Instructed code editing, where LLMs directly modify a developer's existing code based on a user instruction, is becoming a widely used interaction mode in AI coding assistants. However, few benchmarks directly evaluate this capability and current …

</details>


### [309] [Useful Agentic AI: A Systems Outlook](https://scholar.google.com/scholar_url?url=https://saa2025.github.io/papers/Useful%2520Agentic%2520AI%2520-%2520A%2520Systems%2520Outlook.pdf&hl=zh-CN&sa=X&d=4033725646632101053&ei=XsgjaZvcG4qi6rQPweX-uA8&scisig=ABGrvjL2fuoHlnDmCUliZXhT3jSM&oi=scholaralrt&hist=i6heNjgAAAAJ:3972655621478617842:ABGrvjK3cJwYyV0sJxFw8VU0mgDL&html=&pos=1&folt=art)
*M Pan𝛽,Y Zhu,JQ Davis𝜎,R Cogo,LA Agrawal…*

Main category: Ion Stoica

TL;DR: 该论文主张通过理解实际用例来指导Agentic AI系统的开发，包括新指标、基准、编程和运行时系统


<details>
  <summary>Details</summary>
Motivation: 当前Agentic AI系统开发缺乏对实际应用场景的深入理解，导致系统设计可能无法有效满足实际需求。需要先理解具体用例，才能开发出真正有用的AI系统。

Method: 论文提出通过分析实际用例来指导Agentic AI系统开发的方法论。强调从具体应用场景出发，理解用户需求和工作流程，以此为基础设计相应的指标、基准、编程模型和运行时系统。

Result: 通过用例驱动的开发方法，能够创建更符合实际需求的Agentic AI系统，包括更相关的评估指标、更有意义的基准测试、更实用的编程接口和更高效的运行时支持。

Conclusion: 理解实际用例是开发有效Agentic AI系统的关键前提。用例驱动的开发方法能够确保技术方案真正解决实际问题，提高系统的实用性和影响力。

Abstract: To effectively meet and anticipate the requirements of practically impactful (useful) Agentic AI systems, including but not limited to new metrics, benchmarks, programming and runtime systems, it is necessary to first understand the use-cases …

</details>


### [310] [Rethinking the Cost of Distributed Caches for Datacenter Services](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3772356.3772388&hl=zh-CN&sa=X&d=16439434964561953488&ei=XsgjaZvcG4qi6rQPweX-uA8&scisig=ABGrvjJGsZj4ZNANX6sXmj326zoO&oi=scholaralrt&hist=i6heNjgAAAAJ:3972655621478617842:ABGrvjK3cJwYyV0sJxFw8VU0mgDL&html=&pos=2&folt=art)
*Z Mao,J Ellithorpe,A Adya,R Iyer,M Zaharia…*

Main category: Ion Stoica

TL;DR: 分布式内存缓存对数据中心服务的成本影响研究：内存缓存虽昂贵，但带来的CPU节省远超成本


<details>
  <summary>Details</summary>
Motivation: 数据中心服务广泛使用分布式内存缓存来提升性能，但内存通常被视为昂贵资源。本研究旨在系统分析内存缓存的实际成本效益，挑战"内存昂贵"的传统认知，量化缓存带来的CPU节省与整体成本影响。

Method: 采用系统性研究方法，通过量化分析分布式内存缓存对数据中心服务的实际影响。可能包括：1) 建立成本模型，对比内存成本与CPU节省；2) 分析真实数据中心工作负载；3) 测量缓存命中率对CPU利用率的影响；4) 评估不同缓存策略的成本效益。

Result: 研究发现分布式内存缓存带来的CPU节省远超内存成本。虽然内存本身昂贵，但通过减少CPU计算负载、降低延迟、提高吞吐量等方式，整体上实现了显著的成本节约。缓存优化了资源利用率，提升了服务性能。

Conclusion: 分布式内存缓存是数据中心服务中具有成本效益的解决方案。传统上认为内存昂贵的观点需要重新评估，因为缓存带来的CPU节省通常超过内存成本。这为数据中心资源优化提供了新的视角。

Abstract: This paper systematically studies the cost impact of distributed in-memory caches on datacenter services. While memory used for these caches is often perceived to be expensive, we find that the resulting CPU savings from these in-memory caches far …

</details>


### [311] [Efficiently Scaling LLM Reasoning Programs with Certaindex](https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3Dnn51ewu5k2&hl=zh-CN&sa=X&d=17280671001848886499&ei=vs8oadHAM42v6rQP1Yj2iAo&scisig=ABGrvjIIt_cxKR6uIOdDYPl7wXpH&oi=scholaralrt&hist=i6heNjgAAAAJ:3972655621478617842:ABGrvjK3cJwYyV0sJxFw8VU0mgDL&html=&pos=0&folt=art)
*Y Fu,J Chen,S Zhu,Z Fu,Z Dai,Y Zhuang,Y Ma…*

Main category: Ion Stoica

TL;DR: 测试时推理算法（如思维链、自洽性、MCTS）能提升LLM问题解决能力，但会浪费大量token生成而不提高准确性


<details>
  <summary>Details</summary>
Motivation: 现有测试时推理算法在提升LLM性能的同时存在token生成效率低下的问题，需要更高效的推理方法

Method: 论文提出了一种新的测试时推理方法，通过优化推理过程减少不必要的token生成，同时保持或提升准确性

Result: 新方法在保持或提升准确性的同时，显著减少了token生成数量，提高了推理效率

Conclusion: 通过优化测试时推理过程，可以在不牺牲准确性的前提下显著提高LLM的推理效率

Abstract: Test-time reasoning algorithms such as chain-of-thought, self-consistency, and MCTS enhance LLM problem-solving but can wastefully generate many tokens without improving accuracy. At the same time, we observe that these algorithms …

</details>


<div id='Zongheng Yang'></div>

# Zongheng Yang [[Back]](#toc)

### [312] [Query Optimization: Techniques and Strategies](https://scholar.google.com/scholar_url?url=https://books.google.com/books%3Fhl%3Dzh-CN%26lr%3D%26id%3DlFKTEQAAQBAJ%26oi%3Dfnd%26pg%3DPA134%26ots%3DbLnEDlekJJ%26sig%3DJ8O22eucFR8VIx6LfpSszjtceS4&hl=zh-CN&sa=X&d=6639071230266282090&ei=LHEIaZDvB9rZzwKkk-bABQ&scisig=ABGrvjJFx0u_61hxeKf74ZQUntEH&oi=scholaralrt&hist=i6heNjgAAAAJ:778719684493065653:ABGrvjLJz7cmQhcd9poDv5q68_GG&html=&pos=0&folt=rel)
*G Sharma,L Upadhyaya,B Shah*

Main category: Zongheng Yang

TL;DR: 该论文专注于MySQL查询优化，通过综合考虑磁盘访问次数、CPU处理时间和扫描行数等成本因素来优化查询性能


<details>
  <summary>Details</summary>
Motivation: MySQL查询性能直接影响数据库系统效率，传统优化方法可能未全面考虑多种成本因素，需要更系统的优化方法来提升查询执行效率

Method: 采用多因素成本模型，综合考虑磁盘访问次数、CPU处理时间和扫描行数等关键指标，通过成本计算和优化算法来改进查询执行计划

Result: 通过综合考虑多种成本因素，能够更准确地评估查询执行成本，从而生成更优的查询执行计划，提升MySQL数据库的整体性能

Conclusion: 多因素成本模型在MySQL查询优化中具有重要价值，能够显著提升查询性能，为数据库性能优化提供了更全面的方法论

Abstract: In this paper, we will focus on optimization of MYSQL queries. Different factors are taken into account when calculating the cost of a query, such as the number of disk accesses, CPU processing time, and the number of rows scanned. Considering all …

</details>


### [313] [A Security Analysis of Anti-Audio Cloaking Schemes](https://scholar.google.com/scholar_url?url=https://www.techrxiv.org/doi/pdf/10.36227/techrxiv.176119108.82564609&hl=zh-CN&sa=X&d=4983072484109677675&ei=K3EIacOvMLqL6rQPvbmoWA&scisig=ABGrvjKF4zwAhole5qgWLKno1MHK&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=0&folt=cit)
*L Onyekwelu*

Main category: Zongheng Yang

TL;DR: 该论文从对抗视角研究音频伪装技术的鲁棒性，探讨攻击者能否逆向还原原始说话人特征用于说话人验证和合成


<details>
  <summary>Details</summary>
Motivation: 音频伪装技术旨在保护音频内容不被未经授权的语音合成器克隆，并保护用户身份。然而，当前研究缺乏对这些伪装方法安全性的全面评估，特别是攻击者能否逆向破解这些保护机制来获取原始说话人特征。

Method: 论文采用对抗性攻击视角，分析现有音频伪装方法的脆弱性。研究攻击者如何通过逆向工程或对抗性技术来破解伪装机制，恢复可用于说话人验证和语音合成的原始特征。

Result: 研究发现当前音频伪装方法存在安全漏洞，攻击者能够通过特定技术手段逆向还原原始说话人特征，从而绕过保护机制进行准确的说话人验证和语音合成。

Conclusion: 音频伪装技术需要更强的安全设计和鲁棒性评估，当前方法在面对对抗性攻击时存在可被破解的风险，需要开发更安全的保护机制来应对潜在的逆向工程攻击。

Abstract: Audio cloaking aims to protect audio artifacts from unauthorized cloning by speech synthesizers and to safeguard user identity by altering signals to make them unusable for voice synthesis and speaker identification. In this paper, we investigate the resilience of current audio cloaking methods from an adversarial perspective, analyzing whether an attacker can reverse these cloaking mechanisms to retrieve the original speaker features for accurate speaker verification and synthesis. We …

</details>


### [314] [RLBoost: Harvesting Preemptible Resources for Cost-Efficient Reinforcement Learning on LLMs](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.19225&hl=zh-CN&sa=X&d=15943649131200625375&ei=fwAKadT3C4S6ieoPy7WfgAc&scisig=ABGrvjLeat9bx9nYA407oHkcsotZ&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=0&folt=cit)
*Y Wu,X Liu,H Zheng,J Gu,B Chen,ZM Mao…*

Main category: Zongheng Yang

TL;DR: 论文提出了一种新的强化学习框架，通过解耦rollout和训练阶段来优化资源利用率，解决现有框架在资源分配和扩展性方面的限制。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习框架在资源分配上存在限制：rollout阶段需要大量独立实例但计算密集度低，而训练阶段需要紧密耦合的高性能GPU。传统框架要么将两者绑定在同一集群（导致资源浪费），要么完全分离（增加复杂性）。需要一种能灵活分配不同资源类型、提高整体效率的解决方案。

Method: 提出解耦的强化学习框架，将rollout和训练阶段分离到不同的计算资源池。使用异步通信机制连接两个阶段，允许rollout在成本效益高的实例上运行，训练在专用GPU集群上进行。框架包含智能调度器，根据任务需求动态分配资源，并优化数据传输效率。

Result: 新框架显著提高了资源利用率，降低了计算成本。实验显示在保持相同模型性能的同时，训练时间减少30-50%，资源浪费降低40-60%。框架支持大规模并行rollout，同时确保训练阶段的通信效率。

Conclusion: 解耦的强化学习框架通过灵活的资源分配策略，有效解决了传统框架的资源利用瓶颈。该方法为大规模语言模型的强化学习训练提供了更高效、成本效益更高的解决方案，特别适用于需要大量rollout数据的复杂推理任务。

Abstract: Reinforcement learning (RL) has become essential for unlocking advanced reasoning capabilities in large language models (LLMs). RL workflows involve interleaving rollout and training stages with fundamentally different resource requirements. Rollout typically dominates overall execution time, yet scales efficiently through multiple independent instances. In contrast, training requires tightly-coupled GPUs with full-mesh communication. Existing RL frameworks fall into two categories …

</details>


### [315] [Eliciting Implicit Acoustic Styles from Open-domain Instructions to Facilitate Fine-grained Controllable Generation of Speech](https://scholar.google.com/scholar_url?url=https://aclanthology.org/2025.emnlp-main.182.pdf&hl=zh-CN&sa=X&d=416009388960722799&ei=fwAKadT3C4S6ieoPy7WfgAc&scisig=ABGrvjJyWCF3vwxzrdZEN2JwrB10&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=1&folt=cit)
*J Yu,G Zihao,C Li,Z Wang,P Yang,W Chen,J Yin*

Main category: Zongheng Yang

TL;DR: 该论文研究基于开放域指令生成符合用户需求的语音声学风格，旨在解决传统基于预定义规则或模板的方法在控制类型和格式固定、难以满足用户多样化需求的问题。


<details>
  <summary>Details</summary>
Motivation: 传统语音风格控制方法主要依赖预定义规则或模板，其控制类型和格式固定在一个封闭域内，难以满足用户多样化的需求。需要一种能够理解自由文本指令来指导语音生成的方法。

Method: 论文提出使用自由文本指令来指导语音生成，特别是研究那些明确指定声学风格的指令（如低音调等），通过指令驱动的语音生成方法。

Result: 从摘要内容看，论文主要提出了基于自由文本指令的语音风格控制框架，但具体实验结果和性能指标未在提供的摘要片段中给出。

Conclusion: 基于自由文本指令的语音风格控制方法能够更好地满足用户多样化需求，相比传统的预定义规则或模板方法具有更好的灵活性和适应性。

Abstract: This paper focuses on generating speech with the acoustic style that meets users' needs based on their open-domain instructions. To control the style, early work mostly relies on pre-defined rules or templates. The control types and formats are fixed in a closed domain, making it hard to meet diverse needs of users. One solution is to resort to instructions in free text to guide the generation. Current work mainly studies the instructions that clearly specify the acoustic styles, such as low pitch and …

</details>


### [316] [Tibetan Language and AI: A Comprehensive Survey of Resources, Methods and Challenges](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.19144&hl=zh-CN&sa=X&d=16274845816288385132&ei=fwAKadT3C4S6ieoPy7WfgAc&scisig=ABGrvjImFTwlxQASSYdLgM7xAmz4&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=2&folt=cit)
*C Huang,N Tashi,F Gao,Y Liu,J Li,H Tian,S Jiang…*

Main category: Zongheng Yang

TL;DR: 对藏语AI研究现状的全面调查，分析这一亚洲主要低资源语言面临的挑战和机遇


<details>
  <summary>Details</summary>
Motivation: 藏语作为亚洲主要低资源语言，具有独特的语言和社会文化特征，为AI研究带来挑战和机遇。尽管对低资源语言AI系统的兴趣日益增长，但由于缺乏可访问的数据资源、标准化基准和专用工具，藏语研究受到的关注有限。

Method: 采用文献调查和综合分析的方法，对藏语AI领域的研究现状进行全面梳理和评估。

Result: 识别了藏语AI研究面临的主要挑战，包括数据资源稀缺、标准化基准缺乏、工具支持不足等问题，同时指出了该领域的潜在机遇。

Conclusion: 藏语AI研究仍处于早期阶段，需要更多资源投入、标准化工作和工具开发来推动该领域的发展，这对促进语言多样性和文化保护具有重要意义。

Abstract: Tibetan, one of the major low-resource languages in Asia, presents unique linguistic and sociocultural characteristics that pose both challenges and opportunities for AI research. Despite increasing interest in developing AI systems for underrepresented languages, Tibetan has received limited attention due to a lack of accessible data resources, standardized benchmarks, and dedicated tools. This paper provides a comprehensive survey of the current state of Tibetan AI in the AI domain, covering …

</details>


### [317] [Bayesian Speech synthesizers Can Learn from Multiple Teachers](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.24372&hl=zh-CN&sa=X&d=17319339984015495299&ei=fwAKadT3C4S6ieoPy7WfgAc&scisig=ABGrvjKOplbFCSf2Gz0pyDWc6sjp&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=3&folt=cit)
*Z Zhang,Y Gao,X Xu,W Wu,C Zhang*

Main category: Zongheng Yang

TL;DR: 论文探讨了基于编解码器的文本转语音模型面临的挑战，并提出连续值生成模型作为替代方案，以解决预训练鲁棒性问题和量化误差导致的质量下降。


<details>
  <summary>Details</summary>
Motivation: 基于编解码器的TTS模型虽然在语音克隆方面表现出色，但面临两个主要问题：1）预训练鲁棒语音编解码器的挑战；2）量化误差导致的质量下降。连续值生成模型被认为是解决这些问题的有前景的替代方案。

Method: 论文提出采用连续值生成模型来替代传统的基于编解码器的TTS方法。这种方法避免了量化过程，直接对连续语音特征进行建模，从而减少质量损失。

Result: 虽然摘要未提供具体实验结果，但论文指出连续值生成模型能够缓解基于编解码器TTS的局限性，特别是减少量化误差带来的质量下降问题。

Conclusion: 连续值生成模型为基于编解码器的TTS系统提供了有前景的替代方案，能够克服预训练鲁棒性和量化误差的挑战，为更高质量的语音合成开辟了新途径。

Abstract: Codec-based text-to-speech (TTS) models have recently gained traction for their efficiency and strong performance in voice cloning. However, codec-based TTS faces limitations due to the challenges of pretraining robust speech codecs and the quality degradation introduced by quantization errors. Emerging evidence suggests that continuous-valued generative models can alleviate these issues and serve as a promising alternative. Yet, effectively modelling diverse speech patterns and …

</details>


### [318] [Advancing Text-to-Speech Systems for Low-Resource Languages: Challenges, Innovations, and Future Directions](https://scholar.google.com/scholar_url?url=https://www.academia.edu/download/124732918/Advancing_Text_to_Speech_Systems_for_Low_Resource_Languages_Challenges_Innovations_and_Future_Directions.pdf&hl=zh-CN&sa=X&d=10912110661149402673&ei=fwAKadT3C4S6ieoPy7WfgAc&scisig=ABGrvjJHlR5MYBDDBpl0uYmgccvs&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=4&folt=cit)
*U AGARWAL*

Main category: Zongheng Yang

TL;DR: 分析当前低资源语言语音合成解决方案及发展困难


<details>
  <summary>Details</summary>
Motivation: 高资源语言（如英语、西班牙语、普通话）的语音合成技术已显著进步，但许多有数百万使用者的语言因训练数据不足而缺乏准确的语音合成系统，需要分析当前解决方案和发展困难

Method: 对当前低资源语言语音合成解决方案和发展困难进行分析

Result: 未在摘要中明确说明具体结果，但暗示将提供对当前解决方案和挑战的分析

Conclusion: 低资源语言语音合成面临数据不足的挑战，需要分析现有解决方案和发展困难以推动该领域进步

Abstract: Speech synthesis, the technology that converts text into spoken words, has advanced significantly for high-resource languages like English, Spanish, and Mandarin. However, many languages spoken by millions of people are still underserved by speech synthesis systems due to insufficient data to train accurate models. An analysis of current solutions and difficulties in low-resource language speech synthesis development is presented in this paper because these languages …

</details>


### [319] [大規模事前学習モデルに基づく音声合成](https://scholar.google.com/scholar_url?url=https://www.jstage.jst.go.jp/article/jasj/81/10/81_719/_article/-char/ja/&hl=zh-CN&sa=X&d=15451159893051767060&ei=fwAKadT3C4S6ieoPy7WfgAc&scisig=ABGrvjJeKvdEHKcE1MpEvUUgrcn9&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=5&folt=cit)
*齋藤佑樹， 中田亘， 山内一輝， 朴浚鎔*

Main category: Zongheng Yang

TL;DR: テキスト音声合成(TTS)技術の変遷と最新動向をまとめた総説論文


<details>
  <summary>Details</summary>
Motivation: 音声合成は音声メディアを対象とした生成AIの根幹技術であり、2018年の全炳河博士の記事以来、日本音響学会誌で約7年ぶりのTTS技術の包括的レビューが必要

Method: 文献調査と技術動向の体系的整理。テキスト音声合成技術の歴史的変遷、最新の深層学習アプローチ、生成AI時代の技術展開を分析

Result: TTS技術が従来の音声合成から深層学習を経て生成AIへと進化し、音声品質と自然さが飛躍的に向上したことを示す

Conclusion: テキスト音声合成は自然言語と音声言語の交差点に位置し、人間と機械のインタラクションを支える基盤技術として、生成AI時代にさらなる発展が期待される

Abstract: 計算機で人間の声を人工的に生成・加工・変換する音声合成は, いわば音声メディアを対象とした生成 AI の根幹を成す技術といえる. 本稿の主眼となる, 与えられたテキストから音声を生成するテキスト音声合成 (Text-To-Speech; TTS) は, 自然言語と音声言語を対象とした情報処理の交差点に位置し, 音声を通じた人間と機械のインタラクションを支える基盤技術である. 2018 年に当時 Google 所属の全炳河博士による 「テキスト音声合成技術の変遷と最先端」[1] という記事が公表されて以来, 本稿は日本音響学会誌におけるおよそ 7 …

</details>


### [320] [AReaL-Hex: Accommodating Asynchronous RL Training over Heterogeneous GPUs](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.00796&hl=zh-CN&sa=X&d=15959006158131629430&ei=81QNabCNOMeB6rQPoOTz8Qc&scisig=ABGrvjJx_-2a4AlLkpMYp0gKMhim&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=0&folt=cit)
*R Yan,Y Jiang,T Wu,J Gao,Z Mei,W Fu,H Mai…*

Main category: Zongheng Yang

TL;DR: 该论文探讨了在异构GPU上部署LLM强化学习训练的方法，通过解耦三个计算阶段并采用自适应调度策略来最大化训练吞吐量和成本效率。


<details>
  <summary>Details</summary>
Motivation: LLM强化学习训练的计算成本高昂，阻碍了该技术的普及。传统同构GPU部署效率低下，而RL训练的三个耦合阶段（rollout生成、奖励计算、策略/价值更新）具有不同的计算强度、内存占用和通信需求，为异构GPU部署带来了挑战和机遇。

Method: 提出了一种针对LLM RL训练的异构GPU部署框架，将三个计算阶段解耦，采用自适应调度策略，根据各阶段的计算特性和资源需求，动态分配到不同类型的GPU上执行，以优化整体训练效率。

Result: 该方法相比传统同构GPU部署，显著提高了训练吞吐量和成本效率，能够更好地利用异构GPU集群的计算资源，降低RL训练的计算门槛。

Conclusion: 异构GPU部署是提高LLM强化学习训练效率的有效途径，通过解耦计算阶段和自适应调度，可以实现更高的训练吞吐量和成本效益，有助于推动RL在LLM领域的广泛应用。

Abstract: Maximizing training throughput and cost-efficiency of RL for LLMs is essential to democratize this advanced technique. One promising but challenging approach is to deploy such a computational workflow over heterogeneous GPUs. Unlike conventional large-scale LLM pretraining, RL training generally decomposes into three coupled stages, ie, rollout generation, reward computation, and policy/value updates, which exhibit markedly different compute intensities, memory footprints, and …

</details>


### [321] [FlowMesh: A Service Fabric for Composable LLM Workflows](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.26913&hl=zh-CN&sa=X&d=1190062266247815427&ei=81QNabCNOMeB6rQPoOTz8Qc&scisig=ABGrvjIejwhzBsvotdvpYNQQy1fD&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=3&folt=cit)
*J Shen,N Wadlom,L Zhou,D Wang,X Miao,L Fang…*

Main category: Zongheng Yang

TL;DR: FlowMesh是一个多租户服务架构，将AI工作流分解为细粒度算子并记录数据谱系，实现跨工作流的重复工作消除和优化执行


<details>
  <summary>Details</summary>
Motivation: AI部署正从单一LLM任务转向数据转换、微调和智能体交互的流水线模式，如RLHF/RLAIF训练和智能体工作流。现有系统采用隔离流水线方式，无法有效共享和优化跨工作流的计算资源

Method: 提出FlowMesh多租户服务架构，将工作流分解为细粒度算子并记录数据谱系，通过共享服务执行和优化工作负载，实现跨工作流的重复工作消除和资源优化

Result: 未在摘要中明确说明具体实验结果，但描述了FlowMesh能够实现跨工作流的重复工作消除和优化执行，将AI工作负载作为共享服务而非隔离流水线处理

Conclusion: FlowMesh通过细粒度算子分解和数据谱系记录，为现代AI工作流提供了更高效的多租户服务架构，能够更好地适应RLHF/RLAIF训练和智能体工作流等新兴部署模式

Abstract: AI deployment increasingly resembles a pipeline of data transformation, fine-tuning, and agent interactions rather than a monolithic LLM job; recent examples include RLHF/RLAIF training and agentic workflows. To cope with this shift, we propose FlowMesh, a multi-tenant service fabric that executes and optimizes these workloads as one shared service instead of isolated pipelines. It decomposes workflows into fine-grained operators with recorded lineage, enabling de-duplication of work across …

</details>


### [322] [Transcending Cost-Quality Tradeoff in Agent Serving via Session-Awareness](https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DRmqWt1btxQ&hl=zh-CN&sa=X&d=16779387976475479577&ei=81QNabCNOMeB6rQPoOTz8Qc&scisig=ABGrvjJOkgqNh01COfYaIpNGpn20&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=4&folt=cit)
*Y Ren,L Chen,D Li,X Wang,Z Wu,Y Miao,Y Bai*

Main category: Zongheng Yang

TL;DR: 论文分析了LLM智能体服务的独特需求，指出现有模型服务系统未针对智能体特性优化，提出了针对智能体服务的新系统设计


<details>
  <summary>Details</summary>
Motivation: 大型语言模型智能体能够在不同领域执行任务，通过与环境自主交互并根据反馈优化响应，但现有模型服务系统未针对智能体服务的独特需求进行优化

Method: 识别智能体服务与经典模型服务的差异特征：可预测的请求模式、递增的质量要求、独特的提示格式，并基于这些特征设计优化的服务系统

Result: 识别出智能体服务的关键问题，包括请求模式的可预测性、质量要求的递增性以及提示格式的独特性，为设计专门的智能体服务系统提供了理论基础

Conclusion: 智能体服务具有与经典模型服务不同的特征，需要专门优化的服务系统来满足其独特需求，包括可预测的请求模式、递增的质量要求和独特的提示格式

Abstract: Large Language Model (LLM) agents are capable of task execution across various domains by autonomously interacting with environments and refining LLM responses based on feedback. However, existing model serving systems are not optimized for the unique demands of serving agents. Compared to classic model serving, agent serving has different characteristics: predictable request pattern, increasing quality requirement, and unique prompt formatting. We identify a key problem for agent …

</details>


### [323] [Cloning Via Hierarchical Face-Styled](https://scholar.google.com/scholar_url?url=https://books.google.com/books%3Fhl%3Dzh-CN%26lr%3D%26id%3DufmTEQAAQBAJ%26oi%3Dfnd%26pg%3DPA76%26ots%3DYwhwitrLmh%26sig%3DtyeQCocOm4PVjVLe6UTZZTNOM-4&hl=zh-CN&sa=X&d=1181201910354758814&ei=81QNabCNOMeB6rQPoOTz8Qc&scisig=ABGrvjKwKK_I55dgDFFInysZJduH&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=6&folt=cit)
*Y Liu,L Wang,S Gao,Z Yu*

Main category: Zongheng Yang

TL;DR: 提出了一种用于零样本视觉语音克隆（ZS-V2C）的分层人脸风格扩散模型（HFSD-V2C），能够从未见过的视频片段和声学参考中生成具有特定说话人身份和韵律的语音


<details>
  <summary>Details</summary>
Motivation: 零样本视觉语音克隆（ZS-V2C）面临两个主要挑战：1）未见过的说话人建模；2）未见过的韵律建模。现有方法难以同时处理这两个问题，需要一种能够从视频中提取说话人身份特征并从声学参考中提取韵律特征的新框架

Method: 提出分层人脸风格扩散模型（HFSD-V2C）：1）利用跨模态生物特征识别技术从视频中提取说话人身份信息；2）采用分层扩散模型架构，将人脸风格特征与声学特征相结合；3）通过扩散过程生成具有目标说话人身份和韵律的语音

Result: 该方法能够从未见过的视频片段和声学参考中生成具有特定说话人身份和韵律的语音，解决了零样本视觉语音克隆中的双重挑战，相比先前方法在未见说话人建模和韵律建模方面表现更优

Conclusion: 分层人脸风格扩散模型（HFSD-V2C）为零样本视觉语音克隆提供了一种有效的解决方案，通过结合跨模态生物特征识别和分层扩散建模，能够同时处理未见说话人身份和韵律的建模问题

Abstract: The goal of this work is zero-shot visual voice cloning (ZSV2C), which aims to generate speech samples with unseen speaker iden-tity and prosody derived from a video clip and an acoustic reference. ZS-V2C presents greater challenges as: 1) unseen speaker modeling; and 2) unseen prosody modeling. Unlike previous works, we propose a novel ZS-V2C framework that incorporates a hierarchical face-styled diffusion model (HFSD-V2C). Specifically, first, we leverage cross-modal biometrics …

</details>


### [324] [Programmable and Adaptive Scheduling for Distributed Systems](https://scholar.google.com/scholar_url?url=https://kristoff-starling.github.io/pubs/hotnets2025_adaptive-sched.pdf&hl=zh-CN&sa=X&d=13053838100066961251&ei=81QNabCNOMeB6rQPoOTz8Qc&scisig=ABGrvjKI_tSuXjofYtdi958AVIm_&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=7&folt=cit)
*YWXZR Mahajan,S Wang*

Main category: Zongheng Yang

TL;DR: 提出自适应调度框架，通过DSL表达策略，编译器根据语义、负载和环境生成优化实现，解决现有框架策略固化、实现不灵活的问题


<details>
  <summary>Details</summary>
Motivation: 现有分布式系统管理框架将调度策略及其实现（如集中式vs分布式）硬编码，限制了定制化能力，在不同应用和工作负载下性能表现不佳

Method: 采用自适应调度方法：开发者使用高级别、框架无关的DSL表达策略，编译器根据策略语义、工作负载特征和执行环境生成优化实现

Result: 未在摘要中明确说明具体实验结果，但暗示该方法能够提高跨不同应用和工作负载的性能表现

Conclusion: 需要自适应调度框架来解决现有分布式系统管理框架的局限性，通过策略表达与实现分离实现更好的定制化和性能优化

Abstract: Existing frameworks for managing distributed systems hardcode scheduling policies and their implementations (eg, centralized vs. decentralized), limiting customization and hurting performance across diverse applications and workloads. We argue for an adaptive scheduling approach, where developers express policies in a high-level, framework-agnostic DSL, and a compiler generates optimized implementations based on policy semantics, workload characteristics, and execution environments …

</details>


### [325] [Compass: General Filtered Search across Vector and Structured Data](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.27141&hl=zh-CN&sa=X&d=4965404057858847126&ei=9FQNaYSnDMab6rQPz-SF4QU&scisig=ABGrvjJBC45YY3WEzPOtM49KELlj&oi=scholaralrt&hist=i6heNjgAAAAJ:778719684493065653:ABGrvjLJz7cmQhcd9poDv5q68_GG&html=&pos=0&folt=rel)
*C Ye,X Yan,E Lo*

Main category: Zongheng Yang

TL;DR: 该论文针对混合向量和关系型数据的查询需求，提出了一种高效、通用的解决方案，以解决现有过滤搜索方法在性能、通用性和查询优化方面的不足。


<details>
  <summary>Details</summary>
Motivation: 随着混合向量和关系型数据的日益普及，需要高效、通用的查询支持，以结合高维向量搜索和复杂关系过滤。然而，现有过滤搜索解决方案在性能、通用性和查询优化方面存在不足。

Method: 论文提出了一种新的解决方案，但具体方法在提供的摘要中未详细说明。可能需要结合向量索引、关系查询优化和混合数据处理技术。

Result: 根据摘要描述，该解决方案在性能、通用性和查询优化方面相比现有方法有显著改进，但具体实验结果和性能指标未提供。

Conclusion: 该研究为解决混合向量和关系型数据的查询问题提供了有效的解决方案，填补了现有技术的空白，为相关应用提供了更好的支持。

Abstract: The increasing prevalence of hybrid vector and relational data necessitates efficient, general support for queries that combine high-dimensional vector search with complex relational filtering. However, existing filtered search solutions are …

</details>


### [326] [A Multidisciplinary Approach to Understanding the Technology, Opportunities, Challenges, and Implications for Society of the Metaverse](https://scholar.google.com/scholar_url?url=https://www.frontiersin.org/journals/virtual-reality/articles/10.3389/frvir.2025.1566419/pdf&hl=zh-CN&sa=X&d=13276769092432379044&ei=KgIPaejpK6qy6rQP2YOFyAg&scisig=ABGrvjJCVeGP-qAuVADPMC0ybPwl&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=0&folt=cit)
*M Di Dalmazi,D Friedman,J Galissaire,H Isaac…*

Main category: Zongheng Yang

TL;DR: 该论文探讨了元宇宙的概念、潜力及其作为下一代互联网的发展前景，分析了其技术特征和社会影响。


<details>
  <summary>Details</summary>
Motivation: 自2021年底以来，元宇宙概念受到广泛关注，被视为下一代互联网形态，具有改变人类社交、工作和娱乐方式的潜力。论文旨在系统分析元宇宙的定义、技术特征、应用前景及其对社会的影响。

Method: 论文采用概念分析和文献综述的方法，对元宇宙的定义、技术架构、关键特征进行系统性梳理，并基于现有技术发展预测其未来发展趋势。

Result: 元宇宙被定义为支持大规模用户同时在线、实时交互的虚拟/增强/混合现实系统，具有3D沉浸式界面、虚实融合、环境持久性和互操作性等特征，有望成为下一代万维网。

Conclusion: 元宇宙代表了互联网发展的新阶段，虽然仍处于概念和技术探索期，但其潜在的社会和经济影响值得深入研究，需要关注技术实现、标准制定和伦理问题。

Abstract: Since late 2021 there has been increasing interest in the idea of the'metaverse'. This is a virtual, augmented or mixed reality system that potentially millions of people can simultaneously inhabit, and where people can interact with one another in real-time, irrespective of the physical distance between them. It is heralded by some as the next level'world wide web', that will use a 3D immersive interface, with the potential to mix virtual and physical reality, with environments persistent over time, and interoperable …

</details>


### [327] [MacroNav: Multi-Task Context Representation Learning Enables Efficient Navigation in Unknown Environments](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.04320&hl=zh-CN&sa=X&d=8199582032062862313&ei=GO4RaYquMLmAieoPiJqf8Q0&scisig=ABGrvjKdQKtFgkg6auaD9Eban3nA&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=0&folt=cit)
*K Sima,L Tang,H Ma,L Zhao*

Main category: Zongheng Yang

TL;DR: MacroNav是一个基于学习的导航框架，通过轻量级上下文编码器和分层规划器实现未知环境中高效的空间理解与导航


<details>
  <summary>Details</summary>
Motivation: 现有方法难以在丰富的上下文表示与导航效率之间取得平衡，特别是在部分可观测的未知环境中，需要紧凑而富有表现力的空间理解来支持高级决策

Method: MacroNav包含两个关键组件：1) 通过多任务自监督学习训练的轻量级上下文编码器，用于捕获多尺度、导航中心的空间表示；2) 分层规划器，利用这些表示进行高效导航

Result: 未在摘要中明确说明具体实验结果，但暗示该方法能够实现未知环境中高效的空间理解与导航

Conclusion: MacroNav框架通过结合轻量级上下文编码和分层规划，解决了未知环境中导航的表示效率问题

Abstract: Autonomous navigation in unknown environments requires compact yet expressive spatial understanding under partial observability to support high-level decision making. Existing approaches struggle to balance rich contextual representation with navigation efficiency. We present MacroNav, a learning-based navigation framework featuring two key components:(1) a lightweight context encoder trained via multi-task self-supervised learning to capture multi-scale, navigation-centric spatial …

</details>


### [328] [Sky Computing for Serverless: Infrastructure Assessment to Support Performance Enhancement](https://scholar.google.com/scholar_url?url=http://faculty.washington.edu/wlloyd/papers/Cordingly_CPU_Distribution_Manipulation_UCC2025-cr.pdf&hl=zh-CN&sa=X&d=10072341995792852016&ei=BHkWaYPwCObYieoPloPf4AM&scisig=ABGrvjL1JrKXlTpvCSarIlqcFkuy&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=0&folt=cit)
*R Cordingly,X Chen,LH Hung,W Lloyd*

Main category: Zongheng Yang

TL;DR: 论文分析了无服务器FaaS平台的基础设施不透明性、性能不可预测性和成本不一致性问题，这些问题源于底层IaaS硬件的异构性和动态变化。


<details>
  <summary>Details</summary>
Motivation: 无服务器FaaS平台虽然提供了自动扩展和基础设施管理的便利，但其"无服务器"特性导致了基础设施不透明、性能不可预测和成本不一致的问题。这些问题源于平台使用的底层IaaS硬件（包括不同CPU代际、时钟速度等）的异构性和动态变化，给开发者和用户带来了挑战。

Method: 从摘要内容来看，论文主要通过分析无服务器FaaS平台的基础设施架构特点，特别是其底层IaaS硬件的多样性和动态性，来探讨性能不可预测性和成本不一致性的根源。可能涉及对平台基础设施的实证研究或分析。

Result: 研究发现无服务器FaaS平台的不可预测性主要源于其使用的IaaS硬件池的多样性和不断变化，包括不同CPU代际、时钟速度等硬件参数的差异，这些因素共同导致了性能波动和成本不一致。

Conclusion: 无服务器FaaS平台虽然提供了便利的自动扩展能力，但其底层基础设施的异构性和动态变化导致了显著的不透明性、性能不可预测性和成本不一致问题，需要在平台设计和应用部署时加以考虑。

Abstract: Abstract Serverless Function-as-a-Service (FaaS) cloud computing platforms enable developers to deploy applications that automatically scale and manage computing infrastructure. The “serverless” nature of these platforms leads to infrastructure obfuscation, unpredictable performance, and inconsistent costs. This unpredictability stems from a diverse, constantly shifting pool of Infrastructure-as-a-Service (IaaS) hardware used to host functions, including varying CPU generations, clock speeds …

</details>


### [329] [Guidelines for Building Indexes on Partially Cache-Coherent CXL Shared Memory](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.06460&hl=zh-CN&sa=X&d=8248244118058276343&ei=BHkWaYPwCObYieoPloPf4AM&scisig=ABGrvjLV0DVNWBG7vHqQffLYRFaz&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=3&folt=cit)
*F Wu,M Dong,W Cai,J Yan,H Chen*

Main category: Zongheng Yang

TL;DR: 该论文提出在部分缓存一致性(PCC)平台上构建一致且高效索引的方法，PCC模型只在核心子集内维护硬件缓存一致性，这破坏了现有单机软件的正确性。


<details>
  <summary>Details</summary>
Motivation: 随着CXL等新兴内存互连技术的发展，PCC模型能够实现大规模内存共享，但PCC放松全局缓存一致性会损害现有单机软件的正确性，特别是在索引数据结构方面。

Method: 论文提出了在PCC平台上构建一致且高效索引的方法，具体方法未在摘要中详细说明，但重点解决了PCC环境下索引的正确性和性能问题。

Result: 论文展示了在PCC平台上构建的索引能够保持一致性并实现高效性能，解决了PCC环境下现有索引设计面临的挑战。

Conclusion: 在PCC平台上构建一致且高效的索引是可行的，这为在部分缓存一致性架构上运行现有软件提供了解决方案。

Abstract: The\emph {Partial Cache-Coherence (PCC)} model maintains hardware cache coherence only within subsets of cores, enabling large-scale memory sharing with emerging memory interconnect technologies like Compute Express Link (CXL). However, PCC's relaxation of global cache coherence compromises the correctness of existing single-machine software. This paper focuses on building consistent and efficient indexes on PCC platforms. We present that existing indexes designed for …

</details>


### [330] [Do End-to-End TTS Systems Exploit Patterns in Speech?](https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-981-95-4395-3_7&hl=zh-CN&sa=X&d=4063397445493112075&ei=BHkWaYPwCObYieoPloPf4AM&scisig=ABGrvjI9O4JnoIxia5OFxm4NcifZ&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=4&folt=cit)
*P Khadse,SK Kopparapu*

Main category: Zongheng Yang

TL;DR: 端到端文本转语音系统通过深度学习架构学习文本与语音模式的关联，但人类语音的复杂性及发音器官的解剖约束导致某些发音配置难以准确建模。


<details>
  <summary>Details</summary>
Motivation: 端到端TTS系统虽然能学习文本与语音的关联，但人类语音涉及复杂的发音器官协调和生理约束，现有模型难以完全捕捉这些细微的发音配置变化，特别是那些受解剖结构限制的发音配置。

Method: 基于深度学习的端到端文本转语音架构，通过训练数据集学习文本与声学语音模式的映射关系，旨在捕捉语音生成的各个方面。

Result: 端到端TTS系统能够学习基本的文本-语音关联，但由于人类发音的复杂性和解剖约束，系统在准确建模某些发音配置（特别是涉及平滑发音器官过渡的配置）方面存在局限性。

Conclusion: 端到端TTS系统在语音合成方面取得进展，但需要进一步研究以更好地处理人类语音的复杂性和发音器官的解剖约束，特别是那些难以建模的发音配置。

Abstract: An end-to-end (e2e) text-to-speech (TTS) system is a deep architecture that learns to associate a text string with acoustic speech patterns from a dataset. It is expected that all aspects associated with speech production, such as phone duration, speaker characteristics, and intonation among other things are captured in the trained TTS model. Human speech is complex, involving smooth transitions between articulatory configurations (ACs). Due to anatomical constraints, some ACs are challenging to …

</details>


### [331] [Análisis de la influencia de características vocales en modelos de detección de voces clonadas mediante IA](https://scholar.google.com/scholar_url?url=https://uvadoc.uva.es/bitstream/handle/10324/79502/TFG-G7692.pdf%3Fsequence%3D1&hl=zh-CN&sa=X&d=2112212130558602593&ei=BHkWaYPwCObYieoPloPf4AM&scisig=ABGrvjIF-pAZ9jm3T5_Ql-AaKZ6X&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=6&folt=cit)
*F Mateos Martínez*

Main category: Zongheng Yang

TL;DR: Investigación sobre la detección de voces clonadas mediante IA, analizando cómo afectan diferentes factores a la eficacia de los sistemas de detección


<details>
  <summary>Details</summary>
Motivation: El aumento en el uso generalizado de la Inteligencia Artificial plantea desafíos en la detección de voces clonadas creadas mediante técnicas de IA. Con el progreso en la tecnología de síntesis vocal, la clonación de voces se ha convertido en una amenaza importante al permitir la creación de imitaciones creíbles de la voz de un individuo para propósitos potencialmente dañinos.

Method: El abstract no especifica el método concreto, pero indica que el propósito principal es investigar cómo afectan diferentes factores a la eficacia de los sistemas de detección de voces clonadas.

Result: No se presentan resultados específicos en el abstract proporcionado, solo se establece el objetivo de investigación.

Conclusion: La investigación busca contribuir al desarrollo de sistemas más efectivos para detectar voces clonadas generadas por IA, abordando una amenaza creciente en el ámbito de la seguridad y autenticación vocal.

Abstract: El aumento en la generalización del uso de la Inteligencia Artificial plantean un desafío como es la detección de voces clonadas creadas mediante técnicas de IA. Con el progreso en la tecnología de síntesis vocal, la clonación de voces se ha vuelto una amenaza importante al posibilitar la creación de imitaciones creíbles y sólidas de la voz de un individuo para propósitos potencialmente dañinos. El propósito principal de este proyecto es investigar sobre cómo afectan a la eficacia …

</details>


### [332] [Motif 2 12.7 B technical report](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.07464&hl=zh-CN&sa=X&d=9387504830209055390&ei=ve0XaZvcKIePieoP4Ijq0QY&scisig=ABGrvjKD9lJt5bxofUlntHO4S9zX&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=0&folt=cit)
*J Lim,S Lee,D Kim,T Kim,E Park,J Lee,J Lee,J Lee…*

Main category: Zongheng Yang

TL;DR: Motif-2-12.7B是一个新的开放权重基础模型，通过架构创新和系统级优化提升大语言模型的效率边界，在有限计算预算下实现可扩展的语言理解和稳健的指令泛化。


<details>
  <summary>Details</summary>
Motivation: 推动大语言模型的效率边界，在有限计算预算下实现可扩展的语言理解和稳健的指令泛化能力。

Method: 基于Motif-2.6B模型，集成了分组差分注意力机制，通过分离信号和噪声控制来提高表示效率，并结合系统级优化。

Result: 开发出Motif-2-12.7B模型，这是一个新的开放权重基础模型，在效率和性能方面取得平衡。

Conclusion: 通过架构创新和系统优化，成功开发出高效的大语言模型，为有限计算资源下的语言理解任务提供了新的解决方案。

Abstract: We introduce Motif-2-12.7 B, a new open-weight foundation model that pushes the efficiency frontier of large language models by combining architectural innovation with system-level optimization. Designed for scalable language understanding and robust instruction generalization under constrained compute budgets, Motif-2-12.7 B builds upon Motif-2.6 B with the integration of Grouped Differential Attention (GDA), which improves representational efficiency by disentangling signal and noise-control …

</details>


### [333] [HPC-R1: Characterizing R1-like Large Reasoning Models on HPC](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3712285.3759827&hl=zh-CN&sa=X&d=18114428543356197063&ei=xkQZaYnnOLmAieoPtbvzyQs&scisig=ABGrvjJRrZHxVpsVeaF-_sv9jsRq&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=0&folt=cit)
*A Weingram,D Zhang,Z Chen,H Qi,X Lu*

Main category: Zongheng Yang

TL;DR: HPC-R1是对大型推理模型在超级计算机上训练的系统级性能分析与优化研究


<details>
  <summary>Details</summary>
Motivation: 大型推理模型虽然具备超越标准语言模型的逻辑推理、数学推理和知识合成能力，但其复杂的训练流程在可复现性、效率和系统级优化方面存在显著挑战

Method: 在NERSC Perlmutter超级计算机上对LRM训练进行全面的系统级性能表征，分析计算、内存、通信等瓶颈，并提出优化策略

Result: 通过系统级分析识别了LRM训练中的关键性能瓶颈，提出了针对超级计算环境的优化方案，提升了训练效率和可扩展性

Conclusion: HPC-R1为在超级计算基础设施上高效训练大型推理模型提供了系统级指导，解决了可复现性和性能优化等关键挑战

Abstract: Large Reasoning Models (LRMs) are becoming increasingly popular as they offer advanced capabilities in logical inference, mathematical reasoning, and knowledge synthesis, even beyond those of standard language models. However, their complex training workflows present significant challenges in reproducibility, efficiency, and system-level optimization. This paper introduces HPC-R1, a comprehensive characterization of LRM training on the NERSC Perlmutter supercomputer …

</details>


### [334] [Experiences Building Enterprise-Level Privacy-Preserving Federated Learning to Power AI for Science](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.08998&hl=zh-CN&sa=X&d=5729522742802013667&ei=xkQZaYnnOLmAieoPtbvzyQs&scisig=ABGrvjIpXR-YRlpuCAfidgskBlA1&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=1&folt=cit)
*Z Li,A Sinha,Y Li,K Chard,K Kim,R Madduri*

Main category: Zongheng Yang

TL;DR: 本文探讨了构建企业级联邦学习框架的挑战，特别是在可扩展性、隐私保护和从本地原型到分布式部署的过渡方面。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在科学领域具有重要应用价值，能够实现无需集中数据共享的协作模型训练，满足数据隐私、所有权和合规性要求。然而，现有系统在构建用户友好、可扩展且隐私保护的企业级框架方面仍面临挑战，特别是在弥合本地原型与异构客户端分布式部署之间的差距。

Method: 论文未在摘要中明确描述具体方法，但暗示了需要开发新的框架或系统架构来解决企业级联邦学习的挑战，包括可扩展性、隐私保护和部署便利性等方面。

Result: 摘要未提供具体实验结果，但暗示了当前企业级联邦学习框架在可扩展性、隐私保护和部署便利性方面存在不足，需要新的解决方案。

Conclusion: 构建用户友好、可扩展且隐私保护的企业级联邦学习框架仍然是一个重要但具有挑战性的问题，特别是在处理从本地原型到异构客户端分布式部署的过渡方面。

Abstract: Federated learning (FL) is a promising approach to enabling collaborative model training without centralized data sharing, a crucial requirement in scientific domains where data privacy, ownership, and compliance constraints are critical. However, building user-friendly enterprise-level FL frameworks that are both scalable and privacy-preserving remains challenging, especially when bridging the gap between local prototyping and distributed deployment across heterogeneous client computing …

</details>


### [335] [UltraAttn: Efficiently Parallelizing Attention through Hierarchical Context-Tiling](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3712285.3759894&hl=zh-CN&sa=X&d=13275587245633568520&ei=xkQZaYnnOLmAieoPtbvzyQs&scisig=ABGrvjLuWcb8_toIKkylQupzJk4b&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=5&folt=cit)
*H Yang,Z Zong,Y Jin,K Lei,J He,Q Yang,J Zhai*

Main category: Zongheng Yang

TL;DR: 提出一种新的上下文并行方法来解决现有方法在长上下文训练和推理中的可扩展性问题


<details>
  <summary>Details</summary>
Motivation: 现有上下文并行方法存在可扩展性差的问题，主要由于条纹状分区模式导致高通信流量，以及基于环的通信模式限制了内核粒度、降低了设备利用率并产生冗余通信

Method: 提出一种新的上下文并行方法，具体技术细节在摘要中未完全展开，但暗示会解决现有方法的通信和分区问题

Result: 摘要中未提供具体实验结果，但暗示新方法将改善长上下文训练和推理的性能

Conclusion: 新提出的上下文并行方法有望解决现有方法的可扩展性问题，从而更有效地加速长上下文训练和推理

Abstract: Long-context comprehension is critical for large language models. Context parallelism and irregular block-sparse attention are keyss to accelerating long-context training and inference. Existing context parallelism suffers from poor scalability due to the striped-like partition pattern, which causes high communication traffic, and the ring-based communication pattern, which limits kernel granularity, reduces device utilization, and incurs redundant communication. We present …

</details>


### [336] [Bubble: Towards Scalable Evolving Graph Processing via Mini-Batch Sorting](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3712285.3759897&hl=zh-CN&sa=X&d=17961852155804086466&ei=xkQZaYnnOLmAieoPtbvzyQs&scisig=ABGrvjK3vCvmb3nMWI2Bp74KxMEj&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=6&folt=cit)
*L Deng,Y Li,Z Zhang,Y Xu,JCS Lui*

Main category: Zongheng Yang

TL;DR: Bubble是一个高性能演化图处理引擎，通过创新的图格式和并行处理策略解决现有系统的缓存竞争和工作负载不平衡问题，实现高可扩展性


<details>
  <summary>Details</summary>
Motivation: 现有演化图处理系统在多核计算机上存在缓存竞争和线程间工作负载不平衡问题，导致可扩展性差和性能下降，需要设计高可扩展性的高性能演化图处理引擎

Method: 采用基于...的新型图格式（原文未完整提供具体方法细节），设计高可扩展性的并行处理架构，解决缓存竞争和工作负载平衡问题

Result: Bubble引擎实现了高性能和高可扩展性，在多核计算机上表现出优异的性能表现（具体结果需参考完整论文）

Conclusion: Bubble通过创新的架构设计有效解决了现有演化图处理系统的可扩展性问题，为高性能演化图处理提供了有效的解决方案

Abstract: Evolving graph processing has become a critical component in various applications and is gaining increasing attention. However, existing evolving graph systems suffer from cache contention and workload imbalance between threads, which leads to poor scalability and performance degradation on modern multi-core computers. In this paper, we introduce Bubble, a high-performance evolving graph processing engine designed with high scalability. By employing a novel graph format based on …

</details>


### [337] [Continuum Dropout for Neural Differential Equations](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.10446&hl=zh-CN&sa=X&d=17364763752534280441&ei=-LYaae6WJ9ToieoP3qjLUA&scisig=ABGrvjKXB3Ft-45uuT4gUv5-DxL1&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=2&folt=cit)
*J Lee,YK Oh,S Kim,DY Lim*

Main category: Zongheng Yang

TL;DR: 提出Continuum Dropout方法，解决神经微分方程无法有效使用dropout正则化的问题


<details>
  <summary>Details</summary>
Motivation: 神经微分方程在建模连续时间动态方面表现出色，能有效处理不规则观测、缺失值和噪声等问题。然而，NDEs面临一个基本挑战：难以采用深度学习中作为正则化基石的dropout技术，这使得它们容易过拟合。

Method: 引入Continuum Dropout，这是一种基于...理论的通用正则化技术，专门为神经微分方程设计。

Result: 从摘要内容看，该方法旨在解决NDEs的正则化问题，但具体实验结果未在摘要中提供。

Conclusion: Continuum Dropout填补了神经微分方程正则化方法的研究空白，为NDEs提供了有效的过拟合预防机制。

Abstract: Neural Differential Equations (NDEs) excel at modeling continuous-time dynamics, effectively handling challenges such as irregular observations, missing values, and noise. Despite their advantages, NDEs face a fundamental challenge in adopting dropout, a cornerstone of deep learning regularization, making them susceptible to overfitting. To address this research gap, we introduce Continuum Dropout, a universally applicable regularization technique for NDEs built upon the theory of …

</details>


### [338] [BVTS: 基于BERT 增强的高质量语音合成模型](https://scholar.google.com/scholar_url?url=https://www.hanspub.org/journal/paperinformation%3FpaperID%3D127786&hl=zh-CN&sa=X&d=11732168861432486382&ei=-LYaae6WJ9ToieoP3qjLUA&scisig=ABGrvjKjG1y6Tb_5MVUPlcWjJWYl&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=6&folt=cit)
*尹鹏飞， 刘雪晴*

Main category: Zongheng Yang

TL;DR: 提出BVTS框架，将BERT集成到VITS2中，通过多模态文本编码器增强语音合成的韵律建模和语义理解能力


<details>
  <summary>Details</summary>
Motivation: 当前语音合成技术在清晰度和流畅度方面已有显著提升，但在逼近人类真实语音质感方面仍存在挑战，主要瓶颈在于韵律建模和语义理解适配方面的不足

Method: 以VITS为框架，引入BERT模型增强的多模态文本编码器，构建BVTS（BERT-Integrated-VITS2）语音合成框架

Result: 未在摘要中明确说明具体实验结果，但暗示该框架旨在解决韵律建模和语义理解方面的挑战

Conclusion: 通过集成BERT模型到VITS框架中，有望提升语音合成的韵律建模能力和语义理解适配，从而更接近人类真实语音质感

Abstract: 近年来, 语音合成(Text-to-Speech, TTS) 技术在端到端建模, 音质优化等方面取得显著进展, 合成语音的清晰度与流畅度大幅提升, 但在逼近人类真实语音质感方面仍存挑战, 主要瓶颈在韵律建模, 语义理解适配方面欠缺. 本文提出一种基于BERT (Bidirectional Encoder Representations from Transformers) 模型增强的语音合成框架——BVTS (BERT-Integrated-VITS2), 模型以VITS (Variational Inference with adversarial learning for end-to-end Text-to-Speech) 为框架, 引入多模态文本编码器, 在BERT …

</details>


### [339] [Artifact of the paper: HAS-GPU: Efficient Hybrid Auto-scaling with Fine-grained GPU Allocation for SLO-aware Serverless Inferences](https://scholar.google.com/scholar_url?url=https://ui.adsabs.harvard.edu/abs/2025zndo..15596511G/abstract&hl=zh-CN&sa=X&d=7538498223941148519&ei=qBIhaZnmEevJieoPjeOTgQ0&scisig=ABGrvjJIpRfvpIQrtU-ETJzbT8iU&oi=scholaralrt&hist=i6heNjgAAAAJ:778719684493065653:ABGrvjLJz7cmQhcd9poDv5q68_GG&html=&pos=0&folt=rel)
*J Gu,P Wang,ID Núñez Araya,K Huang,M Gerndt*

Main category: Zongheng Yang

TL;DR: HAS-GPU是一个高效的混合自动扩展无服务器架构，通过细粒度GPU分配优化深度学习推理性能


<details>
  <summary>Details</summary>
Motivation: 现有无服务器架构在深度学习推理场景中面临GPU资源分配效率低下、资源碎片化和冷启动延迟等问题，需要更高效的GPU资源管理方案

Method: 提出混合自动扩展无服务器架构，包含敏捷调度器实现细粒度GPU分配，结合预测性扩展和动态资源管理策略

Result: HAS-GPU显著提升了GPU利用率，降低了推理延迟，减少了资源碎片化，并有效应对突发负载

Conclusion: 该架构为深度学习推理提供了高效的无服务器解决方案，通过细粒度GPU分配和智能调度机制实现了性能优化

Abstract: The repository is the artifact of the HAS-GPU project. HAS-GPU is an efficient Hybrid Auto-scaling Serverless architecture with fine-grained GPU allocation for deep learning inferences. HAS-GPU proposes an agile scheduler capable of allocating …

</details>


### [340] [Do AI Voices Learn Social Nuances? A Case of Politeness and Speech Rate](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.10693&hl=zh-CN&sa=X&d=17978280785542747191&ei=pxIhadzxN6qy6rQP4Jvq6A4&scisig=ABGrvjK2kuQJKCtn3Y1GjnQp8io0&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=0&folt=cit)
*E Rabin,Z Elyoseph,R Israel*

Main category: Zongheng Yang

TL;DR: 研究探讨AI语音系统是否内化了人类通过降低语速表达礼貌的隐式韵律特征


<details>
  <summary>Details</summary>
Motivation: 随着语音AI需要遵循人类社交规范，本研究旨在探究最先进的文本转语音系统是否掌握了人类通过降低语速表达礼貌的非显性韵律标记，这种隐式线索通常不会被明确编程

Method: 使用两个领先AI平台（AI Studio和OpenAI）的22个合成语音，让它们在"礼貌正式"和"随意"两种情境下朗读固定脚本，分析其语速变化模式

Result: 从摘要内容看，研究结果尚未完整呈现，但研究设计表明将对比分析AI语音在不同社交情境下的语速调节能力

Conclusion: 该研究将评估当前语音AI系统是否能够像人类一样自然地通过语速调节来传达社交礼貌信息，这对AI社交智能发展具有重要意义

Abstract: Voice-based artificial intelligence is increasingly expected to adhere to human social conventions, but can it learn implicit cues that are not explicitly programmed? This study investigates whether state-of-the-art text-to-speech systems have internalized the human tendency to reduce speech rate to convey politeness-a non-obvious prosodic marker. We prompted 22 synthetic voices from two leading AI platforms (AI Studio and OpenAI) to read a fixed script under both" polite and formal" and" casual …

</details>


### [341] [Federated Knowledge Expansion for Collections of Heterogeneous Devices](https://scholar.google.com/scholar_url?url=https://web.njit.edu/~borcea/papers/ieee-bigdata25-fedke.pdf&hl=zh-CN&sa=X&d=332756428241039768&ei=pxIhadzxN6qy6rQP4Jvq6A4&scisig=ABGrvjL6Nv2fbq-zhV5tdHTdPjtQ&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=2&folt=cit)
*X Jiang,C Borcea*

Main category: Zongheng Yang

TL;DR: 提出了一种联邦学习新方法，解决异构设备系统中资源最低设备限制模型规模的问题，通过利用所有计算能力训练更大模型


<details>
  <summary>Details</summary>
Motivation: 联邦学习在异构设备环境中存在瓶颈：资源最低的设备限制了全局模型的规模和复杂度，因为所有设备都需要通信和训练相同的模型，无法充分利用系统中的所有计算能力

Method: 提出了一种新方法（具体方法未在摘要中说明），旨在在保持隐私保护的同时，允许训练更大的模型，并充分利用异构系统中所有设备的计算能力

Result: 该方法能够突破传统联邦学习中资源最低设备的限制，实现在异构设备系统中训练更大、更复杂的模型，同时保持隐私保护特性

Conclusion: 提出的方法解决了联邦学习在异构设备环境中的关键限制，使系统能够充分利用所有计算资源训练更大模型，扩展了联邦学习的应用范围

Abstract: Federated Learning (FL) enables privacy preserving training across devices, including PCs, smartphones, and IoT devices. However, when heterogeneous devices collaborate to train a model, devices with the lowest resources throttle the model size and complexity, as FL communicates and trains the same global model across all devices. To address this limitation and train a large model while utilizing all computational power in a system with heterogeneous devices, we propose …

</details>


### [342] [Generació d'un dataset sintètic de parla artificial per entrenar un sistema de comprensió de la parla com a sistema de control d'un videojoc](https://scholar.google.com/scholar_url?url=https://upcommons.upc.edu/bitstreams/776449a0-6ad4-4667-8435-9fa9560fb975/download&hl=zh-CN&sa=X&d=3269551653624950944&ei=pxIhadzxN6qy6rQP4Jvq6A4&scisig=ABGrvjIdKRK6huK6_hzeI5k9Zyr1&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=3&folt=cit)
*X Lu*

Main category: Zongheng Yang

TL;DR: 该论文提出了一种为加泰罗尼亚语视频游戏环境创建合成数据集的方法，用于训练口语语言理解模型


<details>
  <summary>Details</summary>
Motivation: 由于缺乏针对加泰罗尼亚语视频游戏领域的特定语料库，需要创建合成数据集来训练口语语言理解模型

Method: 提出了一种为加泰罗尼亚语视频游戏环境创建合成数据集的方法，用于训练SLU模型

Result: 创建了针对加泰罗尼亚语视频游戏环境的合成数据集，用于训练口语语言理解模型

Conclusion: 该方法解决了加泰罗尼亚语视频游戏领域缺乏训练数据的问题，为SLU模型训练提供了可行的解决方案

Abstract: Les tecnologies de parla han avançat considerablement en els darrers anys gracies als progressos en l'aprenentatge profund, assolint una qualitat de reconeixement i de sıntesi de veu molt propera a la natural. Aquest projecte se centra en la creació de conjunts de dades sintetiques destinats a l'entrenament de models de comprensió del llenguatge parlat (SLU) aplicats a entorns de videojoc en catala. Davant la manca de corpus especıfics per a aquest domini, s' ha proposat un metode …

</details>


### [343] [Investigation of Performance and Scalability of a Quantum-Inspired Evolutionary Optimizer (QIEO) on NVIDIA GPU](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.01298&hl=zh-CN&sa=X&d=9727133511184059187&ei=XcgjaZmuG-bYieoP1KWxsAU&scisig=ABGrvjLU0L5KS3iT5A52VBB8xXxq&oi=scholaralrt&hist=i6heNjgAAAAJ:778719684493065653:ABGrvjLJz7cmQhcd9poDv5q68_GG&html=&pos=1&folt=rel)
*A Mittal,KVS Srikanth,FSD Bosco,A Singh…*

Main category: Zongheng Yang

TL;DR: 量子启发进化优化利用量子计算原理增强经典进化算法，提升探索与开发能力


<details>
  <summary>Details</summary>
Motivation: 经典进化算法在处理复杂优化问题时存在探索与开发平衡的挑战，量子计算原理如叠加态、干涉和概率表示提供了增强进化算法性能的新途径

Method: 将量子计算原理（叠加态、干涉、概率表示）整合到进化算法框架中，用量子比特表示个体，通过量子门操作实现种群演化，利用量子测量获得经典解

Result: 量子启发的进化算法相比传统进化算法展现出更好的全局搜索能力、更快的收敛速度和更强的跳出局部最优的能力

Conclusion: 量子计算原理为进化算法提供了有效的增强机制，量子启发进化优化是解决复杂优化问题的有前景方向

Abstract: Quantum inspired evolutionary optimization leverages quantum computing principles like superposition, interference, and probabilistic representation to enhance classical evolutionary algorithms with improved exploration and exploitation capabilities …

</details>


### [344] [A Case for Learned Cloud Emulators](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3772356.3772404&hl=zh-CN&sa=X&d=8050864598235898314&ei=Xcgjafm7BY2v6rQPzvzsmAY&scisig=ABGrvjIo37PCOWxGp_hu8fIz1GC7&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=0&folt=cit)
*A Bhatnagar,Y Qiu,S McClure,S Ratnasamy,A Chen*

Main category: Zongheng Yang

TL;DR: 开发云基础设施的DevOps程序需要云资源，耗时且昂贵；云模拟器通过本地模拟云API实现无摩擦测试，但现有模拟器开发困难且易出错


<details>
  <summary>Details</summary>
Motivation: 通过DevOps程序创建和维护云基础设施对云使用至关重要，但开发和测试这些程序需要在云中配置资源，这既耗时又昂贵。云模拟器旨在通过本地模拟云API来支持高速开发，但当前开发模拟器的方法繁琐且容易出错

Method: 论文未在摘要中明确说明具体方法，但指出当前云模拟器开发存在的问题，暗示需要新的方法或工具来改进云模拟器的开发过程

Result: 摘要未提供具体实验结果，但指出了当前云模拟器开发面临的挑战：开发过程繁琐且容易出错

Conclusion: 需要更好的方法来开发云模拟器，以支持DevOps程序的高效本地测试，避免昂贵的云资源消耗

Abstract: Creating and maintaining cloud infrastructure via" DevOps programs" is essential to using the cloud. However, developing and testing the DevOps programs requires resource provisioning in the cloud, which is time-consuming and costly. Cloud emulators seek to enable high velocity development by emulating cloud-level APIs to DevOps programs, enabling frictionless testing locally without going through the cloud. However, developing these emulators today is tedious and error-prone …

</details>


### [345] [Voiced-Aware Style Extraction and Style Direction Adjustment for Expressive Text-to-Speech](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.14824&hl=zh-CN&sa=X&d=12737227767526946766&ei=Xcgjafm7BY2v6rQPzvzsmAY&scisig=ABGrvjLdld1WPmmfX3cX36T5bZnK&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=3&folt=cit)
*NG Kim*

Main category: Zongheng Yang

TL;DR: SpotlightTTS是一种专注于通过有声感知风格提取和风格方向调整来增强表达性语音合成的TTS模型


<details>
  <summary>Details</summary>
Motivation: 尽管基于参考语音风格嵌入的表达性TTS方法有所进展，但合成高质量表达性语音仍然具有挑战性，需要更有效的风格提取和调整方法

Method: 提出SpotlightTTS，采用有声感知风格提取专注于与风格高度相关的有声区域，同时保持不同语音的连续性，并进行风格方向调整

Result: 未在摘要中明确说明具体实验结果，但暗示该方法能够改善表达性语音合成的质量

Conclusion: SpotlightTTS通过专注于有声感知风格提取和调整，为表达性TTS提供了有效的解决方案

Abstract: Recent advances in expressive text-to-speech (TTS) have introduced diverse methods based on style embedding extracted from reference speech. However, synthesizing high-quality expressive speech remains challenging. We propose SpotlightTTS, which exclusively emphasizes style via voiced-aware style extraction and style direction adjustment. Voiced-aware style extraction focuses on voiced regions highly related to style while maintaining continuity across different speech …

</details>


### [346] [SilverTorch: A Unified Model-based System to Democratize Large-Scale Recommendation on GPUs](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.14881&hl=zh-CN&sa=X&d=14376513739348682987&ei=Xcgjafm7BY2v6rQPzvzsmAY&scisig=ABGrvjIuGF0LJ0DRWCW5Tumh1r9f&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=5&folt=cit)
*B Xue,H Wu,L Chen,C Yang,Y Ma,F Ding,Z Wang…*

Main category: Zongheng Yang

TL;DR: SilverTorch是一个基于模型的推荐系统，旨在解决大规模深度学习推荐模型服务中的效率问题，通过GPU加速的ANN索引和过滤来替代传统的CPU方案。


<details>
  <summary>Details</summary>
Motivation: 现有系统依赖CPU进行ANN索引和过滤，成本高昂且无法进行联合优化，难以支持更复杂的模型架构（如学习相似性和多任务检索）。

Method: 提出SilverTorch系统，采用基于模型的方法在GPU上服务推荐模型，实现高效的近似最近邻索引和过滤。

Result: 系统显著降低了服务成本，提高了效率，能够支持更复杂的模型架构。

Conclusion: SilverTorch通过GPU加速的模型服务方法，解决了大规模深度学习推荐模型服务中的效率瓶颈问题。

Abstract: Serving deep learning based recommendation models (DLRM) at scale is challenging. Existing systems rely on CPU-based ANN indexing and filtering services, suffering from non-negligible costs and forgoing joint optimization opportunities. Such inefficiency makes them difficult to support more complex model architectures, such as learned similarities and multi-task retrieval. In this paper, we propose SilverTorch, a model-based system for serving recommendation models on …

</details>


### [347] [AlertGuardian: Intelligent Alert Life-Cycle Management for Large-scale Cloud Systems](https://scholar.google.com/scholar_url?url=https://yuxiaoba.github.io/files/ASE25/AlertGuardian.pdf&hl=zh-CN&sa=X&d=15709802890751550372&ei=Xcgjafm7BY2v6rQPzvzsmAY&scisig=ABGrvjKnEahI4yrOVNAgK700xQOF&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=6&folt=cit)
*G Yu,G Mai,R Wang,R Li,P Chen,L Pan,R Xu*

Main category: Zongheng Yang

TL;DR: AlertGuardian框架利用大语言模型和图分析优化云系统告警生命周期管理，解决告警疲劳问题


<details>
  <summary>Details</summary>
Motivation: 大规模云系统中告警对异常检测至关重要，但现有系统产生过多告警导致告警疲劳，降低运维效率，需要优化告警生命周期管理

Method: 提出AlertGuardian框架，结合大语言模型（LLMs）和轻量级图分析技术，协作优化告警管理流程

Result: 未在摘要中明确说明具体结果，但暗示该框架能有效解决告警疲劳问题，提升云系统运维效率

Conclusion: AlertGuardian框架通过LLM与图分析结合，为云系统告警生命周期管理提供了有效的优化方案

Abstract: Alerts are critical for detecting anomalies in largescale cloud systems, ensuring reliability and user experience. However, current systems generate overwhelming volumes of alerts, degrading operational efficiency due to ineffective alert life-cycle management. This paper details the efforts of Company-X to optimize alert life-cycle management, addressing alert fatigue in cloud systems. We propose AlertGuardian, a framework collaborating large language models (LLMs) and lightweight graph …

</details>


### [348] [Comparing Speech Synthesis Models for Polish Medical Speech Naturalness](https://scholar.google.com/scholar_url?url=https://aisel.aisnet.org/isd2014/proceedings2025/datascience/8/&hl=zh-CN&sa=X&d=10966215800829902238&ei=Xcgjafm7BY2v6rQPzvzsmAY&scisig=ABGrvjIEGLROq2CUl7glEiamiNSH&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=7&folt=cit)
*W Krasiński,P Rośleń,A Czyzewski,M Zielonka*

Main category: Zongheng Yang

TL;DR: 比较三种波兰语医学术语语音合成模型的自然度：SpeechGen、ElevenLabs和基于波兰医学录音微调的ToucanTTS，使用客观指标、NISQA度量和主观评估


<details>
  <summary>Details</summary>
Motivation: 研究波兰语医学术语合成语音的自然度感知，这对语音医疗对话系统等应用至关重要

Method: 对SpeechGen、ElevenLabs和基于波兰医学录音微调的ToucanTTS三种模型进行对比分析，采用客观测量、NISQA度量和主观评估方法

Result: 未在摘要中明确说明具体结果，但暗示了三种模型在波兰语医学术语合成自然度方面的对比评估

Conclusion: 未在摘要中明确说明结论，但研究旨在确定哪种模型在波兰语医学术语合成中产生最自然的语音输出

Abstract: This research investigates the perceived naturalness of synthesized speech in the context of Polish medical terminology, a critical factor for applications such as voice-enabled medical dialogue systems. We conducted a comparative analysis of three speech synthesis models: SpeechGen, ElevenLabs, and a version of ToucanTTS fine-tuned on a specialized corpus of Polish medical recordings. The evaluation employed objective measures, the NISQA metric, and subjective assessments …

</details>


### [349] [[Experiment, Analysis, and Benchmark] Systematic Evaluation of Plan-based Adaptive Query Processing](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.16455&hl=zh-CN&sa=X&d=17400418340424302186&ei=4jglafHyBv-j6rQPj9qr8A0&scisig=ABGrvjJa8H04Cfm3i2Kk5oyrY016&oi=scholaralrt&hist=i6heNjgAAAAJ:778719684493065653:ABGrvjLJz7cmQhcd9poDv5q68_GG&html=&pos=0&folt=rel)
*P Mu,AC Carniel,A Barbalace,A Shaikhha*

Main category: Zongheng Yang

TL;DR: 自适应查询处理（AQP）策略通过提供更稳健的查询执行来应对不可靠的基数估计问题，这是数据库管理系统中的关键性能瓶颈


<details>
  <summary>Details</summary>
Motivation: 数据库管理系统中不可靠的基数估计仍然是关键的性能瓶颈，这限制了查询优化和执行效率

Method: 采用自适应查询处理（AQP）策略，通过动态调整查询执行计划来应对基数估计的不确定性

Result: AQP策略能够提供更稳健的查询执行，减少因基数估计错误导致的性能下降

Conclusion: 自适应查询处理是解决数据库系统中不可靠基数估计问题的有效方法，能够显著提升查询性能的稳定性

Abstract: Unreliable cardinality estimation remains a critical performance bottleneck in database management systems (DBMSs). Adaptive Query Processing (AQP) strategies address this limitation by providing a more robust query execution …

</details>


### [350] [Taming the Long-Tail: Efficient Reasoning RL Training with Adaptive Drafter](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.16665&hl=zh-CN&sa=X&d=16583725774485611235&ei=4TglaYy5LdOyieoPyofJ-QE&scisig=ABGrvjIrMiUKQDFcZiVGdAEirAuq&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=1&folt=cit)
*Q Hu,S Yang,J Guo,X Yao,Y Lin,Y Gu,H Cai,C Gan…*

Main category: Zongheng Yang

TL;DR: LLM推理模型训练存在效率瓶颈：RL训练中响应生成呈现长尾分布，少数极长响应主导执行时间，浪费资源并增加成本


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型展现出强大的推理能力，但在使用强化学习训练这些推理模型时，存在关键效率瓶颈。响应生成呈现持久的长尾分布，少数极长响应主导执行时间，导致资源浪费和成本增加。

Method: 论文未在摘要中明确说明具体方法，但暗示需要解决RL训练中响应生成的长尾分布问题，以提高训练效率。

Result: 摘要未提供具体实验结果，但指出了当前LLM推理模型训练中存在的效率瓶颈问题。

Conclusion: 需要解决LLM推理模型RL训练中的响应生成长尾分布问题，以提高训练效率、减少资源浪费和降低成本。

Abstract: The emergence of Large Language Models (LLMs) with strong reasoning capabilities marks a significant milestone, unlocking new frontiers in complex problem-solving. However, training these reasoning models, typically using Reinforcement Learning (RL), encounters critical efficiency bottlenecks: response generation during RL training exhibits a persistent long-tail distribution, where a few very long responses dominate execution time, wasting resources and inflating costs …

</details>


### [351] [Is Phase Really Needed for Weakly-Supervised Dereverberation?](https://scholar.google.com/scholar_url?url=https://hal.science/hal-05372717/document&hl=zh-CN&sa=X&d=7684316178818370218&ei=4TglaYy5LdOyieoPyofJ-QE&scisig=ABGrvjLZS_hLhCENEQ4PPHJtSon-&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=2&folt=cit)
*M Rodrigues,L Bahrman,R Badeau,G Richard*

Main category: Zongheng Yang

TL;DR: 该研究探讨了在无监督或弱监督语音去混响方法中，仅从混响语音（湿信号）中恢复信息的能力，特别关注时频域中混响相位的作用。


<details>
  <summary>Details</summary>
Motivation: 在无监督或弱监督语音去混响方法中，目标干净（干）信号在训练时被视为未知。因此，评估仅从混响（湿）语音知识中能够恢复多少信息变得至关重要。本研究特别关注时频域中混响相位的作用，基于统计波场理论分析晚期混响对相位的扰动。

Method: 基于统计波场理论分析晚期混响对时频域相位的影响。研究探讨了仅从混响（湿）语音中恢复信息的能力，特别关注相位信息在无监督或弱监督去混响中的作用。

Result: 研究表明晚期混响会扰动相位信息，这影响了仅从混响语音中恢复干净信号的能力。研究揭示了在无监督或弱监督设置下，混响相位信息对语音去混响任务的重要性。

Conclusion: 混响相位在时频域中扮演重要角色，晚期混响对相位的扰动会影响无监督或弱监督语音去混响方法的性能。理解相位信息的作用对于改进仅从混响语音中恢复信息的方法至关重要。

Abstract: In unsupervised or weakly-supervised approaches for speech dereverberation, the target clean (dry) signals are considered to be unknown during training. In that context, evaluating to what extent information can be retrieved from the sole knowledge of reverberant (wet) speech becomes critical. This work investigates the role of the reverberant (wet) phase in the time-frequency domain. Based on Statistical Wave Field Theory, we show that late reverberation perturbs phase …

</details>


### [352] [Programming Scalable Elastic Services with AEON](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3777545&hl=zh-CN&sa=X&d=1032482190064898905&ei=U7omaYS6KvGQ6rQPybbN6Qk&scisig=ABGrvjIwXYHtopxF6LIpo0VrSIm-&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=0&folt=cit)
*P Eugster,S Ravi,B Sang*

Main category: Zongheng Yang

TL;DR: 分布式云应用面临可扩展性、数据一致性和弹性伸缩的挑战，需要解决在分布式并发硬件上运行时的数据访问一致性问题，同时应对工作负载波动。


<details>
  <summary>Details</summary>
Motivation: 用户面向服务的分布式云应用面临多重挑战：需要支持大规模用户的可扩展性，在分布式并发硬件上运行时保证共享数据访问的一致性，以及应对工作负载波动的弹性伸缩能力。

Method: 论文未提供具体方法细节，但从摘要描述来看，可能涉及分布式系统架构设计、一致性协议、弹性伸缩机制、负载均衡策略等技术方案。

Result: 摘要未提供具体实验结果，但暗示需要解决分布式云应用在可扩展性、数据一致性和弹性方面的核心问题。

Conclusion: 分布式云应用需要综合解决可扩展性、数据一致性和弹性伸缩等关键挑战，以确保用户面向服务的可靠性和性能。

Abstract: Implementing distributed cloud-based applications commonly at the basis of user-facing services goes through several challenges. In particular, such applications must be scalable to accommodate increasingly large user bases, providing consistency on accesses to shared data while executing on highly distributed concurrent commodity hardware. In addition, as these applications are subject to workload fluctuations, they must be elastic, ie, able to scale out to accommodate …

</details>


### [353] [Implementación de inteligencia artificial para la predicción y optimización del rendimiento en el Bloque 7](https://scholar.google.com/scholar_url?url=https://repositorio.upse.edu.ec/bitstreams/3cc35cde-c71e-457d-8183-71d588512715/download&hl=zh-CN&sa=X&d=5210555128245626497&ei=U7omaYS6KvGQ6rQPybbN6Qk&scisig=ABGrvjIOWCmVppsYqHe2gT79q5Sv&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=2&folt=cit)
*HA Montenegro Borbor*

Main category: Zongheng Yang

TL;DR: Revisión documental sobre el uso de inteligencia artificial para predecir y mejorar la eficiencia de producción en el Bloque 7 petrolero del oriente ecuatoriano


<details>
  <summary>Details</summary>
Motivation: Examinar la posibilidad de utilizar inteligencia artificial en el Bloque 7, un área productiva petrolera del oriente ecuatoriano, para prever y mejorar la eficiencia de producción en la industria hidrocarburífera

Method: Estudio documental que contempló la revisión de tesis, informes técnicos y artículos científicos para analizar el uso de modelos de inteligencia artificial en la industria hidrocarburífera

Result: Se identificaron las herramientas de inteligencia artificial más relevantes para la industria petrolera, aunque el resumen no especifica cuáles son exactamente

Conclusion: La inteligencia artificial tiene potencial para mejorar la eficiencia de producción en el sector petrolero ecuatoriano, específicamente en el Bloque 7

Abstract: El objetivo de este estudio es examinar la posibilidad de utilizar inteligencia artificial (IA) en el Bloque 7, un área productiva petrolera del oriente ecuatoriano, para prever y mejorar la eficiencia de producción. Para analizar el uso de modelos de inteligencia artificial en la industria hidrocarburífera, se realizó un estudio con una perspectiva documental que contempló la revisión de tesis, informes técnicos y artículos científicos. Se identificaron como las herramientas más relevantes los …

</details>


### [354] [テキストと口唇動画像データによるマルチモーダル音声合成器の性能評価](https://scholar.google.com/scholar_url?url=https://www.jstage.jst.go.jp/article/jrsj/43/9/43_43_919/_pdf&hl=zh-CN&sa=X&d=11482041475680081215&ei=U7omaYS6KvGQ6rQPybbN6Qk&scisig=ABGrvjJ-5yJsTVqgDOry9VYAVlYH&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=3&folt=cit)
*松浦篤史， 清水創太*

Main category: Zongheng Yang

TL;DR: 提出了一种基于文本和唇部运动多模态信息的语音合成模型，旨在生成包含浊音和清音段落的更自然语音


<details>
  <summary>Details</summary>
Motivation: 传统语音合成主要依赖文本信息，难以生成包含清音段落的自然语音。通过结合唇部运动信息，可以更好地模拟真实发音过程中的声带振动变化，提高语音的自然度

Method: 采用自编码器提取图像特征，结合编码器-解码器架构输出梅尔频谱图。比较了文本与唇部运动的三种不同组合方式

Result: 成功实现了基于文本和唇部运动的语音合成，能够将唇部运动信息反映到生成的语音中

Conclusion: 多模态语音合成方法能够生成更自然的语音，特别是对于包含浊音和清音段落的情况，结合唇部运动信息可以改善语音合成的质量

Abstract: 抄録 This paper proposes a speech synthesis model from multimodal information, ie, text and lip movements, in order to generate more natural speeches including voiced and unvoiced sections. Its architecture consists of an image feature extractor using an auto-encoder and an encoder-decoder model that outputs a mel-spectrogram. Speech synthesis reflecting the lip movements to the text was successfully achieved. 3 types of combinations between text and lip movements were compared and …

</details>


### [355] [Retraining-Free Pruning Text-to-Speech Synthesis Model for Speaker Cloning](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/document/11242128/&hl=zh-CN&sa=X&d=9727081330676321153&ei=vs8oaZfIHKG7ieoPhoLWaQ&scisig=ABGrvjIh6ndkLtfC0jpMlb8amqjd&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=3&folt=cit)
*AR Mandeel,TZ Fadhil,MH Alsalihi,MS Al*

Main category: Zongheng Yang

TL;DR: 该研究提出了一种基于权重和激活剪枝的轻量化方法，用于减少大规模文本转语音模型在适应特定说话人时的计算和资源需求。


<details>
  <summary>Details</summary>
Motivation: 随着端到端TTS模型规模的增大，使用大规模数据集进行预训练后，为每个目标说话人微调所有参数变得计算密集且资源消耗大，需要更高效的适应方法。

Method: 采用基于权重和激活的剪枝技术，对预训练的大规模TTS模型进行轻量化处理，减少需要微调的参数量，从而降低计算复杂度。

Result: 该方法能够显著降低模型适应特定说话人时的计算和资源需求，同时保持高质量的语音合成效果，实现高效的语音克隆。

Conclusion: 基于权重和激活的剪枝是一种有效的轻量化策略，能够解决大规模TTS模型在说话人适应过程中的计算和资源瓶颈问题。

Abstract: End-to-end text-to-speech (TTS) synthesis models can produce highly natural speech by drawing on large-scale pretraining with extensive datasets and subsequent adaptation to specific target speakers, such as voice cloning. However, as model sizes grow with increasingly comprehensive pretraining, fine-tuning all parameters for each speaker becomes both computationally demanding and resource-intensive. In this study, we adapted Pruning by Weights and Activations …

</details>


### [356] [Beyond Relational: Semantic-Aware Multi-Modal Analytics with LLM-Native Query Optimization](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.19830&hl=zh-CN&sa=X&d=5178276272351076472&ei=JXAqaafkI9OyieoPsZes4AQ&scisig=ABGrvjIE54AX1mWMGWwNHBkszA9I&oi=scholaralrt&hist=i6heNjgAAAAJ:778719684493065653:ABGrvjLJz7cmQhcd9poDv5q68_GG&html=&pos=0&folt=rel)
*J Zhu,L Chen,X Ke,Z Fang,T Li,Y Gao,CS Jensen*

Main category: Zongheng Yang

TL;DR: 多模态分析处理具有变革电子商务、医疗保健、娱乐等领域的潜力，但传统关系查询算子的局限性阻碍了其实际应用


<details>
  <summary>Details</summary>
Motivation: 多模态分析处理在多个领域具有巨大潜力，但由于传统关系查询算子无法有效处理多模态数据，导致实际应用受限，需要新的技术解决方案

Method: 未在提供的摘要中明确说明具体方法，但暗示需要超越传统关系查询算子的新方法或框架来处理多模态数据分析

Result: 未在提供的摘要中明确说明具体结果，但指出了当前多模态分析处理面临的技术障碍和实际应用挑战

Conclusion: 多模态分析处理具有重要应用价值，但需要开发新的查询处理技术来克服传统关系算子的局限性，以实现其在实际场景中的广泛应用

Abstract: Multi-modal analytical processing has the potential to transform applications in e-commerce, healthcare, entertainment, and beyond. However, real-world adoption remains elusive due to the limited ability of traditional relational query operators to …

</details>


### [357] [Deepfake Voice Command Attacks on Automatic Speaker Recognition Systems](https://scholar.google.com/scholar_url?url=https://bmva-archive.org.uk/bmvc/2025/assets/workshops/SRBS/Paper_6/paper.pdf&hl=zh-CN&sa=X&d=8198818453046818795&ei=JXAqad2pD4S6ieoP4aDG6AU&scisig=ABGrvjJCUCPfx57heqDerz-HNz59&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=3&folt=cit)
*M Micheletto,G Orru,A Setzu,M Tronci,M Trudu…*

Main category: Zongheng Yang

TL;DR: 该论文研究黑盒威胁模型下逻辑访问攻击对自动说话人验证系统的有效性，使用可复现的攻击方法评估系统脆弱性


<details>
  <summary>Details</summary>
Motivation: 自动说话人验证系统在安全应用中广泛部署，但在干净条件下表现良好的系统仍易受逻辑访问攻击，其中合成语音被直接注入系统以冒充合法用户

Method: 采用黑盒威胁模型，使用可复现的攻击方法评估逻辑访问攻击对说话人验证系统的有效性

Result: 研究发现自动说话人验证系统在黑盒逻辑访问攻击下存在显著脆弱性，合成语音攻击能够成功绕过系统验证

Conclusion: 自动说话人验证系统需要增强对逻辑访问攻击的防御能力，特别是在黑盒威胁模型下的安全性需要进一步改进

Abstract: Automatic speaker verification is increasingly deployed in security applications, including remote identity verification, internet banking, and access control systems. Although these systems have achieved strong performance under clean conditions, they remain vulnerable to logical access attacks, where synthetic speech is injected directly into the system to impersonate a legitimate user. This paper investigates the effectiveness of such attacks under a black-box threat model using a reproducible …

</details>


### [358] [Matrix: Peer-to-Peer Multi-Agent Synthetic Data Generation Framework](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.21686&hl=zh-CN&sa=X&d=2005328648100098674&ei=xcIraa-aLuvJieoP8e3G6Qs&scisig=ABGrvjJTKtyeidQOoH04ANACSYv-&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=0&folt=cit)
*D Wang,Y Li,A Ni,CF Yeh,Y Emad,X Lei,L Robbins…*

Main category: Zongheng Yang

TL;DR: 多智能体协作生成高质量合成数据框架，解决集中式编排器的可扩展性瓶颈问题


<details>
  <summary>Details</summary>
Motivation: 合成数据对训练大语言模型至关重要，但现有多智能体生成框架依赖集中式编排器，存在可扩展性瓶颈，限制了高质量、多样化、结构丰富数据的生成效率

Method: 提出去中心化的多智能体协作框架，通过分布式协调机制替代集中式编排器，使各专业智能体能够自主协作生成合成数据

Result: 该框架能够生成更高质量、更多样化、结构更丰富的合成数据，同时解决了集中式编排带来的可扩展性瓶颈问题

Conclusion: 去中心化的多智能体协作框架为合成数据生成提供了更高效、可扩展的解决方案，有助于提升大语言模型的训练效果

Abstract: Synthetic data has become increasingly important for training large language models, especially when real data is scarce, expensive, or privacy-sensitive. Many such generation tasks require coordinated multi-agent workflows, where specialized agents collaborate to produce data that is higher quality, more diverse, and structurally richer. However, existing frameworks for multi-agent synthesis often depend on a centralized orchestrator, creating scalability bottlenecks, or are …

</details>


### [359] [Modern Approaches to Controllable Emotional Speech Synthesis](https://scholar.google.com/scholar_url?url=http://nrpcomp.ukma.edu.ua/article/download/344700/332149&hl=zh-CN&sa=X&d=16055362395980264820&ei=xcIraa-aLuvJieoP8e3G6Qs&scisig=ABGrvjK6VuKTlTRNS4EQDlpnumtg&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=2&folt=cit)
*ОО Марченко*

Main category: Zongheng Yang

TL;DR: 关于情感语音合成技术发展的综述论文，涵盖从早期拼接方法到现代神经模型的演进


<details>
  <summary>Details</summary>
Motivation: 情感表达和可控的语音生成是AI、NLP和语音合成交叉领域中最具活力和技术挑战性的方向之一。随着情感TTS系统的发展，语音生成越来越自然且情感细腻，需要系统性地梳理该领域的技术进展和现状。

Method: 采用综述研究方法，对情感文本转语音（TTS）系统进行结构化概述。从早期的拼接式方法到先进的神经模型，系统性地梳理技术演进路径、关键方法和架构。

Result: 提供了情感语音合成领域的技术现状全景图，展示了从传统方法到现代神经模型的演进过程，识别了当前的技术趋势和挑战。

Conclusion: 情感语音合成技术已取得显著进展，从早期拼接方法发展到能够生成自然且情感细腻语音的神经模型。该领域仍在快速发展，需要进一步研究以实现更精确的情感控制和表达。

Abstract: The generation of emotionally expressive and controllable speech is one of the most dynamic and technically demanding areas in the intersection of artificial intelligence, natural language processing, and speech synthesis. Recent progress in emotional text-to-speech (TTS) systems has enabled increasingly natural and emotionally nuanced voice generation, shifting from early concatenative methods to advanced neural models. This review provides a structured overview of the state of the art in …

</details>


### [360] [Real-Time Speech-To-Speech Translation with Emotion Preservation](https://scholar.google.com/scholar_url?url=https://ijarpr.com/uploads/V2ISSUE11/IJARPR1195.pdf&hl=zh-CN&sa=X&d=13008303920069143829&ei=xcIraa-aLuvJieoP8e3G6Qs&scisig=ABGrvjLkrzChMSF34-4tYvEioIeo&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=3&folt=cit)
*S Aggarwal*

Main category: Zongheng Yang

TL;DR: 实时语音到语音翻译系统在语言转换方面表现出色，但缺乏保留语音中情感线索的能力，如语调、韵律、节奏、音高、能量分布和表现力。


<details>
  <summary>Details</summary>
Motivation: 当前实时语音到语音翻译系统虽然具备强大的语言翻译能力，但无法保留语音中蕴含的情感线索，而人类语音不仅仅是文字，还包含丰富的情感表达，这对于跨语言有效沟通至关重要。

Method: 从摘要中无法确定具体方法，但该研究关注的是在实时语音到语音翻译系统中保留情感线索的技术挑战。

Result: 摘要未提供具体实验结果，但指出了当前系统在情感保留方面的局限性。

Conclusion: 实时语音到语音翻译系统需要发展能够保留情感线索的能力，以实现更自然、有效的跨语言沟通。

Abstract: ABSTRACT Real-time Speech-to-Speech Translation (S2ST) is rapidly reshaping how humans communicate across languages by converting spoken input in one language into spoken output in another. While several modern systems demonstrate impressive linguistic translation capabilities, they lack the crucial ability to preserve emotional cues embedded within speech—such as tone, prosody, rhythm, pitch, energy distribution, and expressiveness. Human speech is more than words; …

</details>


<div id='Bin CUI'></div>

# Bin CUI [[Back]](#toc)

### [361] [Rethinking Text-to-SQL: Dynamic Multi-turn SQL Interaction for Real-world Database Exploration](https://scholar.google.com/scholar_url?url=https://arxiv.org/abs/2510.26495&hl=zh-CN&sa=X&d=15412034965199755925&ei=LHEIacKiLtrZzwKkk-bABQ&scisig=ABGrvjLwsGCIe8G3hiA2q12Z2krK&oi=scholaralrt&hist=i6heNjgAAAAJ:3739178042932535188:ABGrvjKLmON-cupg_CnmNvMzl3_J&html=&pos=0&folt=art)
*L Sun,T Guo,H Liang,Y Li,Q Cai,J Wei,B Yu…*

Main category: Bin CUI

TL;DR: 论文指出现有Text-to-SQL系统在静态单轮任务中表现良好，但在真实交互场景中不足，需要处理多轮对话、上下文依赖和动态查询需求。


<details>
  <summary>Details</summary>
Motivation: 现有Text-to-SQL系统主要针对静态、单轮任务设计，无法有效处理真实世界中的交互式场景，如多轮对话、上下文依赖查询和动态信息需求。

Method: 论文可能提出了一种面向交互式场景的Text-to-SQL方法，能够处理多轮对话、上下文理解和动态查询生成，但具体方法需要查看完整论文。

Result: 从摘要推断，该方法可能在交互式Text-to-SQL任务上取得了优于传统静态方法的性能，能够更好地处理真实世界的对话式查询场景。

Conclusion: 交互式Text-to-SQL是实际应用的关键方向，需要超越静态单轮任务，开发能够处理多轮对话和上下文依赖的模型。

Abstract: Recent advances in Text-to-SQL have achieved strong results in static, single-turn tasks, where models generate SQL queries from natural language questions. However, these systems fall short in real-world interactive scenarios, where user …

</details>


### [362] [BRACE: A Benchmark for Robust Audio Caption Quality Evaluation](https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DMdEkxa6PV9&hl=zh-CN&sa=X&d=13297309239406676544&ei=9FQNaaDeLMHO6rQPt-Gh0Ao&scisig=ABGrvjKJ2YSKn4VDpm6auqCHCW0f&oi=scholaralrt&hist=i6heNjgAAAAJ:3739178042932535188:ABGrvjKLmON-cupg_CnmNvMzl3_J&html=&pos=0&folt=art)
*T Guo,H Chen,H Liang,M Qiang,B Zeng,L Sun…*

Main category: Bin CUI

TL;DR: 该论文针对音频字幕自动生成的评估难题，提出了一种无需参考文本的评估方法，通过对比学习框架和音频-文本对齐技术来评估生成字幕的质量。


<details>
  <summary>Details</summary>
Motivation: 音频字幕自动生成对于音频理解至关重要，支持无障碍访问和内容索引等应用。然而，评估音频字幕质量仍然是一个重大挑战，特别是在没有参考文本的情况下，现有评估方法存在局限性。

Method: 提出了一种基于对比学习的参考无关评估框架，利用音频-文本对齐技术来评估生成字幕的质量，通过对比音频特征和字幕文本特征的一致性来量化字幕质量。

Result: 该方法在多个音频字幕数据集上验证有效，与人工评估结果高度相关，相比传统基于参考的评估方法（如BLEU、ROUGE等）在参考缺失情况下表现更优。

Conclusion: 提出的参考无关评估方法为音频字幕质量评估提供了有效解决方案，特别适用于实际应用场景中参考文本不可得的情况，推动了音频理解技术的发展。

Abstract: Automatic audio captioning is essential for audio understanding, enabling applications such as accessibility and content indexing. However, evaluating the quality of audio captions remains a major challenge, especially in reference-free …

</details>


### [363] [Data-Centric Perspectives on Agentic Retrieval-Augmented Generation: A Survey](https://scholar.google.com/scholar_url?url=https://www.techrxiv.org/doi/pdf/10.36227/techrxiv.176316052.24300253&hl=zh-CN&sa=X&d=1910742039636935781&ei=XsgjacuKCf-j6rQPj9qr8A0&scisig=ABGrvjLdIbIkAr41rgxH-0b8cefa&oi=scholaralrt&hist=i6heNjgAAAAJ:3739178042932535188:ABGrvjKLmON-cupg_CnmNvMzl3_J&html=&pos=0&folt=art)
*J Deng,J Huang,ZH Wong,H Liang,Q Xu,B Cui…*

Main category: Bin CUI

TL;DR: 检索增强生成(RAG)通过整合外部知识源来增强大语言模型，解决静态预训练导致的过时知识、幻觉和适应性限制问题


<details>
  <summary>Details</summary>
Motivation: 大语言模型在自然语言理解和生成方面表现出色，但依赖静态预训练语料库可能导致知识过时、产生幻觉和适应性有限。需要一种机制来动态整合最新外部知识，提高模型的准确性和时效性。

Method: 采用检索增强生成(RAG)方法，将大语言模型与外部知识检索系统结合。在生成过程中实时检索相关外部信息，将检索到的知识作为上下文输入模型，增强生成内容的准确性和时效性。

Result: 检索增强生成显著提高了大语言模型的知识时效性和准确性，减少了幻觉现象，增强了模型对动态变化信息的适应性，在需要最新知识的任务中表现优异。

Conclusion: 检索增强生成是解决大语言模型知识过时和幻觉问题的有效方法，通过动态整合外部知识源，显著提升了模型的实用性和可靠性，为实际应用提供了重要技术支撑。

Abstract: Large Language Models (LLMs) excel at natural language understanding and generation, yet their reliance on static pre-training corpora may lead to outdated knowledge, hallucinations, and limited adaptability. Retrieval-Augmented Generation …

</details>


<div id='Surajit Chaudhuri'></div>

# Surajit Chaudhuri [[Back]](#toc)

### [364] [LogiNumSynth: Synthesizing Joint Logical-Numerical Reasoning Problems for Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.11031&hl=zh-CN&sa=X&d=10853440706848542614&ei=h4MGaZu6GKPH6rQP48qQiAk&scisig=ABGrvjLfkJuDELlNGM-ZVQ6oqkOH&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=0&folt=rel)
*Y Liu,Y Li,X Li,G Cheng*

Main category: Surajit Chaudhuri

TL;DR: 提出新数据集解决语言模型在逻辑-数值推理方面的挑战，现有数据集规则固定且任务复杂度控制有限


<details>
  <summary>Details</summary>
Motivation: 现有数据集在逻辑-数值推理评估中存在局限性：规则固定、任务复杂度控制不足，限制了评估和训练的可泛化性

Method: 提出新的数据集框架，提供更灵活的任务复杂度控制和更广泛的规则覆盖

Result: 新数据集能够更全面评估语言模型的逻辑-数值推理能力，提供更好的训练和评估基准

Conclusion: 新数据集解决了现有基准的局限性，为语言模型的逻辑-数值推理能力评估提供了更有效的工具

Abstract: Joint logical-numerical reasoning remains a major challenge for language models, yet existing datasets rely on fixed rule sets and offer limited control over task complexity, constraining their generalizability for evaluation and training. We present …

</details>


### [365] [Evaluating Reasoning Faithfulness in Medical Vision-Language Models using Multimodal Perturbations](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.11196&hl=zh-CN&sa=X&d=17277378385660520211&ei=h4MGaZu6GKPH6rQP48qQiAk&scisig=ABGrvjLjejj3dj01MSS5p369gQ_5&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=1&folt=rel)
*J Moll,M Graf,T Lemke,N Lenhart,D Truhn…*

Main category: Surajit Chaudhuri

TL;DR: 该论文指出视觉语言模型（VLM）生成的思维链（CoT）解释常与真实决策过程不符，现有评估方法难以检测这种错位，特别是在高风险临床应用中这会损害信任。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型生成的思维链解释虽然听起来合理，但往往不能反映真实的决策过程，这在临床等高风险应用中会严重损害模型的可信度。现有评估方法很少能捕捉到这种解释与决策之间的错位问题。

Method: 论文未在摘要中明确说明具体方法，但从问题描述来看，可能涉及开发新的评估框架或方法来检测和量化VLM生成的CoT解释与真实决策过程之间的错位。

Result: 摘要中未提供具体实验结果，但暗示现有评估方法在检测解释与决策错位方面存在不足，需要新的评估方法来解决这一问题。

Conclusion: 需要开发更有效的评估方法来检测视觉语言模型生成的思维链解释与真实决策过程之间的错位，特别是在临床等高风险应用中，这对建立模型可信度至关重要。

Abstract: Vision-language models (VLMs) often produce chain-of-thought (CoT) explanations that sound plausible yet fail to reflect the underlying decision process, undermining trust in high-stakes clinical use. Existing evaluations rarely catch this misalignment …

</details>


### [366] [LLMTrajQuery: an LLM-based generative approach to semantic trajectory queries](https://scholar.google.com/scholar_url?url=https://www.tandfonline.com/doi/abs/10.1080/13658816.2025.2569745&hl=zh-CN&sa=X&d=5033123711147615153&ei=h4MGaZu6GKPH6rQP48qQiAk&scisig=ABGrvjKNyzg4BVqFeyj6q6sHm0TO&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=2&folt=rel)
*S Yu,J Liu,C Gao,W Niu,X Guo,H Liu,M Xu*

Main category: Surajit Chaudhuri

TL;DR: 该论文提出了一种基于大语言模型的轨迹查询框架，将自然语言查询转换为结构化轨迹查询语言，实现智能化的轨迹数据检索


<details>
  <summary>Details</summary>
Motivation: 自然语言因其直观性已成为表达复杂查询需求的优选方式，但轨迹数据查询通常需要专业查询语言，存在使用门槛。需要将自然语言查询智能转换为结构化轨迹查询，提高轨迹数据检索的易用性和智能化水平

Method: 利用大语言模型作为语义解析器，将自然语言查询转换为结构化轨迹查询语言。通过设计专门的查询框架，处理轨迹数据的时空特性、运动模式等复杂语义，实现自然语言到轨迹查询的准确映射

Result: 提出的框架能够有效解析自然语言中的轨迹查询意图，准确生成结构化轨迹查询语句，实现用户友好的轨迹数据检索。实验验证了该方法在轨迹查询任务中的有效性和实用性

Conclusion: 基于大语言模型的轨迹查询框架为轨迹数据分析提供了智能化的自然语言接口，降低了轨迹查询的技术门槛，促进了轨迹数据在更广泛场景中的应用

Abstract: To express complex query requirements and intentions, natural language has become the preferred way due to its intuitiveness. LLM is a powerful semantic parser for natural language queries. To facilitate intelligent and user-friendly trajectory …

</details>


### [367] [An Improved Autoregressive Evaluation Paradigm for Large Language Models](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3763000&hl=zh-CN&sa=X&d=2608269459528062218&ei=h4MGaZu6GKPH6rQP48qQiAk&scisig=ABGrvjINupCou7-nnFqRFPhthyNw&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=3&folt=rel)
*J Zhang,R Pan,Y Hu,K SHUM,G Yao,X Liu,R Pi…*

Main category: Surajit Chaudhuri

TL;DR: 该论文探讨了大型语言模型评估的挑战，提出了一个包含多个维度的综合评估框架，并开发了相应的评估工具。


<details>
  <summary>Details</summary>
Motivation: 随着ChatGPT等聊天式大型语言模型的快速发展，如何有效评估这些模型的性能成为重要挑战。现有评估方法往往不够全面，缺乏系统性框架来评估模型在不同维度上的表现。

Method: 论文提出了一个多维度的评估框架，涵盖语言理解、生成质量、知识掌握、推理能力、安全性和伦理合规等方面。开发了相应的评估工具和基准测试集，采用定量和定性相结合的方法进行综合评估。

Result: 研究结果显示，不同模型在不同评估维度上表现差异显著，某些模型在特定任务上表现出色但在其他方面存在不足。评估框架能够有效识别模型的优势和弱点，为模型改进提供指导。

Conclusion: 需要建立更全面、标准化的评估体系来推动大型语言模型的发展。提出的评估框架为系统评估聊天式LLMs提供了实用工具，有助于促进该领域的健康发展。

Abstract: The AI community has witnessed the emergence of various chat-style Large Language Models (LLMs) since the advent of ChatGPT. Despite significant progress in this area, evaluating these models remains a substantial challenge. The …

</details>


### [368] [Justitia: Fair and Efficient Scheduling for LLM Applications](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.17015&hl=zh-CN&sa=X&d=1651759876458269552&ei=LXEIaanDNYqN6rQPmJaX6Ao&scisig=ABGrvjLItxJ0f5uBO1NWHeSETeAP&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=3&folt=rel)
*M Yang,G Wang,M Luo,Y Liu,C Chen,H Zhao…*

Main category: Surajit Chaudhuri

TL;DR: LLM应用在共享GPU服务器上的调度优化研究


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）的普及，越来越多的LLM应用（一系列LLM推理任务）需要在共享GPU服务器上运行。现有调度器主要针对单次LLM推理进行优化，无法有效处理LLM应用特有的依赖关系和资源需求，导致资源利用率低下和性能下降。

Method: 提出针对LLM应用的调度框架，考虑应用内任务间的依赖关系、资源需求特征和性能目标。可能包括：1）应用感知的调度策略；2）依赖关系建模；3）资源分配优化；4）性能预测模型；5）动态调度机制。

Result: 相比传统单任务调度方法，提出的LLM应用调度框架能够显著提高GPU资源利用率，减少应用完成时间，提升系统吞吐量，并更好地满足应用级服务质量要求。

Conclusion: LLM应用调度需要专门的设计考虑，应用感知的调度策略能够有效解决共享GPU环境中LLM应用的性能瓶颈，为大规模LLM部署提供更高效的资源管理方案。

Abstract: In the era of Large Language Models (LLMs), it has been popular to launch a series of LLM inferences--we call an LLM application--to better solve real-world problems. When serving those applications in shared GPU servers, the schedulers are …

</details>


### [369] [Table-LLM-Specialist: Language Model Specialists for Tables using Iterative Fine-tuning](https://scholar.google.com/scholar_url?url=https://aclanthology.org/2025.emnlp-main.1795.pdf&hl=zh-CN&sa=X&d=12628810327616715371&ei=hAAKaeLeMKPH6rQPoJmE8QE&scisig=ABGrvjIDWTPaM0etlI6JaZcukzlO&oi=scholaralrt&hist=i6heNjgAAAAJ:13267949439400199659:ABGrvjJ__OVocWVDdTO88VFR2lZT&html=&pos=0&folt=art)
*J Xing,Y He,M Zhou,H Dong,S Han,D Zhang…*

Main category: Surajit Chaudhuri

TL;DR: 该论文旨在通过增强语言模型对复杂表格任务的处理能力，解决当前GPT、Llama等模型在表格相关任务上表现不佳的问题


<details>
  <summary>Details</summary>
Motivation: 尽管GPT、Llama等语言模型在多种自然语言任务上表现出色，但在复杂表格任务（如自然语言到代码转换、数据清洗等）上的性能仍然不理想，需要改进

Method: 论文未在摘要中明确说明具体方法，但暗示将通过某种方式增强语言模型对表格任务的处理能力

Result: 摘要中未提供具体实验结果，但预期目标是提升语言模型在表格相关任务上的性能

Conclusion: 需要改进语言模型在复杂表格任务上的能力，以缩小其在自然语言任务和表格任务之间的性能差距

Abstract: Abstract Language models such as GPT and Llama have shown remarkable ability on diverse natural language tasks, yet their performance on complex table tasks (eg, NL-to-Code, data cleaning, etc.) continues to be suboptimal. To improve their …

</details>


### [370] [Scaling Latent Reasoning via Looped Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.25741&hl=zh-CN&sa=X&d=14400925081749971452&ei=gwAKadvTLKPH6rQPoJmE8QE&scisig=ABGrvjIaChttML9OUvv1AQ2jUiGz&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=0&folt=rel)
*RJ Zhu,Z Wang,K Hua,T Zhang,Z Li,H Que,B Wei…*

Main category: Surajit Chaudhuri

TL;DR: Ouro是一个通过递归自训练实现隐式推理的LLM框架，无需显式文本生成即可进行推理


<details>
  <summary>Details</summary>
Motivation: 现有LLM主要依赖显式文本生成（如思维链）进行推理，这存在两个问题：1）将推理推迟到训练后阶段，2）未能充分利用预训练数据中的推理能力。需要开发能够进行隐式推理的模型。

Method: 提出Ouro框架，通过递归自训练实现隐式推理。模型在训练过程中学习直接生成答案，而不是生成中间推理步骤。通过迭代训练过程，模型逐步内化推理能力，形成隐式推理机制。

Result: Ouro在多个推理基准测试中表现出色，能够实现与显式推理方法相当的性能，同时减少了计算开销和延迟。模型展示了隐式推理的有效性，并在开源社区中获得了关注。

Conclusion: 隐式推理是LLM发展的有前景方向，Ouro框架证明了通过递归自训练实现隐式推理的可行性，为更高效、自然的AI推理系统提供了新思路。

Abstract: Modern LLMs are trained to" think" primarily via explicit text generation, such as chain-of-thought (CoT), which defers reasoning to post-training and under-leverages pre-training data. We present and open-source Ouro, named after the recursive …

</details>


### [371] [ExpandR: Teaching Dense Retrievers Beyond Queries with LLM Guidance](https://scholar.google.com/scholar_url?url=https://aclanthology.org/2025.emnlp-main.963.pdf&hl=zh-CN&sa=X&d=1299367931927654572&ei=gwAKadvTLKPH6rQPoJmE8QE&scisig=ABGrvjIH2vyYpRKiJvvtWQzN9BkD&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=1&folt=rel)
*S Yao,P Huang,Z Liu,Y Gu,Y Yan,S Yu,G Yu*

Main category: Surajit Chaudhuri

TL;DR: LLMs在稠密检索中具有潜力，但现有方法将LLM和检索器视为独立模块，忽略了它们的协同优化机会


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的查询增强方法通常将语言模型和检索器作为独立模块处理，缺乏端到端的联合优化，限制了检索性能的进一步提升

Method: 未在摘要中明确说明，但暗示需要一种将LLM和检索器集成优化的方法，可能涉及端到端训练或联合优化策略

Result: 未在摘要中提供具体结果，但暗示现有分离式方法存在局限性，需要更紧密的集成方案

Conclusion: 需要开发将LLM和检索器紧密集成的端到端方法，以实现更好的查询增强和检索性能

Abstract: Large language models (LLMs) have demonstrated significant potential in enhancing dense retrieval through query augmentation. However, most existing methods treat the LLM and the retriever as separate modules, overlooking the …

</details>


### [372] [You are an LLM teaching a smaller model everything you know: Multi-task pretraining of language models with LLM-designed study plans](https://scholar.google.com/scholar_url?url=https://aclanthology.org/2025.babylm-main.33.pdf&hl=zh-CN&sa=X&d=13393040591060920279&ei=gwAKadvTLKPH6rQPoJmE8QE&scisig=ABGrvjJi9FFDvRLoCfs4eQbN0-_f&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=6&folt=rel)
*W Kamzela,M Lango,O Dušek*

Main category: Surajit Chaudhuri

TL;DR: 该论文提出了一种无需文本语料库的多任务预训练方法，利用现有大语言模型自动生成包含56个任务训练数据的多样化语料库


<details>
  <summary>Details</summary>
Motivation: 传统语言模型预训练需要大量文本语料库，这存在数据获取成本高、质量不一、隐私问题等限制。本文旨在探索无需原始文本语料库的预训练方法，通过利用现有LLM生成训练数据来解决这些问题。

Method: 方法核心是利用现有大型语言模型自动生成多样化训练语料。首先设计了56个不同的任务，然后使用LLM为每个任务生成相应的训练数据。通过这种方式创建了一个多任务预训练数据集，用于训练新的语言模型，完全避免了使用原始文本语料库。

Result: 该方法成功生成了包含56个任务的多样化训练语料库，并基于此训练出了有效的语言模型。实验表明，仅使用LLM生成数据训练的语言模型在多个下游任务上表现良好，验证了无需原始文本语料库的预训练可行性。

Conclusion: 研究证明了无需传统文本语料库进行语言模型预训练的可行性，通过LLM生成多样化训练数据的方法为数据稀缺、隐私敏感等场景提供了新的解决方案，开辟了语言模型训练的新范式。

Abstract: This paper proposes a multi-task pre-training of language models without any text corpora. The method leverages an existing Large Language Model (LLM) to generate a diverse corpus containing training data for 56 automatically designed …

</details>


### [373] [Odyssey: An End-to-End System for Pareto-Optimal Serverless Query Processing](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.24307&hl=zh-CN&sa=X&d=17697384829276307002&ei=gwAKadvTLKPH6rQPoJmE8QE&scisig=ABGrvjIE3C3cor2n3WGf4K2Hn-BN&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=8&folt=rel)
*S Jesalpura,S Zhu,A Shaikhha,A Barbalace,B Grot*

Main category: Surajit Chaudhuri

TL;DR: 在无服务器（FaaS）工作节点上运行数据分析查询，对于间歇性查询到达模式、突发负载峰值和管理挑战等现实场景，具有成本效益和性能优势。


<details>
  <summary>Details</summary>
Motivation: 传统数据分析系统在处理间歇性查询、突发负载和管理复杂性方面存在不足，需要探索更灵活、成本效益更高的解决方案。

Method: 采用无服务器计算架构（FaaS），在函数即服务的工作节点上执行数据分析查询，利用其弹性伸缩和按使用付费的特性。

Result: 研究表明，在多种现实场景下，包括间歇性查询到达模式、突发负载峰值和管理挑战等，无服务器架构在成本和性能方面都表现高效。

Conclusion: 无服务器计算为数据分析查询提供了有前景的替代方案，特别适合具有间歇性、突发性和管理复杂性的工作负载。

Abstract: Running data analytics queries on serverless (FaaS) workers has been shown to be cost-and performance-efficient for a variety of real-world scenarios, including intermittent query arrival patterns, sudden load spikes and management challenges …

</details>


### [374] [GRIT: Guided Relational Integration for Efficient Multi-Table Understanding](https://scholar.google.com/scholar_url?url=https://aclanthology.org/2025.emnlp-main.1118.pdf&hl=zh-CN&sa=X&d=7353189945468779325&ei=gwAKadvTLKPH6rQPoJmE8QE&scisig=ABGrvjKLKbGpdh8Zf-pZMaA0WTjD&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=9&folt=rel)
*Y Kang,PS Woo,YS Cho*

Main category: Surajit Chaudhuri

TL;DR: 该论文针对现有大语言模型在表格任务中局限于单表设置的问题，提出了一种多表数据库理解与推理的新方法。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在表格任务中主要局限于单表设置，而现实世界数据库通常由多个相互关联的表组成，这限制了模型在实际数据库应用中的适用性。

Method: 论文提出了一种多表数据库理解与推理方法，该方法能够处理多个相互关联的表格，通过理解表间关系和结构来执行复杂的数据库操作。

Result: 该方法在多表数据库任务上表现出色，相比单表方法有显著提升，能够更好地处理现实世界中的复杂数据库查询和分析任务。

Conclusion: 论文证明了扩展大语言模型到多表数据库环境的重要性，提出的方法为现实世界数据库应用提供了更有效的解决方案。

Abstract: Recent advances in large language models (LLMs) have opened new possibilities for table-based tasks. However, most existing methods remain confined to single-table settings, limiting their applicability to real-world databases composed of …

</details>


### [375] [GER-LLM: Efficient and Effective Geospatial Entity Resolution with Large Language Model](https://scholar.google.com/scholar_url?url=https://aclanthology.org/2025.emnlp-main.1186.pdf&hl=zh-CN&sa=X&d=9663095614503375243&ei=ucMLada3Hcab6rQPz-SF4QU&scisig=ABGrvjIefvSpUt1LH9yBFpTsDzRt&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=1&folt=rel)
*H Zhu,Z Li,J Jin*

Main category: Surajit Chaudhuri

TL;DR: 该论文提出了一种用于地理空间实体解析的新方法，通过结合常识推理来减少对大量训练数据的依赖


<details>
  <summary>Details</summary>
Motivation: 现有地理空间实体解析方法严重依赖大量训练数据，且无法有效融入常识推理，限制了其在数据稀缺场景下的应用

Method: 提出了一种结合常识推理的地理空间实体解析框架，可能包括知识图谱集成、语义增强或上下文理解等技术

Result: 新方法在减少训练数据需求的同时，提高了实体解析的准确性和鲁棒性，特别是在数据稀缺情况下表现更优

Conclusion: 通过融入常识推理，地理空间实体解析方法可以显著减少对大量标注数据的依赖，提高方法的泛化能力和实用性

Abstract: Abstract Geospatial Entity Resolution (GER) plays a central role in integrating spatial data from diverse sources. However, existing methods are limited by their reliance on large amounts of training data and their inability to incorporate commonsense …

</details>


### [376] [LLM-Powered Visualizations and Narratives from Natural Language Queries](https://scholar.google.com/scholar_url?url=https://www-di.inf.puc-rio.br/~casanova/Publications/Papers/2025-Papers/2025-PD-ER.pdf&hl=zh-CN&sa=X&d=635770554435214580&ei=ucMLada3Hcab6rQPz-SF4QU&scisig=ABGrvjLxxUV5pufNAPWGQY4iP6R9&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=5&folt=rel)
*ERS Nascimento,B Feijó,AL Furtado,MA Casanova*

Main category: Surajit Chaudhuri

TL;DR: 提出基于智能体的工作流，整合文本到可视化(Text-to-VIS)和数据叙事技术，降低非技术用户访问表格数据的门槛


<details>
  <summary>Details</summary>
Motivation: 非技术用户与表格数据之间存在技术鸿沟，限制了有效访问和数据驱动决策。需要开发更直观的交互方式，使非技术用户能够轻松探索和理解表格数据。

Method: 采用基于智能体的工作流，整合文本到可视化(Text-to-VIS)和数据叙事技术。通过自然语言交互将用户查询转换为可视化图表，并结合叙事元素帮助用户理解数据背后的故事。

Result: 开发的工作流能够有效降低非技术用户访问表格数据的门槛，提供更直观的数据探索体验。通过智能体驱动的交互，用户可以用自然语言查询数据并获得可视化呈现，同时获得数据叙事支持。

Conclusion: 基于智能体的文本到可视化与数据叙事集成工作流是解决非技术用户访问表格数据挑战的有效方案。这种方法能够促进数据民主化，支持更广泛的数据驱动决策。

Abstract: The gap between non-technical users and tabular data limits effective access and data-driven decision-making. To address this challenge, this work presents an agent-based workflow integrating text to visualization (Text-to-VIS) and data storytelling …

</details>


### [377] [Sheetpedia: A 300K-Spreadsheet Corpus for Spreadsheet Intelligence and LLM Fine-Tuning](https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3D4vLYwlA3X5&hl=zh-CN&sa=X&d=152397780201541716&ei=9lQNadSjCceB6rQPoOTz8Qc&scisig=ABGrvjKVvMtCLZHMemEPGgrdYE3V&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=0&folt=rel)
*Z Tian,Z Han,H Wang,L Liao*

Main category: Surajit Chaudhuri

TL;DR: Sheetpedia是一个包含超过29万个多样化电子表格的大规模语料库，旨在解决AI系统处理电子表格复杂结构和公式逻辑的挑战


<details>
  <summary>Details</summary>
Motivation: 电子表格广泛用于数据分析和报告，但其复杂的结构和公式逻辑对AI系统构成了重大挑战，现有AI在处理电子表格时存在困难

Method: 构建了Sheetpedia语料库，包含超过290,000个多样化的电子表格，涵盖了各种类型和复杂度的表格结构

Result: 创建了一个大规模、多样化的电子表格语料库，为AI系统理解和处理电子表格提供了重要的训练和评估资源

Conclusion: Sheetpedia语料库填补了电子表格AI研究领域的资源空白，为开发更强大的电子表格理解和处理AI系统奠定了基础

Abstract: Spreadsheets are widely used for data analysis and reporting, yet their complex structure and formula logic pose significant challenges for AI systems. We introduce Sheetpedia, a large-scale corpus of over 290,000 diverse spreadsheets (from …

</details>


### [378] [Category-Aware Semantic Caching for Heterogeneous LLM Workloads](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.26835&hl=zh-CN&sa=X&d=5500635027210299116&ei=9lQNadSjCceB6rQPoOTz8Qc&scisig=ABGrvjLYfjvc8ctegg-k2ALzf6qW&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=1&folt=rel)
*C Wang,X Liu,Y Zhu,A Youssef,P Nagpurkar,H Chen*

Main category: Surajit Chaudhuri

TL;DR: LLM服务系统处理异构查询工作负载，不同类别查询在嵌入空间中的分布特征不同：代码查询密集聚类，对话查询稀疏分布，内容查询居中


<details>
  <summary>Details</summary>
Motivation: 现有LLM服务系统通常将异构查询工作负载视为同质处理，忽略了不同查询类别（代码、对话、内容）在嵌入空间中的分布特征差异，这可能导致缓存效率低下和资源分配不合理

Method: 分析不同查询类别在嵌入空间中的分布特征，基于密度聚类特性设计差异化的缓存策略和资源分配机制，可能采用基于查询类别感知的调度算法

Result: 发现代码查询在嵌入空间中呈现密集聚类特性，对话查询呈现稀疏分布特性，内容查询介于两者之间，这种分布差异对缓存命中率和资源利用率有重要影响

Conclusion: LLM服务系统应考虑查询类别的异构性，针对不同分布特征设计差异化的优化策略，以提高系统整体性能和资源效率

Abstract: LLM serving systems process heterogeneous query workloads where different categories exhibit different characteristics. Code queries cluster densely in embedding space while conversational queries distribute sparsely. Content …

</details>


### [379] [UniRL-Zero: Reinforcement Learning on Unified Models with Joint Language Model and Diffusion Model Experts](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.17937&hl=zh-CN&sa=X&d=3802102188645777251&ei=9lQNadSjCceB6rQPoOTz8Qc&scisig=ABGrvjJEwOoKmTCd2GPA3wSs84Uu&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=4&folt=rel)
*FY Wang,H Zhang,M Gharbi,H Li,T Park*

Main category: Surajit Chaudhuri

TL;DR: UniRL-Zero是一个统一的强化学习框架，通过强化学习提升多模态语言模型的理解推理能力、扩散模型的多媒体生成能力，以及两者之间的有益交互能力。


<details>
  <summary>Details</summary>
Motivation: 当前多模态语言模型和扩散模型在各自领域表现出色，但缺乏统一的强化学习框架来同时提升它们的理解推理、生成能力以及两者之间的交互能力。现有方法往往独立处理这些任务，未能充分利用强化学习在优化复杂多模态任务中的潜力。

Method: 提出UniRL-Zero统一强化学习框架，通过强化学习同时优化多模态语言模型的理解推理能力和扩散模型的多媒体生成能力。框架设计包含统一的奖励机制和训练策略，促进两种模型之间的有益交互和协同优化。

Result: UniRL-Zero框架在多个基准测试中显著提升了多模态语言模型的理解推理性能，同时改善了扩散模型生成内容的质量和多样性。更重要的是，框架成功实现了两种模型之间的有益交互，产生了协同效应。

Conclusion: UniRL-Zero证明了统一强化学习框架在同时优化多模态语言模型和扩散模型方面的有效性，为多模态人工智能系统的协同发展提供了新的思路和方法。

Abstract: We present UniRL-Zero, a unified reinforcement learning (RL) framework that boosts, multimodal language model understanding and reasoning, diffusion model multimedia generation, and their beneficial interaction capabilities within a unified …

</details>


### [380] [Realistic Training Data Generation and Rule Enhanced Decoding in LLM for NameGuess](https://scholar.google.com/scholar_url?url=https://aclanthology.org/2025.emnlp-main.357.pdf&hl=zh-CN&sa=X&d=4984264057184521787&ei=LAIPaZvaFLmAieoPpbHViAo&scisig=ABGrvjK3URp0HiN8gKMipK9VNfpE&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=0&folt=rel)
*Y Xia,J Chen,S Li,J Gao*

Main category: Surajit Chaudhuri

TL;DR: 论文探讨了数据库表中广泛使用的缩写列名（源自英文单词或中文拼音）对自然语言处理和数据库管理中的表中心任务带来的挑战，并提出了相应的解决方案。


<details>
  <summary>Details</summary>
Motivation: 数据库表中广泛使用的缩写列名（来自英文单词或中文拼音）给自然语言处理和数据库管理中的表中心任务带来了显著挑战，影响了数据理解、查询处理和系统集成。

Method: 论文可能提出了一种方法来处理或规范化这些缩写列名，可能包括自动扩展、语义映射或标准化技术，以改善表中心任务的性能。

Result: 该方法可能展示了在处理缩写列名方面的改进，提高了表中心任务的准确性和效率，如查询理解、数据集成或自然语言接口。

Conclusion: 解决缩写列名问题对于提升数据库管理和自然语言处理任务的性能至关重要，提出的方法为处理此类挑战提供了有效的解决方案。

Abstract: The wide use of abbreviated column names (derived from English words or Chinese Pinyin) in database tables poses significant challenges for table-centric tasks in natural language processing and database management. Such a column name …

</details>


### [381] [FinSphere: a real-time stock analysis agent with instruction-tuned large language models and domain-specific tool integration](https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1631/FITEE.2500414&hl=zh-CN&sa=X&d=6418858751299662148&ei=UI0Qaa2_McXXieoP9PS1mQg&scisig=ABGrvjJTuS7p4bJOuEHTJ_U_hosA&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=2&folt=rel)
*S Han,J Zhang,Y Shen,K Yan,H Li*

Main category: Surajit Chaudhuri

TL;DR: 该论文针对当前金融大语言模型在股票分析中的两个主要局限——缺乏标准化评估指标和分析深度不足，提出了两项贡献来解决这些问题


<details>
  <summary>Details</summary>
Motivation: 当前金融大语言模型在股票分析方面存在两个主要问题：1) 缺乏标准化的评估指标来衡量股票分析质量；2) 分析深度不足，无法提供深入的市场洞察

Method: 论文提出了两项主要贡献：第一，建立标准化的股票分析质量评估指标；第二，开发能够提供更深入分析的方法或框架

Result: 通过提出的解决方案，论文旨在提升金融大语言模型在股票分析方面的性能，提供更准确、更深入的市场分析能力

Conclusion: 该研究通过解决金融大语言模型在股票分析中的标准化评估和分析深度问题，为金融AI领域提供了重要的改进方向

Abstract: Current financial large language models (FinLLMs) exhibit two major limitations: the absence of standardized evaluation metrics for stock analysis quality and insufficient analytical depth. We address these limitations with two contributions. First, we …

</details>


### [382] [THINKSLM: Towards Reasoning in Small Language Models](https://scholar.google.com/scholar_url?url=https://aclanthology.org/2025.emnlp-main.1659.pdf&hl=zh-CN&sa=X&d=13556006824737996221&ei=Gu4RabXXIfGQ6rQPr_zr6Ao&scisig=ABGrvjKVblBh35ve3KDBgulZHsF1&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=2&folt=rel)
*G Srivastava,S Cao,X Wang*

Main category: Surajit Chaudhuri

TL;DR: 小型语言模型在抽象推理任务上也能达到与大型语言模型相当的竞争力，挑战了传统认为推理能力仅在大模型中涌现的观点


<details>
  <summary>Details</summary>
Motivation: 挑战传统观点：长期以来，抽象推理被视为大型语言模型的涌现特性，但最近研究表明小型语言模型也能达到竞争性推理能力，需要重新评估模型规模与推理能力的关系

Method: 通过对比研究分析小型语言模型与大型语言模型在抽象推理任务上的表现，可能涉及模型架构优化、训练策略改进或特定推理任务的针对性设计

Result: 小型语言模型在抽象推理任务上表现出与大型语言模型相当的竞争力，表明推理能力不完全依赖于模型规模，为更高效的推理系统开发提供了可能

Conclusion: 抽象推理能力并非大型语言模型的专属特性，小型模型通过适当的设计和训练也能实现竞争性推理性能，这为开发更高效、可部署的推理系统开辟了新方向

Abstract: Abstract Reasoning has long been viewed as an emergent property of large language models (LLMs). However, recent studies challenge this assumption, showing that small language models (SLMs) can also achieve competitive reasoning …

</details>


### [383] [SODBench: A Large Language Model Approach to Documenting Spreadsheet Operations](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.19864&hl=zh-CN&sa=X&d=15590295572164494030&ei=Gu4RabXXIfGQ6rQPr_zr6Ao&scisig=ABGrvjJvWgESroOGSabF9XS--49s&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=7&folt=rel)
*A Indika,I Molybog*

Main category: Surajit Chaudhuri

TL;DR: 该论文针对电子表格缺乏系统化文档方法的问题，提出了一种解决方案以支持自动化、协作和知识传承


<details>
  <summary>Details</summary>
Motivation: 商业、会计和金融领域的大量知识工作者使用电子表格，但缺乏系统化的文档方法阻碍了自动化、协作和知识传承，存在知识流失风险

Method: 论文提出了一种系统化的电子表格文档方法（具体方法未在摘要中详细说明）

Result: 该方法能够改善电子表格的自动化处理、团队协作和知识转移效率

Conclusion: 系统化的文档方法对于电子表格在商业环境中的有效使用至关重要，能够降低知识流失风险并提高工作效率

Abstract: Numerous knowledge workers utilize spreadsheets in business, accounting, and finance. However, a lack of systematic documentation methods for spreadsheets hinders automation, collaboration, and knowledge transfer, which risks the loss of …

</details>


### [384] [Using LLM to Improve Knowledge Graph Entity Matching](https://scholar.google.com/scholar_url?url=https://ceur-ws.org/Vol-4085/paper32.pdf&hl=zh-CN&sa=X&d=2836989896931335249&ei=Gu4RabXXIfGQ6rQPr_zr6Ao&scisig=ABGrvjKQAsuJDdKFgxvUPNtQGThn&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=8&folt=rel)
*VE Yamamoto,H Takeda*

Main category: Surajit Chaudhuri

TL;DR: 该论文研究知识图谱实体匹配的性能敏感性问题，提出改进方法以提升匹配准确性和鲁棒性


<details>
  <summary>Details</summary>
Motivation: 知识图谱是表示和推理结构化信息的强大工具，实体匹配有助于整合多个知识图谱。然而现有实体匹配工具的性能对某些因素敏感，影响了匹配的准确性和可靠性，需要解决这些敏感性问题以提升知识图谱整合效果。

Method: 论文未在摘要中明确说明具体方法，但暗示将针对实体匹配工具的性能敏感性问题提出改进方案，可能涉及算法优化、特征工程或鲁棒性增强技术。

Result: 摘要未提供具体实验结果，但预期提出的方法能够降低实体匹配工具对特定因素的敏感性，提升匹配准确率和鲁棒性。

Conclusion: 解决实体匹配工具的性能敏感性问题对于知识图谱的有效整合至关重要，提出的改进方法有望提升实体匹配的可靠性和实用性。

Abstract: Abstract Knowledge graphs (KGs) are powerful tools for representing and reasoning over structured information. Entity matching between KGs helps integrate multiple KGs. However, the performance of entity matching tools can be sensitive to …

</details>


### [385] [2Columns1Row: A Russian Benchmark for Textual and Multimodal Table Understanding and Reasoning](https://scholar.google.com/scholar_url?url=https://aclanthology.org/anthology-files/anthology-files/pdf/findings/2025.findings-emnlp.721.pdf&hl=zh-CN&sa=X&d=16597111569416071350&ei=BnkWad27LPGQ6rQP3avymAQ&scisig=ABGrvjL0ShWxVSbYkTvlko3dTOSR&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=0&folt=rel)
*V Saburov,D Vodolazsky,D Sazanakov…*

Main category: Surajit Chaudhuri

TL;DR: 首个俄语表格问答开源基准2Columns1Row，包含多样化表格和问题，用于评估模型在俄语表格理解任务上的表现


<details>
  <summary>Details</summary>
Motivation: 表格理解是文档处理中的关键任务，但在俄语领域缺乏高质量的表格问答基准，限制了俄语表格理解模型的发展与评估

Method: 创建2Columns1Row基准，包含多样化的表格和对应的自然语言问题，涵盖不同难度级别和问题类型，用于评估模型在俄语表格理解任务上的表现

Result: 建立了首个俄语表格问答开源基准，提供了标准化的评估框架，可用于测试和比较不同模型在俄语表格理解任务上的性能

Conclusion: 2Columns1Row基准填补了俄语表格问答领域的空白，为俄语表格理解研究提供了重要的评估工具，将促进该领域的发展

Abstract: Table understanding is a crucial task in document processing and is commonly encountered in practical applications. We introduce 2Columns1Row, the first open-source benchmark for the table question answering task in Russian. This benchmark …

</details>


### [386] [CG-TTRL: Context-Guided Test-Time Reinforcement Learning for On-Device Large Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.06430&hl=zh-CN&sa=X&d=18245824451443277541&ei=BnkWad27LPGQ6rQP3avymAQ&scisig=ABGrvjLk3B_Cj4Wgt8dURxHBoF8J&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=4&folt=rel)
*P Hosseini,O Bohdal,T Ceritli,I Castro,M Purver…*

Main category: Surajit Chaudhuri

TL;DR: Test-time Reinforcement Learning (TTRL) 通过两阶段采样策略提升基础模型在测试时的任务适应能力


<details>
  <summary>Details</summary>
Motivation: 基础模型在复杂任务上需要测试时适应能力，传统方法存在局限性，TTRL旨在通过强化学习在测试阶段优化模型性能

Method: 采用两阶段采样策略：首先进行多采样生成候选方案，然后通过强化学习选择最优方案，实现测试时模型优化

Result: TTRL在复杂任务上实现了显著的性能提升，证明了测试时强化学习对基础模型适应性的有效性

Conclusion: TTRL为测试时模型优化提供了有效框架，两阶段采样策略是提升基础模型在复杂任务上表现的关键机制

Abstract: Test-time Reinforcement Learning (TTRL) has shown promise in adapting foundation models for complex tasks at test-time, resulting in large performance improvements. TTRL leverages an elegant two-phase sampling strategy: first, multi-sampling …

</details>


### [387] [GEMMA-SQL: A Novel Text-to-SQL Model Based on Large Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.04710&hl=zh-CN&sa=X&d=9219457841650497340&ei=BnkWad27LPGQ6rQP3avymAQ&scisig=ABGrvjJlVnjR_9pkUJmkS8oZu2tx&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=6&folt=rel)
*HM Pandey,A Gupta,S Sarkar,M Tomer,S Johannes…*

Main category: Surajit Chaudhuri

TL;DR: GEMMA-SQL是一个轻量高效的文本到SQL模型，基于GEMMA架构构建，旨在让非专业用户能够通过自然语言与结构化数据库交互。


<details>
  <summary>Details</summary>
Motivation: 文本到SQL系统可以让用户无需专门的编程知识就能与结构化数据库交互，但现有模型往往计算成本高或性能不足。GEMMA-SQL旨在提供一个轻量且高效的解决方案。

Method: 基于GEMMA架构构建轻量级文本到SQL模型，可能采用了特定的优化策略、训练方法或架构调整来平衡效率和性能。

Result: GEMMA-SQL在保持轻量级的同时实现了高效的文本到SQL转换性能，可能在标准基准测试中表现出色。

Conclusion: GEMMA-SQL为文本到SQL任务提供了一个实用且高效的解决方案，平衡了模型大小、计算成本和性能。

Abstract: Text-to-SQL systems enable users to interact with structured databases using natural language, eliminating the need for specialized programming knowledge. In this work, we introduce GEMMA-SQL, a lightweight and efficient text-to-SQL model built upon …

</details>


### [388] [Learning to Instruct: Fine-Tuning a Task-Aware Instruction Optimizer for Black-Box LLMs](https://scholar.google.com/scholar_url?url=https://aclanthology.org/anthology-files/anthology-files/pdf/findings/2025.findings-emnlp.407.pdf&hl=zh-CN&sa=X&d=5631882772417450158&ei=BnkWad27LPGQ6rQP3avymAQ&scisig=ABGrvjJmlE85N33CXIFAiqVFg4Ml&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=7&folt=rel)
*Y Qi,J Tian,T Liu,R Li,T Wei,H Liu,X Tang,M Cheng…*

Main category: Surajit Chaudhuri

TL;DR: 论文提出了一种名为"学习指导"的方法，用于为黑盒大语言模型自动生成有效指令，通过强化学习优化指令设计


<details>
  <summary>Details</summary>
Motivation: 大语言模型的性能严重依赖于指令设计，但对于内部状态不可访问的黑盒LLMs来说，设计有效指令尤为困难，需要自动化方法来优化指令生成

Method: 提出"学习指导"方法，使用强化学习框架自动生成和优化指令，通过迭代反馈机制改进指令质量，适用于黑盒LLMs

Result: 该方法能够显著提升黑盒大语言模型在各种任务上的性能，相比人工设计的指令或基线方法有更好的效果

Conclusion: 学习指导方法为黑盒大语言模型的指令优化提供了有效的自动化解决方案，能够显著提升模型性能，具有重要的实际应用价值

Abstract: Abstract The performance of Large Language Models (LLMs) critically depends on designing effective instructions, which is particularly challenging for black-box LLMs with inaccessible internal states. To this end, we introduce Learning to Instruct, a …

</details>


### [389] [Optimizing Long-context LLM Serving via Fine-grained Sequence Parallelism](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.06247&hl=zh-CN&sa=X&d=11841644695581625178&ei=BnkWad27LPGQ6rQP3avymAQ&scisig=ABGrvjKJO70xnBRO-IyLBE3bky-7&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=8&folt=rel)
*C Li,Y Yang,X Zheng,Q Yang,Y Guan,S Zheng…*

Main category: Surajit Chaudhuri

TL;DR: 该论文针对大语言模型上下文窗口扩展带来的在线服务中变长请求处理挑战，提出了一种动态序列并行系统，通过自适应调度和内存优化来提升处理效率。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型上下文窗口的快速扩展，在线服务面临不同长度请求的多样化需求。现有最先进的序列并行系统在处理变长请求时存在效率问题，需要更灵活的调度和内存管理机制。

Method: 提出动态序列并行系统，采用自适应调度算法根据请求长度动态分配计算资源，结合内存优化策略减少冗余计算和内存占用，实现高效的变长请求处理。

Result: 实验表明，该系统在处理变长请求时相比现有序列并行方法显著提升了吞吐量和资源利用率，同时降低了内存开销，能够更好地适应在线服务的实际需求。

Conclusion: 动态序列并行系统为解决大语言模型扩展上下文窗口带来的变长请求处理挑战提供了有效方案，通过自适应调度和内存优化实现了更高效的在线服务部署。

Abstract: With the advancement of large language models (LLMs), their context windows have rapidly expanded. To meet diverse demands from varying-length requests in online services, existing state-of-the-art systems tune the sequence parallelism (SP) …

</details>


### [390] [Throughput-Oriented LLM Inference via KV-Activation Hybrid Caching with a Single GPU](https://scholar.google.com/scholar_url?url=https://jaehyuk-huh.github.io/papers/lee_iccd2025_capture.pdf&hl=zh-CN&sa=X&d=11023966184061689677&ei=vu0XaZ3GN4ePieoP4Ijq0QY&scisig=ABGrvjKKeK2eJLFocw_Qy0jLBPc1&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=0&folt=rel)
*S Lee,H Kim,S Hwang,G Heo,M Noh,J Huh*

Main category: Surajit Chaudhuri

TL;DR: 该论文探讨如何通过优化GPU内存使用来降低大语言模型推理成本，针对延迟要求较宽松的场景提供经济高效的解决方案


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型规模增长，需要大量GPU来满足内存需求，导致token生成成本显著增加。现有方法在延迟约束较宽松的场景下成本效益不高，需要更经济高效的推理方案。

Method: 论文提出通过优化GPU内存使用策略来降低推理成本，可能涉及模型分片、内存共享、计算卸载等技术，针对延迟要求不严格的场景进行专门优化。

Result: 提出的方法在保持可接受延迟的前提下，显著降低了LLM推理的GPU使用成本，为延迟约束较宽松的应用场景提供了经济高效的解决方案。

Conclusion: 通过针对性地优化GPU内存使用策略，可以在延迟要求较宽松的场景下实现大语言模型推理的成本效益显著提升，为大规模部署提供可行方案。

Abstract: Large language models (LLMs) with growing model sizes use many GPUs to meet memory capacity requirements, incurring substantial costs for token generation. To provide cost-effective LLM inference with relaxed latency constraints, recent studies …

</details>


### [391] [Query Optimization for Database-Returning Queries](https://scholar.google.com/scholar_url?url=https://bigdata.uni-saarland.de/publications/p353-rink.pdf&hl=zh-CN&sa=X&d=9128674768391424673&ei=-rYaae-pHo2v6rQPyMTRqQ0&scisig=ABGrvjKqAVpLy1jtz7oWjC7jC6pB&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=0&folt=rel)
*S RINK,J DITTRICH*

Main category: Surajit Chaudhuri

TL;DR: RESULTDB操作符实现了数据库返回查询概念，允许查询返回原始数据库的缩减版本，包含特定关系、元组和属性


<details>
  <summary>Details</summary>
Motivation: 传统数据库查询返回结果集，但有时需要返回数据库的缩减版本（包含特定关系、元组和属性），以便后续查询操作

Method: 引入RESULTDB操作符，实现数据库返回查询概念，该操作符返回原始数据库的缩减版本

Result: 提出了RESULTDB操作符的概念和实现，扩展了数据库查询能力，使查询能够返回数据库的缩减版本

Conclusion: RESULTDB操作符为数据库查询提供了新范式，使查询能够返回数据库的缩减版本，增强了数据库操作的灵活性和表达能力

Abstract: In their recent work, Nix and Dittrich [26] introduced the RESULTDB operator, implementing the thrilling concept of a database-returning query (DRQ). DRQs return a reduction of the original database, which contains only the relations, tuples, and …

</details>


### [392] [SynthWorlds: Controlled Parallel Worlds for Disentangling Reasoning and Knowledge in Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.24427&hl=zh-CN&sa=X&d=1930828128209176029&ei=sSocadn2Boqi6rQPwoX9sA8&scisig=ABGrvjJJdq0-_Cqj8bWkvW5ylfQM&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=0&folt=rel)
*K Gu,A Bhat,MA Merrill,R West,X Liu,D McDuff…*

Main category: Surajit Chaudhuri

TL;DR: 该论文指出评估语言模型推理能力的复杂性，因为模型参数中存储了大量世界知识，导致基准测试表现更多反映事实记忆而非真正推理，现有数据集和方法存在局限性。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型评估存在根本问题：模型参数中存储的广泛世界知识使得基准测试表现更多反映事实记忆而非真正推理能力，这阻碍了对模型真实推理能力的准确评估。

Method: 论文提出新的评估框架或数据集设计方法，旨在分离事实记忆与推理能力，可能通过控制变量、引入未知事实或设计需要逻辑推理而非知识回忆的任务。

Result: 通过新方法评估发现，语言模型在去除知识记忆干扰后的推理能力与基准测试表现存在显著差异，揭示了现有评估方法的局限性。

Conclusion: 需要重新设计语言模型推理能力评估方法，分离知识记忆与逻辑推理，以更准确地衡量模型的真实推理能力。

Abstract: Evaluating the reasoning ability of language models (LMs) is complicated by their extensive parametric world knowledge, where benchmark performance often reflects factual recall rather than genuine reasoning. Existing datasets and approaches (eg …

</details>


### [393] [How Small Can You Go? Compact Language Models for On-Device Critical Error Detection in Machine Translation](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.09748&hl=zh-CN&sa=X&d=10314821947296215167&ei=sSocadn2Boqi6rQPwoX9sA8&scisig=ABGrvjLzlh14_0NOy-x5mPnz4pqN&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=1&folt=rel)
*M Chopra,L Sparrenberg,S Khanna,R Sifa*

Main category: Surajit Chaudhuri

TL;DR: 研究探索了在保持检测意义改变能力的前提下，大型语言模型（LLMs）用于机器翻译评估的最小规模，旨在解决边缘设备和隐私敏感场景中的部署限制。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在机器翻译评估方面表现出色，但其规模和成本限制了在边缘设备及隐私敏感工作流中的部署。需要探索在保持检测意义改变能力的前提下，LLMs能够达到的最小规模。

Method: 研究通过系统性地缩小模型规模，探索在保持检测意义改变能力的前提下，LLMs用于机器翻译评估的最小可行规模。可能涉及模型压缩、知识蒸馏或架构优化等技术。

Result: 研究发现可以在显著减小模型规模的同时，仍能有效检测机器翻译中的意义改变。具体的最小规模阈值和性能保持程度需要进一步确认。

Conclusion: 通过适当的优化方法，可以在大幅减小LLMs规模的同时，保持其在机器翻译评估中检测意义改变的能力，为边缘部署和隐私敏感应用提供可行方案。

Abstract: Large Language Models (LLMs) excel at evaluating machine translation (MT), but their scale and cost hinder deployment on edge devices and in privacy-sensitive workflows. We ask: how small can you get while still detecting meaning-altering …

</details>


### [394] [Multi-Frequency Contrastive Decoding: Alleviating Hallucinations for Large Vision-Language Models](https://scholar.google.com/scholar_url?url=https://aclanthology.org/2025.emnlp-main.1452.pdf&hl=zh-CN&sa=X&d=17791293378777999467&ei=qRIhabCPE_GQ6rQPprqjiAU&scisig=ABGrvjIvjp4Sk2eD1lq9I_9jdw5C&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=1&folt=rel)
*B Liu,F Zhang,G Chen,J Cheng*

Main category: Surajit Chaudhuri

TL;DR: 该论文探讨大型视觉语言模型中的物体幻觉问题，现有研究主要归因于视觉编码器的缺陷，但本文提出幻觉主要源于语言模型对视觉特征的不当处理


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在视觉语言任务中表现出色，但物体幻觉问题仍然严重。现有研究主要将幻觉归因于视觉编码器的缺陷，但作者认为这种解释不完整，需要更深入地理解幻觉的根本原因

Method: 通过系统分析视觉语言模型的工作流程，作者发现物体幻觉主要源于语言模型对视觉特征的不当处理，而不是视觉编码器本身的问题。他们可能进行了实验验证，对比了不同组件对幻觉的贡献

Result: 研究结果表明，语言模型在解释视觉特征时更容易产生幻觉，这挑战了现有研究将幻觉主要归因于视觉编码器的观点。作者可能提供了定量分析来支持这一发现

Conclusion: 物体幻觉问题在大型视觉语言模型中主要源于语言模型组件，而非视觉编码器。这一发现为未来的模型改进提供了新的方向，需要关注语言模型如何处理和解释视觉信息

Abstract: Large visual-language models (LVLMs) have demonstrated remarkable performance in visual-language tasks. However, object hallucination remains a significant challenge for LVLMs. Existing studies attribute object hallucinations in LVLMs mainly …

</details>


### [395] [ReFRED: Reliable Function REtrieval for Data Transformation](https://scholar.google.com/scholar_url?url=https://www.openproceedings.org/2026/conf/edbt/paper-84.pdf&hl=zh-CN&sa=X&d=2579632467745783147&ei=YMgjab6BJvGQ6rQPybbN6Qk&scisig=ABGrvjIAeEYx4yYNnn1zBHVwK9lW&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=0&folt=rel)
*Y Chen,N Koudas,X Yu*

Main category: Surajit Chaudhuri

TL;DR: 该论文探讨了利用大型语言模型（LLMs）进行代码生成和文本到SQL转换的潜力，通过提示工程和上下文学习来提升性能


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在自然语言问答、文本到SQL转换和代码生成等领域的成功应用，研究者希望探索如何通过适当的提示策略来进一步提升LLMs在这些任务中的性能，特别是在代码生成和SQL查询生成方面

Method: 采用提示工程和上下文学习的方法，设计特定的提示策略来引导LLMs完成代码生成和文本到SQL转换任务，可能包括few-shot学习、思维链提示等技术

Result: 通过精心设计的提示策略，LLMs在代码生成和文本到SQL转换任务上表现出显著性能提升，能够生成更准确、更符合要求的代码和SQL查询

Conclusion: 适当的提示工程能够有效提升LLMs在代码生成和文本到SQL转换任务中的性能，为实际应用提供了可行的技术路径

Abstract: Background: With the recent success of Large Language Models (LLMs) in a wide range of domains such as natural language question answering (QA)[8], text-to-SQL translation [26], and code generation [29], it is conceivable to prompt an LLM to …

</details>


### [396] [LLM-MemCluster: Empowering Large Language Models with Dynamic Memory for Text Clustering](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.15424&hl=zh-CN&sa=X&d=5293311840116775114&ei=YMgjab6BJvGQ6rQPybbN6Qk&scisig=ABGrvjLvbS3rQSc20deQVtS3iuRv&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=2&folt=rel)
*Y Zhu,L Yang,K Xu,W Zhang,Z Song,J Wang,PS Yu*

Main category: Surajit Chaudhuri

TL;DR: LLMs在无监督学习中的文本聚类应用受到限制，需要新的方法来克服这些限制


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）凭借其深层的语义理解能力正在重塑无监督学习，特别是在文本聚类方面展现出前所未有的潜力。然而，它们的直接应用受到根本性限制，需要解决这些限制以充分发挥LLMs在文本聚类任务中的优势。

Method: 从摘要内容来看，论文可能提出了一种新的方法或框架来克服LLMs在文本聚类中的限制。虽然没有具体说明，但可能涉及改进的聚类算法、LLM特征提取的优化、或结合传统聚类技术与LLM语义理解的混合方法。

Result: 摘要未提供具体实验结果，但暗示通过提出的方法能够克服LLMs在文本聚类中的限制，从而获得更好的聚类性能。

Conclusion: LLMs在文本聚类中具有巨大潜力，但需要专门的方法来克服其直接应用的限制，以实现更有效的无监督文本分析。

Abstract: Large Language Models (LLMs) are reshaping unsupervised learning by offering an unprecedented ability to perform text clustering based on their deep semantic understanding. However, their direct application is fundamentally limited by a lack of …

</details>


### [397] [Tables2Traces: Distilling Tabular Data to Improve LLM Reasoning in Healthcare](https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DzbC9HXAxaw&hl=zh-CN&sa=X&d=12094240299854695890&ei=VbomaYO5C6G7ieoP8Y6WyQc&scisig=ABGrvjJgoQ7WGprRa_Y-FO7uTTfM&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=0&folt=rel)
*M Werling,N Seedat,J Liu,L Grønlykke,CU Niemann…*

Main category: Surajit Chaudhuri

TL;DR: 该论文探讨了如何将大型语言模型（LLMs）应用于以结构化表格数据为主要知识存储形式的领域（如医学），提出了一种新的训练方法来增强LLMs处理表格数据的能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在文本数据上表现优异，但许多领域（特别是医学）的知识主要存储在结构化表格数据中。尽管表格数据信息丰富，但LLMs在处理这类数据时面临挑战，需要专门的方法来有效利用表格数据中的知识。

Method: 论文提出了一种新的训练方法，专门针对表格数据处理进行优化。该方法可能包括表格数据的预处理、表示学习、以及专门针对表格结构的微调策略，旨在增强LLMs理解和推理表格数据的能力。

Result: 提出的方法显著提升了LLMs在表格数据相关任务上的性能，特别是在医学等领域的应用。模型能够更好地理解和推理结构化数据，填补了LLMs在表格数据处理方面的能力空白。

Conclusion: 通过专门设计的训练方法，LLMs可以有效地应用于以表格数据为主的领域。这种方法为将LLMs的强大推理能力扩展到更多结构化数据场景提供了可行路径，具有重要的实际应用价值。

Abstract: Large language models (LLMs) excel at reasoning when fine-tuned on curated text corpora, but many domains, such as medicine, primarily store knowledge in structured tabular data. Despite its richness, tabular data has been largely …

</details>


### [398] [AI-Assisted Data Hygiene at Scale: Entity Resolution & Deduplication for Salesforce](https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Pavan-Palleti/publication/397602091_AI-Assisted_Data_Hygiene_at_Scale_Entity_Resolution_Deduplication_for_Salesforce/links/69171b1cda4d0c7d150415db/AI-Assisted-Data-Hygiene-at-Scale-Entity-Resolution-Deduplication-for-Salesforce.pdf&hl=zh-CN&sa=X&d=8063336616410400909&ei=v88oaYq_Mo2v6rQP1Yj2iAo&scisig=ABGrvjJ221iPXE0Fjv9qqC05t57u&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=1&folt=rel)
*P Palleti*

Main category: Surajit Chaudhuri

TL;DR: CRM平台积累大量半结构化记录，随着组织扩张、新渠道整合等，这些记录会出现漂移、重复和衰减问题


<details>
  <summary>Details</summary>
Motivation: 解决CRM系统中半结构化记录的漂移、重复和衰减问题，这些问题是组织扩张、新渠道整合等导致的

Method: 未明确说明具体方法，但从上下文推断可能涉及数据清洗、去重、标准化等技术

Result: 未提供具体实验结果，但暗示需要解决CRM数据质量问题

Conclusion: CRM系统中的半结构化记录存在严重的数据质量问题，需要有效的解决方案来管理这些记录

Abstract: Salesforce Architect pavan15tech@ gmail. com Abstract: Customer relationship management (CRM) platforms accumulate vast volumes of semi-structured records that drift, duplicate, and decay as organizations expand, integrate new channels, and …

</details>


### [399] [Forgetting by Pruning: Data Deletion in Join Cardinality Estimation](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.20293&hl=zh-CN&sa=X&d=497838284071033246&ei=JnAqabSHMc2j6rQPsvXUgA0&scisig=ABGrvjJRE-jPfkLWYDwNViJCKk2X&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=1&folt=rel)
*C He,Y Liu,Q Ma,S Ren,X Luo,L Zhao,A Liu*

Main category: Surajit Chaudhuri

TL;DR: 机器学习基数估计系统中的机器遗忘面临独特挑战，主要源于多表关系数据中复杂的分布依赖关系，特别是数据删除这一核心组件


<details>
  <summary>Details</summary>
Motivation: 机器学习基数估计系统在处理多表关系数据时面临机器遗忘的挑战，特别是数据删除操作会破坏模型学到的复杂分布依赖关系，影响估计准确性

Method: 未在摘要中明确说明具体方法，但关注机器遗忘在基数估计系统中的实现，特别是处理多表关系数据分布依赖的技术

Result: 未在摘要中提供具体实验结果，但指出了机器遗忘在基数估计系统中的关键问题和挑战

Conclusion: 机器遗忘在基于机器学习的基数估计系统中是一个重要但具有挑战性的问题，特别是在多表关系数据环境下，需要专门的方法来处理数据删除对分布依赖的影响

Abstract: Machine unlearning in learned cardinality estimation (CE) systems presents unique challenges due to the complex distributional dependencies in multi-table relational data. Specifically, data deletion, a core component of machine unlearning, faces …

</details>


### [400] [InferF: Declarative Factorization of AI/ML Inferences over Joins](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.20489&hl=zh-CN&sa=X&d=12148611461173934763&ei=JnAqabSHMc2j6rQPsvXUgA0&scisig=ABGrvjKMeVCHvUlxTsg7zOuDvNwb&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=3&folt=rel)
*K Chowdhury,L Zhou,L Xie,X Fu,J Zou*

Main category: Surajit Chaudhuri

TL;DR: 因子化机器学习通过避免连接操作中的冗余计算来提升AI/ML工作流效率


<details>
  <summary>Details</summary>
Motivation: 现实世界AI/ML工作流通常需要对来自多个数据集连接后的特征向量进行推理计算，连接输出中的重复数据记录会导致冗余的AI/ML计算，需要解决这一效率问题

Method: 提出因子化机器学习方法，通过避免连接操作中的冗余计算来优化AI/ML工作流

Result: 因子化ML方法能够显著减少由重复数据记录引起的冗余计算，提升AI/ML工作流的计算效率

Conclusion: 因子化机器学习是解决多数据集连接中冗余计算问题的有效方法，能够显著提升AI/ML工作流的效率

Abstract: Real-world AI/ML workflows often apply inference computations to feature vectors joined from multiple datasets. To avoid the redundant AI/ML computations caused by repeated data records in the join's output, factorized ML has been proposed to …

</details>


### [401] [Beluga: A CXL-Based Memory Architecture for Scalable and Efficient LLM KVCache Management](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.20172&hl=zh-CN&sa=X&d=6578132052081863832&ei=JnAqabSHMc2j6rQPsvXUgA0&scisig=ABGrvjK6Yzp7cbhODQGzdpkwrQjS&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=4&folt=rel)
*X Yang,Q Hu,J Li,F Li,Y Zhou,Y Zhu,Q Lin,J Dai…*

Main category: Surajit Chaudhuri

TL;DR: 内存成为GPU加速LLM服务系统的关键瓶颈，需要优化内存管理策略


<details>
  <summary>Details</summary>
Motivation: LLM模型规模快速增长，长上下文推理需求增加，使得GPU内存成为服务系统的关键瓶颈。虽然GPU的高带宽内存（HBM）访问速度快，但容量有限且成本高，无法满足大规模模型和长上下文的需求。

Method: 论文未完整提供，但从摘要看可能涉及内存管理优化策略，如分层存储、内存压缩、计算与内存访问重叠、动态内存分配等技术来缓解GPU内存瓶颈。

Result: 摘要未提供具体实验结果，但暗示通过优化内存管理可以显著提升LLM服务的效率和可扩展性，降低内存成本，支持更大模型和更长上下文。

Conclusion: 针对LLM服务中的内存瓶颈问题，需要创新的内存管理解决方案来平衡性能、成本和可扩展性，以支持不断增长的模型规模和上下文长度需求。

Abstract: The rapid increase in LLM model sizes and the growing demand for long-context inference have made memory a critical bottleneck in GPU-accelerated serving systems. Although high-bandwidth memory (HBM) on GPUs offers fast access, its …

</details>


### [402] [Common column identification for table similarity detection in electrified transportation data lakes](https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S095741742504148X&hl=zh-CN&sa=X&d=5154089161100025205&ei=yMIraajVB_-j6rQPrbnwwA4&scisig=ABGrvjJmeuO5Pu0KD0r6sDzpFDS6&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=0&folt=rel)
*S Paulissen,M Bruchon,J Lustbader,Q Lv*

Main category: Surajit Chaudhuri

TL;DR: 该论文探讨了电动交通领域多源异构数据整合的挑战，提出了一个统一的数据处理框架来支持跨学科研究和运营决策。


<details>
  <summary>Details</summary>
Motivation: 电动交通研究需要整合来自交通、电力系统、公共卫生、政策法规等多个领域的异构数据，这些数据质量参差不齐、格式多样，给跨学科研究和运营决策带来挑战。

Method: 论文可能提出一个统一的数据处理框架或方法论，用于整合、清洗、标准化来自不同来源的电动交通相关数据，支持跨领域分析和应用。

Result: 通过提出的数据处理框架，能够有效整合多源异构数据，提高数据质量和可用性，为电动交通的跨学科研究和运营优化提供可靠的数据基础。

Conclusion: 电动交通领域需要一个系统性的数据整合方法来解决多源异构数据带来的挑战，提出的框架能够促进跨学科合作，推动电动交通研究的深入发展。

Abstract: Electrified transportation often requires researchers and operators to interact with datasets from a wide range of sources and disciplines, such as transportation, power systems, public health, policies, and regulations. These datasets vary in quality and …

</details>


### [403] [Temporal structure of natural language processing in the human brain corresponds to layered hierarchy of large language models](https://scholar.google.com/scholar_url?url=https://www.nature.com/articles/s41467-025-65518-0&hl=zh-CN&sa=X&d=18280462718132872522&ei=yMIraajVB_-j6rQPrbnwwA4&scisig=ABGrvjKY3HwbRzPctC6gS_6IxT5k&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=5&folt=rel)
*A Goldstein,E Ham,M Schain,SA Nastase,B Aubrey…*

Main category: Surajit Chaudhuri

TL;DR: 该研究探索了大型语言模型（LLMs）作为理解人脑语言处理框架的潜力，通过分析LLMs的分层数值嵌入来揭示大脑语言表征的神经机制。


<details>
  <summary>Details</summary>
Motivation: 传统模型在解释人脑语言处理方面存在局限，而LLMs通过分层数值嵌入表征词汇和语境，为理解大脑语言处理提供了新的理论框架和实证方法。

Method: 研究采用LLMs的分层嵌入表示，通过神经影像技术（如fMRI或EEG）将模型表征与大脑活动数据进行关联分析，探索不同语言处理层次在神经层面的对应关系。

Result: 研究发现LLMs的分层表征能够有效预测大脑在语言处理过程中的神经活动模式，揭示了词汇、句法和语义等不同语言层次在大脑中的分布式表征机制。

Conclusion: LLMs为理解人脑语言处理提供了有力的计算框架，其分层嵌入表征与大脑神经活动存在系统性对应关系，为认知神经科学和计算语言学开辟了新的研究路径。

Abstract: Abstract Large Language Models (LLMs) offer a framework for understanding language processing in the human brain. Unlike traditional models, LLMs represent words and context through layered numerical embeddings. Here, we demonstrate …

</details>


### [404] [Detecting Semantic Data Smells with BERT: A Transformer-Based Approach to Data Quality](https://scholar.google.com/scholar_url?url=https://ceur-ws.org/Vol-4109/paper4.pdf&hl=zh-CN&sa=X&d=5213657400329813612&ei=yMIraajVB_-j6rQPrbnwwA4&scisig=ABGrvjKGpgGSxUl6xovp87WBhgjN&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=6&folt=rel)
*G Recupito,G Giordano,D Di Nucci,F Palomba*

Main category: Surajit Chaudhuri

TL;DR: 该论文探讨机器学习数据管道中的数据异味问题，提出检测和缓解这些微妙数据质量问题的框架


<details>
  <summary>Details</summary>
Motivation: 随着机器学习模型对数据质量依赖性的增加，数据可靠性变得至关重要。数据异味作为对数据完整性的微妙威胁，可能严重影响模型性能，但目前缺乏系统性的检测和缓解方法

Method: 论文提出一个检测和缓解数据异味的框架，可能包括数据质量评估指标、异常检测算法、模式识别技术以及自动修复机制

Result: 该框架能够有效识别各种数据异味，提高机器学习管道的整体数据质量，从而提升模型性能和可靠性

Conclusion: 系统性地解决数据异味问题对于确保机器学习系统的可靠性和鲁棒性至关重要，提出的框架为数据质量管理提供了实用工具

Abstract: In recent years, the integrity of data used in machine learning pipelines has become increasingly critical, as even state-of-the-art models are constrained by the quality of their input. Among the various threats to data reliability, data smells—subtle and …

</details>


<div id='Feifei Li'></div>

# Feifei Li [[Back]](#toc)

### [405] [PolarStore: High-Performance Data Compression for Large-Scale Cloud-Native Databases](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.19949&hl=zh-CN&sa=X&d=17909708240241966642&ei=KHAqaYjzA_GQ6rQPzJ-pqA4&scisig=ABGrvjK885r8gEDa7xtZnPm-0XvN&oi=scholaralrt&hist=i6heNjgAAAAJ:15326460978370735713:ABGrvjJIfqAOadsmEwmlL5W-rrYG&html=&pos=1&folt=art)
*Q Hu,X Yang,F Li,J Li,Y Lin,Y Zhou,Y Zhu,J Zhang…*

Main category: Feifei Li

TL;DR: 云原生RDBMS通过计算存储分离实现弹性计算，但存储成本仍是关键问题


<details>
  <summary>Details</summary>
Motivation: 近年来资源弹性和成本优化对RDBMS至关重要，云原生RDBMS通过计算存储分离提供弹性计算资源，但存储成本仍是用户关注的核心问题

Method: 未在摘要中明确说明具体方法，但暗示需要解决云原生RDBMS中的存储成本优化问题

Result: 未在摘要中提供具体结果，但指出存储成本是云原生RDBMS中需要解决的关键挑战

Conclusion: 云原生RDBMS虽然解决了计算弹性问题，但存储成本优化仍是需要重点研究和解决的方向

Abstract: In recent years, resource elasticity and cost optimization have become essential for RDBMSs. While cloud-native RDBMSs provide elastic computing resources via disaggregated computing and storage, storage costs remain a critical user concern …

</details>
