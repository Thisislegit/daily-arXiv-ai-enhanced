<div id=toc></div>

# Table of Contents

- [Rong Zhu](#Rong Zhu) [Total: 6]
- [Ziniu Wu](#Ziniu Wu) [Total: 22]
- [您的个人学术档案](#您的个人学术档案) [Total: 1]
- [Zongheng Yang](#Zongheng Yang) [Total: 114]
- [Thomas Neumann](#Thomas Neumann) [Total: 2]
- [Surajit Chaudhuri](#Surajit Chaudhuri) [Total: 70]
- [Carsten Binnig](#Carsten Binnig) [Total: 27]
- [Ion Stoica](#Ion Stoica) [Total: 7]
- [Ryan Marcus](#Ryan Marcus) [Total: 1]
- [Google Scholar](#Google Scholar) [Total: 102]
- [Matei Zaharia](#Matei Zaharia) [Total: 111]
- [Alekh Jindal](#Alekh Jindal) [Total: 51]
- [Bin CUI](#Bin CUI) [Total: 4]
- [Xuanhe Zhou](#Xuanhe Zhou) [Total: 150]


<div id='Rong Zhu'></div>

# Rong Zhu [[Back]](#toc)

### [1] [BookRAG: A Hierarchical Structure-aware Index-based Approach for Retrieval-Augmented Generation on Complex Documents](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.03413&hl=zh-CN&sa=X&d=4675059194073463520&ei=j9I1abpI8ZDqtA-5qL6wBw&scisig=ALhkC2Tu6M-tXrGqW1miLkwDQKPY&oi=scholaralrt&hist=i6heNjgAAAAJ:8587655636886263605:ALhkC2RIfeTnH2vYbbtY8U2shYS2&html=&pos=0&folt=cit)
*S Wang,Y Zhou,Y Fang*

Main category: Rong Zhu

TL;DR: 该论文针对具有层次结构的现实世界文档（如书籍、手册等），提出了一种改进的检索增强生成（RAG）方法，以提升大语言模型在问答任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法主要关注一般文档，忽略了现实世界中许多文档（如书籍、手册、小册子等）具有层次结构的特点。这种结构信息未被充分利用，限制了RAG在复杂文档问答任务中的性能提升。

Method: 论文提出了一种专门针对层次结构文档的RAG方法，该方法能够有效利用文档的层次结构信息来改进检索过程，从而为LLMs提供更相关的上下文信息。

Result: 该方法在具有层次结构的文档问答任务上表现出优于传统RAG方法的性能，能够更准确地检索相关信息并生成更高质量的答案。

Conclusion: 考虑文档的层次结构对于提升RAG在现实世界文档问答任务中的性能至关重要，提出的方法为处理结构化文档提供了有效的解决方案。

Abstract: As an effective method to boost the performance of Large Language Models (LLMs) on the question answering (QA) task, Retrieval-Augmented Generation (RAG), which queries highly relevant information from external complex documents, has attracted tremendous attention from both industry and academia. Existing RAG approaches often focus on general documents, and they overlook the fact that many real-world documents (such as books, booklets, handbooks, etc.) have a hierarchical structure …

</details>


### [2] [Database constraint and rule learning using large language models](https://scholar.google.com/scholar_url?url=https://patents.google.com/patent/US12475086B2/en&hl=zh-CN&sa=X&d=2594870782002318704&ei=keU4aZ2VNam6ieoPoPyzsQs&scisig=ALhkC2QlRjw2mTERCL9hqKRkMhIp&oi=scholaralrt&hist=i6heNjgAAAAJ:8587655636886263605:ALhkC2RIfeTnH2vYbbtY8U2shYS2&html=&pos=1&folt=cit)
*G Gottlob,J Guo,DM Longo,YN Yifru*

Main category: Rong Zhu

TL;DR: 基于LLM的数据库约束自动生成方法，通过检索数据库元数据、参数化提示工程与LLM交互，最终生成自然语言描述的数据库结构约束


<details>
  <summary>Details</summary>
Motivation: 传统数据库约束定义需要专业知识且耗时，LLM具备理解数据库结构和语义的能力，可自动化生成约束描述，提高数据库设计和维护效率

Method: 1) 从数据库检索数据和元数据；2) 使用具体值参数化生成提示；3) 通过提示与LLM交互获取分析响应；4) 进行数据智能处理，推导数据库结构元素的自然语言描述

Result: 该方法能够自动生成数据库约束的自然语言描述，减少人工定义约束的工作量，提高数据库文档化和维护效率

Conclusion: LLM可用于数据库约束生成，结合参数化提示和数据智能处理能有效理解数据库结构并生成准确的约束描述

Abstract: A method for database constraint generation, executed by at least one processor on a computing device accessing one or more large language models (LLMs), comprising retrieving data and/or metadata from a database; generating prompts by parameterizing inputs with concrete values; interacting with LLMs through these prompts to obtain and analyze responses; and performing data intelligence processing to derive natural-language descriptions of structural database elements …

</details>


### [3] [Gem: Scalable Monotonic Graph Processing Beyond Billion-Scale on a Single Machine](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3769795&hl=zh-CN&sa=X&d=7912960223790816949&ei=keU4aZ2VNam6ieoPoPyzsQs&scisig=ALhkC2RypulwmcWvYp0AGRyo__er&oi=scholaralrt&hist=i6heNjgAAAAJ:8587655636886263605:ALhkC2RIfeTnH2vYbbtY8U2shYS2&html=&pos=2&folt=cit)
*C Huan,Z Yang,H Yang,S Ma,R Gu,F Xi,Y Liu…*

Main category: Rong Zhu

TL;DR: 该论文针对现有单调图算法引擎局限于内存执行的问题，提出了一种支持外存（out-of-core）的单调图处理系统，通过创新的剪枝技术实现大规模图的高效处理。


<details>
  <summary>Details</summary>
Motivation: 单调图算法（如最短路径、BFS、可达性）是图分析的基础，广泛应用于各领域。现有系统采用剪枝技术加速这些算法，但最先进的单调图引擎仅限于内存执行，无法处理超过主存容量的大规模图。而现有的外存图引擎为通用工作负载设计，对单调算法的优化不足。

Method: 论文提出了一种支持外存执行的单调图处理系统，通过创新的剪枝技术来减少磁盘I/O。系统设计考虑了单调算法的特性，优化了数据布局和访问模式，能够在图数据超出内存容量时仍保持高效处理。

Result: 该系统能够处理超过主存容量的大规模图，相比现有外存图引擎在处理单调算法时获得显著性能提升。实验表明，系统在保持单调算法正确性的同时，实现了接近内存级性能的外存处理能力。

Conclusion: 论文成功解决了单调图算法在大规模图处理中的内存限制问题，通过专门设计的外存系统架构和剪枝技术，为大规模图分析提供了高效、可扩展的解决方案。

Abstract: Monotonic graph algorithms, such as shortest path, BFS, and reachability, are fundamental to graph analytics and are widely used across domains. Recent systems employ pruning techniques to accelerate the processing of these algorithms. However, state-of-the-art monotonic graph engines are restricted to in-memory execution and cannot scale to graphs that exceed main memory capacity. In contrast, existing out-of-core graph engines are designed for general-purpose workloads and …

</details>


### [4] [Comparative Analysis of Transformer Models for Stack Overflow Question Quality Classification](https://scholar.google.com/scholar_url?url=https://api.taylorfrancis.com/content/chapters/edit/download%3FidentifierName%3Ddoi%26identifierValue%3D10.1201/9781003533009-21%26type%3Dchapterpdf&hl=zh-CN&sa=X&d=9131266029303586429&ei=x-o-abTKEubYieoP3dLOmAk&scisig=ALhkC2Ss5_TPp8SvG0KG60E5vyUn&oi=scholaralrt&hist=i6heNjgAAAAJ:8587655636886263605:ALhkC2RIfeTnH2vYbbtY8U2shYS2&html=&pos=1&folt=cit)
*V Subramaniyaswamy,V Indragandhi,E Rajasekar…*

Main category: Rong Zhu

TL;DR: 该研究使用多种预训练语言模型（BERT、DistilBERT、XLNet、RoBERTa、ALBERT、ELECTRA）来预测Stack Overflow问题的质量，将问题分为高、中、低三个质量等级。


<details>
  <summary>Details</summary>
Motivation: Stack Overflow等平台对开发者寻找编程解决方案至关重要，问题质量直接影响用户体验和知识共享。当前需要更准确的问题质量预测方法来提升平台效率。

Method: 采用多种预训练语言模型（BERT、DistilBERT、XLNet、RoBERTa、ALBERT、ELECTRA）进行文本分类，将Stack Overflow问题分为高、中、低三个质量等级，并进行比较分析。

Result: 研究比较了不同预训练模型在Stack Overflow问题质量预测任务上的性能，识别出表现最佳的模型，为平台质量评估提供了有效的技术方案。

Conclusion: 软计算技术特别是某些预训练语言模型能有效预测Stack Overflow问题质量，这有助于改善平台内容管理、用户体验和知识共享效率。

Abstract: Platforms like Stack Overflow are crucial for developers looking for programming solutions in today's digital environment. The user experience and knowledge sharing are significantly impacted by the caliber of questions posted. This work seeks to enhance Stack Overflow question quality prediction through a detailed analysis of soft computing techniques such as BERT, DistilBERT, XLNet, RoBERTa, ALBERT, and ELECTRA–this study categorizes questions into three quality classes: High …

</details>


### [5] [Reliable Truth Discovery for Dynamic and Dependent Sources](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11239509/&hl=zh-CN&sa=X&d=4561127897769091949&ei=lw5Kaaj6KJaM6rQP0-TCwQU&scisig=ALhkC2RU7chE2jvtDbRks2Zk5Gc2&oi=scholaralrt&hist=i6heNjgAAAAJ:8587655636886263605:ALhkC2RIfeTnH2vYbbtY8U2shYS2&html=&pos=0&folt=cit)
*H Zhang,S Wang,L Chen,X Li,Q Gao,QZ Sheng*

Main category: Rong Zhu

TL;DR: 该论文针对大数据和生成式AI时代，从动态依赖关系中挖掘真实信息的挑战，提出新的解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注具有冲突信息的依赖源，但现实场景中源之间的依赖关系是动态变化的，这使得真相发现变得更加困难。论文旨在解决动态依赖关系下的真相发现问题。

Method: 论文未在摘要中明确说明具体方法，但从上下文推断，可能涉及对动态依赖关系建模、时间序列分析或适应性算法来处理源之间随时间变化的依赖关系。

Result: 摘要未提供具体实验结果，但暗示该方法能够更有效地处理动态依赖关系下的真相发现问题。

Conclusion: 动态依赖关系是现实世界真相发现的关键挑战，需要新的方法来处理源之间随时间变化的复杂依赖关系。

Abstract: In the era of Big Data and generative artificial intelligence (AI), discovering the truth about various objects from different sources has become a pressing topic. Existing studies primarily focus on dependent sources with conflicting information, where sources may copy information from each other. However, real-world scenarios are often more complex, with dynamic dependence relationships among sources over time. This complexity makes it much more difficult to discover the truth. One of the key …

</details>


### [6] [Detecting AI-Assisted Tampering](https://scholar.google.com/scholar_url?url=https://books.google.com/books%3Fhl%3Dzh-CN%26lr%3D%26id%3DmZulEQAAQBAJ%26oi%3Dfnd%26pg%3DPA191%26ots%3DhXLggihHWy%26sig%3D2bOwOFCFZibE14L9IvNgrgYC_bc&hl=zh-CN&sa=X&d=16212269617922080357&ei=9i1cac2cH-qsieoPjYOSgAM&scisig=ALhkC2TS4TVmU1fuLdj_toIOOdwb&oi=scholaralrt&hist=i6heNjgAAAAJ:8587655636886263605:ALhkC2RIfeTnH2vYbbtY8U2shYS2&html=&pos=0&folt=cit)
*T Lokuruge,A Bouguettaya*

Main category: Rong Zhu

TL;DR: 提出分布式信任信息管理框架，解决众包物联网服务中分布式实体可能篡改信任数据的问题，应对AI工具降低攻击门槛的挑战


<details>
  <summary>Details</summary>
Motivation: 众包物联网服务环境中，分布式实体存储和管理信任信息，传统信任管理框架通常假设这些实体可信。然而，这些实体可能篡改信任数据，使系统易受内部攻击。AI工具（如ChatGPT）的兴起进一步降低了攻击者的门槛，加剧了安全风险。

Method: 提出分布式信任信息管理框架，具体方法未在摘要中详细说明，但核心思想是通过分布式架构管理信任信息，防止单一实体篡改数据，增强系统对内部攻击的抵抗力。

Result: 摘要未提供具体实验结果，但该框架旨在提高众包物联网服务环境中信任管理的安全性和可靠性，抵御内部攻击和AI辅助攻击。

Conclusion: 需要新的信任管理框架来应对众包物联网服务中分布式实体可能篡改信任数据的风险，特别是在AI工具降低攻击门槛的背景下，分布式信任信息管理是必要的解决方案。

Abstract: We propose a distributed trust information management framework for crowdsourced IoT services. The crowdsourced IoT service environment consists of distributed entities that store and manage trust information. Traditional trust management frameworks often assume the trustworthiness of these entities. However, they may tamper with trust data, making the system vulnerable to internal attacks. The rise of AI tools, such as ChatGPT, has further lowered the barrier for adversaries, enabling …

</details>


<div id='Ziniu Wu'></div>

# Ziniu Wu [[Back]](#toc)

### [7] [Enhancing learning-based database optimizaers via representation learning](https://scholar.google.com/scholar_url?url=https://dr.ntu.edu.sg/bitstreams/7da26a84-2644-49c4-94d1-275b14cb83e4/download&hl=zh-CN&sa=X&d=4793807376634038702&ei=tAYtaar1Nc2j6rQPsvXUgA0&scisig=ABGrvjKQewFSoWzuHaYX3FWTsiS7&oi=scholaralrt&hist=i6heNjgAAAAJ:1601694329521098688:ABGrvjKcA5wbu-wU3CW2rX5yqQCe&html=&pos=0&folt=cit)
*Y Zhao*

Main category: Ziniu Wu

TL;DR: 该论文探讨了查询计划表示学习在数据库机器学习系统中的重要性，提出了一种新的表示方法，旨在提升成本估计、查询优化等任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于查询计划的数据库机器学习系统面临表示学习挑战，需要更有效的查询计划向量化表示方法来支持成本估计、查询优化等任务。

Method: 提出了一种新的查询计划表示学习方法，将查询计划（有向无环图）转换为适合机器学习模型输入的向量表示。

Result: 该方法在成本估计、查询优化等任务上表现出优于现有方法的性能，验证了查询计划表示学习对数据库机器学习系统的重要性。

Conclusion: 有效的查询计划表示学习是提升数据库机器学习系统性能的关键，提出的方法为ML4DB系统提供了更好的基础。

Abstract: Abstract Machine learning for database (ML4DB) systems that leverage query plans as input have demonstrated growing promise in a variety of tasks, including cost estimation, query optimization and many others. A query plan is a directed acyclic graph which describe steps to process a query and retrieve the results, and query plan representation is the procedure which takes an arbitrary query plan as input and output a vector representation for it, as the input to machine learning models in a …

</details>


### [8] [Updatable Private Set Intersection and Beyond: Efficient Constructions via Circuit Private Set Intersection](https://scholar.google.com/scholar_url?url=https://eprint.iacr.org/2025/2147.pdf&hl=zh-CN&sa=X&d=128839925027040135&ei=nlcuafjYJOuuieoPn9Oq8Ao&scisig=ABGrvjKT0Ikmc0JqA_PhL9y7j3Mf&oi=scholaralrt&hist=i6heNjgAAAAJ:8133205940682390297:ABGrvjKXJphW1zAH---Rlc_Z3vEU&html=&pos=2&folt=rel)
*F Alborch,T Chauvier,A Faonio,A Fontaine,F Karakoç…*

Main category: Ziniu Wu

TL;DR: 该论文研究了私有集合交集（PSI）协议，特别关注其在实际应用中的性能瓶颈和优化方案，旨在提高PSI协议在真实场景中的效率和实用性。


<details>
  <summary>Details</summary>
Motivation: 尽管私有集合交集（PSI）已在移动私人联系人发现、隐私保护接触者追踪等多个实际应用中得到广泛研究和部署，但现有的大多数PSI协议在实际应用中仍存在性能瓶颈，特别是在大规模数据集和实际部署场景中。论文旨在解决这些性能问题，提高PSI协议在真实世界应用中的效率和实用性。

Method: 论文可能采用了多种技术方法来优化PSI协议，包括但不限于：改进的密码学构造、高效的数据结构设计、并行化处理技术、通信优化策略，以及针对特定应用场景的定制化方案。方法可能涉及对现有PSI协议的深入分析，识别性能瓶颈，并提出相应的优化措施。

Result: 研究结果可能展示了优化后的PSI协议在性能方面的显著提升，包括减少计算时间、降低通信开销、提高吞吐量等。具体结果可能包括在不同数据集规模下的性能对比，以及在实际应用场景中的部署效果评估。

Conclusion: 论文得出结论，通过针对性的优化措施，可以显著提高PSI协议在实际应用中的性能表现，使其更适合大规模部署和实际应用需求。同时，论文可能指出了未来研究方向，包括进一步优化、新应用场景探索以及标准化工作。

Abstract: Abstract Private Set Intersection (PSI) has been widely studied, deployed, and demonstrated through various real-life use cases such as mobile private contact discovery, privacy-preserving contact tracing, etc. Nevertheless, the majority of …

</details>


### [9] [The Application of Pre-trained Transformer Models to UK Court of Appeal Legal Judgments](https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-981-95-4963-4_21&hl=zh-CN&sa=X&d=10874559213121231767&ei=nlcuafjYJOuuieoPn9Oq8Ao&scisig=ABGrvjL7P8rHlksK_K8-ApX8_84U&oi=scholaralrt&hist=i6heNjgAAAAJ:8133205940682390297:ABGrvjKXJphW1zAH---Rlc_Z3vEU&html=&pos=3&folt=rel)
*W Abbas,T Zia,S Tirunagari,V Chennareddy…*

Main category: Ziniu Wu

TL;DR: Transformer预训练语言模型在法律领域的应用，通过法律语料预训练提升法律NLP任务性能


<details>
  <summary>Details</summary>
Motivation: Transformer预训练语言模型在通用NLP领域取得显著成功，但在法律领域应用有限。法律文本具有专业术语、复杂结构和特定推理模式，需要专门的法律语料预训练来提升法律NLP任务性能。

Method: 使用精心策划的法律语料库对语言模型进行预训练，可能包括法律判决文书、法规条文、法律文献等专业文本，采用掩码语言建模等预训练目标，使模型学习法律领域的语言模式和知识。

Result: 在法律语料上预训练的模型在法律NLP任务上表现优于通用预训练模型，能够更好地理解法律术语、处理法律推理、完成法律文本分类、信息抽取、问答等任务。

Conclusion: 针对特定领域（如法律）的预训练语言模型能够显著提升该领域NLP任务的性能，领域专业化预训练是提升模型在专业领域表现的有效途径。

Abstract: The emergence of Transformer-based Pre-trained Language Models (PLMs) has had a significant impact across a variety of Natural Language Processing (NLP) domains. Pre-training language models on curated legal corpora can assist …

</details>


### [10] [TwinBandit Prompt Optimizer: Adaptive Prompt Optimization via Synergistic Dual MAB-Guided Feedback](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3746252.3760824&hl=zh-CN&sa=X&d=16250904473923895985&ei=eQswab6aJ-bYieoPgNO3kQI&scisig=ABGrvjL_i18NY_LiENf6ITY13pgT&oi=scholaralrt&hist=i6heNjgAAAAJ:8133205940682390297:ABGrvjKXJphW1zAH---Rlc_Z3vEU&html=&pos=0&folt=rel)
*YJ Park,SR Lee,AD Vo,M Jung,D Choi*

Main category: Ziniu Wu

TL;DR: 本文提出了一种改进的自动提示工程方法，通过战略性地利用失败反馈与自适应协调的多样化生成策略选择，解决现有APE方法的不足。


<details>
  <summary>Details</summary>
Motivation: 现有自动提示工程方法存在缺陷，未能战略性地利用特定失败反馈，也未能在自适应协调下选择多样化生成策略，限制了提示优化的效果。

Method: 提出一种新方法，结合失败反馈的战略性使用与自适应协调的多样化生成策略选择，通过反馈机制和策略协调来改进提示工程过程。

Result: 该方法相比传统APE方法在提示优化效果上有显著提升，能够更有效地生成高质量的提示，提高下游任务的性能。

Conclusion: 通过战略性地利用失败反馈并协调多样化生成策略，可以显著改进自动提示工程的效果，为提示优化提供更有效的解决方案。

Abstract: A common deficiency in Automatic Prompt Engineering (APE) is the failure to strategically employ specific failure feedback in concert with the adaptive and coordinated selection of diverse generation strategies. To address this deficiency, we …

</details>


### [11] [Lattice-based Forward Secure Certificateless Encryption Scheme for Cloud Data Management](https://scholar.google.com/scholar_url?url=https://dasfaa2025.github.io/paper/research/research_28_paper.pdf&hl=zh-CN&sa=X&d=6656956968092737619&ei=bfYyaaTuDqG7ieoPydy_qAE&scisig=ALhkC2RGgeJFaa8E0_-V056B48J7&oi=scholaralrt&hist=i6heNjgAAAAJ:1601694329521098688:ALhkC2QCKAHaoyavkr4qC4l4tLyC&html=&pos=0&folt=cit)
*S Xu,X Chen,Y Wang,T Xu,F Guo,X Zhang,SM Yiu*

Main category: Ziniu Wu

TL;DR: 针对云数据管理中加密方案存在的密钥托管问题和证书存储开销大的问题，本文提出了一种抗密钥泄露的证书无加密方案


<details>
  <summary>Details</summary>
Motivation: 传统云数据加密方案通常需要完全可信的云服务，存在密钥托管问题，导致证书存储开销大且安全性相对较低。证书无加密虽然解决了这些问题，但在实际云应用中，密钥泄露威胁仍然是一个严重且现实的隐患

Method: 基于证书无加密框架，设计了一种抗密钥泄露的加密方案。该方法通过特定的密钥管理机制来应对密钥泄露威胁，可能包括密钥更新、密钥分割或基于身份的密钥派生等技术

Result: 提出的方案在保持证书无加密优势的同时，增强了系统对密钥泄露的抵抗能力，提高了云数据管理的安全性

Conclusion: 该抗密钥泄露的证书无加密方案有效解决了传统加密方案中的密钥托管问题和证书存储开销问题，同时增强了系统对密钥泄露威胁的防护能力，适用于实际云应用环境

Abstract: Data encryption has been widely studied in cloud data management to protect data security. Most encryption schemes only works with fully trusted cloud services and have issues with key-escrow problems, which result in high storage overhead for key certificates and the security is relatively low. To address these concerns, certificateless encryption was formalized. However, in practical cloud applications, secret key exposure threat delegates a severe and realistic concern, potentially …

</details>


### [12] [Approximate Query Processing under Updates](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3769760&hl=zh-CN&sa=X&d=363715977542659271&ei=xUw3aanAEc2j6rQP2_qhyQ8&scisig=ALhkC2S_Crx9CSZhNAlY2zBwESuF&oi=scholaralrt&hist=i6heNjgAAAAJ:1601694329521098688:ALhkC2QCKAHaoyavkr4qC4l4tLyC&html=&pos=0&folt=cit)
*B Dai,K Yi*

Main category: Ziniu Wu

TL;DR: 通过允许小范围近似误差，实现更新环境下聚合查询的高效处理


<details>
  <summary>Details</summary>
Motivation: 现有增量视图维护算法在处理报告查询时表现良好，但在处理更重要的分析工作负载——聚合查询时可能产生高成本

Method: 通过允许小的近似误差来高效处理更新环境下的聚合查询

Result: 聚合查询可以在更新环境下高效处理

Conclusion: 近似方法为更新环境下的聚合查询处理提供了高效的解决方案

Abstract: Query processing under updates (aka incremental view maintenance) has received increasing attention in recent years, from both theoretical and practical angles. While existing algorithms work well in handling reporting queries, they may incur a high cost on aggregation queries, which are the more important type of analytical workload. In this paper, we show that by allowing a small approximation error, aggregation queries can be processed efficiently under updates. Specifically, we …

</details>


### [13] [APQO: An Adaptive Framework for Parametric Query Optimization](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3769761&hl=zh-CN&sa=X&d=10106752091841813843&ei=xUw3aanAEc2j6rQP2_qhyQ8&scisig=ALhkC2THrW4s_7EDxD4JXMmSciIc&oi=scholaralrt&hist=i6heNjgAAAAJ:1601694329521098688:ALhkC2QCKAHaoyavkr4qC4l4tLyC&html=&pos=1&folt=cit)
*S Li,P Cai,Z Zhang,H Hu,R Zhang,X Zhou,Q Xu…*

Main category: Ziniu Wu

TL;DR: 提出一种新的参数化查询优化方法，通过动态调整计划缓存来适应动态工作负载，避免传统方法在参数分布变化时重用次优计划的问题


<details>
  <summary>Details</summary>
Motivation: 传统基于学习的参数化查询优化方法在静态工作负载中表现良好，但在动态工作负载中无法预测动态变化的计划缓存，导致查询参数分布变化时可能重用次优计划

Method: 不同于传统方法学习从查询参数到执行计划的映射，新方法通过动态调整计划缓存来适应参数分布的变化，能够处理超出先前观察范围的查询参数

Result: 该方法在动态工作负载中能够有效避免重用次优计划，提高查询性能，相比传统方法在参数分布变化时具有更好的适应性

Conclusion: 通过动态调整计划缓存的方法解决了传统参数化查询优化在动态工作负载中的局限性，为处理参数分布变化的查询优化提供了新思路

Abstract: Previous learning-based parameter query optimization (PQO) methods excel in static workloads by precisely selecting optimal plans in a cache with a fixed set of representative plans. However, these methods struggle in dynamic workloads because they cannot predict over dynamically changed plan caches. These queries that fall outside the previously observed query parameter distribution have the risk of reusing suboptimal plans. Unlike traditional PQO methods that learn mappings from …

</details>


### [14] [TQEx: Tensor-based Query Engine Enhanced by Bridging the Gap](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3769835&hl=zh-CN&sa=X&d=10649406151625141347&ei=keU4abffI5iTieoP9sm_0AY&scisig=ALhkC2QoPmY0IiLjqHk8TxkJ7zwv&oi=scholaralrt&hist=i6heNjgAAAAJ:8133205940682390297:ALhkC2SR8Uk0-bcx8xwn2F__iyOC&html=&pos=0&folt=rel)
*H Zhang,R Pang,Y Zhu,H Zhang,C Gao,M Zhong…*

Main category: Ziniu Wu

TL;DR: 论文探讨了AI发展背景下硬件专业化与异构化趋势，分析了多样化专用硬件架构带来的挑战，并提出了相应的解决方案


<details>
  <summary>Details</summary>
Motivation: 随着AI技术发展和计算需求增长，硬件正变得越来越专业化和异构化。各种专用硬件架构的出现，每种都有不同的特性和优势，这给系统设计、编程模型和资源管理带来了新的挑战。需要解决如何有效利用这些异构硬件资源的问题。

Method: 论文可能提出了一种系统性的方法或框架来处理异构硬件环境，可能包括统一的编程抽象、资源调度算法、性能优化策略或跨平台兼容性解决方案。具体方法可能涉及硬件抽象层、编译器优化、运行时系统或协同设计方法。

Result: 论文展示了提出的方法在管理异构硬件资源方面的有效性，可能包括性能提升、资源利用率改善、编程简化或能效优化等方面的量化结果。可能通过实验验证了在不同类型专用硬件上的性能表现。

Conclusion: 异构硬件架构是AI计算发展的必然趋势，需要创新的系统级解决方案来充分发挥其潜力。论文提出的方法为解决异构硬件环境中的挑战提供了有效途径，为未来计算系统设计指明了方向。

Abstract: With the development of AI and the growing demand for computational power, hardware is becoming increasingly specialized and heterogeneous. The emergence of diverse specialized hardware architectures, each with distinct characteristics and …

</details>


### [15] [CloudGlide: Deconstructing the Landscape of Cloud-Based Analytics](https://scholar.google.com/scholar_url?url=https://www.vldb.org/pvldb/vol18/p5638-misegiannis.pdf&hl=zh-CN&sa=X&d=7291483903525338832&ei=agA8abawFuCuieoP1s6B2AU&scisig=ALhkC2Sm6dx_3gUWyZoe5Ik7iN6S&oi=scholaralrt&hist=i6heNjgAAAAJ:8133205940682390297:ALhkC2SR8Uk0-bcx8xwn2F__iyOC&html=&pos=0&folt=rel)
*MG Misegiannis,D Ritter,V Leis,J Giceva*

Main category: Ziniu Wu

TL;DR: 云分析系统设计面临多维决策空间，包括资源供应、缓存策略、调度机制和定价模型等关键维度


<details>
  <summary>Details</summary>
Motivation: 随着云分析系统设计选项的急剧增加，需要在复杂的多维度设计空间中进行系统性决策，以优化性能、成本和资源利用率

Method: 识别并分析云分析系统的关键设计维度：资源供应（静态vs临时）、缓存（容量、分层）、调度（准入阈值、并行度）和定价（预留、按需等）

Result: 建立了云分析系统设计的多维决策框架，明确了影响系统性能和成本的关键设计变量及其相互关系

Conclusion: 云分析系统设计需要综合考虑多个相互关联的维度，系统化的设计决策框架对于优化云分析工作负载至关重要

Abstract: Cloud-based analytics now exposes an increasingly vast space of design choices. Key axes include provisioning (static vs. ephemeral), caching (capacity, tiering), scheduling (admission thresholds, parallelism), and pricing (reserved, on-demand …

</details>


### [16] [CUBE: A Cardinality Estimator Based on Neural CDF](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.09622&hl=zh-CN&sa=X&d=6562751309767707358&ei=xuo-ae-bCIKUieoP5cGFWQ&scisig=ALhkC2TrLcEQCM_ewg5BetEMv9Id&oi=scholaralrt&hist=i6heNjgAAAAJ:1601694329521098688:ALhkC2QCKAHaoyavkr4qC4l4tLyC&html=&pos=0&folt=cit)
*X Yan,T Nie,B Fang,D Shen,K Yue,Y Ge*

Main category: Ziniu Wu

TL;DR: 论文指出传统基于概率模型的基数估计方法在追求高准确率时无法兼顾低延迟和可扩展性，随着数据维度增加，优化时间可能超过实际查询执行时间。


<details>
  <summary>Details</summary>
Motivation: 现代数据库优化器依赖基数估计器的准确性来选择最优执行计划。现有数据驱动方法使用概率模型提高了估计精度，但无法同时保证低推理延迟，且忽视了可扩展性问题。随着数据维度增长，优化时间可能超过实际查询执行时间。

Method: 论文未在摘要中明确说明具体方法，但暗示需要解决现有概率模型方法在延迟和可扩展性方面的不足。

Result: 摘要未提供具体实验结果，但指出现有方法存在推理延迟高、可扩展性差的问题。

Conclusion: 需要开发既能保持高估计精度，又能保证低推理延迟和良好可扩展性的基数估计方法。

Abstract: Modern database optimizer relies on cardinality estimator, whose accuracy directly affects the optimizer's ability to choose an optimal execution plan. Recent work on data-driven methods has leveraged probabilistic models to achieve higher estimation accuracy, but these approaches cannot guarantee low inference latency at the same time and neglect scalability. As data dimensionality grows, optimization time can even exceed actual query execution time. Furthermore, inference with …

</details>


### [17] [ECCO: Leveraging Cross-Camera Correlations for Efficient Live Video Continuous Learning](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.11727&hl=zh-CN&sa=X&d=7672855533727709800&ei=0nlFad-rG7m26rQPgpXiSA&scisig=ALhkC2SJDqTQyIG1FV3nIBh7p5dG&oi=scholaralrt&hist=i6heNjgAAAAJ:1601694329521098688:ALhkC2QCKAHaoyavkr4qC4l4tLyC&html=&pos=0&folt=cit)
*Y He,F Kossmann,S Seshan,P Steenkiste*

Main category: Ziniu Wu

TL;DR: ECCO是一个视频分析框架，通过跨摄像头共享模型更新来降低连续学习的计算和通信成本，解决现有方法为每个摄像头单独重训练模型导致的资源不可扩展问题。


<details>
  <summary>Details</summary>
Motivation: 当前视频分析系统为每个摄像头单独重训练轻量级DNN模型以应对实时数据漂移，但这种方法计算和通信成本高，无法扩展到大规模摄像头部署。

Method: ECCO框架的核心洞察是数据漂移通常表现出跨摄像头的相似性。通过识别和利用这些相似性，ECCO能够跨摄像头共享模型更新，从而减少重复计算和通信开销。

Result: ECCO显著降低了连续学习的计算和通信成本，使大规模摄像头部署的视频分析系统更加资源高效和可扩展。

Conclusion: ECCO通过利用跨摄像头数据漂移的相似性，为视频分析中的连续学习提供了资源高效的解决方案，解决了现有方法在可扩展性方面的局限性。

Abstract: Recent advances in video analytics address real-time data drift by continuously retraining specialized, lightweight DNN models for individual cameras. However, the current practice of retraining a separate model for each camera suffers from high compute and communication costs, making it unscalable. We present ECCO, a new video analytics framework designed for resource-efficient continuous learning. The key insight is that the data drift, which necessitates model retraining, often shows …

</details>


### [18] [Fast Ingest and Query Performance in PostgreSQL with SplinterDB Indexes](https://scholar.google.com/scholar_url?url=https://raw.githubusercontent.com/wiki/vmware/splinterdb/SplinterDB-Postgres-vFinal.pdf&hl=zh-CN&sa=X&d=11826889296896860295&ei=lw5KadOQCaC16rQPm4fPgQQ&scisig=ALhkC2SNdNXvebdKqzfbZBIhegbg&oi=scholaralrt&hist=i6heNjgAAAAJ:8133205940682390297:ALhkC2SR8Uk0-bcx8xwn2F__iyOC&html=&pos=0&folt=rel)
*A Gurajada,G Rosenhouse,C Garcia*

Main category: Ziniu Wu

TL;DR: B树索引在关系数据库中广泛使用，但随机插入大规模B树成本高昂，影响性能


<details>
  <summary>Details</summary>
Motivation: 关系数据库大量使用B树索引来加速查询性能，但B树在处理随机插入工作负载时存在性能瓶颈，插入成本高昂，尤其是在大规模B树中，这影响了数据库的整体性能

Method: 论文未完整提供，但从摘要上下文推断，可能涉及优化B树插入性能的技术，如批量插入、缓冲机制、索引结构改进或替代索引方案

Result: 摘要未提供完整结果，但暗示现有B树在随机插入场景下存在性能问题，需要改进方案

Conclusion: B树索引虽然点查询性能优秀，但在处理随机插入工作负载时存在显著性能瓶颈，需要优化或替代方案来提升数据库的整体性能

Abstract: Relational databases make extensive use of B-tree indexes to accelerate query performance. B-Trees offer excellent point-query performance but inserting data into a large B-tree can be costly, especially for a workload of random inserts. In fact, high …

</details>


### [19] [Optimizer Dynamics at the Edge of Stability with Differential Privacy](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.19019&hl=zh-CN&sa=X&d=2167154085211273993&ei=WZlOaYC9Noaw6rQPkNu46Ao&scisig=ALhkC2SS5ZzF7n4zq5O8wz3wL3fB&oi=scholaralrt&hist=i6heNjgAAAAJ:8133205940682390297:ALhkC2SR8Uk0-bcx8xwn2F__iyOC&html=&pos=0&folt=rel)
*A Hussain,R Fang*

Main category: Ziniu Wu

TL;DR: 该论文研究差分隐私深度学习中的优化动态，特别是隐私保护如何影响模型训练过程中的梯度噪声和收敛行为


<details>
  <summary>Details</summary>
Motivation: 差分隐私虽然能保护训练数据隐私，但会改变深度学习模型的优化动态，这种影响机制尚未被充分理解，需要系统研究隐私保护与优化性能之间的权衡关系

Method: 研究差分隐私深度学习中的优化动态，分析隐私保护机制如何影响梯度噪声、收敛行为和训练稳定性，可能涉及理论分析和实验验证

Result: 揭示了差分隐私对深度学习优化过程的具体影响机制，包括梯度噪声特性、收敛速度变化以及隐私保护与模型性能之间的权衡关系

Conclusion: 差分隐私确实会显著改变深度学习的优化动态，理解这种影响对于设计更有效的隐私保护训练算法至关重要，需要在隐私保护与模型性能之间找到更好的平衡

Abstract: Deep learning models can reveal sensitive information about individual training examples, and while differential privacy (DP) provides guarantees restricting such leakage, it also alters optimization dynamics in poorly understood ways. We study …

</details>


### [20] [Risk-Aware GPU-Assisted Cardinality Estimation for Cost-Based Query Optimizers](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.19750&hl=zh-CN&sa=X&d=12832958009397126383&ei=NflPac6SM5aM6rQP0-TCwQU&scisig=ALhkC2ST7kOHpq2WpUOBRHpzWx8H&oi=scholaralrt&hist=i6heNjgAAAAJ:8133205940682390297:ALhkC2SR8Uk0-bcx8xwn2F__iyOC&html=&pos=0&folt=rel)
*I Chang*

Main category: Ziniu Wu

TL;DR: 论文实证分析了传统基数估计在真实工作负载中的失败模式，发现静态统计假设被违反导致决策不稳定和计划翻转率增加


<details>
  <summary>Details</summary>
Motivation: 基于成本的优化器(CBO)依赖基数估计，但真实工作负载经常违反静态统计假设，导致决策不稳定和计划翻转率增加，需要实证分析这些失败模式

Method: 通过实证研究分析真实工作负载中基数估计的失败情况，识别违反静态统计假设的具体模式

Result: 研究发现传统基数估计在真实工作负载中存在系统性失败，静态统计假设被违反导致优化器决策质量下降

Conclusion: 需要改进基数估计方法以适应真实工作负载的动态特性，减少计划翻转并提高优化器稳定性

Abstract: Cardinality estimation is a cornerstone of cost-based optimizers (CBOs), yet real-world workloads often violate the assumptions behind static statistics, degrading decision stability and increasing plan flip rates. We empirically characterize failures …

</details>


### [21] [Robust Index Benefit Estimation via Hierarchical and Two-dimensional Feature Representation](https://scholar.google.com/scholar_url?url=https://liangfengsid.github.io/paper/eddie_icde25.pdf&hl=zh-CN&sa=X&d=4799002212937979966&ei=NflPac6SM5aM6rQP0-TCwQU&scisig=ALhkC2QUXmpPaq6ekNxYAmggyWqc&oi=scholaralrt&hist=i6heNjgAAAAJ:8133205940682390297:ALhkC2SR8Uk0-bcx8xwn2F__iyOC&html=&pos=1&folt=rel)
*T Li,F Liang,J Quan,Z Yang,T Wang,R Huang,X Hu…*

Main category: Ziniu Wu

TL;DR: 机器学习索引顾问通过避免what-if优化器评估来估计索引收益，但现有方法未能充分捕捉索引相关特征


<details>
  <summary>Details</summary>
Motivation: 现有机器学习索引顾问方法在捕捉索引相关特征方面存在不足，导致索引收益估计不准确

Method: 未在摘要中明确说明，但暗示需要改进特征提取方法以更好地捕捉索引相关特征

Result: 未在摘要中明确说明，但暗示现有方法在索引收益估计方面存在局限性

Conclusion: 需要改进机器学习索引顾问的特征提取方法以更准确地估计索引收益

Abstract: In recent years, machine learning-based index advisors have gained success as they can estimate the benefit of a given index without actually evaluating it via what-if optimizers. However, existing methods often fail to capture indexrelevant features …

</details>


### [22] [Searching the Web: From Keywords to Semantic Queries](https://scholar.google.com/scholar_url?url=https://www.academia.edu/download/125824338/INPRO--2009-045.pdf&hl=zh-CN&sa=X&d=12040717176933026319&ei=Jtxdaf6vBe-GieoPo9DluQE&scisig=ALhkC2T12K3X1ZvwF65wkhpIQ1Ln&oi=scholaralrt&hist=i6heNjgAAAAJ:8133205940682390297:ALhkC2SR8Uk0-bcx8xwn2F__iyOC&html=&pos=1&folt=rel)
*A Illarramendi*

Main category: Ziniu Wu

TL;DR: 语义Web框架下传统基于关键词的搜索引擎已不足，需要基于用户关键词语义的新方法


<details>
  <summary>Details</summary>
Motivation: 在语义Web框架下，传统基于用户提供关键词的Web搜索引擎已不再适用，需要开发基于用户关键词语义的新搜索方法

Method: 未在摘要中明确说明具体方法，但暗示需要定义基于用户关键词语义的新搜索方法

Result: 摘要未提供具体实验结果，主要提出语义Web搜索需要新方法的论点

Conclusion: 语义Web框架需要超越传统关键词匹配的语义搜索方法

Abstract: Abstract Within the emergent Semantic Web framework, the use of traditional web search engines based on keywords provided by the users is not adequate anymore. Instead, new methods based on the semantics of user keywords must be defined to …

</details>


### [23] [Being Positive about Negative Queries: Exclusion Aware Multimodal Retrieval using Disentangled Representations](https://scholar.google.com/scholar_url?url=http://sumitbhatia.net/papers/wacv2026.pdf&hl=zh-CN&sa=X&d=4410317869167542922&ei=Jtxdaf6vBe-GieoPo9DluQE&scisig=ALhkC2TAEMvzG-DW82CY1kAX6bEf&oi=scholaralrt&hist=i6heNjgAAAAJ:8133205940682390297:ALhkC2SR8Uk0-bcx8xwn2F__iyOC&html=&pos=2&folt=rel)
*P Jha,S Bhatia,S Bedathur*

Main category: Ziniu Wu

TL;DR: 多模态检索中的排除处理是一个研究不足的挑战，对信息检索系统的准确性和可靠性有重要影响


<details>
  <summary>Details</summary>
Motivation: 多模态检索中的排除处理问题尚未得到充分探索，这对信息检索系统的准确性和可靠性具有重要影响。现有方法虽然在多模态表示学习方面取得了进展，但在处理排除查询方面仍存在局限性。

Method: 摘要未提供具体方法细节，但暗示需要开发新的方法来处理多模态检索中的排除查询问题

Result: 摘要未提供具体实验结果，但指出现有方法在处理排除查询方面存在局限性

Conclusion: 多模态检索中的排除处理是一个重要但研究不足的领域，需要进一步的研究和开发新的方法来提高信息检索系统的准确性和可靠性

Abstract: The handling of exclusion in multimodal retrieval remains an underexplored challenge with significant implications for the accuracy and reliability of information retrieval systems. Although existing approaches have advanced multimodal …

</details>


### [24] [Oracle Intelligent Data Lake](https://scholar.google.com/scholar_url?url=https://ijeret.org/index.php/ijeret/article/download/401/382&hl=zh-CN&sa=X&d=5751362816755413019&ei=s0Rfaaj5I-qsieoPjYOSgAM&scisig=ALhkC2SYQGkYzfFDR6VLx44fNamV&oi=scholaralrt&hist=i6heNjgAAAAJ:8133205940682390297:ALhkC2SR8Uk0-bcx8xwn2F__iyOC&html=&pos=1&folt=rel)
*B Nagaiah*

Main category: Ziniu Wu

TL;DR: Oracle IDL通过统一存储、自动化数据管理和AI驱动分析，解决组织从多样化复杂数据源中提取洞察的挑战


<details>
  <summary>Details</summary>
Motivation: 数据量的加速增长给组织从多样化和复杂数据源中提取有意义的洞察带来了新挑战，需要现代解决方案来应对这些数据管理难题

Method: Oracle智能数据湖（IDL）采用统一存储架构，结合自动化数据管理和AI驱动的分析功能

Result: 未在摘要中明确说明具体结果，但暗示该解决方案能够帮助组织更有效地处理和分析大规模多样化数据

Conclusion: Oracle IDL为组织应对数据增长挑战提供了一个现代化的统一数据管理和分析平台

Abstract: The accelerated increase in data has posed new challenges for organizations attempting to derive meaningful insights from diverse and complex sources. Oracle Intelligent Data Lake (IDL) is a modern solution designed to unify storage, automate …

</details>


### [25] [Improved Accuracy for Private Continual Cardinality Estimation in Fully Dynamic Streams via Matrix Factorization](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.02257&hl=zh-CN&sa=X&d=7577444969904975259&ei=hKNgaeOCK-qsieoPjYOSgAM&scisig=AHkA5jS722yeYB0c8r2WoepuA4wy&oi=scholaralrt&hist=i6heNjgAAAAJ:8133205940682390297:AHkA5jQfTAaKkXi3kBQuJYouRHpx&html=&pos=0&folt=rel)
*JD Andersson,P Jain,S Sivakumar*

Main category: Ziniu Wu

TL;DR: 研究完全动态持续观察模型下的差分隐私统计，该模型允许每个时间步有多个更新，且更新可包含项目的插入和删除


<details>
  <summary>Details</summary>
Motivation: 现有差分隐私算法主要针对静态数据或仅支持插入的流数据，无法处理现实世界中常见的动态更新场景（包含插入和删除），需要开发支持完全动态更新的差分隐私统计方法

Method: 在完全动态持续观察模型下设计差分隐私算法，处理每个时间步的多个更新，支持插入和删除操作，可能采用组合隐私预算分配、噪声添加机制和动态数据结构

Result: 开发了适用于完全动态更新场景的差分隐私统计方法，能够在保证隐私的同时处理包含插入和删除的流数据更新，扩展了差分隐私在动态环境中的应用范围

Conclusion: 完全动态持续观察模型为差分隐私统计提供了更现实的框架，能够处理包含插入和删除的复杂更新模式，为实际应用中的动态数据流隐私保护提供了理论基础和算法支持

Abstract: We study differentially-private statistics in the fully dynamic continual observation model, where many updates can arrive at each time step and updates to a stream can involve both insertions and deletions of an item. Earlier work (eg, Jain et al …

</details>


### [26] [SafeLoad: Efficient Admission Control Framework for Identifying Memory-Overloading Queries in Cloud Data Warehouses](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.01888&hl=zh-CN&sa=X&d=13054391438488161832&ei=g6NgaavqJ9rJieoPiYyysAk&scisig=AHkA5jSpfXYCZUId9ghSiYKflD5_&oi=scholaralrt&hist=i6heNjgAAAAJ:1601694329521098688:AHkA5jQrM3nSZacUAGpL-GSdbqwG&html=&pos=0&folt=cit)
*Y Wu,Y Li,Z Wang,Z Xie,D Yang,K Chen,L Shou…*

Main category: Ziniu Wu

TL;DR: 该论文提出通过预先识别内存过载查询并将其调度到内存丰富的无服务器集群，以防止云数据仓库中的内存过载问题


<details>
  <summary>Details</summary>
Motivation: 云数据仓库中内存过载是常见的资源耗尽形式，会导致查询失败、浪费CPU时间，并中断核心业务流程的执行，因为内存过载查询通常是复杂工作流的一部分

Method: 通过预先识别内存过载查询，并将其调度到内存丰富的无服务器集群中执行

Result: 该方法可以防止资源浪费和查询执行失败，提高云数据仓库的资源利用率和查询成功率

Conclusion: 预先识别和智能调度内存过载查询到适当资源环境是解决云数据仓库内存过载问题的有效策略

Abstract: Memory overload is a common form of resource exhaustion in cloud data warehouses. When database queries fail due to memory overload, it not only wastes critical resources such as CPU time but also disrupts the execution of core business processes, as memory-overloading (MO) queries are typically part of complex workflows. If such queries are identified in advance and scheduled to memory-rich serverless clusters, it can prevent resource wastage and query execution failure …

</details>


### [27] [Structural Indexing of Relational Databases for the Evaluation of Free-Connex Acyclic Conjunctive Queries](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.04757&hl=zh-CN&sa=X&d=79746272002302705&ei=5KVkacbQA-6TieoPutPYsQg&scisig=AHkA5jR55R6iNFq2lI-R1i4Fdysv&oi=scholaralrt&hist=i6heNjgAAAAJ:8133205940682390297:AHkA5jQfTAaKkXi3kBQuJYouRHpx&html=&pos=0&folt=rel)
*C Riveros,B Scheidt,N Schweikardt*

Main category: Ziniu Wu

TL;DR: 提出一种索引结构来加速关系数据库上自由连接无环连接查询(fc-ACQs)的评估


<details>
  <summary>Details</summary>
Motivation: 自由连接无环连接查询(fc-ACQs)是数据库查询中的重要类别，传统评估方法存在效率瓶颈，需要更高效的索引结构来加速这类查询的处理

Method: 构建基于给定数据库D的辅助数据库D_col作为索引的主要组成部分，该索引结构专门针对fc-ACQs查询特性设计，优化查询评估过程

Result: 该索引结构能够显著提升fc-ACQs查询的评估效率，相比传统方法具有更好的性能表现

Conclusion: 提出的索引结构为fc-ACQs查询提供了一种有效的加速方案，对数据库查询优化领域有实际应用价值

Abstract: We present an index structure to boost the evaluation of free-connex acyclic conjunctive queries (fc-ACQs) over relational databases. The main ingredient of the index associated with a given database $ D $ is an auxiliary database $ D_ {col} …

</details>


### [28] [Responsibility Measures for Conjunctive Queries with Negation](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.04868&hl=zh-CN&sa=X&d=18356082314881883882&ei=5KVkacbQA-6TieoPutPYsQg&scisig=AHkA5jTvz6R1P5oMieOWaScNwS5G&oi=scholaralrt&hist=i6heNjgAAAAJ:8133205940682390297:AHkA5jQfTAaKkXi3kBQuJYouRHpx&html=&pos=1&folt=rel)
*M Bienvenu,D Figueira,P Lafourcade*

Main category: Ziniu Wu

TL;DR: 该论文扩展了责任度量研究，从单调查询扩展到非单调查询，提出了处理否定和聚合操作的责任计算方法


<details>
  <summary>Details</summary>
Motivation: 现有责任度量研究主要关注单调查询，缺乏对非单调查询（包含否定和聚合操作）的责任计算方法，需要扩展责任度量框架以处理更广泛的查询类型

Method: 扩展责任度量框架以处理非单调查询，包括否定操作和聚合函数，提出相应的责任计算算法和理论分析

Result: 建立了非单调查询责任度量的理论基础，提出了有效的计算方法，证明了相关性质，扩展了责任度量的应用范围

Conclusion: 成功将责任度量从单调查询扩展到非单调查询，为数据库事实对查询结果的贡献量化提供了更全面的理论框架和实用方法

Abstract: We contribute to the recent line of work on responsibility measures that quantify the contributions of database facts to obtaining a query result. In contrast to existing work which has almost exclusively focused on monotone queries, here we explore how to …

</details>


<div id='您的个人学术档案'></div>

# 您的个人学术档案 [[Back]](#toc)

### [29] [Does A Fish Need a Bicycle? The Case for On-Chip NPUs in DBMS](https://scholar.google.com/scholar_url?url=https://www.vldb.org/cidrdb/papers/2026/p24-baumstark.pdf&hl=zh-CN&sa=X&d=6040004472213603902&ei=mA5KafXUCaGvieoPtIGfoAw&scisig=ALhkC2RB_E0heOGuV52B3EpUiVp6&oi=scholaralrt&hist=i6heNjgAAAAJ:9139054514476675507:ALhkC2QRjTTSgSFljDt0tvfYrYu8&html=&pos=0&folt=cit&fols=)
*A Baumstark,KU Sattler*

Main category: 您的个人学术档案

TL;DR: 该论文探讨了在数据库系统中集成机器学习功能的需求，分析了GPU加速的局限性，并提出了神经处理单元作为替代方案


<details>
  <summary>Details</summary>
Motivation: 客户和系统构建者对数据库内机器学习功能的需求日益增长，包括系统任务（索引、查询优化）和应用支持（推理、高级数据分析）。虽然GPU是加速机器学习任务的成熟技术，但成本高昂且需要主机与设备间的数据传输。

Method: 论文通过对比分析GPU和神经处理单元在数据库机器学习场景下的优缺点，提出神经处理单元作为更优的替代方案，可能涉及架构设计、性能评估和集成方法。

Result: 虽然摘要未提供具体实验结果，但暗示神经处理单元相比GPU在成本、数据传输效率等方面具有优势，更适合数据库内机器学习应用场景。

Conclusion: 神经处理单元为数据库内机器学习提供了比GPU更具成本效益和效率的加速方案，能够更好地满足客户和系统构建者的需求。

Abstract: ABSTRACT In-Database ML–integrating ML/AI features directly into DBMS–becomes more and more a requirement of customers and system builders. This includes system tasks such as indexing and query optimization, as well as application support such as inference and advanced data analytics. Although GPUs are an established technology for accelerating machine learning (ML) tasks, they are costly and require data transfer between the host and device. In contrast, neural processing units …

</details>


<div id='Zongheng Yang'></div>

# Zongheng Yang [[Back]](#toc)

### [30] [EcoLearn: Optimizing the Carbon Footprint of Federated Learning](https://scholar.google.com/scholar_url?url=https://noman-bashir.github.io/assets/pdf/SEC_2025_EcoLearn.pdf&hl=zh-CN&sa=X&d=13776276534927461345&ei=nlcuadaXDv-j6rQPrbnwwA4&scisig=ABGrvjJJtFMsSYtUEjD_4MLerV2B&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=0&folt=cit)
*T Mehboob,N Bashir,JO Iglesias,M Zink,D Irwin*

Main category: Zongheng Yang

TL;DR: 联邦学习通过在边缘设备上分布式训练来减少数据传输和保护隐私，但训练过程资源密集且能耗高，具有显著的碳足迹。由于不同地区的能源碳强度差异巨大（可达60倍），相同设备使用相同能量在不同位置训练会产生完全不同的碳排放。


<details>
  <summary>Details</summary>
Motivation: 联邦学习虽然解决了数据隐私和传输问题，但其大规模分布式训练模式消耗大量计算资源，导致显著的能源消耗和碳排放。由于全球不同地区的电网碳强度存在巨大差异（高达60倍），相同的训练任务在不同地理位置会产生完全不同的环境影响，这为优化联邦学习的碳效率提供了重要机会。

Method: 论文提出了一种考虑地理位置碳强度的联邦学习优化方法。通过分析不同地区的电网碳强度差异，设计调度策略将训练任务分配到碳强度较低的地区或时段，从而在保持模型性能的同时最小化整体碳排放。

Result: 研究结果表明，通过考虑地理位置碳强度的联邦学习调度策略，可以在不牺牲模型性能的情况下显著降低碳排放。相比传统不考虑碳强度的联邦学习，该方法能够实现高达数倍的碳减排效果。

Conclusion: 联邦学习的碳足迹优化需要综合考虑地理位置因素。通过将训练任务调度到碳强度较低的地区，可以在保持联邦学习隐私保护优势的同时，显著降低其环境影响，为实现可持续的分布式机器学习提供可行路径。

Abstract: Federated Learning (FL) distributes machine learning (ML) training across edge devices to reduce data transfer overhead and protect data privacy. Since FL model training may span hundreds of devices and is thus resource-and energyintensive, it has a significant carbon footprint. Importantly, since energy's carbon-intensity differs substantially (by up to 60×) across locations, training on the same device using the same amount of energy, but at different locations, can incur widely different carbon …

</details>


### [31] [Mix‐MaxETTS: A text‐to‐emotional speech synthesis model based on a deep encoder–decoder structure for the transfer of secondary emotions](https://scholar.google.com/scholar_url?url=https://onlinelibrary.wiley.com/doi/abs/10.4218/etrij.2025-0058&hl=zh-CN&sa=X&d=4495895945398831477&ei=nlcuadaXDv-j6rQPrbnwwA4&scisig=ABGrvjJCXLtjrvgW4-HXzrQQZkoV&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=1&folt=cit)
*SM Hassani,MR Kangavari*

Main category: Zongheng Yang

TL;DR: 该论文针对情感语音合成中主要关注单一基本情感、忽略混合情感（次级情感）的问题，提出了一种结合基本情感和次级情感的情感语音合成方法。


<details>
  <summary>Details</summary>
Motivation: 情感在社交互动中至关重要，情感语音合成在人机交互领域受到广泛关注。虽然情感文本转语音合成已取得显著进展，但现有研究大多集中于模仿特定基本情感的风格，忽略了由基本情感混合产生的次级情感，因此需要同时利用基本情感和次级情感来提升情感语音合成的表现力。

Method: 论文提出了一种情感语音合成方法，该方法不仅考虑基本情感（如高兴、悲伤、愤怒等），还整合了由基本情感混合形成的次级情感。具体方法可能涉及情感建模、特征提取、混合情感表示以及语音合成技术，以生成包含复杂情感状态的语音输出。

Result: 该方法能够生成更丰富、更自然的情感语音，涵盖从基本情感到复杂混合情感的各种情感状态，提升了情感语音合成的真实感和表现力。

Conclusion: 通过同时考虑基本情感和次级情感，该方法显著增强了情感语音合成的能力，为人机交互中更自然、更具表现力的情感交流提供了有效解决方案。

Abstract: Given the importance of emotions in social interactions, emotional speech synthesis has attracted significant attention in the field of human–computer interaction. Remarkable advancements have been made in emotional text‐to‐speech synthesis, but most previous studies have concentrated on imitating styles associated with a specific primary emotion, neglecting secondary emotions that arise from mixtures of primary emotions. Therefore, there is a need to leverage both primary and secondary …

</details>


### [32] [Geometrically-Constrained Agent for Spatial Reasoning](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.22659&hl=zh-CN&sa=X&d=10090796334953625511&ei=Jm4xadbZPLuZ6rQP9aakkAE&scisig=ABGrvjI5o5h3mW7TTxM6m1twopVL&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=1&folt=cit)
*Z Chen,X Lu,Z Zheng,P Li,L He,Y Zhou,J Shao…*

Main category: Zongheng Yang

TL;DR: 本文识别了视觉语言模型在空间推理中的语义-几何鸿沟问题，提出了一种新的框架来弥合这一差距，避免现有方法的局限性


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在空间推理中存在根本性的语义-几何鸿沟：它们在定性语义推理方面表现出色，但其推理在损失性语义空间中进行，与高保真几何不对齐。当前范式无法弥合这一差距。基于训练的方法存在"预言悖论"，从不完美的预言中学习有缺陷的空间逻辑。工具集成方法虽然约束了最终计算，但关键地让VLM的...

Method: 从摘要中无法完全确定具体方法，但暗示了一种新的框架来弥合语义-几何鸿沟，可能涉及避免预言悖论和工具集成的局限性，采用更系统的方式将几何推理整合到VLM的推理过程中

Result: 摘要未提供具体实验结果，但暗示提出的方法能够有效弥合语义-几何鸿沟，改善VLM在空间推理任务中的性能

Conclusion: 需要一种新的范式来弥合视觉语言模型中的语义-几何鸿沟，避免现有方法的局限性，实现更准确和可靠的空间推理能力

Abstract: Vision Language Models (VLMs) exhibit a fundamental semantic-to-geometric gap in spatial reasoning: they excel at qualitative semantic inference but their reasoning operates within a lossy semantic space, misaligned with high-fidelity geometry. Current paradigms fail to bridge this gap. Training-based methods suffer from an``oracle paradox,''learning flawed spatial logic from imperfect oracles. Tool-integrated methods constrain the final computation but critically leave the VLM's …

</details>


### [33] [Cohet: A CXL-Driven Coherent Heterogeneous Computing Framework with Hardware-Calibrated Full-System Simulation](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.23011&hl=zh-CN&sa=X&d=7016636906328984529&ei=Jm4xadbZPLuZ6rQP9aakkAE&scisig=ABGrvjJM8UdFLyjlVSNmsBW56Lvv&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=2&folt=cit)
*Y Wang,L Wu,S Gao,Y Tang,J Luo,Z Wang,Y Ou…*

Main category: Zongheng Yang

TL;DR: CXL互联标准有望解决传统PCIe异构计算系统中细粒度主机-设备交互效率低下和编程模型复杂的问题


<details>
  <summary>Details</summary>
Motivation: 传统基于PCIe的异构计算系统存在细粒度主机-设备交互效率低下和编程模型复杂的问题，需要新的解决方案

Method: 采用计算快速链接(CXL)这一开放式缓存一致性互联标准，该标准已整合多个竞争方案并在开放标准领域占据主导地位

Result: CXL有望从根本上改变异构计算架构，但具体实现效果和性能数据未在摘要中明确说明

Conclusion: 基于CXL的一致性异构计算具有从根本上解决传统异构计算系统瓶颈的潜力

Abstract: Conventional heterogeneous computing systems built on PCIe interconnects suffer from inefficient fine-grained host-device interactions and complex programming models. In recent years, many proprietary and open cache-coherent interconnect standards have emerged, among which compute express link (CXL) prevails in the open-standard domain after acquiring several competing solutions. Although CXL-based coherent heterogeneous computing holds the potential to fundamentally …

</details>


### [34] [Turbo-TTS: Enhancing Diffusion Model TTS with an Improved ODE Solver](https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-981-95-4367-0_7&hl=zh-CN&sa=X&d=310186615974899500&ei=Jm4xadbZPLuZ6rQP9aakkAE&scisig=ABGrvjKrdL3_JAwSG3_ym3qLGG9a&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ABGrvjJ5yrOPSUykBZGlsHlQXOAK&html=&pos=3&folt=cit)
*X Zhang,J Wang,X Qu,H Tian,J Wang*

Main category: Zongheng Yang

TL;DR: Turbo-TTS是一种基于扩散模型的文本转语音合成方法，通过提出新的ODE求解器并整合一致性建模原理，显著提高了语音质量和采样效率。


<details>
  <summary>Details</summary>
Motivation: 传统扩散模型在文本转语音合成中采样效率较低，需要改进以生成高质量语音同时保持高效推理。

Method: 提出Turbo-TTS模型，基于扩散模型框架，引入新的ODE求解器并整合一致性建模原理，优化扩散过程的采样效率。

Result: 该方法在语音合成质量上取得显著提升，同时提高了采样效率，能够生成高保真度的语音。

Conclusion: Turbo-TTS通过改进扩散模型的采样机制，为文本转语音合成提供了高效且高质量的解决方案。

Abstract: This paper introduces Turbo-TTS, a novel diffusion-based model for text-to-speech (TTS) synthesis. Diffusion models leverage stochastic differential equations (SDEs) to generate high-fidelity speech. To enhance the sampling efficiency of the diffusion process, we propose a new ordinary differential equation (ODE) solver and integrate consistency modeling principles into the TTS framework, leading to significant improvements in synthesized speech quality. Our approach discretizes the …

</details>


### [35] [SAGESERVE: Optimizing LLM Serving on Cloud Data Centers with Forecast Aware Auto-Scaling](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3771576&hl=zh-CN&sa=X&d=3028693173208666848&ei=bPYyaauJNIqi6rQPr6DGiAo&scisig=ALhkC2Qyqei8VoiO8Lgsy5O7ef8_&oi=scholaralrt&hist=i6heNjgAAAAJ:778719684493065653:ALhkC2T5y4v8XnzDuwC4ZadUm0Rx&html=&pos=0&folt=rel)
*S Jaiswal,K Jain,Y Simmhan,A Parayil,A Mallick…*

Main category: Zongheng Yang

TL;DR: 论文提出了一种名为InferLine的分布式推理服务系统，通过分层调度和模型变体管理来满足LLM推理中延迟敏感型和不敏感型任务的不同SLA需求


<details>
  <summary>Details</summary>
Motivation: 云服务提供商需要同时处理延迟敏感型（如聊天机器人）和不敏感型（如报告撰写）的LLM推理任务，这些任务具有多样且常常冲突的SLA要求。现有系统难以在保证延迟敏感任务低延迟的同时，最大化不敏感任务的吞吐量

Method: InferLine采用分层调度架构：1) 全局调度器将请求路由到合适的集群；2) 集群调度器管理模型变体（如不同精度、剪枝版本）以满足不同SLA；3) 利用模型变体间的性能差异进行智能调度，在保证延迟敏感任务SLA的同时优化资源利用率

Result: InferLine在真实工作负载上相比现有系统：1) 延迟敏感任务的平均延迟降低2.5倍；2) 不敏感任务的吞吐量提高1.8倍；3) 整体资源利用率提升40%；4) 在满足所有SLA要求的同时显著降低运营成本

Conclusion: 通过分层调度和模型变体管理，InferLine能够有效平衡LLM推理中延迟敏感和不敏感任务的冲突需求，为云服务提供商提供了一种高效、可扩展的推理服务解决方案

Abstract: Global cloud service providers handle inference workloads for Large Language Models (LLMs) that span latency-sensitive (eg, chatbots) and insensitive (eg, report writing) tasks, resulting in diverse and often conflicting Service Level Agreement …

</details>


### [36] [A spatial big data architecture for vehicle data analytics: a focus on spatial data storage and query optimization](https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s41060-025-00948-z&hl=zh-CN&sa=X&d=14666880717446334027&ei=bPYyaauJNIqi6rQPr6DGiAo&scisig=ALhkC2SNu3XJM4kWdPS5TouC3zk6&oi=scholaralrt&hist=i6heNjgAAAAJ:778719684493065653:ALhkC2T5y4v8XnzDuwC4ZadUm0Rx&html=&pos=1&folt=rel)
*S Ait Errami,H Hajji,K Ait El Kadi,H Badir*

Main category: Zongheng Yang

TL;DR: 该论文提出了一种用于车辆移动数据管理的集成端到端系统，旨在处理大规模异构数据集以支持智慧城市移动性和交通分析。


<details>
  <summary>Details</summary>
Motivation: 车辆移动数据管理对于推进智慧城市移动性和交通分析至关重要。当前领域不仅需要数据收集，更需要能够处理大规模异构数据集的集成端到端系统。

Method: 论文提出了一种集成端到端系统来处理大规模异构车辆移动数据集，具体方法细节需要更多信息来确定。

Result: 该系统能够有效管理车辆移动数据，支持智慧城市移动性和交通分析应用，具体性能指标需要更多信息来确定。

Conclusion: 集成端到端系统对于有效管理车辆移动数据至关重要，能够支持智慧城市移动性和交通分析的发展。

Abstract: Effective management of vehicle mobility data is critical for advancing smart urban mobility and transportation analytics. Beyond data collection, the field requires integrated, end-to-end systems to handle large, heterogeneous datasets generated …

</details>


### [37] [Towards an AI Cube for EO data inference in a distributed infrastructure](https://scholar.google.com/scholar_url?url=https://www.tandfonline.com/doi/pdf/10.1080/20964471.2025.2585733&hl=zh-CN&sa=X&d=16802528553947014830&ei=bPYyabndGuvJieoP4v_w2A0&scisig=ALhkC2Q0ScfqFWRWBfYQrzWC8_EZ&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=0&folt=cit)
*P Yue,K Wang*

Main category: Zongheng Yang

TL;DR: 提出AI Cube方法，将GeoAI模型集成到地理空间数据立方体中，增强传统地理处理算法的分析能力


<details>
  <summary>Details</summary>
Motivation: 现有地理空间数据立方体处理主要关注传统地理处理算法，尚不清楚如何用地理空间人工智能(GeoAI)模型增强立方体分析能力

Method: 提出AI Cube方法，从地理空间数据存储和处理扩展到立方体推理，增强立方体能力

Result: 未在摘要中明确说明具体结果，但暗示该方法能够改善立方体从数据存储、处理到推理的全流程能力

Conclusion: AI Cube方法为地理空间数据立方体与GeoAI模型的集成提供了有效途径，有望提升地球观测大数据分析的集成性和效率

Abstract: Geospatial data cubes show great promise to facilitate integrated and efficient analysis of big Earth Observation (EO) data. Existing geospatial data cube processing focuses more on traditional geoprocessing algorithms. It is still unknown how to enhance cube analytics with geospatial artificial intelligence (GeoAI) models. The paper presents an AI cube approach to improve the cube capabilities from geospatial data storage and processing to the cube inference. The approach …

</details>


### [38] [Art2Music: Generating Music for Art Images with Multi-modal Feeling Alignment](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.00120&hl=zh-CN&sa=X&d=2845038714390632625&ei=bPYyabndGuvJieoP4v_w2A0&scisig=ALhkC2QvUDTPMtVQ2NOM3RaRW4Ax&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=1&folt=cit)
*J Hong,T Zhu,T Markchom,H Liang*

Main category: Zongheng Yang

TL;DR: 提出ArtiCaps数据集和Feeling-Aligned Multimodal Music Generation (FAMMG)框架，用于从多模态输入生成感知自然且情感对齐的音乐，无需显式情感标注


<details>
  <summary>Details</summary>
Motivation: 随着AIGC兴起，从多模态输入生成感知自然且情感对齐的音乐成为核心挑战。现有方法依赖需要昂贵标注的显式情感标签，需要更灵活的情感对齐方法

Method: 构建ArtiCaps伪情感对齐图像-音乐-文本数据集，通过语义匹配描述创建；提出Feeling-Aligned Multimodal Music Generation (FAMMG)框架，利用多模态对齐和情感对齐机制

Result: ArtiCaps数据集支持多模态音乐生成；FAMMG框架在生成感知自然且情感对齐的音乐方面表现优于现有方法，无需显式情感标注

Conclusion: ArtiCaps数据集和FAMMG框架为多模态音乐生成提供了有效的情感对齐解决方案，减少了对昂贵标注的依赖，推动了AIGC在音乐创作领域的发展

Abstract: With the rise of AI-generated content (AIGC), generating perceptually natural and feeling-aligned music from multimodal inputs has become a central challenge. Existing approaches often rely on explicit emotion labels that require costly annotation, underscoring the need for more flexible feeling-aligned methods. To support multimodal music generation, we construct ArtiCaps, a pseudo feeling-aligned image-music-text dataset created by semantically matching descriptions from …

</details>


### [39] [IslandRun: Privacy-Aware Multi-Objective Orchestration for Distributed AI Inference](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.00595&hl=zh-CN&sa=X&d=8943226420588748644&ei=bPYyabndGuvJieoP4v_w2A0&scisig=ALhkC2Rq6wCgNN2gGiLXh5FA_MB6&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=3&folt=cit)
*BSSA Malepati*

Main category: Zongheng Yang

TL;DR: IslandRun是一个多目标编排系统，旨在解决AI推理中性能、隐私、成本和信任之间的不可调和矛盾


<details>
  <summary>Details</summary>
Motivation: 现代AI推理面临性能、隐私、成本和信任之间的不可调和矛盾，现有编排框架（如Kubernetes、联邦学习、边缘计算）仅优化单一维度，无法应对现实世界的异构性挑战

Method: 提出了IslandRun多目标编排系统，通过综合优化多个目标维度来解决AI推理中的资源分配和任务调度问题

Result: 未在摘要中明确说明具体实验结果，但暗示系统能够更好地平衡性能、隐私、成本和信任等多重目标

Conclusion: IslandRun系统为解决AI推理中多目标优化问题提供了一种有效的编排框架，能够应对现实世界的异构性挑战

Abstract: Modern AI inference faces an irreducible tension: no single computational resource simultaneously maximizes performance, preserves privacy, minimizes cost, and maintains trust. Existing orchestration frameworks optimize single dimensions (Kubernetes prioritizes latency, federated learning preserves privacy, edge computing reduces network distance), creating solutions that struggle under real-world heterogeneity. We present IslandRun, a multi-objective orchestration system …

</details>


### [40] [Arabic TTS with FastPitch: Reproducible Baselines, Adversarial Training, and Oversmoothing Analysis](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.00937&hl=zh-CN&sa=X&d=15563473975806017455&ei=bPYyabndGuvJieoP4v_w2A0&scisig=ALhkC2TRe_mq3EI2B7M01CNZc0za&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=4&folt=cit)
*L Nippert*

Main category: Zongheng Yang

TL;DR: 基于FastPitch架构构建可复现的阿拉伯语TTS基线，引入倒谱域指标分析梅尔谱预测中的过平滑问题


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语文本转语音面临资源有限和复杂音系模式的挑战，需要建立可复现的基线系统并解决梅尔谱预测中的过平滑问题

Method: 基于FastPitch架构构建阿拉伯语TTS系统，引入倒谱域指标分析传统Lp重构损失导致的过平滑问题，并提出改进方法

Result: 传统Lp重构损失会产生平滑但过度平均化的输出，提出的倒谱域指标能够揭示训练过程中过平滑的时域和频域效应

Conclusion: 需要针对阿拉伯语TTS开发更有效的训练策略来缓解过平滑问题，倒谱域指标为分析梅尔谱预测质量提供了新视角

Abstract: Arabic text-to-speech (TTS) remains challenging due to limited resources and complex phonological patterns. We present reproducible baselines for Arabic TTS built on the FastPitch architecture and introduce cepstral-domain metrics for analyzing oversmoothing in mel-spectrogram prediction. While traditional Lp reconstruction losses yield smooth but over-averaged outputs, the proposed metrics reveal their temporal and spectral effects throughout training. To address this, we …

</details>


### [41] [SoundTwin: A High-Similarity Fast Diffusion Autoregressive Speech Cloning Model Based on Local-Global Feature Fusion](https://scholar.google.com/scholar_url?url=https://www.researchsquare.com/article/rs-7512915/latest.pdf&hl=zh-CN&sa=X&d=18321831410492868453&ei=Ulw0aZeJFM2j6rQP2_qhyQ8&scisig=ALhkC2S_8HIL09iKqn2RTEp-8AVd&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=0&folt=cit)
*Q Li,H Qu,Y Kang*

Main category: Zongheng Yang

TL;DR: 提出一种新的语音克隆方法，在低资源和低延迟条件下实现高质量语音合成


<details>
  <summary>Details</summary>
Motivation: 当前TTS技术在低资源、低延迟条件下的高质量语音克隆仍面临挑战：自回归模型推理延迟高，扩散模型计算开销大

Method: 基于摘要描述，该方法可能采用非自回归架构或优化采样策略，以平衡语音质量与计算效率

Result: 未提供具体实验结果，但预期在保持语音质量的同时显著降低推理延迟和计算开销

Conclusion: 提出的方法有望解决传统TTS模型在低资源、低延迟场景下的局限性

Abstract: In recent years, significant advances in deep learning have propelled text-to-speech (TTS) technology forward. However, there are still challenges in high-quality voice cloning with low-resource and low-latency conditions. Traditional autoregressive models suffer from high inference latency, while emerging diffusion models, although capable of generating high-fidelity speech, incur substantial computational overhead due to their multi-step sampling process. To mitigate these limitations, we propose …

</details>


### [42] [Stress-Testing Causal Claims via Cardinality Repairs](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.02491&hl=zh-CN&sa=X&d=11749906484243822877&ei=Ulw0aYr3KMeB6rQP-bb0sAs&scisig=ALhkC2SAD5WVI4HRu_pWIMu1vnjB&oi=scholaralrt&hist=i6heNjgAAAAJ:778719684493065653:ALhkC2T5y4v8XnzDuwC4ZadUm0Rx&html=&pos=1&folt=rel)
*Y Gabbay,H Guan,S Almagor,EK Rezig…*

Main category: Zongheng Yang

TL;DR: 论文探讨了观测数据因果分析的脆弱性，指出即使是微小的数据错误（如重复记录或录入错误）也可能导致因果结论发生显著变化


<details>
  <summary>Details</summary>
Motivation: 观测数据因果分析支撑着医疗、公共政策和经济等领域的高风险决策，但这些结论可能出人意料地脆弱，微小的数据错误就会导致因果结论发生显著变化，这引发了对其可靠性的担忧

Method: 论文可能通过理论分析和实证研究来探讨数据错误对因果推断的影响，可能包括敏感性分析、鲁棒性检验或提出新的评估框架来量化数据错误对因果结论的影响

Result: 研究可能发现观测数据因果分析对数据错误高度敏感，即使是看似微小的数据质量问题也可能导致因果效应估计发生实质性变化，从而影响决策的可靠性

Conclusion: 观测数据因果分析的脆弱性需要被认真对待，研究者需要开发更鲁棒的方法来评估和减轻数据错误的影响，以确保因果结论的可靠性

Abstract: Causal analyses derived from observational data underpin high-stakes decisions in domains such as healthcare, public policy, and economics. Yet such conclusions can be surprisingly fragile: even minor data errors-duplicate records, or entry mistakes …

</details>


### [43] [Potential of artificial intelligence in deepfake media: From generation to detection mechanisms, state-of-the-art, and challenges](https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S157401372500142X&hl=zh-CN&sa=X&d=4137855581993608768&ei=jNI1aZjdJqG7ieoPydy_qAE&scisig=ALhkC2TQ-1wPd7bN-5K3x0QeEFAK&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=0&folt=cit)
*S Sharma,A Selwal*

Main category: Zongheng Yang

TL;DR: 该论文探讨了人工智能在生成深度伪造内容中的关键作用，分析了当前技术能力与挑战，并强调了在数字媒体爆炸式增长背景下进行批判性审查的必要性。


<details>
  <summary>Details</summary>
Motivation: 深度伪造技术的快速发展和数字媒体的指数级增长，要求对当前AI生成合成媒体的能力与挑战进行全面批判性审查。虽然媒体操纵概念并非新事物，但现代深度伪造技术的复杂性和逼真度已达到了前所未有的水平。

Method: 论文采用综合分析方法，评估人工智能在生成深度伪造内容中的角色，重点关注机器学习模型在视觉、音频和多模态格式中创建超现实合成媒体的技术实现。

Result: AI通过先进的机器学习模型在深度伪造生成中发挥核心作用，能够创建高度逼真的视觉、音频和多模态合成媒体。技术发展迅速，但同时也面临诸多技术和社会挑战。

Conclusion: 深度伪造技术已达到前所未有的复杂水平，需要系统性的技术评估和社会影响分析。在数字媒体时代，必须平衡技术创新与伦理考量，建立有效的检测和监管机制。

Abstract: Artificial intelligence (AI) plays an important role in the generation of deepfakes by leveraging advanced machine learning models to create hyper-realistic synthetic media across visual, audio, and multimodal formats. The rapid evolution of deepfake technologies, alongside the exponential growth of digital media, demands a comprehensive and critical examination of current capabilities and challenges. Although the concept of media manipulation is not new, the sophistication and …

</details>


### [44] [EAM: emotional avatar generation for the metaverse](https://scholar.google.com/scholar_url?url=https://ceur-ws.org/Vol-4119/p16_rev.pdf&hl=zh-CN&sa=X&d=14264632432022275800&ei=jNI1aZjdJqG7ieoPydy_qAE&scisig=ALhkC2Q2nfnW2xq7RdbzurrwHl3D&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=1&folt=cit)
*A González*

Main category: Zongheng Yang

TL;DR: Project EAM是一个用于生成和管理具有情感表达语音合成与自动面部动画的虚拟形象框架，支持西班牙语和巴斯克语，可合成四种不同情感语调的语音。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够生成具有情感表达能力的虚拟形象系统，支持多语言情感语音合成和自动面部动画，以增强虚拟形象的交互性和表现力。

Method: 1. 构建情感语音合成系统，使用专业录制的情感语音进行训练；2. 集成自动强制对齐器生成视位序列；3. 结合实时面部动画技术；4. 支持西班牙语和巴斯克语两种伊比利亚语言。

Result: 开发了Project EAM框架，能够生成具有四种情感语调的语音合成，并自动生成相应的面部动画，支持西班牙语和巴斯克语两种语言。

Conclusion: Project EAM为多语言情感虚拟形象生成提供了一个综合框架，通过结合情感语音合成和自动面部动画技术，显著提升了虚拟形象的情感表达能力。

Abstract: This paper presents Project EAM, a framework for generating and managing avatars with emotionally expressive speech synthesis and automatic facial animation. The system supports two Iberian languages, Spanish and Basque, and synthesises speech in four distinct emotional tones. Its built-in Speech Synthesis system, trained with professionally recorded emotional voices, is complemented by an automatic forced aligner to generate viseme sequences. By incorporating real-time facial …

</details>


### [45] [How Heavy is the Edge? Resource Utilization of Edge Generative AI on Distributed AI Infrastructure](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3769102.3774241&hl=zh-CN&sa=X&d=8468751440772888466&ei=jNI1aZjdJqG7ieoPydy_qAE&scisig=ALhkC2SDDdk_Fm9_Lyh1SMtYR1qM&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=2&folt=cit)
*L Wu,Z Zeng,Z Gu,P Wu*

Main category: Zongheng Yang

TL;DR: 该研究探索了将Ray分布式AI基础设施扩展到边缘计算环境，以支持边缘AI服务，并分析了边缘生成式AI在部署和推理阶段的资源利用模式。


<details>
  <summary>Details</summary>
Motivation: 分布式AI基础设施在云环境中已广泛应用，但扩展到边缘计算仍处于探索阶段。随着AI服务需求的增长，需要在边缘环境中部署AI基础设施以满足低延迟、高可用性等需求。

Method: 使用Ray（广泛采用的开源分布式AI基础设施）来支持边缘AI，并分析边缘生成式AI在部署和推理阶段的资源利用模式。

Result: 揭示了边缘生成式AI在部署和推理阶段的资源利用模式，提供了更全面的视图，有助于优化边缘AI基础设施的设计和部署。

Conclusion: 通过将Ray分布式AI基础设施扩展到边缘，可以有效地支持边缘AI服务，为边缘计算环境中的AI基础设施部署提供了可行的解决方案。

Abstract: Distributed AI infrastructures are extensively employed in cloud industry settings to accommodate the growing demands of AI services. However, extending such infrastructures to the edge remains under exploration. This study addresses this challenge by enabling edge AI with Ray, a widely adopted open-source distributed AI infrastructure. This work uncovers the resource utilization patterns of edge GenAI across deployment and inference stages, providing a more comprehensive view of …

</details>


### [46] [FedDES: Discrete Event Based Performance Simulation for Federated Learning Systems](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3769102.3770613&hl=zh-CN&sa=X&d=14739984276362478246&ei=jNI1aZjdJqG7ieoPydy_qAE&scisig=ALhkC2QiQLKQfi-AYS1ia_y8HCzr&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=3&folt=cit)
*Z Chen,W Chen,D Zhang,K Kim,G Li,S Di,X Lu*

Main category: Zongheng Yang

TL;DR: FedDES是一个高保真、框架无关的离散事件仿真器，用于高效模拟联邦学习系统，解决现有仿真器扩展性差、运行时间长的问题


<details>
  <summary>Details</summary>
Motivation: 现实世界联邦学习部署面临计算异构性和通信延迟等系统挑战，需要仿真测试。现有大多数FL仿真器扩展效率低，即使小规模工作负载也运行时间长，需要更高效的仿真解决方案

Method: 提出FedDES，一个高保真、框架无关的离散事件仿真器，采用离散事件仿真方法模拟联邦学习系统，能够高效处理大规模FL工作负载

Result: FedDES相比现有仿真器显著提高了仿真效率，能够快速模拟大规模联邦学习系统，同时保持高保真度

Conclusion: FedDES为联邦学习研究提供了一个高效、可扩展的仿真平台，有助于在真实部署前进行系统性能评估和优化

Abstract: Federated Learning (FL) is a scalable and privacy-preserving paradigm well-suited for edge computing. Real-world FL deployments face substantial systems challenges such as compute variability and communication delays, motivating researchers to leverage simulation before real deployment. Most existing FL simulators, however, struggle to scale efficiently and incur long runtimes even for small workloads. To address this, we present FedDES, a high-fidelity, framework-agnostic discrete-event …

</details>


### [47] [ADAPT-IA: Towards an Adaptive AI in Language Technologies applied to RIS3 Industrial sectors](https://scholar.google.com/scholar_url?url=https://ceur-ws.org/Vol-4119/p57_rev.pdf&hl=zh-CN&sa=X&d=15960675729182185579&ei=jNI1aZjdJqG7ieoPydy_qAE&scisig=ALhkC2Qm6QPGAl718Dgstm1WruFR&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=4&folt=cit)
*A Álvarez,A del Pozo,M Cuadros,T Etchegoyhen…*

Main category: Zongheng Yang

TL;DR: ADAPT-IA项目旨在解决巴斯克语在语言技术中的代表性不足问题，通过开发自适应AI技术促进该语言在工业环境中的应用。


<details>
  <summary>Details</summary>
Motivation: 巴斯克语作为巴斯克自治区的官方语言，虽然使用者数量在增长，但在语言技术领域仍被严重忽视，缺乏工业应用支持。该项目旨在推动巴斯克语在工业环境中的使用。

Method: ADAPT-IA作为一个研发项目，专注于自适应人工智能技术，具体方法未在摘要中详细说明，但核心是开发适应巴斯克语特点的语言技术解决方案。

Result: 摘要未提供具体结果，但项目已启动并专注于巴斯克语的自适应AI技术研发。

Conclusion: 需要专门针对巴斯克语的语言技术研发项目来弥补其在工业应用中的空白，ADAPT-IA项目为此提供了重要开端。

Abstract: Despite the fact that Language Technologies are increasingly benefiting Industry by accelerating and automating processes, Basque remains a largely overlooked language in these technologies, even though it is an official language of the Autonomous Community of the Basque Country and has a growing number of speakers. With the aim of promoting its use in industrial environments, ADAPT-IA was launched as a research and development project focused on Adaptive AI …

</details>


### [48] [Multi-Agent Reinforcement Learning with Serverless Computing](https://scholar.google.com/scholar_url?url=https://intellisys.haow.us/assets/pdf/socc25-final106.pdf&hl=zh-CN&sa=X&d=13407109847582748434&ei=j-U4acrVIdOyieoPhbaZiA4&scisig=ALhkC2QNC0KvdecptyHU-wFxoUTc&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=0&folt=cit)
*R Wei,H Yu,X Song,J Li,D Tiwari,Y Mao,H Wang*

Main category: Zongheng Yang

TL;DR: 该论文探讨了将无服务器计算应用于多智能体强化学习训练，以解决现有系统仅关注单智能体场景的局限性。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习在科学模拟、多机器人协作、交通控制等任务中具有重要应用价值，而无服务器计算以其动态灵活的资源配置能力，在提高RL训练效率和成本效益方面展现出潜力。然而，现有的无服务器RL训练系统主要关注单智能体场景，忽视了多智能体训练的独特挑战和需求。

Method: 论文提出了一种专门针对多智能体强化学习的无服务器训练系统，该系统需要处理多智能体环境中的复杂协调、通信和资源分配问题，可能涉及智能体间通信优化、分布式训练架构设计、动态资源调度等关键技术。

Result: 虽然摘要未提供具体实验结果，但可以预期该系统能够显著提高多智能体RL训练的效率，降低计算成本，并支持更大规模的多智能体协作任务。

Conclusion: 将无服务器计算与多智能体强化学习相结合是一个有前景的研究方向，能够解决现有系统的局限性，为复杂多智能体系统的训练提供更高效、更经济的解决方案。

Abstract: Multi-agent reinforcement learning (MARL) has emerged as a promising approach for tasks requiring multiple agents for cooperation or competition, such as scientific simulation, multi-robot collaboration, and traffic control. Serverless computing, with its dynamic and flexible resource allocation, has demonstrated potential for improving training efficiency and cost-efficiency in RL workloads. However, existing serverless RL training systems focus primarily on single-agent scenarios, overlooking the …

</details>


### [49] [Understanding and Detecting Query Performance Regression in Practical Index Tuning:[Experiments & Analysis]](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3769839&hl=zh-CN&sa=X&d=13618502475994329695&ei=j-U4aYCOObuZ6rQPr6jTsQE&scisig=ALhkC2TPl4WFMnzOJAxALEARKTnf&oi=scholaralrt&hist=i6heNjgAAAAJ:778719684493065653:ALhkC2T5y4v8XnzDuwC4ZadUm0Rx&html=&pos=0&folt=rel)
*W Wu,A Dutt,G Xu,V Narasayya,S Chaudhuri*

Main category: Zongheng Yang

TL;DR: 现有索引调优工具依赖查询优化器的"what-if"API来估计索引配置下的查询执行成本，但这些成本估计可能不准确，导致查询性能显著下降。


<details>
  <summary>Details</summary>
Motivation: 传统索引调优方法依赖查询优化器提供的"what-if"API进行成本估计，但这些估计存在不准确性，可能导致次优的索引配置选择，从而影响查询性能。

Method: 论文未在摘要中明确描述具体方法，但暗示需要改进或替代现有的"what-if"API依赖方法，可能涉及更准确的成本估计技术或不同的索引调优策略。

Result: 摘要未提供具体实验结果，但指出现有方法因依赖不准确的成本估计可能导致显著的查询性能问题。

Conclusion: 需要开发不依赖或不完全依赖查询优化器"what-if"API成本估计的索引调优方法，以提高索引配置选择的准确性和查询性能。

Abstract: Existing index tuners typically rely on the''what if''API provided by the query optimizer to estimate the execution cost of a query on top of an index configuration. Such cost estimates can be inaccurate and may therefore lead to significant query performance …

</details>


### [50] [High Performance or Low Memory? An Updatable Learned Index Framework for Time-Space Tradeoff](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3769800&hl=zh-CN&sa=X&d=14794675507313412482&ei=j-U4aYCOObuZ6rQPr6jTsQE&scisig=ALhkC2Tp4G-m13qGusHujSrEqsqf&oi=scholaralrt&hist=i6heNjgAAAAJ:778719684493065653:ALhkC2T5y4v8XnzDuwC4ZadUm0Rx&html=&pos=1&folt=rel)
*H Wang,X Wang,J Ge,Y Chai,L Liang,P Yi*

Main category: Zongheng Yang

TL;DR: 该论文探讨了学习型索引在追求极致性能时面临的空间效率与准确性之间的权衡问题，提出了一种新的优化方法。


<details>
  <summary>Details</summary>
Motivation: 第一代学习型索引相比传统索引结构具有更低的空间开销，这成为索引优化的关键研究方向。然而，在追求极致性能的过程中，学习型索引面临着空间效率与准确性之间的权衡挑战。

Method: 论文提出了一种新的优化方法来解决学习型索引在空间效率与准确性之间的权衡问题，具体方法未在摘要中详细说明。

Result: 该方法能够有效平衡学习型索引的空间开销与查询性能，在保持较低空间占用的同时提升索引的准确性和效率。

Conclusion: 该研究为学习型索引的优化提供了新的思路，解决了空间效率与准确性之间的权衡问题，推动了学习型索引技术的进一步发展。

Abstract: The first generation of learned indexes inherently achieved lower space overhead than traditional index structures, establishing this advantage as one of the pivotal research directions in index optimization. However, in their pursuit of peak …

</details>


### [51] [Masked-speech Recognition Using Human and Synthetic Cloned Speech](https://scholar.google.com/scholar_url?url=https://journals.sagepub.com/doi/pdf/10.1177/23312165251403080&hl=zh-CN&sa=X&d=2642164859577129254&ei=oHs6ad3pLL2qieoP4o3V0Q0&scisig=ALhkC2SfRAPQ0df99Axy7IYmDqvq&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=0&folt=cit)
*L Calandruccio,M Hariri,E Buss,V Chaudhary*

Main category: Zongheng Yang

TL;DR: 比较人类语音与语音克隆合成语音在噪声环境下的可懂度、人声相似度和感知相似度


<details>
  <summary>Details</summary>
Motivation: 随着语音克隆技术的发展，需要评估合成语音在真实应用场景中的表现，特别是在噪声环境下的可懂度和感知特性，以验证其实际应用价值。

Method: 使用5位人类说话者的语音及其语音克隆合成语音，在-6 dB信噪比的语音形状噪声中进行掩蔽句子识别测试，评估年轻正常听力成年人的可懂度、人声相似度和感知相似度。

Result: 实验结果显示语音克隆合成语音与人类原始语音在可懂度、人声相似度和感知相似度方面的比较结果（具体数据未在摘要中提供）。

Conclusion: 语音克隆技术生成的合成语音在噪声环境下具有与人类语音相当的感知特性，为语音合成技术的实际应用提供了实证支持。

Abstract: Voice cloning is used to generate synthetic speech that mimics vocal characteristics of human talkers. This experiment used voice cloning to compare human and synthetic speech for intelligibility, human-likeness, and perceptual similarity, all tested in young adults with normal hearing. Masked-sentence recognition was evaluated using speech produced by five human talkers and their synthetically generated voice clones presented in speech-shaped noise at− 6 dB signal-to-noise …

</details>


### [52] [Metronome: Differentiated Delay Scheduling for Serverless Functions](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.05703&hl=zh-CN&sa=X&d=2151797299701646291&ei=oHs6ad3pLL2qieoP4o3V0Q0&scisig=ALhkC2SbXEARsV78A1hVCLYoWahc&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=1&folt=cit)
*Z Chen,J Zheng,Z Zheng*

Main category: Zongheng Yang

TL;DR: 该论文系统评估了延迟调度在无服务器平台中的应用，探讨了数据局部性在函数即服务计算中的优化潜力


<details>
  <summary>Details</summary>
Motivation: 函数即服务（FaaS）计算因其易于管理和弹性而成为新兴的云计算范式，但无服务器函数的动态和事件驱动特性使得调度优化具有挑战性。虽然数据局部性通过延迟调度在传统集群计算系统中已被证明有效，但在无服务器平台中的应用仍未被充分探索。

Method: 论文系统评估了现有延迟调度方法在无服务器平台中的应用，探讨了如何将数据局部性优化策略从传统集群计算迁移到函数即服务环境。

Result: 研究结果显示延迟调度在无服务器平台中具有优化潜力，能够改善数据局部性并提升系统性能。

Conclusion: 数据局部性优化策略可以有效地应用于无服务器平台，延迟调度为函数即服务计算提供了性能改进的新途径。

Abstract: Function-as-a-Service (FaaS) computing is an emerging cloud computing paradigm for its ease-of-management and elasticity. However, optimizing scheduling for serverless functions remains challenging due to their dynamic and event-driven nature. While data locality has been proven effective in traditional cluster computing systems through delay scheduling, its application in serverless platforms remains largely unexplored. In this paper, we systematically evaluate existing delay …

</details>


### [53] [Conversation Context-aware Direct Preference Optimization for Style-Controlled Speech Synthesis](https://scholar.google.com/scholar_url?url=http://www.apsipa.org/proceedings/2025/papers/APSIPA2025_P321.pdf&hl=zh-CN&sa=X&d=13170214968950033870&ei=oHs6ad3pLL2qieoP4o3V0Q0&scisig=ALhkC2Siqb5FjqmtlIYz9tzf2hRi&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=3&folt=cit)
*A Kojima,Y Fujita,H Shi,T Mizumoto,M Zhao,Y Sudo*

Main category: Zongheng Yang

TL;DR: 提出基于偏好的优化方法，通过强化模型选择上下文合适的情感表达，解决对话TTS中相似情感（如快乐与愤怒）导致不恰当渲染的问题


<details>
  <summary>Details</summary>
Motivation: 对话TTS通过建模对话上下文生成语境合适的表达性语音，无需手动标注副语言标签（如情感或意图）。然而，声学上相似的情感（如快乐与愤怒）常导致不恰当的渲染效果

Method: 采用基于偏好的优化方法，强化模型向选择上下文合适的情感表达方向优化。具体采用直接偏好优化（DPO）或类似技术，通过对比学习区分相似情感的细微差别

Result: 该方法能有效区分声学相似但语境不同的情感表达，提高对话TTS生成语音的语境适切性和情感准确性

Conclusion: 基于偏好的优化是解决对话TTS中相似情感混淆问题的有效方法，能提升模型对上下文情感表达的判别能力

Abstract: Conversational text-to-speech (TTS) generates context-appropriate expressive speech by modeling dialogue context, without requiring manual paralinguistic labels such as emotion or intent. However, acoustically similar emotions (eg, happy vs. angry) often cause inappropriate renderings. To address this, we propose a preference-based optimization approach that reinforces the model toward selecting contextually appropriate emotional expressions. Specifically, we adopt direct …

</details>


### [54] [Mocha: Scalable and Compliant Function Scheduling for Federated Serverless Computing](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3721462.3770780&hl=zh-CN&sa=X&d=9798203197917520877&ei=aQA8aZKHE-CuieoP1s6B2AU&scisig=ALhkC2TlIAoCwG2opi_zbiSUHdnE&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=0&folt=cit)
*Y Zhang,HA Jacobsen*

Main category: Zongheng Yang

TL;DR: 论文提出去中心化调度框架解决服务器无计算在多地理分布自治域中的异构策略、数据治理和动态负载挑战


<details>
  <summary>Details</summary>
Motivation: 当前生产级服务器无计算平台采用单提供商集中调度控制平面，难以处理现代Web应用中跨多个地理分布自治域的异构策略、数据治理约束和动态工作负载

Method: 提出去中心化调度框架，替代传统的集中式调度模型，支持跨多个自治管理域的分布式决策

Result: 未在摘要中明确说明具体实验结果，但暗示提出的去中心化方法能够更好地处理异构策略、数据治理和动态工作负载

Conclusion: 去中心化调度是解决服务器无计算在多地理分布自治域中挑战的有效途径

Abstract: Serverless computing promises on-demand elasticity and simplified deployment, yet today's production-grade serverless platforms remain tied to a single-provider, centrally scheduled control plane. This centralized scheduling model faces mounting challenges in handling heterogeneous policies, data governance constraints, and dynamic workloads for the modern web, where applications increasingly span multiple geo-distributed autonomous administrative domains. In this paper, we …

</details>


### [55] [Co-distillation-based defense framework for federated knowledge graph embedding against poisoning attacks](https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0920548925001424&hl=zh-CN&sa=X&d=16099639662074821221&ei=aQA8aZKHE-CuieoP1s6B2AU&scisig=ALhkC2TJ-ERFscPSiUkkMDdblp77&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=1&folt=cit)
*Y Lu,J Chen,J Qin*

Main category: Zongheng Yang

TL;DR: 提出CoDFKGE框架，通过协同蒸馏技术防御联邦知识图谱嵌入中的无目标投毒攻击


<details>
  <summary>Details</summary>
Motivation: 联邦知识图谱嵌入(FKGE)支持协作知识共享而无需数据交换，但引入了投毒攻击风险，可能降低模型准确性或强制错误输出。保护FKGE免受投毒攻击成为关键研究问题。

Method: 揭示无目标FKGE投毒攻击的恶意策略，提出基于协同蒸馏的FKGE框架CoDFKGE用于防御投毒攻击

Result: 未在摘要中明确说明具体实验结果，但框架旨在有效防御投毒攻击

Conclusion: CoDFKGE框架为解决联邦知识图谱嵌入中的投毒攻击问题提供了有效防御方案

Abstract: Federated knowledge graph embedding (FKGE) enables collaborative knowledge sharing without data exchange, but it also introduces risks of poisoning attacks that degrade model accuracy or force incorrect outputs. Protecting FKGE from poisoning attacks becomes a critical research problem. This paper reveals the malicious strategy of untargeted FKGE poisoning attacks and proposes CoDFKGE, a co-distillation-based FKGE framework for defending against poisoning attacks …

</details>


### [56] [Improving Automatic Speech Recognition Model for Super-Elderly Voice Using Speech Synthesis Model](https://scholar.google.com/scholar_url?url=http://www.apsipa.org/proceedings/2025/papers/APSIPA2025_P406.pdf&hl=zh-CN&sa=X&d=6932124041701543591&ei=aQA8aZKHE-CuieoP1s6B2AU&scisig=ALhkC2SfGDzOsAp85loO_1JBPxLZ&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=2&folt=cit)
*R Uematsu,CS Leow,N Kitaoka,H Nishizaki*

Main category: Zongheng Yang

TL;DR: 提出基于Style-Bert-VITS2的老年人语音数据增强框架，通过文本转语音合成优化老年人语音识别


<details>
  <summary>Details</summary>
Motivation: 老年人语音识别面临年龄相关声学特征和训练数据有限的挑战，现有语音识别技术对老年人语音效果不佳

Method: 使用Style-Bert-VITS2从少量老年人语音语料库学习，生成保留老年人声学特征的合成训练数据，通过数据增强提升识别性能

Result: 未提供具体实验结果，但方法旨在改善老年人语音识别性能

Conclusion: 提出的数据增强框架通过合成老年人语音数据，有望解决老年人语音识别中的数据稀缺问题

Abstract: Although speech recognition technology has made remarkable progress, recognizing elderly speech remains challenging due to age-related acoustic characteristics and limited training data. This paper introduces a novel data augmentation framework that utilizes text-to-speech synthesis specifically optimized for elderly voices. Our approach employs Style-Bert-VITS2 to learn from a small elderly speech corpus and generate additional training data while preserving …

</details>


### [57] [Spatio-Temporal Shifting to Reduce Carbon, Water, and Land-Use Footprints of Cloud Workloads](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.08725&hl=zh-CN&sa=X&d=16231333991185301401&ei=IoQ9ae7IL5iTieoP5LbfuQw&scisig=ALhkC2R2RrcCEuXzY5bJEsBvcv6Z&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=1&folt=cit)
*G Attenni,Y Moawad,N Bartolini,L Thamsen*

Main category: Zongheng Yang

TL;DR: 通过时空云工作负载转移降低云计算的碳、水和土地利用足迹


<details>
  <summary>Details</summary>
Motivation: 云计算基础设施的环境足迹日益受到关注，需要探索通过智能工作负载调度来减少碳、水和土地利用影响的方法

Method: 使用AWS和Azure的真实数据以及大数据分析和FaaS应用的工作负载轨迹进行模拟研究，分析空间和时间工作负载转移的潜力

Result: 空间转移能显著降低碳、水和土地利用足迹，减少幅度在20%到85%之间

Conclusion: 时空云工作负载转移是实现云计算环境可持续性的有效策略，空间转移尤其具有显著的环境效益

Abstract: In this paper, we investigate the potential of spatial and temporal cloud workload shifting to reduce carbon, water, and land-use footprints. Specifically, we perform a simulation study using real-world data from multiple cloud providers (AWS and Azure) and workload traces for different applications (big data analytics and FaaS). Our simulation results indicate that spatial shifting can substantially lower carbon, water, and land use footprints, with observed reductions ranging from 20% to 85 …

</details>


### [58] [Real-Time, low audio latency based AI-Powered application architecture design](https://scholar.google.com/scholar_url?url=https://ojs.uni-miskolc.hu/index.php/psaie/article/download/4090/3145&hl=zh-CN&sa=X&d=13536499681120898847&ei=IoQ9ae7IL5iTieoP5LbfuQw&scisig=ALhkC2SV0B_axQo9tngIEiMpDmiJ&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=2&folt=cit)
*P Mileff*

Main category: Zongheng Yang

TL;DR: 开发了一款基于OpenAI语言模型的移动应用，具备实时文本流式响应和Azure TTS同步音频合成功能


<details>
  <summary>Details</summary>
Motivation: 创建一款能够提供交互式对话体验的移动应用，结合实时文本响应和语音合成功能，提升用户体验

Method: 采用Node.js后端服务器处理OpenAI流式通信，实现句子分割以优化响应处理，集成Azure文本转语音服务进行音频合成

Result: 成功实现了一个具备实时文本流式响应和同步音频合成的移动应用，提供流畅的交互式对话体验

Conclusion: 该应用架构有效整合了OpenAI语言模型和Azure TTS服务，为用户提供了高质量的交互式对话体验

Abstract: This paper presents the design and implementation of a mobile application that provides users with an interactive conversational experience powered by OpenAI's language model. A key feature of this application is its real-time text response streaming, coupled with synchronized audio synthesis using Azure's text-to-speech (TTS) services. The architecture includes a Node. js backend server that handles OpenAI communication in streaming mode, sentence segmentation for response …

</details>


### [59] [Exqutor: Extended Query Optimizer for Vector-augmented Analytical Queries](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.09695&hl=zh-CN&sa=X&d=7591307439889847309&ei=xeo-aaurMbCP6rQPgsi1wQo&scisig=ALhkC2RymA2QkFp1i5I8AZ-TRTaK&oi=scholaralrt&hist=i6heNjgAAAAJ:778719684493065653:ALhkC2T5y4v8XnzDuwC4ZadUm0Rx&html=&pos=0&folt=rel)
*H Kim,C Lim,H An,R Sen,K Park*

Main category: Zongheng Yang

TL;DR: 向量相似性搜索在数据科学管道中日益重要，特别是在检索增强生成（RAG）中，它通过高效检索相关外部信息来增强大语言模型推理


<details>
  <summary>Details</summary>
Motivation: 向量相似性搜索在数据科学特别是RAG应用中的重要性日益增长，需要高效检索相关外部信息来增强大语言模型的推理能力

Method: 基于向量相似性搜索的方法，通过将信息编码为向量表示，在向量空间中高效检索与查询最相关的文档片段

Result: 向量相似性搜索能够显著提升RAG系统的性能，通过快速准确地检索相关信息来增强大语言模型的生成质量和事实准确性

Conclusion: 向量相似性搜索是数据科学和RAG系统中的关键技术，对于提升大语言模型推理能力和信息检索效率具有重要作用

Abstract: Vector similarity search is becoming increasingly important for data science pipelines, particularly in Retrieval-Augmented Generation (RAG), where it enhances large language model inference by enabling efficient retrieval of relevant external …

</details>


### [60] [Supporting Dynamic Agentic Workloads: How Data and Agents Interact](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.09548&hl=zh-CN&sa=X&d=5856952489887178567&ei=xeo-aaurMbCP6rQPgsi1wQo&scisig=ALhkC2RKr-D8o7iqSHNVux3_Mbq2&oi=scholaralrt&hist=i6heNjgAAAAJ:778719684493065653:ALhkC2T5y4v8XnzDuwC4ZadUm0Rx&html=&pos=1&folt=rel)
*I Giurgiu,ME Nidd*

Main category: Zongheng Yang

TL;DR: 多智能体系统与LLM暴露了传统数据架构的局限性，需要新的数据管理范式


<details>
  <summary>Details</summary>
Motivation: 基于大语言模型和多智能体系统的兴起，传统数据库和数据架构在设计上存在根本性限制，无法满足现代智能系统的需求

Method: 未在摘要中明确说明具体方法，但暗示需要重新设计数据管理架构以适应多智能体系统和LLM的需求

Result: 识别了传统数据架构在多智能体系统环境下的局限性，提出了对新型数据管理范式的需求

Conclusion: 需要开发专门为多智能体系统和LLM设计的新型数据管理架构，以克服传统系统的局限性

Abstract: The rise of multi-agent systems powered by large language models (LLMs) and specialized reasoning agents exposes fundamental limitations in today's data management architectures. Traditional databases and data fabrics were designed for …

</details>


### [61] [A robust artificial intelligence informed over complete rational dilation wavelet transform technique coupled with deep learning for long-term rainfall prediction](https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0952197625034578&hl=zh-CN&sa=X&d=4836722085133926128&ei=xeo-aeyxHI2v6rQP-5Lh8QE&scisig=ALhkC2TvmPQGnTIURircpPsm6UGk&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=1&folt=cit)
*M Diykh,M Ali,AA Farooque,AA Aldhafeeri,M Jamei…*

Main category: Zongheng Yang

TL;DR: 该论文探讨利用人工智能模型提高降雨预测精度，以应对气候变化引发的强降雨影响


<details>
  <summary>Details</summary>
Motivation: 气候变化导致强降雨强度增加，引发洪水、干旱、水质恶化、滑坡和农作物损害等全球性影响。为缓解这些影响，需要准确预测降雨的动态特性以实现可持续利用，但降雨固有的非线性特征显著影响模型精度。

Method: 论文提出使用人工智能模型来检测复杂的降雨模式，AI模型在识别这些非线性模式方面已显示出有前景的结果。

Result: 从摘要描述来看，AI模型在检测复杂降雨模式方面表现出良好潜力，但具体实验结果未在摘要中详细说明。

Conclusion: 人工智能模型为解决降雨预测中的非线性问题提供了有前景的解决方案，对于应对气候变化引发的强降雨影响具有重要意义。

Abstract: The intensity of heavy rainfall, driven by climate change, has significant effects worldwide, including flash flood, droughts, water degradation, landslides and crop damages. To ameliorate these impacts, accurate forecasting is crucial to address the dynamic nature of rainfall for sustainable utilization. But the non-linearity inherited within the rainfall significantly influence the model precision. Artificial Intelligence (AI) models have shown promising results in detecting complex rainfall patterns. This …

</details>


### [62] [PyUAT: An open-source Python framework for uncertainty-aware, efficient, and scalable model-driven cell tracking](https://scholar.google.com/scholar_url?url=https://journals.plos.org/plosone/article%3Fid%3D10.1371/journal.pone.0337110&hl=zh-CN&sa=X&d=17692300862756502798&ei=xeo-aeyxHI2v6rQP-5Lh8QE&scisig=ALhkC2RxBBs5a9PYzNLaiKwY6Uwy&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=2&folt=cit)
*J Seiffarth,K Nöh*

Main category: Zongheng Yang

TL;DR: 提出一种基于概率的不确定性感知追踪（UAT）方法，用于解决微生物细胞追踪中的挑战，包括随机细胞运动、频繁分裂和有限帧率等问题。


<details>
  <summary>Details</summary>
Motivation: 活细胞成像中的单细胞追踪对于理解表型异质性和细胞对环境变化的响应至关重要。然而，微生物细胞追踪面临特殊挑战：细胞生长具有随机运动特性、频繁分裂，且为避免伪影只能采用有限帧率进行时间序列记录。

Method: 提出概率不确定性感知追踪（UAT）范式，该方法能够处理细胞追踪中的不确定性，特别针对微生物细胞的随机运动、分裂事件和有限采样率等挑战。

Result: 未在摘要中明确说明具体结果，但暗示该方法能够有效应对微生物细胞追踪的挑战，提高追踪的准确性和可靠性。

Conclusion: 不确定性感知追踪（UAT）为微生物细胞追踪提供了一种有前景的解决方案，能够处理细胞生长过程中的随机性和有限观测数据带来的挑战。

Abstract: Tracking individual cells in live-cell imaging provides fundamental insights into phenotypic heterogeneity and cellular responses to environmental change. However, microbial cell tracking is particularly challenging, as cell growth is characterized by stochastic cell movements and frequent divisions, while time-lapses are recorded at limited frame rates to avoid counterfactual results. Here, we investigate how probabilistic Uncertainty-Aware Tracking (UAT), a paradigm based …

</details>


### [63] [LLM-Driven Psychological Companionship for LBC: A Multi-Tone Emotional Voice Synthesis Framework](https://scholar.google.com/scholar_url?url=https://www.worldscientific.com/doi/abs/10.1142/S0218213025500228&hl=zh-CN&sa=X&d=8520753999387469965&ei=xeo-aeyxHI2v6rQP-5Lh8QE&scisig=ALhkC2SLt53sX1mct84PP9mDIjJX&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=3&folt=cit)
*S Qin,G Wang,X Xiong*

Main category: Zongheng Yang

TL;DR: 提出一个多音调情感语音合成框架，结合语音识别、大语言模型和语音合成技术，专门针对留守儿童的心理陪伴需求


<details>
  <summary>Details</summary>
Motivation: 大语言模型快速发展但留守儿童心理陪伴问题关注不足，留守儿童因缺乏陪伴面临心理挑战，需要专门的情感陪伴解决方案

Method: 多音调情感语音合成框架，集成语音识别、大语言模型和语音合成技术，包含情感心理学专业知识库和情感状态识别模块

Result: 未提供具体实验结果，但框架设计旨在通过情感语音合成提供心理陪伴支持

Conclusion: 该框架有望为留守儿童提供有效的情感陪伴支持，缓解心理孤独问题

Abstract: The rapid development of large language models (LLMs) has significantly benefited various industries. However, the psychological challenges experienced by left-behind children (LBC) due to a lack of companionship have received insufficient attention. To address this issue, we propose a Multi-Tone Emotional Voice Synthesis Framework that integrates speech recognition, LLMs, and voice synthesis technologies. Specifically, an emotional psychology specialized knowledge and a …

</details>


### [64] [Compiler-Enhanced Language for Scalable Data Workflows](https://scholar.google.com/scholar_url?url=https://www.preprints.org/frontend/manuscript/d69436a20ebb2b935673b50cf6a29459/download_pub&hl=zh-CN&sa=X&d=4150939884343236965&ei=xeo-aeyxHI2v6rQP-5Lh8QE&scisig=ALhkC2SKpse1RzBudiJKYcGC7WNl&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=5&folt=cit)
*H Arora*

Main category: Zongheng Yang

TL;DR: 一种专为高性能数据并行操作设计的编程语言，支持流和数据帧等多种数据类型，通过编译器基础设施实现分布式系统上的高效部署


<details>
  <summary>Details</summary>
Motivation: 简化健壮、可扩展的数据科学应用开发，通过抽象底层复杂性，使开发者能够专注于业务逻辑而非分布式系统细节

Method: 设计专门的数据并行编程语言，集成先进的编译器基础设施，支持流和数据帧等多样化数据类型，实现程序在分布式系统上的高效翻译和部署

Result: 创建了一个创新的编程语言框架，能够简化数据密集型应用的开发，提高开发效率，同时保持高性能和可扩展性

Conclusion: 该编程语言框架为数据科学应用开发提供了有效的解决方案，通过语言层面的抽象和编译器优化，实现了开发效率与运行性能的良好平衡

Abstract: This paper introduces a sophisticated programming language specifically designed for high-performance, dataparallel operations across diverse data types, including streams and data frames. Our framework integrates with advanced compiler infrastructure to facilitate the efficient translation and deployment of data-intensive programs on distributed systems. This innovative language aims to simplify the development of robust, scalable data science applications by abstracting away low …

</details>


### [65] [A Hybrid Attention Mechanism to Improve Tacotron 2 Performance for Indonesian Text-to-Speech Synthesis](https://scholar.google.com/scholar_url?url=http://www.apsipa.org/proceedings/2025/papers/APSIPA2025_P483.pdf&hl=zh-CN&sa=X&d=7747616323129992255&ei=xeo-aeyxHI2v6rQP-5Lh8QE&scisig=ALhkC2Q14VVNbMu-U0IY_FxMzCjm&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=6&folt=cit)
*A Catherina,B Prihasto,BM Pratama,LW Kang…*

Main category: Zongheng Yang

TL;DR: 该论文提出了一种基于Tacotron 2架构和HiFi-GAN声码器的印尼语语音合成系统，通过混合注意力机制改进对齐精度和训练收敛性。


<details>
  <summary>Details</summary>
Motivation: 虽然Tacotron 2在高资源语言中表现出色，但针对印尼语的适配研究仍显不足，需要解决注意力对齐和训练收敛的问题。

Method: 采用Tacotron 2架构结合HiFi-GAN声码器，提出混合注意力机制，融合位置敏感注意力与基于内容的注意力，以提升对齐精度和训练稳定性。

Result: 系统在印尼语语音合成任务中表现出改进的对齐精度和更快的训练收敛速度，生成语音质量得到提升。

Conclusion: 提出的混合注意力机制有效解决了印尼语Tacotron 2系统的对齐问题，为低资源语言语音合成提供了可行的技术方案。

Abstract: This paper presents a speech synthesis system for the Indonesian language using the Tacotron 2 architecture and HiFi-GAN vocoder. While Tacotron 2 has demonstrated strong performance in high-resource languages, adapting it for Indonesian remains underexplored. To address this, we propose a hybrid attention mechanism that combines location-sensitive and content-based attention to improve alignment accuracy and convergence during training. The system is trained on a …

</details>


### [66] [ОБЗОР МОДЕЛЕЙ И ИНСТРУМЕНТОВ ИСКУССТВЕННОГО ИНТЕЛЛЕКТА ДЛЯ ГЕНЕРАЦИИ КОНТЕНТА ВИДЕОПРЕЗЕНТАЦИЙ](https://scholar.google.com/scholar_url?url=https://science.kuzstu.ru/wp-content/Events/Conference/itsit/2025/itsit/docs/054_%25D0%2595%25D0%25BB%25D0%25B8%25D1%2581%25D0%25B5%25D0%25B5%25D0%25B2.pdf&hl=zh-CN&sa=X&d=7966614322043105591&ei=xeo-aeyxHI2v6rQP-5Lh8QE&scisig=ALhkC2SKF6DGac8sWZATD_vn3Uso&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=7&folt=cit)
*ДС Елисеев*

Main category: Zongheng Yang

TL;DR: 论文分析了在线教育的发展趋势，重点关注微学习（microlearning）作为数字教育转型的关键方向，探讨了其市场增长、教学效果和应用前景。


<details>
  <summary>Details</summary>
Motivation: 在线教育作为数字教育转型的核心领域正在快速发展，全球在线学习市场在2024年已超过3424亿美元并持续增长。微学习（5-15分钟短视频讲座）成为最受欢迎的教学形式之一，但需要系统研究其教学效果和应用价值。

Method: 基于市场数据分析（引用2024年行业报告）和教育理论框架，探讨微学习的教学特征、优势及其在数字教育环境中的应用模式。

Result: 微学习格式因其短时、高效的特点，在提升学习参与度、知识吸收率和适应性方面表现出显著优势，成为在线教育市场增长的重要驱动力。

Conclusion: 微学习作为在线教育的重要创新形式，在数字教育转型中具有广阔应用前景，其短时高效的特点符合现代学习者的需求，值得进一步推广和研究。

Abstract: Развитие онлайн-образования является одним из ключевых направлений цифровой трансформации образовательной среды. По данным аналитических агентств, мировой рынок онлайн-обучения в 2024 году превысил 342, 4 млрд долларов США и продолжает расти [1]. Одним из наиболее востребованных стал формат—microlearning, предполагающий подачу материала короткими видеолекциями с продолжительностью 5–15 минут. Такой подход повышает …

</details>


### [67] [NotebookOS: A Replicated Notebook Platform for Interactive Training with On-Demand GPUs](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3760250.3762230&hl=zh-CN&sa=X&d=889723506234425634&ei=fmdAaaq1ML2qieoPuKej0QM&scisig=ALhkC2S8qlzA3YLYF2HzaKDaw7Br&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=0&folt=cit)
*B Carver,J Zhang,H Wang,K Mahadik,Y Cheng*

Main category: Zongheng Yang

TL;DR: NotebookOS是一个针对交互式深度学习训练优化的GPU高效笔记本平台，解决传统平台因长时间预留GPU导致的利用率极低和成本过高问题


<details>
  <summary>Details</summary>
Motivation: 交互式笔记本编程在现代ML/AI工作流中普遍存在，交互式深度学习训练成为主要用例。现有平台如Jupyter和Colab为保证响应性，为长时间运行的笔记本会话预留GPU，但GPU使用具有间歇性和偶发性，导致GPU利用率极低且成本过高

Method: 引入NotebookOS，一个针对交互式深度学习训练独特需求定制的GPU高效笔记本平台

Result: 未在摘要中提供具体结果数据

Conclusion: NotebookOS旨在解决传统笔记本平台GPU利用率低和成本高的问题，为交互式深度学习训练提供更高效的平台

Abstract: Interactive notebook programming is universal in modern ML and AI workflows, with interactive deep learning training (IDLT) emerging as a dominant use case. To ensure responsiveness, platforms like Jupyter and Colab reserve GPUs for long-running notebook sessions, despite their intermittent and sporadic GPU usage, leading to extremely low GPU utilization and prohibitively high costs. In this paper, we introduce NotebookOS, a GPU-efficient notebook platform tailored for the unique …

</details>


### [68] [Asynchronous Reasoning: Training-Free Interactive Thinking LLMs](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.10931&hl=zh-CN&sa=X&d=3136170978840839129&ei=fmdAaaq1ML2qieoPuKej0QM&scisig=ALhkC2Sq3PORTdIzzBZi23OhnrV4&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=1&folt=cit)
*G Yakushev,N Babina,MV Dastgerdi,V Zhdanovskiy…*

Main category: Zongheng Yang

TL;DR: 论文探讨了LLM推理过程中的实时交互问题，提出了一种支持并行推理和响应的架构，使模型能够在思考的同时对外界输入做出反应。


<details>
  <summary>Details</summary>
Motivation: 当前LLM的"思考-回答"顺序模式限制了实时交互能力，无法适应语音助手等需要同时处理输入和输出的应用场景，而人类能够并行处理听、思考和说话的过程。

Method: 提出了一种支持并行推理和响应的LLM架构，使模型能够在内部推理的同时对外界输入做出反应，打破了传统的顺序处理模式。

Result: 该方法使LLM能够在推理过程中实时响应外部输入，提高了模型的交互性和适应性，特别适用于需要实时反馈的应用场景。

Conclusion: 并行推理架构能够显著提升LLM在实时交互场景中的表现，为语音助手等应用提供了更自然、更高效的人机交互方式。

Abstract: Many state-of-the-art LLMs are trained to think before giving their answer. Reasoning can greatly improve language model capabilities and safety, but it also makes them less interactive: given a new input, a model must stop thinking before it can respond. Real-world use cases such as voice-based or embedded assistants require an LLM agent to respond and adapt to additional information in real time, which is incompatible with sequential interactions. In contrast, humans can listen, think, and …

</details>


### [69] [Mordukhovich subdifferential optimization framework for multi-criteria voice cloning of pathological speech](https://scholar.google.com/scholar_url?url=https://epubl.ktu.edu/object/elaba:264326659/264326659.pdf&hl=zh-CN&sa=X&d=18037595432600947514&ei=fmdAaaq1ML2qieoPuKej0QM&scisig=ALhkC2Sh7TZ-mvZUYHmtB_o0zf11&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=2&folt=cit)
*R Maskeliūnas,R Damaševičius,A Kulikajevas…*

Main category: Zongheng Yang

TL;DR: 提出基于Mordukhovich次微分优化(MSO)的语音克隆框架，解决立陶宛语病理语音合成的多目标优化问题


<details>
  <summary>Details</summary>
Motivation: 现有语音合成模型通常针对单一目标优化或仅限于主要语言，无法处理立陶宛语这种资源匮乏语言中独特音素的病理语音合成多目标平衡问题

Method: 采用Mordukhovich次微分优化(MSO)框架，明确平衡四个相互竞争的目标，处理立陶宛语病理语音合成的多目标挑战

Result: 未在摘要中明确说明具体实验结果，但暗示该方法能有效处理资源匮乏语言中独特音素的病理语音合成问题

Conclusion: MSO驱动的语音克隆框架为解决资源匮乏语言病理语音合成的多目标优化问题提供了新途径

Abstract: Abstract [eng] This study introduces a novel voice cloning framework driven by Mordukhovich Subdifferential Optimization (MSO) to address the complex multi-objective challenges of pathological speech synthesis in under-resourced Lithuanian language with unique phonemes not present in most pre-trained models. Unlike existing voice synthesis models that often optimize for a single objective or are restricted to major languages, our approach explicitly balances four competing …

</details>


### [70] [Disfluency Disentanglement Enhancement in Spoken-Text-Style Transfer for Spontaneous Speech Synthesis](https://scholar.google.com/scholar_url?url=http://www.apsipa.org/proceedings/2025/papers/APSIPA2025_P048.pdf&hl=zh-CN&sa=X&d=8628295698256004314&ei=fmdAaaq1ML2qieoPuKej0QM&scisig=ALhkC2SAjiO-lkQ1PZvxeKvfNG6X&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=3&folt=cit)
*Y Nakata,D Yoshioka,WC Huang,T Toda*

Main category: Zongheng Yang

TL;DR: 提出基于掩码语言模型的语音文本风格转换方法，用于处理口语中的不流利现象，解决未知词和正常/不流利词混淆问题


<details>
  <summary>Details</summary>
Motivation: 语音文本风格转换旨在将给定文本转换为期望风格同时保持语义内容。本文专注于建模口语文本中的不流利现象，这可以作为自发语音合成的预处理步骤。先前方法存在未知词和正常/不流利词混淆的问题。

Method: 提出基于掩码语言模型的方法，通过临时替换策略来处理口语不流利现象，具体包括对未知词和正常/不流利词混淆问题的解决方案

Result: 未在摘要中明确说明具体实验结果，但暗示该方法能够有效解决先前方法存在的问题

Conclusion: 提出的掩码语言模型方法为语音文本风格转换中的不流利建模提供了有效解决方案，可作为自发语音合成的预处理步骤

Abstract: Spoken-text-style transfer (STST) aims to convert a given text to a desired style while preserving its semantic content. In this paper, we focus on modeling the disfluency in spoken text, which can be useful as a preprocessing step in spontaneous speech synthesis. Previous methods suffer from unknown words and confusion between normal and disfluent words. Our proposed solutions to the above-mentioned problems include a masked language model (MLM) approach to temporally replace …

</details>


### [71] [CADER: Cost-Efficient Cloud Application Deployment With Tenant Requirement Guarantee in Multi-Clouds](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11219081/&hl=zh-CN&sa=X&d=10984109168659546251&ei=fEJCabvPNKGvieoPtIGfoAw&scisig=ALhkC2QvztQRWB4mWTv1YEmK6E1h&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=0&folt=cit)
*H Tu,Z Hua,Q Ma,H Luo,T Zou,G Zhao,H Xu*

Main category: Zongheng Yang

TL;DR: 多云部署策略研究，旨在降低供应商锁定风险，平衡部署成本、访问延迟和流量需求三个关键指标


<details>
  <summary>Details</summary>
Motivation: 减少供应商锁定风险，解决专用硬件可用性问题，推动云应用采用多云部署策略

Method: 未在摘要中明确说明具体方法，但指出现有工作存在不足，需要新的解决方案来处理多云部署中的三个关键指标

Result: 摘要未提供具体实验结果，但暗示现有方法在处理多云部署的成本、延迟和流量需求方面存在局限性

Conclusion: 多云部署面临部署成本、访问延迟和流量需求三个关键且耦合的指标挑战，现有解决方案存在不足，需要进一步研究

Abstract: Motivated by the need to reduce vendor lock-in and address concerns regarding dedicated hardware availability, cloud applications have increasingly adopted a multi-cloud deployment strategy, in which cloud applications are deployed in different zones associated with various cloud service providers. When deploying cloud applications in multi-clouds, there are three crucial and coupled metrics: deployment cost, access delay and traffic demand. Unfortunately, existing works …

</details>


### [72] [Predicting and Synchronising Co-Speech Gestures for Enhancing Human–Robot Interactions Using Deep Learning Models](https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2313-7673/10/12/835&hl=zh-CN&sa=X&d=12863876966094367651&ei=fEJCabvPNKGvieoPtIGfoAw&scisig=ALhkC2QYytjidCY2vKUbok3gq5q8&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=3&folt=cit)
*E Fernández*

Main category: Zongheng Yang

TL;DR: 机器人通过多模态表达增强人机交互感知，但自主表达面临挑战


<details>
  <summary>Details</summary>
Motivation: 随着机器人在人机交互任务中的应用增加，需要让人类将机器人视为合适的交互伙伴。这可以通过赋予机器人有生命的外观来实现，其中一种方法是让机器人能够自主进行表达，即结合多模态动作来传递信息。

Method: 论文提出通过赋予机器人自主表达能力，结合多模态动作（如语音、表情、肢体动作等）来传达信息，从而增强其有生命的外观和交互能力。

Result: 虽然论文摘要未提供具体实验结果，但指出了机器人自主表达面临的挑战，暗示需要解决多模态动作协调、时机把握、情境适应性等问题。

Conclusion: 赋予机器人自主表达能力是增强人机交互感知的有效方法，但实现这一目标面临技术挑战，需要进一步研究和解决。

Abstract: In recent years, robots have started to be used in tasks involving human interaction. For this to be possible, humans must perceive robots as suitable interaction partners. This can be achieved by giving the robots an animate appearance. One of the methods that can be utilised to endow a robot with a lively appearance is giving it the ability to perform expressions on its own, that is, combining multimodal actions to convey information. However, this can become a challenge if the robot has to use …

</details>


### [73] [Motif-2-12.7 B-Reasoning: A Practitioner's Guide to RL Training Recipes](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.11463&hl=zh-CN&sa=X&d=10996802808458488532&ei=0XlFaZLFMN_OieoPg6WE2QY&scisig=ALhkC2RVn0a9VJcf_oCKPrlg58tX&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=0&folt=cit)
*J Lim,S Lee,D Kim,T Kim,E Park,J Lee,J Lee,J Lee…*

Main category: Zongheng Yang

TL;DR: Motif-2-12.7 B-Reasoning是一个12.7B参数的语言模型，旨在弥合开源模型与专有前沿模型在复杂推理和长上下文理解方面的差距，通过系统、数据和算法优化的综合训练方案解决推理适应中的常见挑战。


<details>
  <summary>Details</summary>
Motivation: 当前开源模型与专有前沿模型在复杂推理和长上下文理解方面存在显著差距，且在推理适应过程中常出现模型崩溃和训练不稳定的问题，需要开发一个综合的训练方案来提升开源模型的推理能力。

Method: 提出一个全面的、可复现的训练方案，涵盖系统、数据和算法三个层面的优化。方法结合内存优化技术，专门针对复杂推理和长上下文理解任务进行模型训练。

Result: 开发了Motif-2-12.7 B-Reasoning模型，这是一个12.7B参数的语言模型，在复杂推理和长上下文理解方面表现出色，缩小了开源模型与专有前沿模型的性能差距。

Conclusion: 通过系统、数据和算法的综合优化方案，成功开发了一个高性能的12.7B参数推理模型，为开源社区提供了接近专有前沿模型推理能力的解决方案。

Abstract: We introduce Motif-2-12.7 B-Reasoning, a 12.7 B parameter language model designed to bridge the gap between open-weight systems and proprietary frontier models in complex reasoning and long-context understanding. Addressing the common challenges of model collapse and training instability in reasoning adaptation, we propose a comprehensive, reproducible training recipe spanning system, data, and algorithmic optimizations. Our approach combines memory …

</details>


### [74] [DART: A State-Aware Online Co-Scheduling Runtime for Data-Parallel Training](https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0167739X25005977&hl=zh-CN&sa=X&d=5423979863495365054&ei=0XlFaZLFMN_OieoPg6WE2QY&scisig=ALhkC2R-as7DXpYKfEEEJeJnbo1X&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=1&folt=cit)
*TJ Sun,AY Son,EN Huh*

Main category: Zongheng Yang

TL;DR: DART是一个框架无关的在线协同调度运行时系统，通过推断状态条件化的资源重要性来动态优化数据并行训练，减少静态设置导致的资源浪费


<details>
  <summary>Details</summary>
Motivation: 数据并行训练通常采用静态设置，在计算、输入和通信瓶颈发生变化时会造成时间浪费。动态控制可以缩短挂钟时间，但缺乏状态感知的估计器会导致追逐高方差的单节点测量，并将资源重要性视为时间不变，忽略了训练和集群状态的变化

Method: DART是一个框架无关的在线协同调度运行时系统，通过推断状态条件化的资源重要性来实现动态资源调度。它能够感知训练和集群状态的变化，避免单纯追逐高方差的单节点测量

Result: 论文结果显示DART能够有效缩短数据并行训练的挂钟时间，通过动态调整资源分配来适应变化的瓶颈，相比静态设置和传统的动态控制方法有更好的性能表现

Conclusion: DART通过状态感知的资源重要性推断和动态协同调度，解决了数据并行训练中静态设置和传统动态控制的局限性，显著提高了训练效率

Abstract: Data-parallel training at scale is often run with static settings, which waste time when compute, input, and communication bottlenecks shift. Dynamic control can shorten wall clock time but, without a state-aware estimator, it tends to chase high-variance per-node measurements and treats resource importance as time-invariant despite changes in the training and cluster state. We present DART, a framework-agnostic online co-scheduling runtime that infers state-conditioned resource-importance …

</details>


### [75] [Learning discrete neural latent spaces for high-performance speech decoding](https://scholar.google.com/scholar_url?url=https://iopscience.iop.org/article/10.1088/1741-2552/ae2ccd/meta&hl=zh-CN&sa=X&d=10702588629810694893&ei=0XlFaZLFMN_OieoPg6WE2QY&scisig=ALhkC2Rq3wYa-eeVUKZf5bpTn76Q&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=2&folt=cit)
*Y Jia,Q Lian,L Wang,Y Wang,Y Qi*

Main category: Zongheng Yang

TL;DR: 该论文提出了一种学习离散神经潜在空间的方法，用于从脑信号中解码语音，以改进语音脑机接口的性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要探索连续神经潜在空间进行语音解码，但忽略了语音生产中的固有离散特性。语音脑机接口为失语症患者提供了有前景的解决方案，而神经表示学习在其中起着重要作用。

Method: 提出学习离散神经潜在空间的方法，以更好地捕捉语音生产中的离散特性，改进从脑信号中解码语音的过程。

Result: 从摘要中无法获取具体实验结果，但该方法旨在改进语音解码性能，为语音脑机接口提供更有效的神经表示学习框架。

Conclusion: 学习离散神经潜在空间可以更好地建模语音生产中的离散特性，有望提高语音脑机接口的解码性能和实用性。

Abstract: Objective. Speech brain-computer interfaces (BCIs), which directly transform neural signals into intelligible voices, offer a promising avenue for people with aphasia. To decode speech information from brain signals, neural representation learning plays an important role. Approach. Existing studies mainly explored continuous neural latent spaces for speech decoding and ignored the intrinsic discrete property in speech production. Here, we propose to learn a discrete neural latent spaces by …

</details>


### [76] [All-in-One ASR: Unifying Encoder-Decoder Models of CTC, Attention, and Transducer in Dual-Mode ASR](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.11543&hl=zh-CN&sa=X&d=13046932261981454401&ei=0XlFaZLFMN_OieoPg6WE2QY&scisig=ALhkC2RS2LllePb9EWOZ2kFtxug1&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=3&folt=cit)
*T Moriya,M Mimura,T Tanaka,H Sato,R Masumura…*

Main category: Zongheng Yang

TL;DR: 提出All-in-One ASR统一框架，使单个模型支持多种ASR范式（CTC、AED、Transducer）和两种工作模式（离线和流式），解决多模型维护成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 不同ASR架构（CTC、AED、Transducer）各有优势，但为每种场景维护独立模型会导致开发部署成本高昂，需要统一框架简化系统。

Method: 提出统一框架，通过共享编码器和可切换解码器支持多种ASR范式，实现离线和流式模式的灵活切换，减少模型维护负担。

Result: 单个模型在多种ASR任务上表现与专用模型相当或更优，显著降低计算和存储开销，提升部署灵活性。

Conclusion: All-in-One ASR框架证明了单一模型支持多种ASR范式的可行性，为实际应用提供了高效灵活的解决方案。

Abstract: This paper proposes a unified framework, All-in-One ASR, that allows a single model to support multiple automatic speech recognition (ASR) paradigms, including connectionist temporal classification (CTC), attention-based encoder-decoder (AED), and Transducer, in both offline and streaming modes. While each ASR architecture offers distinct advantages and trade-offs depending on the application, maintaining separate models for each scenario incurs substantial development and deployment …

</details>


### [77] [DisCo-Speech: Controllable Zero-Shot Speech Generation with A Disentangled Speech Codec](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.13251&hl=zh-CN&sa=X&d=946311454801485596&ei=0XlFaZLFMN_OieoPg6WE2QY&scisig=ALhkC2TzcPlYj1TYo1SeacdZWuUA&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=5&folt=cit)
*T Li,W Ge,Z Wang,Z Cui,Y Ma,Y Gao,C Deng…*

Main category: Zongheng Yang

TL;DR: DisCo-Speech是一个零样本可控的文本转语音框架，通过解耦音色和韵律的编码表示，解决了现有基于编解码器的语言模型中两者紧密耦合的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于编解码器的语言模型在文本转语音中取得了革命性进展，但标准编解码器将音色和韵律紧密耦合在一起。这种耦合导致基于延续的语言模型不可避免地复制这种纠缠，阻碍了对音色和韵律的独立控制。虽然最近有研究尝试通过编解码器设计来打破这种纠缠，但解耦不足仍然是关键瓶颈。

Method: 提出了DisCo-Speech框架，这是一个零样本可控的文本转语音框架。该方法通过解耦音色和韵律的编码表示来实现独立控制，具体技术细节未在摘要中详细说明，但核心思想是打破标准编解码器中音色和韵律的紧密耦合关系。

Result: 摘要中未提供具体的实验结果数据，但暗示该方法能够实现零样本可控的文本转语音，允许对音色和韵律进行独立控制。

Conclusion: DisCo-Speech框架通过解耦音色和韵律的编码表示，解决了现有基于编解码器的语言模型中两者紧密耦合的问题，实现了零样本可控的文本转语音，为独立控制音色和韵律提供了有效解决方案。

Abstract: Recent codec-based language models~(LMs) have revolutionized text-to-speech~(TTS). However, since standard codecs tightly couple timbre and prosody, continuation-based LMs inevitably replicate this entanglement, hindering independent control. Recent efforts attempt to break this entanglement via codec design, but insufficient decoupling remains a critical bottleneck. To tackle this challenge, we propose DisCo-Speech, a zero-shot controllable TTS framework that …

</details>


### [78] [RollMux: Phase-Level Multiplexing for Disaggregated RL Post-Training](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.11306&hl=zh-CN&sa=X&d=3110308741171741100&ei=0XlFaZLFMN_OieoPg6WE2QY&scisig=ALhkC2Q_Yz8I3OpImWP5CoKEKZVp&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=6&folt=cit)
*T Wu,L Cao,Y Wei,W Gao,Y Zhao,D An,S Xiong…*

Main category: Zongheng Yang

TL;DR: RollMux是一个用于强化学习后训练中rollout-training解耦架构的调度系统，通过消除严格同步依赖来减少集群空闲时间，提升硬件利用率


<details>
  <summary>Details</summary>
Motivation: 强化学习后训练中rollout和training的物理解耦架构虽然能最大化硬件效率，但on-policy算法的严格同步要求导致严重的依赖气泡，使得一个集群运行时另一个集群必须空闲等待，造成硬件利用率低下

Method: RollMux通过调度优化消除严格同步依赖，允许rollout和training集群更高效地并行工作，减少空闲等待时间

Result: RollMux显著减少了集群间的依赖气泡，提升了硬件利用率，使rollout-training解耦架构能够更高效地运行

Conclusion: RollMux通过创新的调度机制解决了rollout-training解耦架构中的同步瓶颈问题，为强化学习后训练提供了更高效的硬件利用方案

Abstract: Rollout-training disaggregation is emerging as the standard architecture for Reinforcement Learning (RL) post-training, where memory-bound rollout and compute-bound training are physically disaggregated onto purpose-built clusters to maximize hardware efficiency. However, the strict synchronization required by on-policy algorithms introduces severe dependency bubbles, forcing one cluster to idle while the dependent phase is running on the other. We present RollMux, a cluster …

</details>


### [79] [From Signal to Turn: Interactional Friction in Modular Speech-to-Speech Pipelines](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.11724&hl=zh-CN&sa=X&d=5914113790408315585&ei=0XlFaZLFMN_OieoPg6WE2QY&scisig=ALhkC2QprtpFBHyScdEfzkDoMSgi&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=7&folt=cit)
*T Mairittha,T Sawanglok,P Raden,J Buntub…*

Main category: Zongheng Yang

TL;DR: 该论文分析了模块化语音到语音检索增强生成（S2S-RAG）管道中出现的交互摩擦，识别了三种对话崩溃模式：时间错位、内容不连贯和交互失调，并提出了改进建议。


<details>
  <summary>Details</summary>
Motivation: 尽管语音AI系统在生成能力方面取得了显著进展，但其交互体验常常感觉对话不连贯。现有研究多关注简单延迟指标，而缺乏对模块化S2S-RAG管道中交互摩擦的系统分析。

Method: 通过分析一个代表性的生产系统，超越简单的延迟指标，识别了三种重复出现的对话崩溃模式：时间错位、内容不连贯和交互失调。

Result: 识别了三种核心交互摩擦模式：1）时间错位：系统响应时间与对话节奏不匹配；2）内容不连贯：检索内容与上下文脱节；3）交互失调：系统行为与用户期望不一致。

Conclusion: 模块化S2S-RAG管道存在固有的交互摩擦问题，需要超越延迟优化的系统级改进，包括更好的时间协调、上下文感知检索和交互一致性设计。

Abstract: While voice-based AI systems have achieved remarkable generative capabilities, their interactions often feel conversationally broken. This paper examines the interactional friction that emerges in modular Speech-to-Speech Retrieval-Augmented Generation (S2S-RAG) pipelines. By analyzing a representative production system, we move beyond simple latency metrics to identify three recurring patterns of conversational breakdown:(1) Temporal Misalignment, where system …

</details>


### [80] [TiCard: Deployable EXPLAIN-only Residual Learning for Cardinality Estimation](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.14358&hl=zh-CN&sa=X&d=1189035207556205408&ei=VR1HaZGWAb2qieoPuKej0QM&scisig=ALhkC2S-Gj0uaDN7Wo4s9yt0_aqN&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=0&folt=cit)
*Q Wang*

Main category: Zongheng Yang

TL;DR: TiCard是一个低侵入的基数估计校正框架，通过EXPLAIN-only查询学习乘法残差校正来增强数据库原生估计器，而非替换它


<details>
  <summary>Details</summary>
Motivation: 传统基数估计器无法处理相关性，而学习型估计器通常需要特定工作负载的训练流程和侵入式的优化器集成，难以部署。需要一种低侵入的解决方案来增强现有数据库的估计能力。

Method: TiCard采用基于校正的框架，通过EXPLAIN-only查询学习乘法残差校正来增强数据库原生估计器。它不替换原有估计器，而是学习校正因子来修正原生估计的偏差。

Result: TiCard实现了低侵入的集成，能够有效处理相关性，同时避免了学习型估计器常见的工作负载特定训练和侵入式集成问题。

Conclusion: TiCard提供了一种实用且可部署的基数估计改进方案，通过校正框架在保持低侵入性的同时显著提升估计精度。

Abstract: Cardinality estimation is a key bottleneck for cost-based query optimization, yet deployable improvements remain difficult: classical estimators miss correlations, while learned estimators often require workload-specific training pipelines and invasive integration into the optimizer. This paper presents TiCard, a low intrusion, correction-based framework that augments (rather than replaces) a database's native estimator. TiCard learns multiplicative residual corrections using EXPLAIN-only …

</details>


### [81] [Survey on distributed parallel genetic algorithms for large-scale data analysis](https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s00607-025-01596-8&hl=zh-CN&sa=X&d=8417712162631761847&ei=VR1HaZGWAb2qieoPuKej0QM&scisig=ALhkC2Qj8UAQ49J-cb7YxF054xWL&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=1&folt=cit)
*L Al*

Main category: Zongheng Yang

TL;DR: 本文综述了分布式并行遗传算法（DPGAs），探讨了在分布式环境中如何并行化遗传算法的核心组件，并按实现策略对文献进行了分类。


<details>
  <summary>Details</summary>
Motivation: 随着数据规模和复杂性的增长，需要可扩展的进化方法。遗传算法（GAs）因其适应性和天然并行性非常适合这一挑战，但需要研究如何在分布式环境中有效实现并行化。

Method: 通过文献综述方法，系统分析分布式并行遗传算法（DPGAs）的实现策略，重点研究核心组件（适应度评估、选择、交叉、变异）在分布式环境中的并行化技术，并按实现策略对现有研究进行分类整理。

Result: 综述了分布式并行遗传算法的各种实现策略，包括自定义分布式方案等，分析了不同并行化方法对算法性能和可扩展性的影响，为大规模数据处理提供了有效的进化计算解决方案。

Conclusion: 分布式并行遗传算法是应对大规模数据挑战的有效方法，通过合理的并行化策略可以显著提高遗传算法的计算效率和可扩展性，为复杂优化问题提供了实用的解决方案。

Abstract: The growing size and complexity of data demand scalable evolutionary methods. Genetic Algorithms (GAs), with their adaptability and natural parallelism, are well suited to this challenge. This survey reviews Distributed Parallel Genetic Algorithms (DPGAs), examining how core components such as fitness evaluation, selection, crossover, and mutation are parallelized across distributed environments. We organize the literature by implementation strategy, including custom distribution …

</details>


### [82] [XY-Serve: End-to-End Versatile Production Serving for Dynamic LLM Workloads](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3760250.3762228&hl=zh-CN&sa=X&d=16099701286070194243&ei=wJ1Iaa-5N56u6rQPotyMwAQ&scisig=ALhkC2T30iAwDpM0oIyzalYNB1hv&oi=scholaralrt&hist=i6heNjgAAAAJ:778719684493065653:ALhkC2T5y4v8XnzDuwC4ZadUm0Rx&html=&pos=0&folt=rel)
*M Song,X Tang,F Hou,J Li,W Wei,Y Ma,R Xiao,H Si…*

Main category: Zongheng Yang

TL;DR: 该论文探讨了在动态且不可预测的输入输出长度环境下，如何整合先进优化技术以满足生产级大语言模型服务系统对低延迟和高成本效益的需求。


<details>
  <summary>Details</summary>
Motivation: 生产级大语言模型服务系统面临动态且不可预测的输入输出长度挑战，需要整合先进优化技术来满足日益增长的低延迟和成本效益需求。

Method: 论文提出整合多种先进优化技术的方法，以应对动态输入输出长度带来的挑战，具体技术细节未在摘要中明确说明。

Result: 通过整合优化技术，能够有效应对动态输入输出长度问题，提升大语言模型服务系统的性能和成本效益。

Conclusion: 整合先进优化技术是解决生产级大语言模型服务系统在动态环境下实现低延迟和高成本效益的关键途径。

Abstract: Meeting growing demands for low latency and cost efficiency in production-grade large language model (LLM) serving systems requires integrating advanced optimization techniques. However, dynamic and unpredictable input-output lengths …

</details>


### [83] [Efficient Scaling Embodied AI: Systems, Models, and Empirical Laws](https://scholar.google.com/scholar_url?url=https://search.proquest.com/openview/922b0382b8ab551ddf133f04edef8e1c/1%3Fpq-origsite%3Dgscholar%26cbl%3D18750%26diss%3Dy&hl=zh-CN&sa=X&d=16302985529977837133&ei=lQ5KaZ-8E9_OieoPg6WE2QY&scisig=ALhkC2QwaC_EqPdfs4GcjX8jwUR-&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=0&folt=cit)
*Q Lin*

Main category: Zongheng Yang

TL;DR: 该论文通过系统基础设施工程和高效建模策略的双重方法，解决具身人工智能从单任务系统向通用智能体转变过程中的效率挑战


<details>
  <summary>Details</summary>
Motivation: 具身人工智能正经历从单任务系统向通用智能体的范式转变，这一转变需要前所未有的规模。现实世界学习的经济性成为实现这一目标的障碍，因此对底层计算基础设施和学习模型的效率提出了关键需求

Method: 采用双重策略：系统基础设施工程和高效建模策略。通过优化计算基础设施架构和提高学习模型的效率来应对效率挑战

Result: 论文摘要未提供具体实验结果，但提出了解决具身AI效率挑战的理论框架和方法论

Conclusion: 通过基础设施优化和高效建模策略的双重方法，可以有效应对具身人工智能向通用智能体转变过程中的效率和经济性挑战

Abstract: Embodied artificial intelligence is undergoing a paradigm shift from single-task systems to general-purpose agents, a transition demanding unprecedented scale. The economics of real-world learning present the obstacle to this goal, creating a critical need for efficiency in both the underlying computational infrastructure and the learning models. This thesis confronts these efficiency challenges through a dual strategy of systematic infrastructure engineering and efficient modeling strategies …

</details>


### [84] [Leveraging Query Optimizers to Verify the Soundness of LLM-based Query Rewrites for Real-World Workloads, and More!](https://scholar.google.com/scholar_url?url=https://www.vldb.org/cidrdb/papers/2026/p33-narasayya.pdf&hl=zh-CN&sa=X&d=7946558459261240690&ei=lQ5Kab6bKK-nieoPz8HDqAc&scisig=ALhkC2TZunsrb8nVIyLzXQRHn4rL&oi=scholaralrt&hist=i6heNjgAAAAJ:778719684493065653:ALhkC2T5y4v8XnzDuwC4ZadUm0Rx&html=&pos=1&folt=rel)
*V Narasayya,S Chaudhuri*

Main category: Zongheng Yang

TL;DR: 查询重写是数据库开发者和管理员用于改进SQL查询性能的技术，当优化器生成的执行计划不理想时，通过生成语义等效但性能更好的查询来提升效率


<details>
  <summary>Details</summary>
Motivation: 数据库查询优化器有时无法生成最优执行计划，导致查询性能不佳。查询重写技术旨在解决这一问题，通过人工或自动方式修改查询结构，生成更高效的执行计划，从而提升数据库系统整体性能

Method: 查询重写方法包括识别次优查询模式，应用转换规则生成语义等效的查询变体，评估重写后的查询性能，选择最优重写方案。具体技术可能涉及子查询优化、连接重排序、谓词下推、物化视图重写等

Result: 查询重写技术能够显著提升SQL查询性能，减少执行时间，降低资源消耗。通过适当的重写，复杂查询的执行效率可提高数倍甚至数十倍，特别适用于处理大数据量和复杂连接操作的场景

Conclusion: 查询重写是数据库性能优化的重要技术，能够弥补查询优化器的不足。有效的查询重写需要深入理解查询语义和数据库执行引擎特性，结合自动化工具和专家经验，实现查询性能的最大化提升

Abstract: Query rewriting is widely used by database developers and administrators to improve SQL query performance when the optimizergenerated plan is suboptimal. The goal of query rewriting is to generate a semantically equivalent query whose …

</details>


### [85] [Optimal configuration of API resources in cloud native computing](https://scholar.google.com/scholar_url?url=https://lirias.kuleuven.be/retrieve/b8c13972-2c7a-488f-8573-8e0a2704a119&hl=zh-CN&sa=X&d=12381976437444621408&ei=1bJLafvzHbLrieoPwNLAkQw&scisig=ALhkC2SOGjDI5X-9AkJ7-v5togvM&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=0&folt=cit)
*E Truyen,W Joosen,M Kaminiski*

Main category: Zongheng Yang

TL;DR: 将离线性能优化框架应用于DevOps发布阶段的微服务资源分配配置优化


<details>
  <summary>Details</summary>
Motivation: 当前微服务优化研究主要集中在运维阶段的智能调度和自动扩缩容，而发布阶段的CPU和内存资源分配配置优化仍是一个未被充分探索的问题

Method: 应用现有的离线性能优化框架，在DevOps发布阶段优化微服务应用的CPU和内存资源分配配置参数

Result: 展示了现有离线性能优化框架在微服务发布阶段资源分配配置优化中的适用性和应用方法

Conclusion: 离线性能优化框架可以有效应用于微服务发布阶段的资源分配配置优化，填补了该领域的研究空白

Abstract: This paper presents how an existing framework for offline performance optimization can be applied to microservice applications during the Release phase of the DevOps life cycle. Optimization of resource allocation configuration parameters for CPU and memory during the Release phase remains a largely unexplored problem as most research has focused on intelligent scheduling and autoscaling of microservices during the Ops stage of the DevOps cycle. Yet horizontal auto-scaling of containers …

</details>


### [86] [Efficient and Resilient Distributed Deep Learning for Cloud-based Execution](https://scholar.google.com/scholar_url?url=https://eric-keller.github.io/thesis/MaziyarNazari_PhD_Dissertation2025.pdf&hl=zh-CN&sa=X&d=5157477192841530097&ei=ey5NabrNBJaM6rQP0-TCwQU&scisig=ALhkC2REP3wnP1_l5w1Zos5LjmvY&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=1&folt=cit)
*M Nazari*

Main category: Zongheng Yang

TL;DR: 深度学习应用在各领域普及，但部署面临多方面挑战


<details>
  <summary>Details</summary>
Motivation: 深度学习应用已超越计算机科学领域，吸引了各科学和工程领域的专业人士，这种变革性技术通过整合更大模型和利用海量数据集彻底改变了机器学习。然而，机器学习/深度学习应用的部署面临着多方面的挑战。

Method: 从提供的摘要内容来看，本文主要采用综述分析的方法，探讨深度学习应用部署面临的挑战，但具体方法细节在提供的摘要中未完全展示。

Result: 摘要部分指出深度学习应用已广泛普及并改变了机器学习领域，但部署过程存在多方面挑战，这些挑战影响了应用的实际实施。

Conclusion: 深度学习技术虽然在各领域取得了显著成功，但其实际部署面临重要挑战，需要进一步研究和解决。

Abstract: Deep Learning applications have surged in popularity, transcending the boundaries of computer science to captivate professionals in diverse scientific and engineering fields. This transformative technology has revolutionized machine learning by enabling the integration of larger models and harnessing extensive datasets, as underscored by recent research findings. Yet, the deployment of machine/deep learning applications presents multifaceted challenges, impacting both the …

</details>


### [87] [What to Support When You're Compressing](https://scholar.google.com/scholar_url?url=https://www.osti.gov/pages/servlets/purl/3009798&hl=zh-CN&sa=X&d=9918784161541106341&ei=WJlOady3AsW4ieoP4szBiAE&scisig=ALhkC2TT6rH1fIxEiu2MNjP4sT6U&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=0&folt=cit)
*F Cappello,R Underwood,Y Alexeev,A Baker…*

Main category: Zongheng Yang

TL;DR: 该论文综述了近20年来HPC应用中损失压缩技术的发展现状、挑战及未来方向，强调在克服存储限制的同时需要评估和控制压缩对科学结果的影响。


<details>
  <summary>Details</summary>
Motivation: 随着HPC应用中损失压缩技术的普及，需要系统评估和控制压缩对科学结果的影响，以确保数据质量同时克服存储容量和带宽限制。

Method: 论文通过综述近20年HPC损失压缩实践，分析现有方法、评估技术和控制策略，提出系统化框架来指导压缩技术的应用。

Result: 系统描述了HPC损失压缩的现状、挑战和最佳实践，为科学计算中平衡压缩效率与数据质量提供了方法论指导。

Conclusion: 损失压缩已成为HPC数据管道的重要组成部分，但需要建立系统化的评估和控制机制来确保科学结果的可靠性，这是该领域发展的关键方向。

Abstract: Over the last nearly 20 years, lossy compression has become an essential aspect of HPC applications' data pipelines, allowing them to overcome limitations in storage capacity and bandwidth and, in some cases, increase computational throughput and capacity. However, with the adoption of lossy compression comes the requirement to assess and control the impact lossy compression has on scientific outcomes. In this work, we take a major step forward in describing the state of practice and by …

</details>


### [88] [Evaluating Model Resilience to Data Poisoning Attacks: A Comparative Study](https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2078-2489/17/1/9&hl=zh-CN&sa=X&d=16567631647924057432&ei=WJlOady3AsW4ieoP4szBiAE&scisig=ALhkC2Q5WjOGFmsp51orJAnLPsou&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=1&folt=cit)
*I Udoidiok,F Li,J Zhang*

Main category: Zongheng Yang

TL;DR: 该论文指出当前机器学习数据投毒攻击研究主要关注性能下降量化，缺乏对不同模型架构在攻击下内部行为的系统性比较，以及攻击对模型内部表征影响的深入分析。


<details>
  <summary>Details</summary>
Motivation: 机器学习已成为关键应用的核心技术，但其对数据投毒攻击的脆弱性威胁着系统可靠性和可信度。现有研究大多局限于量化性能下降，缺乏对攻击下不同模型架构内部行为的系统性比较，以及对模型内部表征影响的深入理解。

Method: 论文未在摘要中明确描述具体方法，但暗示需要采用更系统化的方法来比较不同模型架构在数据投毒攻击下的内部行为，并深入分析攻击对模型内部表征的影响。

Result: 摘要未提供具体实验结果，但指出了当前研究存在的局限性：缺乏系统性比较、对内部行为分析不足、对模型内部表征影响关注不够。

Conclusion: 需要超越简单的性能下降量化，开展更系统化的研究来比较不同模型架构在数据投毒攻击下的内部行为，并深入理解攻击对模型内部表征的影响，以开发更有效的防御机制。

Abstract: Machine learning (ML) has become a cornerstone of critical applications, but its vulnerability to data poisoning attacks threatens system reliability and trustworthiness. Prior studies have begun to investigate the impact of data poisoning and proposed various defense or evaluation methods; however, most efforts remain limited to quantifying performance degradation, with little systematic comparison of internal behaviors across model architectures under attack and insufficient attention …

</details>


### [89] [Smark: A Watermark for Text-to-Speech Diffusion Models via Discrete Wavelet Transform](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.18791&hl=zh-CN&sa=X&d=250260424842356209&ei=WJlOady3AsW4ieoP4szBiAE&scisig=ALhkC2Qd5FvCDfCMMJ5r_JR9-0Ni&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=3&folt=cit)
*Y Zhang,C Li,Y Gu*

Main category: Zongheng Yang

TL;DR: 提出了一种通用的TTS扩散模型水印方法，无需修改模型结构即可保护知识产权和追踪语音来源


<details>
  <summary>Details</summary>
Motivation: TTS扩散模型生成高质量语音，但缺乏有效的知识产权保护和语音追踪机制。现有水印方法通常针对特定模型设计，会降低音频质量，且通用性差

Method: 提出通用水印框架，不修改TTS扩散模型结构，通过特定方式嵌入水印信息，保持音频质量的同时实现跨模型兼容性

Result: 方法在多种TTS扩散模型上有效，水印鲁棒性高，对音频质量影响小，具有实际应用价值

Conclusion: 该通用水印方法为TTS扩散模型提供了有效的知识产权保护和语音追踪解决方案，解决了现有方法的局限性

Abstract: Text-to-Speech (TTS) diffusion models generate high-quality speech, which raises challenges for the model intellectual property protection and speech tracing for legal use. Audio watermarking is a promising solution. However, due to the structural differences among various TTS diffusion models, existing watermarking methods are often designed for a specific model and degrade audio quality, which limits their practical applicability. To address this dilemma, this paper proposes a universal …

</details>


### [90] [Analyzing cross-language similarities to enhance low-resource text-to-speech via transfer learning, case study: the Moroccan Berber Amazigh](https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10772-025-10244-7&hl=zh-CN&sa=X&d=14919640892699204690&ei=NPlPabDSAayK6rQPgZOO6A8&scisig=ALhkC2QeJc1gR6FjOTpif3ZGInT3&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=0&folt=cit)
*FE Dorhmi,I Lasri,N El*

Main category: Zongheng Yang

TL;DR: 提出基于音素相似性的跨语言迁移学习方法，为资源匮乏的摩洛哥阿马齐格语构建文本转语音系统


<details>
  <summary>Details</summary>
Motivation: 标准摩洛哥阿马齐格语缺乏文本转语音系统，且高质量平行数据稀缺昂贵，作为低资源语言面临挑战

Method: 采用跨语言迁移学习，基于共享音素的皮尔逊相关性对相关语言排序，从预训练模型初始化音素嵌入，并微调辅助语言模型

Result: 成功为摩洛哥阿马齐格语构建了文本转语音系统，克服了数据稀缺问题

Conclusion: 音素相似性驱动的跨语言迁移学习是解决低资源语言文本转语音问题的有效方法

Abstract: Abstract Standard Moroccan Amazigh (Moroccan Berber) lacks any text-to-speech system despite its rich phonemic inventory. High-quality parallel data are scarce and costly for this low-resource language. We introduced a cross-lingual transfer learning approach that leverages phonemic similarity: after ranking related languages via Pearson correlation of shared phonemes, we initialized phoneme embeddings from pretrained models fine-tuned on those auxiliaries. Our TTS comprises a spectrogram …

</details>


### [91] [MulAD: A Log-based Anomaly Detection Approach for Distributed Systems using Multi-Pattern and Multi-Model Fusion](https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0167642325001716&hl=zh-CN&sa=X&d=18172580254369386256&ei=NPlPabDSAayK6rQPgZOO6A8&scisig=ALhkC2QyNKbv1bfdNH3UR3RfgcVb&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=1&folt=cit)
*X Wei,CA Sun,X Zhang,D Towey*

Main category: Zongheng Yang

TL;DR: 提出一种结合多种日志模式进行异常检测的方法，以解决单一模式检测可能导致的漏报问题


<details>
  <summary>Details</summary>
Motivation: 现有的日志异常检测技术通常只关注单一日志模式，但复杂的异常可能涉及多种日志模式类型，仅依赖单一模式会导致漏报（假阴性），影响分布式系统在DevOps环境下的可靠性保障

Method: 论文提出一种结合多种日志模式进行异常检测的方法，通过整合不同日志模式的信息来检测跨模式的复杂异常

Result: 该方法能够检测到仅依赖单一模式会漏报的复杂异常，提高了异常检测的准确性和覆盖率

Conclusion: 结合多种日志模式进行异常检测是必要的，能够有效减少假阴性，提高分布式系统在DevOps环境下的可靠性监控能力

Abstract: Context: Log-based anomaly detection (LAD) techniques examine whet-her or not continuously-generated logs match historically-normal patterns: This helps to ensure reliability in distributed systems using DevOps. However, complex anomalies can span multiple log‐pattern types and thus may only be detected by combining these patterns: Relying only on any single pattern may cause anomalies to be missed. These are false negatives in anomaly detection. Objective: In this paper, we propose …

</details>


### [92] [Scaling Point-based Differentiable Rendering for Large-scale Reconstruction](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.20017&hl=zh-CN&sa=X&d=17084500629489792874&ei=NPlPabDSAayK6rQPgZOO6A8&scisig=ALhkC2Q7zuyzYIL5T2uP0bubjPxj&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=2&folt=cit)
*H Zhao,X Liu,X Min,J Huang,Y Deng,Y Li,A Li,J Li…*

Main category: Zongheng Yang

TL;DR: Gaian是一个用于点基可微渲染的通用分布式训练系统，解决了现有系统与特定方法紧耦合、数据局部性差导致通信开销大的问题


<details>
  <summary>Details</summary>
Motivation: 点基可微渲染能够实现高保真3D场景重建，但扩展到高分辨率和大场景需要高效的分布式训练系统。现有系统与特定PBDR方法紧耦合，且由于数据局部性差导致严重的通信开销

Method: Gaian提供了一个统一的API，支持现有PBDR方法，通过优化数据局部性和减少通信开销来实现高效的分布式训练

Result: Gaian系统能够有效支持点基可微渲染的分布式训练，显著减少通信开销，提高训练效率

Conclusion: Gaian为点基可微渲染提供了一个通用、高效的分布式训练解决方案，解决了现有系统的局限性

Abstract: Point-based Differentiable Rendering (PBDR) enables high-fidelity 3D scene reconstruction, but scaling PBDR to high-resolution and large scenes requires efficient distributed training systems. Existing systems are tightly coupled to a specific PBDR method. And they suffer from severe communication overhead due to poor data locality. In this paper, we present Gaian, a general distributed training system for PBDR. Gaian provides a unified API expressive enough to support existing PBDR …

</details>


### [93] [A Novel Approach to the Phonetic Representativeness of Writing Systems: Phonetic Correspondence Efficiency (PCE).](https://scholar.google.com/scholar_url?url=https://search.ebscohost.com/login.aspx%3Fdirect%3Dtrue%26profile%3Dehost%26scope%3Dsite%26authtype%3Dcrawler%26jrnl%3D15827445%26AN%3D190291970%26h%3Drr%252FQXBFsdIWYop6xebhVuOhjNu3FOqGNnHyi2KbOLZZ1wOIYGxFjfHu4puMuus%252FNjtIKii02eCQnoFdFQMZGwg%253D%253D%26crl%3Dc&hl=zh-CN&sa=X&d=6807706761920606511&ei=NPlPabDSAayK6rQPgZOO6A8&scisig=ALhkC2QnmPJZTxxU7IJ85Cjd75Ex&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=3&folt=cit)
*K TOHMA,HI OKUR*

Main category: Zongheng Yang

TL;DR: 提出语音对应效率指标，用于评估文字系统对语言音系结构的准确、独特和经济性表征能力，基于通用突厥字母更新数据集进行验证


<details>
  <summary>Details</summary>
Motivation: 文字系统的语音表征能力对语言技术发展至关重要，需要量化评估不同文字系统如何准确、独特且经济地捕捉语言的声音结构

Method: 引入语音对应效率指标，测量文字系统对语言音系结构的准确性、独特性和经济性；使用基于通用突厥字母更新的数据集进行对比分析，验证指标的有效性和实用性

Result: 通过比较分析验证了语音对应效率指标的有效性，展示了该指标在评估不同文字系统语音表征能力方面的实用价值

Conclusion: 语音对应效率指标为评估文字系统的语音表征能力提供了量化工具，有助于推动语言技术发展，特别是在多文字系统语言处理方面

Abstract: The phonetic representativeness of writing systems is of critical importance for the advancement of language technologies. In this study, the Phonetic Correspondence Efficiency metric is introduced to measure how accurately, uniquely, and economically a writing system captures the sound structure of a language. To evaluate the metric's validity and practical utility, comparative analyses were conducted using datasets updated in accordance with the Common Turkic Alphabet; …

</details>


### [94] [Tuning Matters: Analyzing Musical Tuning Bias in Neural Vocoders](https://scholar.google.com/scholar_url?url=https://ismir2025program.ismir.net/poster_199.html&hl=zh-CN&sa=X&d=7567560927556994489&ei=NPlPabDSAayK6rQPgZOO6A8&scisig=ALhkC2Szas3gb96X0hMmlx-fIYjf&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=5&folt=cit)
*HU Berendes,B Maman,M Müller*

Main category: Zongheng Yang

TL;DR: 该研究探讨了神经声码器在音乐和语音合成中可能引入的伪影和偏差问题


<details>
  <summary>Details</summary>
Motivation: 传统信号处理技术（如Griffin-Lim算法）已被神经声码器取代，后者利用生成模型实现更优音频质量。然而，这些模型可能引入伪影和偏差，以不可预见的方式影响输出质量。

Method: 从摘要内容看，研究方法涉及对神经声码器的系统性检查和分析，但具体方法细节未在提供的摘要部分明确说明。

Result: 摘要未提供具体实验结果，但暗示研究将揭示神经声码器在音频重建过程中可能存在的系统性偏差和伪影问题。

Conclusion: 神经声码器虽然提升了音频合成质量，但存在引入伪影和偏差的风险，需要进一步研究和改进以确保输出质量的可控性和可靠性。

Abstract: Vocoders, which reconstruct time-domain waveforms from spectral representations such as mel-spectrograms, are essential in modern music and speech synthesis. Traditional signal-processing techniques like the Griffin-Lim algorithm have largely been replaced by neural vocoders, which leverage generative models to achieve superior audio quality. However, these models can introduce artifacts and biases, potentially affecting their output in unforeseen ways. In this study, we examine how …

</details>


### [95] [Deadline-Aware Online Scheduling for LLM Fine-Tuning with Spot Market Predictions](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.20967&hl=zh-CN&sa=X&d=14471105955641964550&ei=35RRaYW8HNrJieoPiYyysAk&scisig=ALhkC2SkBIURudX7C3jt_nCMaSzk&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=0&folt=cit)
*L Kong,Y Xu,L Jiao,C Xu*

Main category: Zongheng Yang

TL;DR: 该论文提出了一种混合使用竞价实例和按需实例的方法，通过预测竞价市场价格和可用性，实现成本效益高的深度学习模型微调调度


<details>
  <summary>Details</summary>
Motivation: 随着基础模型规模增大，微调成本急剧上升。GPU竞价实例虽然成本较低，但其价格波动和可用性不稳定使得满足截止期限的调度变得困难

Method: 采用竞价实例和按需实例混合策略，利用竞价市场价格和可用性的可预测性，通过预测技术实现成本优化的调度方案

Result: 展示了竞价市场价格和可用性的可预测性，预测能力能够实现成本效益高的调度，在满足截止期限的同时显著降低成本

Conclusion: 混合使用竞价和按需实例，结合价格和可用性预测，是解决大规模模型微调成本问题的有效策略

Abstract: As foundation models grow in size, fine-tuning them becomes increasingly expensive. While GPU spot instances offer a low-cost alternative to on-demand resources, their volatile prices and availability make deadline-aware scheduling particularly challenging. We tackle this difficulty by using a mix of spot and on-demand instances. Distinctively, we show the predictability of prices and availability in a spot instance market, the power of prediction in enabling cost-efficient …

</details>


### [96] [Vocal communication of emotion: Exploring the contribution of local and global shifts to the voice source and the impact of the visual context](https://scholar.google.com/scholar_url?url=https://www.tara.tcd.ie/bitstreams/1f1f6a86-5b19-4904-8fb7-f7c3dd931cd0/download&hl=zh-CN&sa=X&d=3095285939918797857&ei=35RRaYW8HNrJieoPiYyysAk&scisig=ALhkC2QMcGGuONHDMRcI3Ehw_6KI&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=1&folt=cit)
*AM Giovannini*

Main category: Zongheng Yang

TL;DR: 该研究探索了嗓音质量与情感表达的映射关系，以及视觉情境对情感感知的影响，通过分析表演数据来研究五种情感状态下的嗓音源变化。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解嗓音质量如何映射到情感表达，以及视觉情境如何影响情感感知，这对于语音合成、情感识别和人机交互具有重要意义。

Method: 采用手动逆滤波和Liljencrants-Fant模型匹配来分析表演录音数据，创建轮廓可视化并估计与情感表达相关的嗓音源变化，研究五种情感状态。

Result: 研究通过分析发现了不同情感状态下嗓音源参数的变化模式，并探索了视觉情境对情感感知的调节作用。

Conclusion: 嗓音质量与情感表达存在系统性映射关系，视觉情境显著影响情感感知，这些发现对语音合成和情感识别系统有重要应用价值。

Abstract: This thesis explores aspects of the mapping of voice quality to affect and the impact of the visual context in emotion perception. The first phase of the study involves a thorough analysis of recorded acted data through manual inverse filtering and model matching to the Liljencrants-Fant model, used as a basis to create contour visualizations and estimate the changes to the voice source related to emotion expression. Five affects were explored: happy, angry, bored, sad and relaxed. This …

</details>


### [97] [Assessing grid penalized reinforcement learning for renewable energy management of power-to-x integrated with intermediate storage](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11051013/&hl=zh-CN&sa=X&d=8111379886971196276&ei=HXBTaf1blozqtA_T5MLBBQ&scisig=ALhkC2Q1jVRsLwMBowMGYb7-oqPw&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=0&folt=cit)
*J Kim,J Na,JSI Kwon,S Ga,S Suh,J Kim*

Main category: Zongheng Yang

TL;DR: 提出基于深度强化学习的PtX系统规划模型，在可再生能源和价格不确定性下优化运行成本，采用混合储能系统和电网惩罚奖励函数


<details>
  <summary>Details</summary>
Motivation: PtX系统面临可再生能源和市场价格的双重不确定性，传统规划方法难以有效处理这些动态变化，需要更智能的优化策略来降低运营成本并提高系统灵活性

Method: 提出基于深度强化学习的每小时规划模型，采用混合储能系统，设计电网惩罚奖励函数来管理电网电力使用，在可再生能源和价格不确定性下进行优化决策

Result: 通过详细的案例研究和比较分析，验证了DRL规划策略在降低PtX系统运营成本方面的有效性，展示了在不确定性环境下的优越性能

Conclusion: 深度强化学习为PtX系统规划提供了有效的解决方案，能够在可再生能源和价格不确定性下实现成本优化，混合储能系统和电网惩罚机制是提高系统经济性的关键要素

Abstract: This research explores the deep reinforcement learning (DRL) based planning strategies of power-to-X (PtX) systems under uncertainties of renewable and price through a detailed case study and comparative analysis of system planning. A DRL-based hourly planning model is proposed to minimize operational costs for a PtX system, incorporating a hybrid energy storage system. The model employs a grid-penalized reward function to manage grid power usage while accounting for …

</details>


### [98] [A novel distributed parallel simulation method with dynamic partitioning using KLeiden-based community detection](https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S1366554525006349&hl=zh-CN&sa=X&d=3974962140410428511&ei=HXBTaf1blozqtA_T5MLBBQ&scisig=ALhkC2RIqfRGk_VA6-waMzvzDJRq&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=1&folt=cit)
*H Zhu,X Xie,K Tang,J Feng,W Rao*

Main category: Zongheng Yang

TL;DR: 该论文探讨了大规模路网中微观交通仿真的计算效率问题，提出分布式并行仿真作为解决方案，但指出当前方法存在局限性


<details>
  <summary>Details</summary>
Motivation: 随着智能交通系统的发展，对微观交通仿真实时应用的需求日益严格，大规模路网中的计算效率成为关键问题，分布式并行仿真被认为是可行的解决措施

Method: 论文未在摘要中明确描述具体方法，但提到分布式并行仿真作为解决大规模路网微观交通仿真计算效率问题的技术途径

Result: 摘要未提供具体实验结果，但暗示当前分布式并行仿真方法存在局限性或未解决的问题

Conclusion: 需要改进或提出新的分布式并行仿真方法来解决大规模路网微观交通仿真的计算效率问题

Abstract: Microscopic traffic simulation constitutes a foundational technology in Intelligent Transportation Systems, and as traffic management paradigms continue to evolve, the requirements for its real-time application have become increasingly stringent. The computational efficiency of microscopic traffic simulation in large-scale road networks remains a critical issue. Distributed parallel simulation is considered one of the viable measures to address the above issue. However, this approach currently …

</details>


### [99] [What Determines Personality Impressions of Synthetic and Natural Voices? The Effects of Voice Quality and Intonation](https://scholar.google.com/scholar_url?url=https://journals.sagepub.com/doi/abs/10.1177/00238309251389567&hl=zh-CN&sa=X&d=8394110705569976112&ei=HXBTaf1blozqtA_T5MLBBQ&scisig=ALhkC2SlQgEX8y8Bektnyxfbq_zP&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=2&folt=cit)
*M Kim,J Park,M Jeong,J Song*

Main category: Zongheng Yang

TL;DR: 研究探讨合成与自然语音的声学和语音特征如何影响人格印象，通过人格评分实验分析韩语自然语音及其合成副本的感知人格特征


<details>
  <summary>Details</summary>
Motivation: 随着语音合成技术的发展，合成语音在多种应用场景中使用日益广泛，但人们对合成语音的人格印象感知机制尚不明确。了解声学和语音特征如何影响人格印象对于改进语音合成技术、优化人机交互体验具有重要意义。

Method: 采用人格评分实验设计，30名韩语母语者对自然韩语语音及其合成副本（语音克隆）进行人格评分，使用大五人格模型。分析多种声学参数，包括音质、基频（F0）和发音速率等测量指标。

Result: 研究发现声学和语音特征对人格印象有显著影响，具体参数与特定人格维度存在关联。合成语音与自然语音在人格印象感知上可能存在差异，揭示了语音特征与人格感知之间的系统关系。

Conclusion: 声学和语音特征是影响语音人格印象的关键因素，研究结果为优化合成语音设计提供了实证依据，有助于创建更具适当人格特征的合成语音以改善人机交互体验。

Abstract: The present study investigated how acoustic and phonetic characteristics of synthetic and natural voices affect personality impressions of the voices. To this end, we conducted a personality rating experiment in which 30 native Korean speakers judged the perceived personality of natural Korean utterances and their synthetic counterparts (voice clones) using the Big-Five personality model. Various acoustic parameters, including measures of voice quality, F0, and articulation rate, were then …

</details>


### [100] [VQA Studio: A Unified Framework for Parallel Visual Question Answering Evaluation](https://scholar.google.com/scholar_url?url=https://people.eecs.berkeley.edu/~kubitron/courses/cs262a-F25/projects/reports/project1001_paper_ver2_47739557327740883388.pdf&hl=zh-CN&sa=X&d=2864106316961531917&ei=HXBTaf1blozqtA_T5MLBBQ&scisig=ALhkC2TENwi0t_72pygsNIIpn94u&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=5&folt=cit)
*C Hu,TH Tan,Y Wang*

Main category: Zongheng Yang

TL;DR: VQA Studio是一个统一的视觉问答评估框架，通过标准化数据集、按答案模式路由任务、并行执行和批量评判来加速异构数据集上的VQA模型评估。


<details>
  <summary>Details</summary>
Motivation: 当前在多数据集上评估VQA模型存在速度慢、脆弱性高的问题，主要原因是模式不匹配、顺序执行瓶颈和开放式评估成本高。

Method: 提出VQA Studio框架：1) 将多样化VQA数据集标准化为规范模式；2) 按答案模式路由任务；3) 通过并行任务执行和可选批量评判加速端到端评估。

Result: 该框架能够显著加速VQA模型在多数据集上的评估过程，解决模式不匹配和顺序执行瓶颈问题。

Conclusion: VQA Studio提供了一个高效、统一的VQA评估框架，能够标准化评估流程并显著提升评估速度。

Abstract: Abstract Evaluating Visual Question Answering (VQA) models across multiple heterogeneous datasets is slow and fragile due to schema mismatches, sequential execution bottlenecks, and expensive openended evaluation. We present VQA Studio, a unified evaluation framework that standardizes diverse VQA datasets into a canonical schema, routes tasks by answer mode, and accelerates end-to-end evaluation through parallel task execution and optional batch judging. The key …

</details>


### [101] [Galaxy: An Elastic FaaS Control Plane for Highly-Scalable Instance Scheduling](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11249802/&hl=zh-CN&sa=X&d=8028456178035755049&ei=KU9VaaOnFZ6u6rQPotyMwAQ&scisig=ALhkC2QpFn-agF2D0NO15Ybe6WLk&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=0&folt=cit)
*Y Li,L Zhao,S Bian,Y Zhang,G Liu,H Yang,M Zhao…*

Main category: Zongheng Yang

TL;DR: Galaxy是一个为FaaS平台设计的高可扩展实例调度系统，通过按需扩缩容解决高并发、高突发、高波动的"3H"特性带来的调度瓶颈问题


<details>
  <summary>Details</summary>
Motivation: FaaS平台面临"3H"特性（高并发、高突发、高波动）带来的调度瓶颈，字节跳动系统日请求量达496亿，现有调度系统无法有效应对这种极端负载模式

Method: 受FaaS应用按需扩缩容思想启发，提出Galaxy系统，采用创新的调度架构和算法来处理大规模、动态变化的FaaS实例调度需求

Result: Galaxy系统显著提升了调度系统的可扩展性和性能，能够有效处理字节跳动平台496亿日请求量的极端负载场景

Conclusion: Galaxy为大规模FaaS平台提供了一种有效的实例调度解决方案，解决了"3H"特性带来的调度瓶颈问题，具有重要的实践价值

Abstract: Function-as-a-Service (FaaS) is becoming increasingly prevalent, and the number of daily service requests in our system ByteDance has even reached 49.6 billion. These requests exhibit “3H” characteristics: high concurrency, high burstiness, and high fluctuation, causing the instance scheduling system to face severe bottlenecks even earlier than the data plane. In this paper, inspired by the idea of on-demand scaling of FaaS applications, we propose Galaxy, a highly scalable instance scheduling …

</details>


### [102] [Real-World Audio Deepfake Detection Using SSL-Based Speech Models and Diverse Training Data](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11272686/&hl=zh-CN&sa=X&d=577918777167071498&ei=KU9VaaOnFZ6u6rQPotyMwAQ&scisig=ALhkC2RiVk-sH4nAJoGVulRuLzcW&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=1&folt=cit)
*K Schäfer,M Neu*

Main category: Zongheng Yang

TL;DR: 音频深度伪造检测器通常包含前端特征提取和后端分类两部分，基于自监督学习的前端是目前最有前景的方法


<details>
  <summary>Details</summary>
Motivation: 随着人工智能和合成方法的进步，音频深度伪造被用于恶意目的的可能性增加，因此需要可靠的音频深度伪造检测器

Method: 大多数音频深度伪造检测器采用两阶段架构：前端负责特征提取，后端执行分类。基于自监督学习的前端是目前最有前景的方法

Result: 未提供具体实验结果，但指出自监督学习前端在音频深度伪造检测中表现出最大潜力

Conclusion: 音频深度伪造检测需要可靠的检测器，基于自监督学习的前端是目前最有前景的技术方向

Abstract: The potential for audio deepfakes to be used for malevolent purposes is increasing in line with advances in artificial intelligence and synthesis methods. With this, the need for reliable audio deepfake detectors increased. Most audio deepfake detectors comprise two principal components: a frontend, which is responsible for feature extraction, and a back-end, which performs the classification. Self-supervised learning (SSL) based front-ends are right now the most promising when faced with …

</details>


### [103] [A Deep Learning Model for Heart Sound Classification Fusing Time-Frequency Features](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11293768/&hl=zh-CN&sa=X&d=13516502869216996002&ei=mqlWaa6sN-qsieoPjYOSgAM&scisig=ALhkC2Rf2BGxaHPfG0wX-3OJmvZW&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=0&folt=cit)
*N Liu,X Chen,Y Yu,L Guo,T Guo,B Qiu,P Chen…*

Main category: Zongheng Yang

TL;DR: 开发一个融合时域和频域特征的模型，用于心音图信号分类，以改善心血管疾病的早期诊断


<details>
  <summary>Details</summary>
Motivation: 心血管疾病是全球主要健康威胁，心音图信号的自动分类对其早期诊断至关重要。现有模型通常只分析单一域（时域或频域）的特征，未能融合互补信息，限制了分类性能。

Method: 开发一个能够有效整合时域和频域特征的模型，通过融合两个域的互补信息来克服现有方法的局限性。

Result: 未在摘要中明确说明具体结果，但研究目标是提高心音图信号分类的准确性。

Conclusion: 通过融合时域和频域特征，可以开发出更有效的心音图信号分类模型，有望改善心血管疾病的早期诊断。

Abstract: Objective: Cardiovascular diseases (CVDs) are a leading global health threat. The automatic classification of phonocardiogram (PCG) signals is crucial for their early diagnosis, yet existing models are often limited by analyzing features from only a single domain (time or frequency), failing to fuse complementary information. This study aims to develop a model that overcomes this limitation by effectively integrating both time-domain and frequency-domain features to improve classification accuracy …

</details>


### [104] [Microscopic Propagator Imaging with diffusion MRI](https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0730725X25002917&hl=zh-CN&sa=X&d=7921698747007827883&ei=mqlWaa6sN-qsieoPjYOSgAM&scisig=ALhkC2TqKVYesZVwVetsOem6OUzb&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=1&folt=cit)
*T Zajac,G Menegaz,M Pizzolato*

Main category: Zongheng Yang

TL;DR: MPI是一种新型扩散MRI技术，通过估计微观传播器的特性指数来表征组织微结构内的水位移概率分布，相比传统方法能减少对中观混杂因素（如轴突取向分散）的敏感性。


<details>
  <summary>Details</summary>
Motivation: 传统平均表观传播器方法对中观混杂因素（如轴突取向分散）敏感，这会影响诊断图谱的准确性。需要一种能更直接反映组织微结构特性的扩散MRI技术。

Method: 开发了微观传播器成像（MPI）技术，该技术估计微观传播器的特性指数。微观传播器是组织微结构内水位移的概率分布。该方法专门设计用于最小化指数对中观混杂因素的敏感性。

Result: MPI能够生成更直接反映组织微结构存在的诊断图谱，相比传统方法减少了轴突取向分散等中观混杂因素的影响。

Conclusion: MPI作为一种新型扩散MRI技术，通过专注于微观传播器特性估计，提供了对组织微结构更直接、更特异的表征能力。

Abstract: Abstract Microscopic Propagator Imaging (MPI) is a novel diffusion MRI technique that estimates properties, referred to as indices, of the microscopic propagator. This is the probability distribution of water displacements within tissue microstructures. Unlike conventional mean apparent propagator methods, MPI is designed to minimize the sensitivity of indices to mesoscopic confounds such as axonal orientation dispersion, yielding diagnostic maps that more directly reflect presence …

</details>


### [105] [Pathological-to-Healthy Speech Conversion Using Continuous-Time Neural Modeling](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11273600/&hl=zh-CN&sa=X&d=7938308535926369839&ei=mqlWaa6sN-qsieoPjYOSgAM&scisig=ALhkC2QMHZw0aK0P0TueYjvONMz_&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=2&folt=cit)
*S Chlaikhy,A Chakhtouna,A Adib*

Main category: Zongheng Yang

TL;DR: 提出一种模块化、可解释的病理语音恢复方法，无需平行训练数据，通过神经ODE、扩散模型和声码器三阶段恢复健康语音


<details>
  <summary>Details</summary>
Motivation: 运动性言语障碍患者（如构音障碍、帕金森病、中风）的语音可懂度降低，日常交流困难，需要无需平行训练数据的语音恢复方法

Method: 三阶段模块化方法：1）神经ODE架构纠正扭曲的MFCC特征；2）扩散模型生成高质量声学特征；3）声码器合成恢复后的语音

Result: 方法在无平行训练数据的情况下有效恢复病理语音，提高可懂度，模块化设计提供可解释性

Conclusion: 提出的模块化路径为病理语音恢复提供了一种无需平行数据、可解释的解决方案，有望改善言语障碍患者的交流能力

Abstract: Patients with motor speech disorders like dysarthria, Parkinson's, or stroke often present with lower speech intelligibility, making everyday communication difficult. Here, we introduce a modular and interpretable pathway for pathological-to-healthy speech restoration in the absence of parallel training material. The pathway is comprised of three phases:(1) A Neural Ordinary Differential Equation (Neural ODE) architecture designed to correct distorted Mel-Frequency Cepstral Coefficients …

</details>


### [106] [学位申請者氏名有山大地](https://scholar.google.com/scholar_url?url=https://tokyo-metro-u.repo.nii.ac.jp/record/2001542/files/ariyama_daichi_fulltext.pdf&hl=zh-CN&sa=X&d=381486803582898023&ei=mqlWaa6sN-qsieoPjYOSgAM&scisig=ALhkC2RmzzYCYjt1jTkCDsu9P0iH&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=3&folt=cit)
*安藤大地， 馬場哲晃， 中安翌， 濵野峻行*

Main category: Zongheng Yang

TL;DR: 本論文は即興演奏支援手法を提案し、実演支援デバイスを開発してその効果を検証した。即興演奏は練習・経験や既存フレーズ引用に基づく側面があり、この引用行為に着目した支援システムを構築した。


<details>
  <summary>Details</summary>
Motivation: 即興演奏は「その場の思いつき」ではなく、演奏者の練習・経験や既存フレーズの引用に基づくパフォーマンスであるという側面がある。このフレーズ引用行為を支援することで、即興演奏パフォーマンスの質的向上を目指す。

Method: 即興演奏支援手法を提案し、その実演を助けるデバイスを開発。具体的にはフレーズ引用行為に着目した支援システムを構築し、演奏者が既存フレーズを効果的に引用・活用できる仕組みを実装した。

Result: 提案手法と開発デバイスの効果を検証し、即興演奏パフォーマンス支援における有効性を確認した。具体的な評価結果は示されていないが、支援システムの実用性を実証した。

Conclusion: 即興演奏支援手法と実演支援デバイスは、演奏者のフレーズ引用行為を効果的に支援し、即興演奏パフォーマンスの質的向上に寄与できることを示した。

Abstract: 要旨本論文では即興演奏パフォーマンスを支援することを目的とした手法の提案, 及び手法の実演を助けるデバイスの開発を行いその効果を検証する. 本研究で扱う即興演奏とは, 事前に演奏内容がすべて, あるいは一部規定されていない音楽の形態であるが, 即興演奏に関わる既知の研究は, 即興演奏が 「その場の思いつき」 であることを否定し, 即興演奏が演奏者の練習と経験, あるいは既存のフレーズの引用に基づいたパフォーマンスであるという側面があることを示している. このフレーズの引用行為は …

</details>


### [107] [GPU Native Computation of Scalable Tensor Programs](https://scholar.google.com/scholar_url?url=https://lambda.uta.edu/STAG_BigData25.pdf&hl=zh-CN&sa=X&d=1328397257644617838&ei=mqlWaa6sN-qsieoPjYOSgAM&scisig=ALhkC2S_FRGf4hFmkjfwsAT4wXj9&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=4&folt=cit)
*TA Khan,L Fegaras*

Main category: Zongheng Yang

TL;DR: 论文探讨了在多节点多GPU环境中并行化科学和机器学习计算时，由于主机与GPU内存间频繁数据拷贝导致的性能瓶颈问题，并提出优化线性代数运算的解决方案。


<details>
  <summary>Details</summary>
Motivation: GPU的普及使得并行计算在工业和学术界日益流行，但开发能够跨多节点多GPU分布计算的系统具有挑战性。当中间数据需要在主机和GPU内存之间频繁拷贝时，GPU的优势会被抵消，导致整体计算速度下降。

Method: 论文可能提出了一种优化线性代数运算的方法，通过减少主机与GPU内存间的数据拷贝来提升多节点多GPU系统的性能。具体方法可能涉及内存管理优化、数据传输策略改进或计算调度算法。

Result: 通过减少主机与GPU内存间的数据拷贝，系统能够更有效地利用GPU计算能力，显著提升多节点多GPU环境下科学和机器学习计算的性能。

Conclusion: 优化主机与GPU内存间的数据传输是提升多节点多GPU系统性能的关键，通过减少不必要的拷贝操作可以充分发挥GPU的并行计算优势。

Abstract: Widespread availability of GPUs has made parallelizing scientific and machine learning computations popular in both industry and academia. However, developing systems that can distribute computation across multiple nodes, each equipped with multiple GPUs, is non-trivial. The benefits of using GPUs can be nullified when intermediate data needs to be frequently copied between the host and GPU memories, which slows down the whole computation. Moreover, optimizing linear …

</details>


### [108] [Diving into 3D Parallelism with Heterogeneous Spot Instance GPUs: Design and Implications](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.20953&hl=zh-CN&sa=X&d=11208108137854574973&ei=Q_RXaYbQGe6TieoPutPYsQg&scisig=ALhkC2SxCCLcBKtiYFObNz2bmGEt&oi=scholaralrt&hist=i6heNjgAAAAJ:778719684493065653:ALhkC2T5y4v8XnzDuwC4ZadUm0Rx&html=&pos=1&folt=rel)
*Y Wang,Y Xu,Q Duan,Y Liu,L Jiao,Y Yu,J Wu*

Main category: Zongheng Yang

TL;DR: 该论文针对大语言模型分布式训练在异构GPU环境中的需求，提出了一种新的系统或方法来优化训练效率


<details>
  <summary>Details</summary>
Motivation: 大语言模型的快速发展和新GPU产品的不断发布，显著增加了在异构GPU环境中进行分布式训练的需求。传统方法在异构环境下效率低下，需要新的解决方案来优化资源利用和训练性能。

Method: 论文提出了一种针对异构GPU环境的分布式训练系统或方法，可能涉及负载均衡、通信优化、资源调度等技术，以解决异构硬件带来的挑战。

Result: 该方法在异构GPU环境中相比传统方法表现出更好的训练效率和资源利用率，能够有效处理不同型号GPU之间的性能差异。

Conclusion: 该研究为异构GPU环境下的LLM分布式训练提供了有效的解决方案，有助于降低硬件升级成本并提高训练灵活性。

Abstract: The rapid growth of large language models (LLMs) and the continuous release of new GPU products have significantly increased the demand for distributed training across heterogeneous GPU environments. In this paper, we present a …

</details>


### [109] [LJ-TTS: A Paired Real and Synthetic Speech Dataset for Single-Speaker TTS Analysis](https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2079-9292/15/1/169&hl=zh-CN&sa=X&d=15267163006803749154&ei=Q_RXaYHWB9KV6rQP84i9kQc&scisig=ALhkC2R3RXvMNWZiXyXbN6240wjU&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=0&folt=cit)
*V Negroni,D Salvi,L Comanducci,TM Wani,M Uecker…*

Main category: Zongheng Yang

TL;DR: LJ-TTS是一个大规模单说话人数据集，包含真实录音和11种最先进TTS模型生成的合成语音，用于支持TTS合成与分析研究


<details>
  <summary>Details</summary>
Motivation: 为TTS研究和分析提供高质量、受控的单说话人数据集，支持不同TTS模型在相同条件下的精确比较

Method: 基于高质量单说话人英语录音，使用11种最先进的TTS模型（包括自回归和非自回归架构）生成合成语音，构建统一数据集

Result: 创建了包含真实录音和多种TTS模型输出的综合数据集，为TTS研究提供了标准化的比较基准

Conclusion: LJ-TTS数据集为TTS合成与分析研究提供了有价值的资源，支持在受控单说话人设置下对不同TTS模型进行系统评估

Abstract: In this paper, we present LJ-TTS, a large-scale single-speaker dataset of real and synthetic speech designed to support research in text-to-speech (TTS) synthesis and analysis. The dataset builds upon high-quality recordings of a single English speaker, alongside outputs generated by 11 state-of-the-art TTS models, including both autoregressive and non-autoregressive architectures. By maintaining a controlled single-speaker setting, LJ-TTS enables precise comparison of speech …

</details>


### [110] [RollArt: Scaling Agentic RL Training via Disaggregated Infrastructure](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.22560&hl=zh-CN&sa=X&d=17762195533616535506&ei=Q_RXaYHWB9KV6rQP84i9kQc&scisig=ALhkC2Rh2nKAhEnMmCaehqYqGl9z&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=2&folt=cit)
*W Gao,Y Zhao,T Wu,S Xiong,W Wang,D An,L Cao…*

Main category: Zongheng Yang

TL;DR: 本文提出为Agentic RL训练设计解耦式基础设施架构，以应对其异构工作负载特性，通过专用硬件提升训练效率


<details>
  <summary>Details</summary>
Motivation: Agentic RL训练工作负载高度异构，包含计算密集的prefill阶段、带宽受限的解码以及CPU密集型环境模拟，传统统一基础设施无法高效处理这些不同特性的任务

Method: 提出解耦式基础设施架构，将不同工作负载分配到最适合的专用硬件上，如GPU处理计算密集型任务，CPU处理环境模拟，专用加速器处理特定任务

Result: 通过解耦架构能够显著提升Agentic RL训练效率，降低资源浪费，实现更好的硬件利用率

Conclusion: Agentic RL训练需要专门设计的解耦式基础设施来应对其异构工作负载特性，通过专用硬件组合实现高效训练

Abstract: Agentic Reinforcement Learning (RL) enables Large Language Models (LLMs) to perform autonomous decision-making and long-term planning. Unlike standard LLM post-training, agentic RL workloads are highly heterogeneous, combining compute-intensive prefill phases, bandwidth-bound decoding, and stateful, CPU-heavy environment simulations. We argue that efficient agentic RL training requires disaggregated infrastructure to leverage specialized, best-fit hardware. However …

</details>


### [111] [Role-Based Fault Tolerance System for LLM RL Post-Training](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.22492&hl=zh-CN&sa=X&d=2233776582314204438&ei=Q_RXaYHWB9KV6rQP84i9kQc&scisig=ALhkC2TtBJIaC-sEltVcaUEjr3jw&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=3&folt=cit)
*Z Chen,B Zhong,X Li,Q Dai,X Zhao,M Ye,R Cheng…*

Main category: Zongheng Yang

TL;DR: 提出基于角色隔离的容错框架，解决RL后训练中训练和推理交错执行时的故障问题


<details>
  <summary>Details</summary>
Motivation: RL后训练交错执行训练和推理工作负载，现有LLM容错框架仅针对训练或推理单一场景，无法优化RL异步执行中的故障处理

Method: 基于角色隔离的故障隔离方法，通过角色划分确保单机故障不影响其他机器，利用异步执行优化RL训练

Result: 未在摘要中明确说明，但暗示该方法能有效解决RL后训练的故障问题

Conclusion: 角色隔离的容错框架能有效处理RL后训练中训练和推理交错执行时的系统故障

Abstract: RL post-training for LLMs has been widely scaled to enhance reasoning and tool-using capabilities. However, RL post-training interleaves training and inference workloads, exposing the system to faults from both sides. Existing fault tolerance frameworks for LLMs target either training or inference, leaving the optimization potential in the asynchronous execution unexplored for RL. Our key insight is role-based fault isolation so the failure in one machine does not affect the others. We treat …

</details>


### [112] [OxygenREC: An Instruction-Following Generative Framework for E-commerce Recommendation](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.22386&hl=zh-CN&sa=X&d=10097359293233378571&ei=Q_RXaYHWB9KV6rQP84i9kQc&scisig=ALhkC2TfCVAU9kCgIYk4B_QFaZ9y&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=4&folt=cit)
*X Hao,M Zhang,A Li,X Qian,Z Ma,Y Zang,S Yang…*

Main category: Zongheng Yang

TL;DR: 该论文指出传统推荐系统存在多阶段优化目标不一致问题，生成式推荐虽通过端到端框架缓解了这一问题，但现有方法仍依赖基于归纳模式的匹配机制，缺乏基于世界知识进行演绎推理以揭示复杂用户意图的能力，而大语言模型虽具备深度推理能力但...


<details>
  <summary>Details</summary>
Motivation: 传统推荐系统存在多阶段优化目标不一致的问题，生成式推荐虽然通过端到端框架缓解了这一问题，但现有方法仍主要依赖基于归纳模式的匹配机制，这些方法虽然响应迅速，但缺乏基于世界知识进行演绎推理以揭示复杂用户意图的能力。同时，大语言模型展现出强大的深度推理能力，但...

Method: 从摘要中无法确定具体方法，但论文似乎提出了一种结合生成式推荐和大语言模型优势的新方法，旨在解决现有推荐系统在复杂用户意图理解方面的局限性。

Result: 摘要未提供具体实验结果，但暗示了结合大语言模型深度推理能力与生成式推荐框架的潜在优势。

Conclusion: 论文认为需要一种能够结合大语言模型深度推理能力和生成式推荐框架优势的新方法，以更好地理解和满足复杂用户意图。

Abstract: Traditional recommendation systems suffer from inconsistency in multi-stage optimization objectives. Generative Recommendation (GR) mitigates them through an end-to-end framework; however, existing methods still rely on matching mechanisms based on inductive patterns. Although responsive, they lack the ability to uncover complex user intents that require deductive reasoning based on world knowledge. Meanwhile, LLMs show strong deep reasoning capabilities, but their …

</details>


### [113] [A Survey of Distributed Asynchronous Many-Task Models and Their Applications](https://scholar.google.com/scholar_url?url=https://www.techrxiv.org/doi/pdf/10.36227/techrxiv.176652588.81044275&hl=zh-CN&sa=X&d=13996852473097428818&ei=Q_RXaYHWB9KV6rQP84i9kQc&scisig=ALhkC2TWnqFNn_Ut-N1lV1LqC8UV&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=5&folt=cit)
*J Schuchart,P Diehl,M Bauer,A Bouteiller,G Daiss…*

Main category: Zongheng Yang

TL;DR: 异步多任务运行时系统已成为高性能计算中表达细粒度并行性和管理异步性的重要范式，从早期数据流概念演变而来，支持动态任务生成、显式依赖管理和异步执行，以解决传统批量同步模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统批量同步并行模型在高性能计算中存在局限性，无法有效处理细粒度并行性和异步执行，需要新的运行时系统来支持动态任务生成、显式依赖管理和计算通信重叠。

Method: 基于异步多任务运行时系统，采用数据流概念，实现动态任务生成、显式依赖管理和异步执行机制，以支持计算与通信的重叠。

Result: 异步多任务运行时系统能够有效表达细粒度并行性，管理异步执行，提高计算与通信的重叠效率，克服传统批量同步模型的限制。

Conclusion: 异步多任务运行时系统是高性能计算中表达细粒度并行性和管理异步性的重要范式，能够有效解决传统批量同步模型的局限性，支持动态任务生成和计算通信重叠。

Abstract: Asynchronous many-task (AMT) runtime systems have become an important paradigm for expressing fine-grained parallelism and managing asynchrony in high-performance computing (HPC). Originating from early dataflow concepts, AMTs have evolved to enable dynamic task generation, explicit dependency management, and asynchronous execution, facilitating the overlap of computation and communication. These capabilities address the limitations of traditional bulk-synchronous models …

</details>


### [114] [Gradient-Based Optimization of Force Field Parameters for Martini Lipid Models](https://scholar.google.com/scholar_url?url=https://chemrxiv.org/engage/api-gateway/chemrxiv/assets/orp/resource/item/69459177afb3b1111822a959/original/gradient-based-optimization-of-force-field-parameters-for-martini-lipid-models.pdf&hl=zh-CN&sa=X&d=4474521762188080110&ei=Q_RXaYHWB9KV6rQP84i9kQc&scisig=ALhkC2TBR453pdNf7-v6De7lVNwH&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=6&folt=cit)
*DP Ramirez*

Main category: Zongheng Yang

TL;DR: 基于梯度的优化方法加速了Martini框架中粗粒度力场参数的优化过程


<details>
  <summary>Details</summary>
Motivation: 粗粒度模型在分子模拟中广泛应用，但其参数化过程仍然具有挑战性且耗时费力。Martini框架作为现代粗粒度建模的基石，需要更高效的参数优化方法。

Method: 采用最近开发的基于梯度的优化方法，在Martini框架内加速粗粒度力场参数的精细化。以Martini脂质模型作为测试平台，探索了三个难度递增的优化场景。

Result: 梯度优化方法显著加速了粗粒度力场参数的优化过程，提高了参数化效率

Conclusion: 基于梯度的优化方法为粗粒度力场参数优化提供了有效的加速途径，特别是在Martini框架中具有重要应用价值

Abstract: Physics-based coarse-grained (CG) models are widely used in (bio) molecular simulations, yet their parameterization remains challenging and labor-intensive. In this work, we demonstrate how recently developed gradient-based optimization methods can substantially accelerate the refinement of CG force field (FF) parameters within the Martini framework, a cornerstone of modern CG modeling. Using Martini lipid models as a testbed, we explore three increasingly challenging …

</details>


### [115] [Integration of Sentiment Analysis and Speech Text Processing in Phonetic Flow System](https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Akhilendra-Khare-2/publication/398176421_Integration_of_Sentiment_Analysis_and_Speech_Text_Processing_in_Phonetic_Flow_System/links/69452fec0c98040d481ee091/Integration-of-Sentiment-Analysis-and-Speech-Text-Processing-in-Phonetic-Flow-System.pdf&hl=zh-CN&sa=X&d=17873602574302366828&ei=Q_RXaYHWB9KV6rQP84i9kQc&scisig=ALhkC2TuBVhJB-oYB6VFKkBouPAm&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=7&folt=cit)
*RR Vandana,A Khare,S Harizan*

Main category: Zongheng Yang

TL;DR: 提出集成语音转文本、文本转语音和情感分析的统一系统，解决现有方案异构性导致用户体验不平衡的问题


<details>
  <summary>Details</summary>
Motivation: 当前人机交互应用需要同时处理语音识别、语音合成和情感分析，但现有解决方案采用异构方法，导致用户体验不平衡，需要设计集成系统来统一处理这些任务

Method: 设计集成系统，能够同时执行语音转文本（STT）、文本转语音（TTS）处理，以及输入文本的情感分析，并采用邻域感知方法

Result: 未在摘要中明确说明具体结果，但暗示通过集成方法可以改善用户体验平衡性

Conclusion: 需要开发集成语音处理、情感分析和邻域感知的统一系统，以提升人机交互应用的整体用户体验

Abstract: Human-computer interaction (HCI) applications increasingly rely on reading speech, understanding emotional context, and generating natural language. The heterogeneous set of approaches the existing solutions use for sentiment analysis, speech synthesis, and speech recognition results in an unbalanced user experience. Designing an integrated system that can perform speech-to-text (STT) and text-to-speech (TTS) processing, sentiment analysis of input text, and neighboring aware …

</details>


### [116] [Costruzione di Personaggi Virtuali Conversazionali con Modelli Open-Source di Linguaggio e Sintesi Vocale](https://scholar.google.com/scholar_url?url=https://unire.unige.it/bitstream/handle/123456789/14431/tesi36134903.pdf%3Fsequence%3D1&hl=zh-CN&sa=X&d=15868134478381580232&ei=Q_RXaYHWB9KV6rQP84i9kQc&scisig=ALhkC2Rc-fxljIf8aJlG8Yrad6Pz&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=8&folt=cit)
*F Solinas*

Main category: Zongheng Yang

TL;DR: 开发开源、离线、轻量化的AI对话系统，用于虚拟角色交互，解决商业方案成本高、云端依赖和离线不可用的问题


<details>
  <summary>Details</summary>
Motivation: 虚拟角色在游戏、教育、文化遗产等交互体验中至关重要，但传统脚本对话限制了真实感和沉浸感。虽然LLM、ASR、TTS等AI技术能实现动态自然交互，但商业解决方案成本高、依赖云端、无法离线使用，限制了预算有限或离线场景的部署

Method: 提出一个开源、离线、轻量化的AI对话系统，整合大型语言模型、自动语音识别和文本转语音技术，实现虚拟角色的动态自然交互

Result: 论文应展示了一个功能完整的系统，能够实现虚拟角色的实时语音对话，在资源受限环境下运行，相比商业方案更具可访问性和成本效益

Conclusion: 该开源系统为虚拟角色交互提供了可行的替代方案，解决了成本、隐私和离线可用性问题，推动了AI技术在交互体验中的普及应用

Abstract: Virtual characters play a central role in interactive experiences across gaming, education, and cultural heritage, yet traditional scripted dialogues limit realism and immersion. Recent advances in AI, including Large Language Models (LLMs), Automatic Speech Recognition (ASR), and Text-to-Speech (TTS), enable dynamic, natural interactions, but commercial solutions are costly, cloud-dependent, and inaccessible for budget-or offline-constrained deployments. This thesis presents a …

</details>


### [117] [A Hybrid Forecasting and Reinforcement Learning Approach for Latency-Constrained Scaling of Generative AI Systems](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3773274.3774258&hl=zh-CN&sa=X&d=3402443520725744095&ei=XG9ZafW1Kt_OieoPg6WE2QY&scisig=ALhkC2SN39XJUeYwi7EJtYiarrMr&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=0&folt=cit)
*Y Peng,R Sinnott*

Main category: Zongheng Yang

TL;DR: 该论文探讨生成式AI应用中GPU资源的高效利用策略，旨在解决计算开销大、工作负载多变、推理延迟要求低与GPU资源有限之间的矛盾。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI应用的普及，模型部署优化成为关键问题，主要挑战包括：1）生成式AI模型带来巨大计算开销；2）工作负载具有高度可变性；3）许多AI应用需要低延迟推理；4）GPU资源通常有限且供不应求。

Method: 论文研究GPU资源高效利用的策略，可能涉及模型部署优化、资源调度、负载均衡、推理加速等技术方法，具体方法需要进一步阅读全文确定。

Result: 根据摘要，论文研究了GPU资源高效利用的策略，但具体实验结果和性能提升数据需要阅读完整论文才能获取。

Conclusion: 生成式AI的广泛采用使得GPU资源优化部署成为关键挑战，需要开发有效的策略来平衡计算需求、工作负载变化和延迟要求与有限硬件资源之间的矛盾。

Abstract: The increasing popularity of generative AI applications has introduced new challenges in how to effectively utilize hardware (GPUs). As generative AI models become more widely adopted, optimising the deployment of models emerges as a critical concern due to the substantial computational overheads, variable workloads, and the need for low-latency inference of many AI applications needing GPUs with often limited availability. In this paper, we investigate strategies for the efficient …

</details>


### [118] [From Novelty to Threat in the Evolution of Deepfakes and Their Disruptive Influence on Higher Education](https://scholar.google.com/scholar_url?url=https://www.igi-global.com/chapter/from-novelty-to-threat-in-the-evolution-of-deepfakes-and-their-disruptive-influence-on-higher-education/398651&hl=zh-CN&sa=X&d=5169204146757481987&ei=XG9ZafW1Kt_OieoPg6WE2QY&scisig=ALhkC2RGZIwGWFtl66VIGXdCCRQM&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=1&folt=cit)
*SS Hameed,JP Vijai,B Kirubhaharan…*

Main category: Zongheng Yang

TL;DR: 该章节探讨了深度伪造技术从实验性技术发展为高等教育机构面临的重要数字威胁的过程，并分析了其影响、应对策略和未来趋势。


<details>
  <summary>Details</summary>
Motivation: 深度伪造技术已从实验性技术发展为对高等教育机构构成重大威胁的成熟技术，需要系统分析其发展轨迹、影响机制和应对策略。

Method: 通过文献综述和案例分析，系统梳理深度伪造技术的发展历程，分析其对高等教育机构的具体威胁，并提出多层次应对框架。

Result: 识别了深度伪造技术在高等教育中的主要威胁领域，包括学术诚信、身份验证、信息传播等，并提出了技术、政策和教育层面的综合应对策略。

Conclusion: 高等教育机构需要建立全面的深度伪造应对体系，结合技术检测、政策制定和教育培训，以应对这一不断演变的数字威胁。

Abstract: The rapid evolution of deepfake technology, from an experimental curiosity to an accessible and sophisticated threat, represents one of the most significant challenges facing higher education institutions in the digital age. This chapter maps the develop-

</details>


### [119] [Moroccan Darija Text-to-Speech Synthesis](https://scholar.google.com/scholar_url?url=https://books.google.com/books%3Fhl%3Dzh-CN%26lr%3D%26id%3DYZilEQAAQBAJ%26oi%3Dfnd%26pg%3DPA126%26ots%3D-gCQexUUwl%26sig%3DHZA9CXpHXKOURLu0HCnA3JogufY&hl=zh-CN&sa=X&d=3726196275818081727&ei=9S1cadKAA9aOieoP3p6U4Q8&scisig=ALhkC2QlwXg_S5cFUlALA7flAaKN&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=0&folt=cit)
*S Driouech,A Mourhir*

Main category: Zongheng Yang

TL;DR: 通过微调FastSpeech 2模型，实现了针对低资源语言摩洛哥达里贾语的语音合成，使用2小时女性语音数据集


<details>
  <summary>Details</summary>
Motivation: 深度学习在文本转语音方面取得了显著进展，但高资源语言受益更多，而低资源语言如摩洛哥达里贾语仍未被充分探索。本研究旨在填补这一空白，为摩洛哥达里贾语实现语音合成。

Method: 通过微调最先进的非自回归基于Transformer的模型FastSpeech 2来实现摩洛哥达里贾语的语音合成。使用了一个包含2小时女性语音的达里贾语数据集。

Result: 论文摘要未提供具体实验结果，但表明通过微调FastSpeech 2模型，成功实现了摩洛哥达里贾语的语音合成系统。

Conclusion: 这项工作展示了使用有限数据（2小时语音）通过微调预训练模型，为低资源语言实现语音合成的可行性，为类似低资源语言的语音合成研究提供了参考。

Abstract: With advancements in deep learning, Text-to-Speech has achieved remarkable results for high-resource languages; however, low-resource languages, such as Moroccan Darija, remain underexplored. This work addresses this gap by implementing speech synthesis for Moroccan Darija by finetuning the state-of-the-art model FastSpeech 2, which is a non-autoregressive transformer-based model. We used a 2-h Darija speech dataset featuring a female voice. To enable effective model …

</details>


### [120] [Empowering Accessibility](https://scholar.google.com/scholar_url?url=https://books.google.com/books%3Fhl%3Dzh-CN%26lr%3D%26id%3DtZulEQAAQBAJ%26oi%3Dfnd%26pg%3DPA480%26ots%3DljVvhyE39p%26sig%3DFzhDnyaeAXQ5RFXreC6fy7c0x8s&hl=zh-CN&sa=X&d=8904154379462979824&ei=9S1cadKAA9aOieoP3p6U4Q8&scisig=ALhkC2QfjFtJAoIsKr2aAhtH36Zv&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=1&folt=cit)
*O Gal,M Giurgiu*

Main category: Zongheng Yang

TL;DR: 开发了一个AI驱动的辅助系统，通过集成实时图像检测、直接卷积文本转语音和基于大语言模型的决策模块，增强视障人士的无障碍访问能力。


<details>
  <summary>Details</summary>
Motivation: 为视障人士开发一个全面的辅助系统，解决他们在日常环境中识别物体、理解场景和获取信息方面的挑战，提高独立性和生活质量。

Method: 系统整合了YOLOv8和SSD进行实时物体检测，使用直接卷积文本转语音技术生成语音输出，并采用基于大语言模型的决策模块进行场景理解和上下文推理。采用云架构确保可扩展性和设备独立性。

Result: 开发了一个功能完整的辅助系统原型，能够实时检测物体、生成语音描述，并通过LLM进行智能决策。系统具有跨平台兼容性和可扩展性。

Conclusion: 提出的AI驱动辅助系统为视障人士提供了有效的无障碍解决方案，通过多技术集成实现了全面的环境感知和智能交互能力。

Abstract: This paper introduces an advanced AI-driven assistive system designed to enhance accessibility for individuals with visual impairments by integrating real-time image detection, direct convolutional text-to-speech (DCTTS), and a large language model (LLM)-based decision-making module. The system lever-ages cloud-based architecture to ensure scalability and device independence, allowing seamless interaction across various platforms. By utilizing YOLOv8 and SSD for object …

</details>


### [121] [KELP: Robust Online Log Parsing Through Evolutionary Grouping Trees](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.00633&hl=zh-CN&sa=X&d=6844921240318693061&ei=skRfabu7H9rJieoPiYyysAk&scisig=ALhkC2Q7lfZW7PzpMGBgyWmqUCQp&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=0&folt=cit)
*S Singh,SN Ramachandran*

Main category: Zongheng Yang

TL;DR: KELP是一种基于进化学习的高吞吐量日志解析器，能够适应生产环境的动态变化，解决传统静态模板解析器因模式漂移而导致的脆弱性问题。


<details>
  <summary>Details</summary>
Motivation: 实时日志分析是现代基础设施可观测性的基石，但现有的在线解析器架构不适合生产环境的动态特性。基于静态模板模型的传统解析器非常脆弱：微小的模式漂移会无声地破坏解析管道，导致警报丢失和运维负担。

Method: 提出了KELP（Kelp Evolutionary Log Parser），一种基于进化学习的高吞吐量日志解析器。该方法采用新颖的进化学习机制，能够动态适应日志模式的变化，而不是依赖静态模板。

Result: KELP实现了高吞吐量的日志解析，能够有效处理生产环境中的模式漂移问题，避免因模式变化导致的解析管道中断和警报丢失。

Conclusion: KELP通过进化学习方法解决了传统静态模板解析器的脆弱性问题，为动态生产环境提供了更可靠、适应性更强的实时日志分析解决方案。

Abstract: Real-time log analysis is the cornerstone of observability for modern infrastructure. However, existing online parsers are architecturally unsuited for the dynamism of production environments. Built on fundamentally static template models, they are dangerously brittle: minor schema drifts silently break parsing pipelines, leading to lost alerts and operational toil. We propose\textbf {KELP}(\textbf {K} elp\textbf {E} volutionary\textbf {L} og\textbf {P} arser), a high-throughput parser built on a novel …

</details>


### [122] [Integrating Multi-Armed Bandit, Active Learning, and Distributed Computing for Scalable Optimization](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.00615&hl=zh-CN&sa=X&d=3054072689767203626&ei=skRfabu7H9rJieoPiYyysAk&scisig=ALhkC2SveVg4a0nWnRS7Vbwiej15&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=1&folt=cit)
*F Hui*

Main category: Zongheng Yang

TL;DR: ALMAB-DC是一个用于可扩展黑盒优化的统一模块化框架，针对科学和工程领域中依赖昂贵评估且梯度信息不可用或不可靠的优化问题。


<details>
  <summary>Details</summary>
Motivation: 现代科学和工程优化问题通常依赖昂贵的黑盒评估（如物理模拟或深度学习流程），其中梯度信息不可用或不可靠。传统优化方法因计算成本过高和可扩展性差而变得不实用。

Method: 提出ALMAB-DC框架，这是一个统一且模块化的可扩展黑盒优化框架，整合了多种优化技术。

Result: 未在摘要中明确说明具体结果，但暗示该框架能够解决传统方法难以处理的高成本、不可扩展的黑盒优化问题。

Conclusion: ALMAB-DC为依赖昂贵黑盒评估的优化问题提供了一个实用且可扩展的解决方案。

Abstract: Modern optimization problems in scientific and engineering domains often rely on expensive black-box evaluations, such as those arising in physical simulations or deep learning pipelines, where gradient information is unavailable or unreliable. In these settings, conventional optimization methods quickly become impractical due to prohibitive computational costs and poor scalability. We propose ALMAB-DC, a unified and modular framework for scalable black-box optimization that integrates …

</details>


### [123] [TeleWorld: Towards Dynamic Multimodal Synthesis with a 4D World Model](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.00051&hl=zh-CN&sa=X&d=9619243672194519902&ei=skRfabu7H9rJieoPiYyysAk&scisig=ALhkC2TVt0HU6gxEF--dC21k64Ij&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=2&folt=cit)
*Y Chen,Y Liang,J Wang,T Chen,J Cheng,Z Gu…*

Main category: Zongheng Yang

TL;DR: TeleWorld是一个实时多模态4D世界建模系统，旨在解决现有视频生成模型在实时交互、长时一致性和动态场景持久记忆方面的局限性，推动AI系统向实用世界模型发展。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型虽然在视觉质量上表现出色，但在实时交互、长时一致性以及动态场景的持久记忆方面存在明显不足，这阻碍了它们发展成为实用的世界模型。因此需要开发能够更好地表示、生成并与动态环境交互的AI系统。

Method: TeleWorld采用实时多模态4D世界建模方法，具体技术细节未在摘要中详细说明，但核心是构建能够捕捉时空动态的4D表示。

Result: 摘要中未提供具体实验结果，但暗示TeleWorld能够实现实时交互、保持长时一致性，并具备动态场景的持久记忆能力。

Conclusion: TeleWorld代表了向实用世界模型发展的重要一步，通过实时多模态4D建模解决了现有视频生成模型的关键限制。

Abstract: World models aim to endow AI systems with the ability to represent, generate, and interact with dynamic environments in a coherent and temporally consistent manner. While recent video generation models have demonstrated impressive visual quality, they remain limited in real-time interaction, long-horizon consistency, and persistent memory of dynamic scenes, hindering their evolution into practical world models. In this report, we present TeleWorld, a real-time multimodal 4D world modeling …

</details>


### [124] [“MITIGATING DEEPFAKE-BASED IMPERSONATION AND SYNTHETIC DATA RISKS IN REMOTE HEALTHCARE SYSTEMS](https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Joy-Awoleye/publication/395845441_MITIGATING_DEEPFAKE-BASED_IMPERSONATION_AND_SYNTHETIC_DATA_RISKS_IN_REMOTE_HEALTHCARE_SYSTEMS/links/68e46e4bf3032e2b4be709c1/MITIGATING-DEEPFAKE-BASED-IMPERSONATION-AND-SYNTHETIC-DATA-RISKS-IN-REMOTE-HEALTHCARE-SYSTEMS.pdf&hl=zh-CN&sa=X&d=14134418830890152608&ei=g6Ngaf3iD4aw6rQPkNu46Ao&scisig=ALhkC2RwROxAl6knE54TPSqqlePN&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=0&folt=cit)
*R Mashinge,KB Muhwati,K Magora,J Awoleye*

Main category: Zongheng Yang

TL;DR: 论文提出了一种结合多模态生物特征认证和区块链技术的综合架构，用于保护远程医疗系统免受深度伪造、语音克隆和合成数据的攻击。


<details>
  <summary>Details</summary>
Motivation: 远程医疗系统的安全性和完整性面临严峻挑战，深度伪造技术、语音克隆和合成数据攻击日益威胁着依赖音视频通信和电子健康记录的远程医疗平台，这些平台已成为高级冒充攻击的有吸引力的目标。

Method: 提出了一种综合架构，结合多模态生物特征认证（包括面部识别等）和区块链技术，以遏制深度伪造技术带来的威胁。

Result: 未在摘要中明确说明具体实验结果，但提出的架构旨在增强远程医疗系统的安全性和完整性，抵御深度伪造攻击。

Conclusion: 需要采用结合多模态生物特征认证和区块链技术的综合安全架构来保护远程医疗系统免受深度伪造和其他高级攻击的威胁。

Abstract: The security and integrity of remote healthcare systems are raised as an urgent issue of fighting deepfake technologies, voice cloning, and synthetic data. Since telemedicine platforms are increasingly relying on audiovisual communication and electronic health records (EHR), they actively become appealing victim targets in high-level impersonation attacks. An exhaustive architecture to curb threats postulated through deepfakes, through a combination of multimodal biometric (face …

</details>


### [125] [AirSpeech: Lightweight Speech Synthesis Framework for Home Intelligent Space Service Robots](https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2079-9292/15/1/239&hl=zh-CN&sa=X&d=3454977247389704160&ei=g6Ngaf3iD4aw6rQPkNu46Ao&scisig=ALhkC2QAx1MbC9iVlEiGR4QXpzdb&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=1&folt=cit)
*X Qin,F Pan,J Gao,S Huang,Y Sun,X Zhong*

Main category: Zongheng Yang

TL;DR: 该论文针对家庭环境中TTS系统在环境噪声和说话人适应性方面的不足，提出改进Mel频谱图质量的方法以提升TTS性能


<details>
  <summary>Details</summary>
Motivation: 家庭环境中的TTS系统面临环境噪声鲁棒性不足和说话人特征适应性有限的问题，而现有方法忽视了Mel频谱图质量对TTS性能的关键影响

Method: 论文未详细说明具体方法，但从摘要推断可能涉及改进Mel频谱图生成过程，以增强对噪声的鲁棒性和说话人特征的适应性

Result: 摘要未提供具体实验结果，但暗示通过提升Mel频谱图质量可以改善TTS系统在家庭环境中的性能

Conclusion: 需要关注Mel频谱图质量在TTS系统中的关键作用，特别是针对家庭环境中的噪声鲁棒性和说话人适应性挑战

Abstract: Text-to-Speech (TTS) methods typically employ a sequential approach with an Acoustic Model (AM) and a vocoder, using a Mel spectrogram as an intermediate representation. However, in home environments, TTS systems often struggle with issues such as inadequate robustness against environmental noise and limited adaptability to diverse speaker characteristics. The quality of the Mel spectrogram directly affects the performance of TTS systems, yet existing methods overlook the …

</details>


### [126] [AeroSketch: Near-Optimal Time Matrix Sketch Framework for Persistent, Sliding Window, and Distributed Streams](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.02019&hl=zh-CN&sa=X&d=16050122352599555934&ei=g6Ngaf3iD4aw6rQPkNu46Ao&scisig=ALhkC2R1jrNZ9q1d5oLkp6L1k67G&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=2&folt=cit)
*H Yin,D Wen,J Li,Z Wei,X Zhang,P Zhao,ZH Zhou*

Main category: Zongheng Yang

TL;DR: 该论文综述了矩阵素描技术在处理高维流数据中的应用，重点分析了现有算法在空间和通信复杂度方面的优化，并指出了当前方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的矩阵数据通常以高吞吐量的向量流形式到达，无法完整存储或处理。为了在有限的计算、内存和通信资源下实现实时分析，需要开发矩阵素描技术来提供流数据的紧凑近似表示。

Method: 论文综述了近年来发展的矩阵素描技术，这些技术通过压缩和近似方法处理流式矩阵数据。重点分析了达到最优空间和通信复杂度的算法，并讨论了现有方法的局限性。

Result: 矩阵素描技术能够有效处理高维流数据，部分算法已实现最优的空间和通信复杂度。然而，现有方法在某些方面仍存在局限性，需要进一步改进。

Conclusion: 矩阵素描技术是处理流式矩阵数据的重要工具，虽然已有算法达到最优复杂度，但仍需继续研究以克服现有方法的局限性，提高实际应用效果。

Abstract: Many real-world matrix datasets arrive as high-throughput vector streams, making it impractical to store or process them in their entirety. To enable real-time analytics under limited computational, memory, and communication resources, matrix sketching techniques have been developed over recent decades to provide compact approximations of such streaming data. Some algorithms have achieved optimal space and communication complexity. However, these approaches often require …

</details>


### [127] [Towards Prosodically Informed Mizo TTS without Explicit Tone Markings](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.02073&hl=zh-CN&sa=X&d=18066107962762957800&ei=g6Ngaf3iD4aw6rQPkNu46Ao&scisig=ALhkC2SuQuCEjvcAlmhPQRIv_j2y&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=3&folt=cit)
*A Mohanta,P Sarmah,R Sinha,W Lalhminghlui*

Main category: Zongheng Yang

TL;DR: 开发了一个用于低资源、声调语言Mizo的文本转语音系统，仅使用5.18小时数据，通过Tacotron2和VITS模型实现了感知可接受和可理解的语音合成。


<details>
  <summary>Details</summary>
Motivation: Mizo语作为一种低资源、有声调的藏缅语系语言，缺乏高质量的文本转语音系统。研究旨在为这种资源有限的少数民族语言开发可行的语音合成技术。

Method: 首先使用Tacotron2建立基线模型，然后在相同数据上使用VITS构建另一个TTS模型。两种模型都仅使用5.18小时的训练数据进行开发。

Result: 通过主观和客观评估，两个模型的输出都被认为是感知上可接受且可理解的。这表明即使在极低资源条件下，也能为Mizo语开发出有效的TTS系统。

Conclusion: 该研究证明了为低资源、有声调语言开发可行TTS系统的可能性，为其他类似语言的语音合成技术发展提供了参考。

Abstract: This paper reports on the development of a text-to-speech (TTS) system for Mizo, a low-resource, tonal, and Tibeto-Burman language spoken primarily in the Indian state of Mizoram. The TTS was built with only 5.18 hours of data; however, in terms of subjective and objective evaluations, the outputs were considered perceptually acceptable and intelligible. A baseline model using Tacotron2 was built, and then, with the same data, another TTS model was built with VITS. In both subjective and …

</details>


### [128] [Neyron STT, TTS va mashinali tarjima tizimlari o 'rtasida uzviy bog 'liqlikni IDEF1X modeli orqali modellashtirish](https://scholar.google.com/scholar_url?url=https://cyberleninka.ru/article/n/neyron-stt-tts-va-mashinali-tarjima-tizimlari-o-rtasida-uzviy-bog-liqlikni-idef1x-modeli-orqali-modellashtirish&hl=zh-CN&sa=X&d=2537543826788921170&ei=g6Ngaf3iD4aw6rQPkNu46Ao&scisig=ALhkC2RskQMaEXouE8JtzdN0kwmH&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=4&folt=cit)
*MN Solidjonovich,NN Davlataliyevich*

Main category: Zongheng Yang

TL;DR: 提出基于IDEF1X数据模型的人工智能系统集成建模方法，用于连接STT、TTS和NMT系统，实现聋哑人有效沟通


<details>
  <summary>Details</summary>
Motivation: 为聋哑人提供有效沟通支持，需要整合语音转文本、文本转语音和神经机器翻译等多种人工智能技术，但这些系统间的信息流和数据结构缺乏统一建模

Method: 使用IDEF1X数据建模方法，对STT、TTS和NMT系统之间的集成关系进行形式化建模，明确系统间信息流和数据存储结构

Result: 建立了能够清晰描述多模态人工智能系统间信息交互和数据存储的集成模型，为聋哑人沟通辅助系统的开发提供了结构化框架

Conclusion: IDEF1X数据建模方法适用于复杂人工智能系统的集成设计，能够有效支持聋哑人沟通辅助系统的开发与实现

Abstract: Ushbu maqolada kar-soqovlar bilan samarali muloqotni ta'minlovchi sun'iy intellektga asoslangan STT (Speech-to-Text), TTS (Text-to-Speech) va neyron mashinali tarjima (NMT) tizimlari o 'rtasidagi uzviy bog 'liqlikni IDEF1X ma'lumotlar modeli yordamida modellashtirish yondashuvi taklif etiladi. Model tizimlararo axborot oqimini aniqlashtirish va ma'lumotlar bazasi strukturasini formal tarzda ifodalash imkonini beradi. Taklif etilgan yondashuv turli neyron tarmoqlar asosida ishlovchi …

</details>


### [129] [The NRCC Submission to the Blizzard Challenge 2025](https://scholar.google.com/scholar_url?url=https://www.isca-archive.org/blizzard_2025/pine25_blizzard.pdf&hl=zh-CN&sa=X&d=12751635664207891546&ei=g6Ngaf3iD4aw6rQPkNu46Ao&scisig=ALhkC2RIsl_XLfgtFm1HQcycMOP7&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=6&folt=cit)
*A Pine*

Main category: Zongheng Yang

TL;DR: NRCC参与2025 Blizzard挑战赛，为Bildts语言构建文本转语音系统，使用荷兰语和Bildts数据训练自定义字形到音素转换引擎和StyleTTS2模型


<details>
  <summary>Details</summary>
Motivation: 参与2025 Blizzard挑战赛，为低资源语言Bildts开发文本转语音系统，解决该语言缺乏高质量语音合成技术的问题

Method: 结合荷兰语和Bildts数据，训练自定义字形到音素转换引擎，并基于StyleTTS2架构构建文本转语音模型

Result: 开发了Bildts语言的文本转语音系统，提交至Blizzard挑战赛进行评估，具体评估结果在论文中呈现

Conclusion: 成功为低资源语言Bildts构建了文本转语音系统，展示了跨语言数据融合和先进TTS架构在低资源语言语音合成中的可行性

Abstract: This paper describes the National Research Council of Canada's (NRCC) submission to the 2025 Blizzard Challenge involving building text-to-speech systems for the Bildts language. I describe the data and processing, training, and inference procedures for the submitted system, and present my interpretation of the evaluation. Using a combination of Dutch and Bildts data, I trained a custom grapheme-to-phoneme engine and a StyleTTS2 based text-to-speech model. I also outline an …

</details>


### [130] [Submission from ZMM-TTS for Blizzard Challenge 2025](https://scholar.google.com/scholar_url?url=https://www.isca-archive.org/blizzard_2025/alabi25_blizzard.pdf&hl=zh-CN&sa=X&d=16295659598723810197&ei=g6Ngaf3iD4aw6rQPkNu46Ao&scisig=ALhkC2RDeB4Srrn7iBdqcFh8Pjw2&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:ALhkC2Q2eiStCnwSInI6DwdFfuod&html=&pos=7&folt=cit)
*JO Alabi,C Gong,E Cooper,Y Jiang,D Klakow…*

Main category: Zongheng Yang

TL;DR: 使用ZMM-TTS模块化多语言TTS模型参加2025年Bildts低资源语言变体的Blizzard挑战，通过约7小时数据微调并比较字符、IPA和音素三种输入类型


<details>
  <summary>Details</summary>
Motivation: 解决低资源西弗里斯兰语变体Bildts的语音合成问题，参加2025年Blizzard挑战，探索在有限数据下构建高质量TTS系统的方法

Method: 使用ZMM-TTS模块化多语言TTS模型，包含文本到向量和向量到波形两个独立模块；在约7小时Bildts数据上进行微调；比较三种输入类型：原始字符、IPA字符和音素表示；对比基于不同预训练多语言ZMM-TTS模型构建的系统

Result: 论文未提供具体实验结果，但描述了完整的实验设置和方法论，包括数据规模、模型架构、输入类型比较和预训练模型选择

Conclusion: 展示了ZMM-TTS模型在低资源语言Bildts语音合成任务中的应用潜力，通过系统比较不同输入类型和预训练模型为低资源TTS研究提供了方法论参考

Abstract: Abstract We address the 2025 Blizzard Challenge for Bildts, a lowresource West Frisian language variety, using ZMM-TTS, a modular multilingual TTS model with separate text-to-vec and vec-to-waveform modules. We fine-tune the model on approximately 7 hours of Bildts data and explore the three input types supported by ZMM-TTS: raw characters, IPA characters, and phoneme representations. We also compare systems built by fine-tuning two pre-trained ZMM-TTS multilingual …

</details>


### [131] [MiMo-V2-Flash Technical Report](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.02780&hl=zh-CN&sa=X&d=15999438925092848053&ei=RO1hacHPAdrJieoPiYyysAk&scisig=AHkA5jTyTqDcQAJDaD_ZL6SVj9is&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:AHkA5jQJ09t5uyNUKDlpVNk33Ubd&html=&pos=0&folt=cit)
*B Xiao,B Xia,B Yang,B Gao,B Shen,C Zhang,C He…*

Main category: Zongheng Yang

TL;DR: MiMo-V2-Flash是一个309B总参数、15B激活参数的混合专家模型，采用滑动窗口注意力与全局注意力的混合架构，通过多令牌预测在27万亿令牌上预训练，专为快速推理和智能体能力设计。


<details>
  <summary>Details</summary>
Motivation: 开发一个兼具大规模参数容量和高效推理能力的模型，通过混合专家架构平衡模型规模与计算效率，同时结合局部和全局注意力机制来提升推理和智能体任务的性能。

Method: 采用混合专家架构（309B总参数，15B激活参数），结合滑动窗口注意力（128令牌窗口）与全局注意力的5:1混合比例，使用多令牌预测方法在27万亿令牌上进行预训练，支持32k上下文长度。

Result: 模型实现了快速、强大的推理能力和智能体功能，混合注意力架构在保持计算效率的同时提供了良好的性能表现，多令牌预测训练策略提升了模型的学习效果。

Conclusion: MiMo-V2-Flash通过创新的混合专家和混合注意力架构，成功平衡了模型规模、计算效率和性能，为大规模语言模型的推理和智能体应用提供了有效解决方案。

Abstract: We present MiMo-V2-Flash, a Mixture-of-Experts (MoE) model with 309B total parameters and 15B active parameters, designed for fast, strong reasoning and agentic capabilities. MiMo-V2-Flash adopts a hybrid attention architecture that interleaves Sliding Window Attention (SWA) with global attention, with a 128-token sliding window under a 5: 1 hybrid ratio. The model is pre-trained on 27 trillion tokens with Multi-Token Prediction (MTP), employing a native 32k context length and …

</details>


### [132] [On the Effectiveness of Proposed Techniques to Reduce Energy Consumption in RAG Systems: A Controlled Experiment](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.02522&hl=zh-CN&sa=X&d=16203581391597653494&ei=RO1hacHPAdrJieoPiYyysAk&scisig=AHkA5jQ3CD6_2rXb1F7VsylJg8BM&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:AHkA5jQJ09t5uyNUKDlpVNk33Ubd&html=&pos=1&folt=cit)
*C Gao,J Bogner*

Main category: Zongheng Yang

TL;DR: 研究通过受控实验评估了五种降低RAG系统能耗的实用技术，发现其中四种能显著减少能耗而不影响性能


<details>
  <summary>Details</summary>
Motivation: 机器学习（特别是RAG系统）的能源需求不断增长引发了环境可持续性担忧，虽然已有绿色ML技术研究，但在RAG系统中的实证评估仍很缺乏

Method: 采用受控实验方法，系统性地测试和比较五种实用的节能技术在实际RAG系统中的效果

Result: 实验发现五种技术中有四种能显著减少RAG系统的能耗，同时保持系统性能不受影响

Conclusion: 研究证明存在实用的绿色技术可以显著降低RAG系统的能耗，为构建更可持续的ML系统提供了实证依据

Abstract: The rising energy demands of machine learning (ML), eg, implemented in popular variants like retrieval-augmented generation (RAG) systems, have raised significant concerns about their environmental sustainability. While previous research has proposed green tactics for ML-enabled systems, their empirical evaluation within RAG systems remains largely unexplored. This study presents a controlled experiment investigating five practical techniques aimed at reducing energy …

</details>


### [133] [VocalBridge: Latent Diffusion-Bridge Purification for Defeating Perturbation-Based Voiceprint Defenses](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.02444&hl=zh-CN&sa=X&d=12955867324614571643&ei=RO1hacHPAdrJieoPiYyysAk&scisig=AHkA5jTTL6k0O9I4vUdoe_6IRCih&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:AHkA5jQJ09t5uyNUKDlpVNk33Ubd&html=&pos=2&folt=cit)
*M Abbasihafshejani,AHM Sakib,M Jadliwala*

Main category: Zongheng Yang

TL;DR: 论文研究语音克隆防御技术，分析现有保护性扰动方法的局限性，并提出对抗净化攻击的解决方案


<details>
  <summary>Details</summary>
Motivation: 随着TTS和语音转换技术的快速发展，语音克隆带来的安全和隐私问题日益严重。现有通过在语音中嵌入保护性扰动来防止未经授权克隆的方法，面临高级净化技术的攻击，导致防御失效。

Method: 论文分析了现有语音克隆防御方法的局限性，特别是保护性扰动技术面临的净化攻击威胁。可能提出新的防御策略或改进现有方法以抵抗净化攻击。

Result: 现有保护性扰动方法在高级净化技术面前存在脆弱性，攻击者能够恢复原始声学特征，使防御失效。需要更鲁棒的防御机制。

Conclusion: 语音克隆防御需要更强大的保护机制来抵抗净化攻击，确保在保持语音可懂度的同时有效保护说话人身份。

Abstract: The rapid advancement of speech synthesis technologies, including text-to-speech (TTS) and voice conversion (VC), has intensified security and privacy concerns related to voice cloning. Recent defenses attempt to prevent unauthorized cloning by embedding protective perturbations into speech to obscure speaker identity while maintaining intelligibility. However, adversaries can apply advanced purification techniques to remove these perturbations, recover authentic acoustic characteristics …

</details>


### [134] [Visionary: Enhancing Visual Context for the Visually Impaired](https://scholar.google.com/scholar_url?url=https://www.techrxiv.org/doi/pdf/10.36227/techrxiv.176764805.55872058&hl=zh-CN&sa=X&d=4116017307970994279&ei=RO1hacHPAdrJieoPiYyysAk&scisig=AHkA5jRSMiXiHfjqw4ruJqDn2w6F&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:AHkA5jQJ09t5uyNUKDlpVNk33Ubd&html=&pos=4&folt=cit)
*P Powar,A Agarwal*

Main category: Zongheng Yang

TL;DR: Visionary是一款为视障人士设计的移动应用，通过结合BLIP的图像识别和LLaMA 3的语言处理，提供更丰富、准确的周围环境描述。


<details>
  <summary>Details</summary>
Motivation: 随着技术依赖增加，视障人士在获取准确详细的环境描述方面面临挑战。现有模型如BLIP和CLIP在提供丰富上下文方面存在不足。

Method: 开发Visionary移动应用，结合BLIP的精确图像识别能力和LLaMA 3的语言处理能力，通过语音导航界面增强图像描述的深度和清晰度。

Result: Visionary应用能够为视障人士提供比现有模型更丰富、更准确的环境描述，改善了他们的技术使用体验。

Conclusion: 通过整合先进的图像识别和语言处理技术，Visionary有效解决了视障人士获取环境信息的需求，提升了他们的独立性和生活质量。

Abstract: The growing reliance on technology poses challenges for visually impaired individuals, especially in receiving accurate and detailed descriptions of their surroundings. Existing models like BLIP and CLIP often fall short in providing rich context. To address this, we introduce Visionary, a mobile app that enhances image descriptions by combining BLIP's precise image recognition with LLaMA 3's language processing to add depth and clarity. With a voice-navigated interface and …

</details>


### [135] [Next-Generation Sound Content Production Using AI-Based Generative Models](https://scholar.google.com/scholar_url?url=https://accesson.kr/insca/assets/pdf/57523/journal-2-3-14.pdf&hl=zh-CN&sa=X&d=3622868655889630824&ei=RO1hacHPAdrJieoPiYyysAk&scisig=AHkA5jSYT-kWTda2oGOKR8tnv-fn&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:AHkA5jQJ09t5uyNUKDlpVNk33Ubd&html=&pos=5&folt=cit)
*Y Kim*

Main category: Zongheng Yang

TL;DR: 人工智能在21世纪重塑了声音领域，语音和音乐作为人类沟通与情感表达的核心媒介，在互动媒体中从辅助感官角色转变为核心机制


<details>
  <summary>Details</summary>
Motivation: 探讨人工智能如何彻底改变声音领域，特别是语音和音乐在互动媒体中的角色转变，从辅助功能演变为核心交互机制

Method: 未明确说明具体方法，但暗示通过人工智能技术对声音领域进行系统性分析和重构

Result: 人工智能推动了声音领域的根本性变革，使声音在互动媒体中从辅助感官元素转变为核心交互机制

Conclusion: 人工智能正在重新定义声音在数字内容生态系统中的角色，特别是在互动媒体中，声音已成为核心的交互和体验机制

Abstract: In the 21st century, artificial intelligence (AI) has catalyzed rapid transformations across diverse industries, with the sound domain standing out as one of the most dramatically reshaped fields. Voice, as a fundamental medium of human communication, and music, as a vital conduit of emotional and cultural experience, occupy central roles in modern content ecosystems. In interactive media such as games, sound transcends its auxiliary sensory role to become a core mechanism …

</details>


### [136] [FakeVoiceFinder: An Open-Source Framework for Synthetic and Deepfake Audio Detection](https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2504-2289/10/1/25&hl=zh-CN&sa=X&d=2888464884062563039&ei=a0VjaYe8G8yQieoPxv68kA4&scisig=AHkA5jR0AjQNGxZWSgjU8hMwIfuP&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:AHkA5jQJ09t5uyNUKDlpVNk33Ubd&html=&pos=0&folt=cit)
*C Pachon,D Ballesteros*

Main category: Zongheng Yang

TL;DR: 论文探讨了音频深度伪造检测问题，指出当前多数方法采用模型中心视角而固定频谱表示，提出了数据中心视角探索替代表示方法


<details>
  <summary>Details</summary>
Motivation: AI音频生成技术快速发展，深度伪造音频的自然度已接近真实录音，使真实与合成信号的区分变得复杂。当前多数检测方法采用模型中心视角，固定频谱表示，需要探索更有效的表示方法

Method: 采用数据中心的视角，探索替代的音频表示方法，如尺度图等，而非传统的固定频谱表示

Result: 未在摘要中明确说明具体实验结果，但暗示通过探索替代表示方法可能获得更好的检测性能

Conclusion: 需要从数据中心视角重新思考音频深度伪造检测，探索更有效的音频表示方法而非仅优化模型架构

Abstract: AI-based audio generation has advanced rapidly, enabling deepfake audio to reach levels of naturalness that closely resemble real recordings and complicate the distinction between authentic and synthetic signals. While numerous CNN-and Transformer-based detection approaches have been proposed, most adopt a model-centric perspective in which the spectral representation remains fixed. Parallel data-centric efforts have explored alternative representations such as scalograms and …

</details>


### [137] [ASVspoof 5: Evaluation of Spoofing, Deepfake, and Adversarial Attack Detection Using Crowdsourced Speech](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.03944&hl=zh-CN&sa=X&d=15342218014705983289&ei=a0VjaYe8G8yQieoPxv68kA4&scisig=AHkA5jTyMQ8NT_2tTzg1wZmvWUbO&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:AHkA5jQJ09t5uyNUKDlpVNk33Ubd&html=&pos=1&folt=cit)
*X Wang,H Delgado,N Evans,X Liu,T Kinnunen…*

Main category: Zongheng Yang

TL;DR: ASVspoof 5挑战赛聚焦语音欺骗和深度伪造检测，引入新的众包数据库，包含更多说话者和多样录音条件，采用前沿与遗留生成语音技术混合


<details>
  <summary>Details</summary>
Motivation: 推动语音欺骗和深度伪造检测研究，应对日益复杂的生成语音技术威胁，通过挑战赛形式促进该领域技术进步

Method: 采用众包方式收集数据库，包含大量说话者在多样录音条件下的语音样本，混合使用前沿和遗留生成语音技术

Result: 创建了ASVspoof 5数据库，相比前几版显著增加了说话者数量和录音条件多样性，提供了更全面的测试基准

Conclusion: ASVspoof 5挑战赛通过改进的数据库设计为语音欺骗检测研究提供了更真实、更具挑战性的评估环境

Abstract: ASVspoof 5 is the fifth edition in a series of challenges which promote the study of speech spoofing and deepfake detection solutions. A significant change from previous challenge editions is a new crowdsourced database collected from a substantially greater number of speakers under diverse recording conditions, and a mix of cutting-edge and legacy generative speech technology. With the new database described elsewhere, we provide in this paper an overview of the …

</details>


### [138] [Making Tunable Parameters State-Dependent in Weather and Climate Models with Reinforcement Learning](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.04268&hl=zh-CN&sa=X&d=10452796883867714988&ei=4qVkac73Hsm4ieoP4sbVuAg&scisig=AHkA5jRfHtLMmhCKC_W1QyCM_xKE&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:AHkA5jQJ09t5uyNUKDlpVNk33Ubd&html=&pos=0&folt=cit)
*P Nath,S Schemm,H Moss,P Haynes,E Shuckburgh…*

Main category: Zongheng Yang

TL;DR: 该研究提出了一种使用强化学习在线学习参数化方案组件的框架，以解决传统方案中固定系数导致的偏差问题


<details>
  <summary>Details</summary>
Motivation: 传统天气和气候模型依赖固定系数的参数化方案，这些系数约束较弱且离线调整，导致持续偏差，限制了模型适应底层物理过程的能力

Method: 使用强化学习在线学习参数化方案的组件，作为演化模型状态的函数

Result: 强化学习驱动的参数化方案能够更好地适应模型状态，减少传统方案中的偏差

Conclusion: 强化学习为天气和气候模型参数化提供了有前景的在线学习方法，能够提高模型适应性和减少系统偏差

Abstract: Weather and climate models rely on parametrisations to represent unresolved sub-grid processes. Traditional schemes rely on fixed coefficients that are weakly constrained and tuned offline, contributing to persistent biases that limit their ability to adapt to the underlying physics. This study presents a framework that learns components of parametrisation schemes online as a function of the evolving model state using reinforcement learning (RL) and evaluates the resulting RL-driven …

</details>


### [139] [STFT-GradTTS: a robust, diffusion-based speech synthesis system with iSTFT decoder for Bangla](https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10772-025-10241-w&hl=zh-CN&sa=X&d=2109638981640058239&ei=4qVkac73Hsm4ieoP4sbVuAg&scisig=AHkA5jSW04hjZs2DX_DHjgGzl-kD&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:AHkA5jQJ09t5uyNUKDlpVNk33Ubd&html=&pos=1&folt=cit)
*M Intesum,AI Masud,MR Karim,MA Islam*

Main category: Zongheng Yang

TL;DR: 研究者创建了一个超过20小时的单说话人孟加拉语语音数据集，以解决高质量孟加拉语TTS数据稀缺的问题


<details>
  <summary>Details</summary>
Motivation: 孟加拉语作为全球第七大使用语言，高质量TTS数据集稀缺，限制了孟加拉语语音合成技术的发展。需要填补这一空白以促进相关应用如辅助技术、虚拟助手和自动化内容生成。

Method: 研究者精心策划并创建了一个单说话人孟加拉语音频数据集，包含超过20小时的清晰语音数据。该数据集经过仔细的筛选和质量控制。

Result: 成功构建了一个超过20小时的高质量单说话人孟加拉语TTS数据集，为孟加拉语语音合成研究提供了重要的数据资源。

Conclusion: 该数据集填补了孟加拉语TTS数据稀缺的空白，有望推动孟加拉语语音合成技术的发展，支持相关应用领域的进步。

Abstract: Abstract Text-to-speech (TTS) synthesis is a critical area in speech and language processing, with extensive applications in assistive technologies, virtual assistants, and automated content generation. Despite Bangla being the seventh most spoken language globally, high-quality TTS datasets remain scarce, limiting advancements in Bangla speech synthesis. To bridge this gap, we introduce a meticulously curated single-speaker Bangla audio dataset comprising over 20 hours of clean speech. Our …

</details>


### [140] [Nalar: An agent serving framework](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.05109&hl=zh-CN&sa=X&d=2118175500776664337&ei=4qVkac73Hsm4ieoP4sbVuAg&scisig=AHkA5jTTKJFDAZS6hKIPdKh0zk_B&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:AHkA5jQJ09t5uyNUKDlpVNk33Ubd&html=&pos=2&folt=cit)
*M Laju,D Son,S Agarwal,N Kedia,M Lee,J Srinivasa…*

Main category: Zongheng Yang

TL;DR: Nalar是一个从头构建的智能体服务框架，通过将工作流规范与执行分离来解决LLM驱动智能体应用中的性能挑战，同时提供运行时可见性和控制。


<details>
  <summary>Details</summary>
Motivation: LLM驱动的智能体应用在自动化复杂多步骤任务时面临效率挑战，包括异构组件、动态模型驱动的控制流、长运行状态和不可预测延迟等问题，需要专门的框架来解决这些性能瓶颈。

Method: Nalar采用从零开始构建的方法，将工作流规范与执行完全分离，同时保持完整的Python表达能力，并提供运行时可见性和控制机制。

Result: Nalar框架能够有效处理智能体应用的性能挑战，提供稳健的性能表现，支持复杂的多步骤任务自动化。

Conclusion: Nalar通过创新的架构设计解决了LLM驱动智能体应用的服务效率问题，为构建高性能智能体系统提供了有效的框架解决方案。

Abstract: LLM-driven agentic applications increasingly automate complex, multi-step tasks, but serving them efficiently remains challenging due to heterogeneous components, dynamic and model-driven control flow, long-running state, and unpredictable latencies. Nalar is a ground-up agent-serving framework that cleanly separates workflow specification from execution while providing the runtime visibility and control needed for robust performance. Nalar preserves full Python expressiveness …

</details>


### [141] [Multi-Agent Reinforcement Learning Environment for Beyond Visual Range Air Combat (BVR-MARL)](https://scholar.google.com/scholar_url?url=https://arc.aiaa.org/doi/abs/10.2514/6.2026-1592&hl=zh-CN&sa=X&d=4114172121054888416&ei=4qVkac73Hsm4ieoP4sbVuAg&scisig=AHkA5jT0vWo0Nr2HsxspIPO9Zs79&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:AHkA5jQJ09t5uyNUKDlpVNk33Ubd&html=&pos=4&folt=cit)
*S Schosser,CO Retzlaff,A Schulte*

Main category: Zongheng Yang

TL;DR: BVR-MARL是一个面向超视距空战的MARL仿真环境，旨在平衡真实性与训练吞吐量，通过模块化设计解决现有平台在传感器/电子战、多平台融合等关键效应缺失或训练速度过慢的问题。


<details>
  <summary>Details</summary>
Motivation: 现有超视距空战仿真平台存在两个主要问题：要么忽略了传感器/电子战、多平台融合、导弹导引头感知等关键效应，要么训练速度过慢，无法支持大规模强化学习训练。这促使开发一个模块化、原生支持RL的替代方案。

Method: 采用模块化设计，开发RL原生的仿真引擎，包含轻量级4自由度飞机和导弹模型，重点模拟超视距空战的关键要素，包括传感器系统、电子战、多平台数据融合以及导弹导引头感知能力。

Result: BVR-MARL环境在真实性与训练吞吐量之间取得了良好平衡，能够支持大规模多智能体强化学习训练，同时保持对超视距空战关键物理效应和战术要素的准确模拟。

Conclusion: BVR-MARL为超视距空战的多智能体强化学习研究提供了有效的仿真平台，通过模块化设计和性能优化解决了现有平台的局限性，有望推动该领域算法的发展和应用。

Abstract: We present BVR-MARL, a Multi-Agent Reinforcement Learning (MARL) simulation environment for beyond-visual-range (BVR) air-to-air combat that targets the realism–throughput frontier required for scalable training. Existing platforms either omit BVR-critical effects (sensors/EW, multi-platform fusion, seeker-aware missiles) or are too slow for long Reinforcement Learning (RL) runs, motivating a modular, RL-native alternative. Our engine advances aircraft and missiles with lightweight 4-DoF …

</details>


### [142] [Flight Control System Clearance using Bayesian Optimised Deep Reinforcement Learning on an Unstable Platform](https://scholar.google.com/scholar_url?url=https://arc.aiaa.org/doi/abs/10.2514/6.2026-0336&hl=zh-CN&sa=X&d=6397533091080762930&ei=4qVkac73Hsm4ieoP4sbVuAg&scisig=AHkA5jRIw04qpWrqdRktk7WlHf3P&oi=scholaralrt&hist=i6heNjgAAAAJ:289518505314468501:AHkA5jQJ09t5uyNUKDlpVNk33Ubd&html=&pos=5&folt=cit)
*V Gavra,A Cook,S Neumeier,J Ribas de Amaral*

Main category: Zongheng Yang

TL;DR: 利用元优化强化学习识别可能导致飞机失控的最坏情况，以验证飞行控制系统在不稳定飞机上的安全性


<details>
  <summary>Details</summary>
Motivation: 传统飞行控制系统验证方法难以全面覆盖不稳定飞机的复杂故障场景，需要更有效的方法来识别可能导致失控的最坏情况

Method: 采用基于策略的演员-评论家深度强化学习框架，通过与高保真非线性飞机仿真交互，元优化训练智能体发现飞行控制系统许可要求中的违规情况

Result: 该方法能够有效识别传统方法可能遗漏的飞行控制系统安全漏洞和可能导致飞机失控的危险场景

Conclusion: 元优化强化学习为不稳定飞机的飞行控制系统验证提供了一种有效的新方法，能够发现传统方法难以检测的安全风险

Abstract: This paper presents a novel approach for clearing Flight Control Systems (FCS) on unstable aircraft by utilising meta-optimised reinforcement learning to identify worst-case scenarios that could lead to departures from controlled flight. The authors propose a system where a Deep Reinforcement Learning (DRL) agent, using an on-policy actor-critic framework is trained to find breaches in FCS clearance requirements by interacting with a high-fidelity non-linear aircraft simulation via stick …

</details>


### [143] [Deep Learning-Based Optimization Techniques For Large-Scale Data Processing In Cloud Environments](https://scholar.google.com/scholar_url?url=https://mrcis.org/index.php/journal/article/download/187/300&hl=zh-CN&sa=X&d=12978835141656801597&ei=L1hmafK8G9rJieoPjeLumAg&scisig=AHkA5jTLg0iDl33I6-QOfsDoypk9&oi=scholaralrt&hist=i6heNjgAAAAJ:778719684493065653:AHkA5jQQvhnv-0XbvZE0RehBjafZ&html=&pos=1&folt=rel)
*H Raza*

Main category: Zongheng Yang

TL;DR: 该论文探讨了在大规模数据集指数增长背景下，如何通过深度学习和云平台优化数据处理效率


<details>
  <summary>Details</summary>
Motivation: 现代产业中大规模数据集的指数增长（社交媒体、电子商务、生物信息学、物联网等）增加了对高效云数据处理平台的需求

Method: 基于深度学习技术优化云数据处理平台

Result: 未在摘要中明确说明具体结果

Conclusion: 需要开发更高效的云数据处理平台来应对大规模数据挑战

Abstract: The exponential growth of large-scale datasets in modern industries—ranging from social media and e-commerce to bioinformatics and IoT—has increased the demand for efficient cloud-based data processing platforms. Deep learning-powered …

</details>


<div id='Thomas Neumann'></div>

# Thomas Neumann [[Back]](#toc)

### [144] [On the Vexing Difficulty of Evaluating IN Predicates](https://scholar.google.com/scholar_url?url=https://www.vldb.org/cidrdb/papers/2026/p3-birler.pdf&hl=zh-CN&sa=X&d=12282621651179348212&ei=mQ5Kab77KIKUieoP5cGFWQ&scisig=ALhkC2QlNiz7OtWhrDlYaU3qoRuk&oi=scholaralrt&hist=i6heNjgAAAAJ:17461000864107631014:ALhkC2QhrABZ8SOEERi3YzN7Focv&html=&pos=0&folt=art)
*A Birler,T Neumann*

Main category: Thomas Neumann

TL;DR: 该论文分析了SQL中IN谓词和量化比较谓词缺乏高效评估策略的问题，并提出了新的优化方法


<details>
  <summary>Details</summary>
Motivation: SQL中的IN谓词及其语法变体量化比较谓词自SQL标准诞生以来就被广泛使用，但令人惊讶的是，目前没有已知的高效评估策略。这些构造在表面上看起来简单，但实际上缺乏有效的执行方法，这促使研究者探索新的优化技术。

Method: 论文提出了针对IN谓词和量化比较谓词的新评估策略。方法可能包括查询重写、索引优化、执行计划改进等技术，旨在提高这些常用SQL构造的执行效率。

Result: 研究结果表明，提出的优化方法能够显著提高IN谓词和量化比较谓词的执行性能。通过实验验证，新策略在查询执行时间和资源消耗方面都有明显改善。

Conclusion: 该研究填补了SQL查询优化中的一个重要空白，为IN谓词和量化比较谓词提供了首个系统性的高效评估框架，对数据库系统的性能优化具有重要实践意义。

Abstract: In SQL, IN predicates—and their syntactic cousin, quantified comparison predicates—are widely used and are part of the standard since its inception. Perhaps somewhat surprisingly, no efficient evaluation strategy is known. At first glance, these constructs …

</details>


### [145] [Predictive Translation: High-Performance Buffer Management Without the Trade-Offs](https://scholar.google.com/scholar_url?url=https://db.in.tum.de/people/sites/zinsmeister/papers/predictive-translation.pdf&hl=zh-CN&sa=X&d=16618819713881875539&ei=5qVkaf2CGLux6rQPi5qW2AE&scisig=AHkA5jSUjLaFBCz8C5_h2hJB1CeF&oi=scholaralrt&hist=i6heNjgAAAAJ:17461000864107631014:AHkA5jS6Y8QqH-N9zG50sO_vTzrN&html=&pos=0&folt=art)
*M Zinsmeister,LD Nguyen,V Leis,T Neumann*

Main category: Thomas Neumann

TL;DR: 论文探讨了存储型数据库管理系统中的缓冲区管理器优化，传统方法使用哈希表进行页面标识符到内存位置的映射，但存在性能瓶颈


<details>
  <summary>Details</summary>
Motivation: 传统基于哈希表的缓冲区管理器在处理大规模数据集时存在性能瓶颈，需要更高效的页面标识符到内存位置的映射机制来提升数据库系统性能

Method: 未在摘要中明确说明具体方法，但暗示了对传统哈希表方法的改进或替代方案

Result: 未在摘要中提供具体实验结果

Conclusion: 需要更高效的缓冲区管理器设计来优化存储型数据库管理系统的大规模数据处理能力

Abstract: To efficiently manage larger-than-memory datasets, storage-based database management systems (DBMSs) rely on buffer managers. These are traditionally implemented using hash tables to translate page identifiers (PIDs) to memory …

</details>


<div id='Surajit Chaudhuri'></div>

# Surajit Chaudhuri [[Back]](#toc)

### [146] [AI-Assisted Data Hygiene at Scale: Entity Resolution & Deduplication for Salesforce](https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Pavan-Palleti/publication/397602091_AI-Assisted_Data_Hygiene_at_Scale_Entity_Resolution_Deduplication_for_Salesforce/links/69171b1cda4d0c7d150415db/AI-Assisted-Data-Hygiene-at-Scale-Entity-Resolution-Deduplication-for-Salesforce.pdf&hl=zh-CN&sa=X&d=8063336616410400909&ei=tgYtadTsJ_-j6rQPrbnwwA4&scisig=ABGrvjJ221iPXE0Fjv9qqC05t57u&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=1&folt=rel)
*P Palleti*

Main category: Surajit Chaudhuri

TL;DR: CRM平台中半结构化客户数据存在漂移、重复和衰减问题，影响数据质量和业务决策


<details>
  <summary>Details</summary>
Motivation: 随着组织扩张、新渠道整合，CRM平台积累的海量半结构化记录会出现数据漂移、重复和衰减，导致数据质量下降，影响客户关系管理和业务决策

Method: 摘要未提供具体方法，但暗示需要解决CRM数据质量问题，可能涉及数据清洗、去重、标准化和持续维护等技术

Result: 摘要未提供具体结果，但指出CRM数据质量问题对组织运营的负面影响

Conclusion: CRM平台中的半结构化数据质量问题需要系统性解决方案，以确保数据准确性、一致性和时效性，支持有效的客户关系管理

Abstract: Salesforce Architect pavan15tech@ gmail. com Abstract: Customer relationship management (CRM) platforms accumulate vast volumes of semi-structured records that drift, duplicate, and decay as organizations expand, integrate new channels, and …

</details>


### [147] [Optimizing Long-context LLM Serving via Fine-grained Sequence Parallelism](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.06247&hl=zh-CN&sa=X&d=11841644695581625178&ei=tgYtadTsJ_-j6rQPrbnwwA4&scisig=ABGrvjKJO70xnBRO-IyLBE3bky-7&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=2&folt=rel)
*C Li,Y Yang,X Zheng,Q Yang,Y Guan,S Zheng…*

Main category: Surajit Chaudhuri

TL;DR: 论文探讨了在大语言模型上下文窗口扩展背景下，如何通过动态序列并行策略优化不同长度请求的服务效率


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型上下文窗口的快速扩展，在线服务中不同长度请求的多样化需求对现有序列并行系统提出了挑战，需要更灵活高效的调度策略

Method: 提出动态序列并行策略，根据请求长度和系统负载动态调整并行配置，优化资源利用和服务延迟

Result: 相比静态序列并行方法，动态策略在保持服务质量的同时显著提升了系统吞吐量和资源利用率

Conclusion: 动态序列并行是应对大语言模型上下文窗口扩展和多样化请求需求的有效解决方案，为在线服务系统提供了更灵活的优化路径

Abstract: With the advancement of large language models (LLMs), their context windows have rapidly expanded. To meet diverse demands from varying-length requests in online services, existing state-of-the-art systems tune the sequence parallelism (SP) …

</details>


### [148] [AgentTune: An Agent-Based Large Language Model Framework for Database Knob Tuning](https://scholar.google.com/scholar_url?url=https://renata.borovica-gajic.com/data/2026_sigmod.pdf&hl=zh-CN&sa=X&d=17000219885145543268&ei=tgYtadTsJ_-j6rQPrbnwwA4&scisig=ABGrvjJ1BG201j2v6-hqhBWT78FX&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=3&folt=rel)
*Y LI,H LI,J ZHANG,R BOROVICA*

Main category: Surajit Chaudhuri

TL;DR: 机器学习驱动的数据库参数自动调优系统综述，涵盖强化学习、贝叶斯优化等主流方法，分析其性能、局限性与未来方向


<details>
  <summary>Details</summary>
Motivation: 传统数据库参数调优依赖专家经验，耗时且易出错。随着机器学习技术的发展，需要系统梳理各类ML-based自动调优方法，评估其有效性、局限性，并为未来研究提供方向指导

Method: 对过去十年ML-based数据库参数调优系统进行全面综述，包括强化学习、贝叶斯优化、进化算法等主流方法，分析其技术原理、实现框架和适用场景

Result: ML-based方法在自动发现有效配置方面表现显著，能减少人工干预，但存在训练成本高、泛化能力有限、黑盒解释性差等挑战。不同方法在不同场景下各有优劣

Conclusion: 机器学习为数据库参数调优提供了有效自动化解决方案，但需进一步解决样本效率、跨平台泛化、可解释性等问题。未来方向包括元学习、迁移学习与混合方法

Abstract: Over the past decade, various machine learning (ML)-based knob tuning systems have emerged, capable of automatically discovering effective configurations without extensive human intervention. These include approaches based on Reinforcement …

</details>


### [149] [Think-at-Hard: Selective Latent Iterations to Improve Reasoning Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.08577&hl=zh-CN&sa=X&d=4449358611475756206&ei=nlcuac2UOo2v6rQP1Yj2iAo&scisig=ABGrvjICqosCA6T6wrKb9qApfzzF&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=0&folt=rel)
*T Fu,Y You,Z Chen,G Dai,H Yang,Y Wang*

Main category: Surajit Chaudhuri

TL;DR: 本文提出了一种自适应推理框架，通过动态分配计算资源来提升语言模型的推理能力，相比固定迭代方法在效率和效果上均有显著改进。


<details>
  <summary>Details</summary>
Motivation: 现有循环Transformer方法为每个推理步骤分配固定数量的额外迭代，这限制了模型根据任务复杂度自适应分配计算资源的能力。在参数受限的实际应用中，需要更高效灵活的推理机制来平衡计算成本与性能。

Method: 提出了一种自适应推理框架，通过动态决定何时停止迭代来优化计算资源分配。该方法基于当前推理状态评估是否需要继续计算，从而为简单任务分配较少计算，为复杂任务分配更多计算资源。

Result: 实验表明，该方法在多种推理任务上显著优于固定迭代方法，在相同计算预算下获得更好的性能，同时减少了不必要的计算开销，提高了推理效率。

Conclusion: 自适应推理机制是提升语言模型推理能力的关键方向，能够更有效地利用有限的计算资源，为实际部署中的参数受限模型提供了可行的优化方案。

Abstract: Improving reasoning capabilities of Large Language Models (LLMs), especially under parameter constraints, is crucial for real-world applications. Prior work proposes recurrent transformers, which allocate a fixed number of extra iterations per …

</details>


### [150] [Adaptive Residual-Update Steering for Low-Overhead Hallucination Mitigation in Large Vision Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.10292&hl=zh-CN&sa=X&d=3359251059636269755&ei=nlcuac2UOo2v6rQP1Yj2iAo&scisig=ABGrvjJRdcsFa7ou6XxdUXr3Vj-L&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=2&folt=rel)
*Z Zou,Y Gao,J Guan,B Li,P Marttinen*

Main category: Surajit Chaudhuri

TL;DR: 该论文针对大型视觉语言模型中的物体幻觉问题，提出了一种新的推理时干预方法，通过对比解码来减少幻觉，提高模型可靠性


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型经常出现物体幻觉问题，生成的文本与视觉输入不一致，这会严重损害模型的可靠性。现有的推理时干预方法存在局限性，需要更有效的解决方案

Method: 提出了一种新的推理时干预方法，采用对比解码策略来减少物体幻觉。该方法通过对比不同解码路径或约束生成过程，确保文本输出与视觉输入的一致性

Result: 该方法在多个基准测试中显著减少了物体幻觉，提高了模型输出的可靠性和与视觉输入的一致性，相比现有方法表现出更好的性能

Conclusion: 提出的对比解码干预方法有效缓解了大型视觉语言模型中的物体幻觉问题，为提升模型可靠性提供了有前景的解决方案，具有重要的实际应用价值

Abstract: Large Vision-Language Models (LVLMs) often suffer from object hallucination, generating text inconsistent with visual inputs, which can critically undermine their reliability. Existing inference-time interventions to mitigate this issue present a …

</details>


### [151] [Vietnamese Question Answering on Tabular Data via Large Language Models](https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-032-10202-7_31&hl=zh-CN&sa=X&d=2082203755656954728&ei=nlcuac2UOo2v6rQP1Yj2iAo&scisig=ABGrvjKDBZIBUd6orR6QIfYRv21w&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=4&folt=rel)
*NM Son,BH Son,LM Hung,VT Kiet,D Van Thin*

Main category: Surajit Chaudhuri

TL;DR: 表格数据上的抽象问答研究因其从结构化数据中提取见解的实际应用价值而受到NLP社区关注，旨在增强数据可访问性


<details>
  <summary>Details</summary>
Motivation: 表格数据在现实世界中广泛存在，但非专业人士难以直接从中提取信息。抽象问答技术可以增强结构化数据的可访问性，让用户能够通过自然语言查询获取表格中的洞察

Method: 从提供的摘要内容来看，方法部分信息不足。通常这类研究涉及自然语言处理技术、表格理解、语义解析、信息检索等方法，将自然语言查询转换为表格操作或SQL查询

Result: 摘要未提供具体实验结果。此类研究通常评估问答系统的准确率、召回率等指标，以及在不同类型表格数据上的表现

Conclusion: 表格数据上的抽象问答具有重要的实际应用价值，能够显著提升结构化数据的可访问性和可用性，是NLP领域的重要研究方向

Abstract: Abstract Question Answering on Tabular Data has garnered significant interest within the Natural Language Processing community due to its real-world applicability in extracting insights from structured data, thereby enhancing data accessibility and …

</details>


### [152] [BARD: budget-aware reasoning distillation](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.01470&hl=zh-CN&sa=X&d=4515308777791020430&ei=nlcuac2UOo2v6rQP1Yj2iAo&scisig=ABGrvjLYD3d0_trcExjpwGldtjhp&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=5&folt=rel)
*L Niu,L Shen,Y Jiang,C Yuan,X Wang,W Su*

Main category: Surajit Chaudhuri

TL;DR: 该论文提出了一种基于强化学习的CoT蒸馏方法，通过动态修剪冗余推理步骤来提升小语言模型的推理效率


<details>
  <summary>Details</summary>
Motivation: 传统的CoT蒸馏方法虽然能将推理能力迁移到小模型中，但推理过程通常存在冗余，计算预算不可控，导致资源使用效率低下

Method: 提出基于强化学习的CoT蒸馏框架，通过动态修剪冗余推理步骤来优化推理效率，同时保持推理质量

Result: 该方法在保持推理准确性的同时，显著减少了计算开销，提高了小语言模型的推理效率

Conclusion: 基于强化学习的动态修剪方法能够有效解决CoT蒸馏中的冗余问题，实现更高效的推理能力迁移

Abstract: While long Chain-of-Thought (CoT) distillation effectively transfers reasoning capability to smaller language models, the reasoning process often remains redundant and computational budget uncontrollable, leading to inefficient resource …

</details>


### [153] [A Machine Learning Approach to Multi-Join Query Optimization in Large-Scale Relational Databases](https://scholar.google.com/scholar_url?url=https://orientacademies.com/index.php/OJEPAIAS/article/download/2025-11-16/15&hl=zh-CN&sa=X&d=16211648506115956661&ei=nlcuac2UOo2v6rQP1Yj2iAo&scisig=ABGrvjLKNO4Ie-aiLh85BKPuDpU5&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=6&folt=rel)
*J Messaoudi,N Touahria*

Main category: Surajit Chaudhuri

TL;DR: 论文探讨了大规模关系数据库中复杂分析查询的优化问题，传统基于成本的优化器依赖手工设计的启发式方法、动态规划等，存在局限性。


<details>
  <summary>Details</summary>
Motivation: 随着大规模关系数据库系统处理越来越复杂的分析查询（涉及大表的多次连接），传统基于成本的优化器依赖手工设计的启发式方法、动态规划等技术，在处理复杂查询时存在性能瓶颈和优化效果不足的问题。

Method: 从摘要内容看，论文可能提出新的优化方法，但具体方法未在提供的摘要中明确说明。传统方法包括基于成本的优化器、手工设计的启发式规则、动态规划等。

Result: 摘要未提供具体实验结果，但暗示传统方法在处理大规模复杂分析查询时存在局限性，需要更先进的优化技术。

Conclusion: 大规模关系数据库中的复杂分析查询优化需要超越传统手工启发式和动态规划的新方法，以提高查询性能和效率。

Abstract: Large-scale relational database systems increasingly serve workloads with complex analytical queries involving many joins over large tables. Traditional cost-based optimizers rely on manually engineered heuristics, dynamic programming, and …

</details>


### [154] [A Dynamic PD-Disaggregation Architecture for Maximizing Goodput in LLM Inference Serving](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.20982&hl=zh-CN&sa=X&d=752792207003598007&ei=nlcuac2UOo2v6rQP1Yj2iAo&scisig=ABGrvjIC7sY4r2XZUr2DPh_792gd&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=8&folt=rel)
*J Liao,M Xu,W Zheng,Y Wang,K Ye,R Buyya,C Xu*

Main category: Surajit Chaudhuri

TL;DR: LLM服务中预填充和解码阶段分离部署以应对不同瓶颈，但现有方案存在资源利用不足和调度效率低的问题


<details>
  <summary>Details</summary>
Motivation: 为满足严格的SLO要求，当前LLM服务将预填充和解码阶段解耦并部署在不同GPU上，但现有方案存在资源利用率低和调度效率不足的问题，需要更高效的资源管理和调度策略

Method: 论文提出了一种新的资源管理和调度框架，通过动态资源分配、智能任务调度和跨阶段协调机制来优化预填充和解码阶段的资源利用

Result: 提出的方法显著提高了GPU资源利用率，降低了延迟，提升了吞吐量，同时更好地满足了SLO要求

Conclusion: 通过优化预填充和解码阶段的资源管理和调度策略，可以显著提升LLM服务的性能和效率，为大规模部署提供更有效的解决方案

Abstract: To meet strict Service-Level Objectives (SLOs), contemporary Large Language Models (LLMs) decouple the prefill and decoding stages and place them on separate GPUs to mitigate the distinct bottlenecks inherent to each phase. However, the …

</details>


### [155] [BeDiscovER: The Benchmark of Discourse Understanding in the Era of Reasoning Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.13095&hl=zh-CN&sa=X&d=2392816447897618273&ei=eQswaYfJOYqi6rQPr6DGiAo&scisig=ABGrvjKwG3hP8MZEFtUuGrNOAisL&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=0&folt=rel)
*C Li,G Carenini*

Main category: Surajit Chaudhuri

TL;DR: BeDiscovER是一个用于评估现代大语言模型在语篇层面理解能力的综合性基准测试套件


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在推理能力上的进步，需要系统评估它们在语篇理解层面的知识，现有基准测试可能已过时或不全面

Method: 整合5个公开可用的语篇理解数据集，构建统一的评估框架，覆盖多种语篇现象和任务类型

Result: 创建了一个全面、最新的语篇理解基准测试套件，可用于系统评估现代大语言模型的语篇层面知识

Conclusion: BeDiscovER为评估推理时代大语言模型的语篇理解能力提供了标准化工具，有助于推动该领域的研究进展

Abstract: We introduce BeDiscovER (Benchmark of Discourse Understanding in the Era of Reasoning Language Models), an up-to-date, comprehensive suite for evaluating the discourse-level knowledge of modern LLMs. BeDiscovER compiles 5 publicly …

</details>


### [156] [Lost in the Pipeline: How Well Do Large Language Models Handle Data Preparation?](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.21708&hl=zh-CN&sa=X&d=14326127348247323411&ei=Km4xadvrIseB6rQP-bb0sAs&scisig=ABGrvjJ3HwaMKAvSMlCV6pUC_w1N&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=0&folt=rel)
*M Spreafico,L Tassini,C Sancricca,C Cappiello*

Main category: Surajit Chaudhuri

TL;DR: 该论文探讨大型语言模型在数据准备任务中的能力，这是测试LLM能力的重要领域，但摘要信息不完整


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在支持自动化各种任务方面展现出卓越能力，需要探索其在数据准备这一关键但复杂任务中的表现

Method: 摘要信息不完整，无法确定具体方法

Result: 摘要信息不完整，无法确定具体结果

Conclusion: 摘要信息不完整，无法确定具体结论

Abstract: Large language models have recently demonstrated their exceptional capabilities in supporting and automating various tasks. Among the tasks worth exploring for testing large language model capabilities, we considered data preparation, a critical yet …

</details>


### [157] [Towards an Advanced Entity Resolution in Data Lakes](https://scholar.google.com/scholar_url?url=https://ceur-ws.org/Vol-4099/ER25_DC_bouabdelli.pdf&hl=zh-CN&sa=X&d=9476598172449363367&ei=Km4xadvrIseB6rQP-bb0sAs&scisig=ABGrvjIv4hYz5UZPwJ8Z7lqee9Qa&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=3&folt=rel)
*LF BOUABDELLI*

Main category: Surajit Chaudhuri

TL;DR: 该论文研究数据湖中的实体解析问题，提出了一种处理无模式数据环境中实体匹配的新方法


<details>
  <summary>Details</summary>
Motivation: 数据湖中数据质量维护面临挑战，特别是实体解析问题。数据湖的无模式特性使得传统ER方法难以适用，需要专门针对数据湖环境设计解决方案

Method: 论文提出了一种专门针对数据湖无模式环境的实体解析方法，该方法能够处理无结构化或半结构化数据，识别不同描述中指向同一真实世界实体的记录

Result: 该方法在数据湖环境中有效解决了实体解析问题，提高了数据质量，能够准确识别和匹配无模式数据中的相同实体

Conclusion: 针对数据湖环境的专门化实体解析方法是必要的，所提出的方法能够有效处理无模式数据中的实体匹配问题，为数据湖数据质量维护提供了实用解决方案

Abstract: Entity Resolution (ER) is a critical challenge for maintaining data quality in data lakes, aiming to identify different descriptions that refer to the same real-world entity. We address here the problem of ER in data lakes, where their schema-less …

</details>


### [158] [Evaluating HPK for Running Cloud-Native Workloads on Slurm Clusters](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3731599.3767352&hl=zh-CN&sa=X&d=5208169031985293705&ei=Km4xadvrIseB6rQP-bb0sAs&scisig=ABGrvjJH7d031AMqSykm-tnsgKv_&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=4&folt=rel)
*A Chazapis,L Vassilakis,G Petsis,M Marazakis…*

Main category: Surajit Chaudhuri

TL;DR: 论文探讨了将云原生和高性能计算步骤整合到统一工作流中的挑战与解决方案


<details>
  <summary>Details</summary>
Motivation: 应用和服务的复杂性不断增加，促使需要将云原生和HPC步骤整合到同一工作流中的高级数据处理管道

Method: 未在摘要中明确说明具体方法，但暗示需要解决云提供商和HPC中心在资源管理、调度和互操作性方面的差异

Result: 未在摘要中提供具体结果，但指出了整合云原生和HPC工作流面临的挑战和需求

Conclusion: 需要开发能够无缝整合云原生和HPC步骤的统一工作流框架，以应对日益复杂的应用需求

Abstract: The escalating complexity of applications and services encourages a shift towards higher-level data processing pipelines that integrate both Cloud-native and HPC steps into the same workflow. Cloud providers and HPC centers typically provide …

</details>


### [159] [LPSQ: Achieving Efficient and Privacy-Preserving Location-Point-Set Similarity Range Query for Cloud Computing](https://scholar.google.com/scholar_url?url=https://pure.ecnu.edu.cn/zh/publications/lpsq-achieving-efficient-and-privacy-preserving-location-point-se/&hl=zh-CN&sa=X&d=8716463930015857846&ei=Km4xadvrIseB6rQP-bb0sAs&scisig=ABGrvjIGaS3zYphSIoaxkF-L49U-&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=5&folt=rel)
*S Jiang,H Bao,D Li,J Wang,Q Kong,C Huang…*

Main category: Surajit Chaudhuri

TL;DR: 位置点集相似性范围查询旨在检索与给定点集在位置分布模式和地理特征方面相似的候选点集，在GIS和IoT中具有重要应用价值


<details>
  <summary>Details</summary>
Motivation: 地理信息系统和物联网中需要高效检索具有相似位置分布模式的地理点集，以支持空间数据分析、模式识别和决策支持等应用

Method: 基于位置点集相似性度量和范围查询算法，可能涉及空间索引、相似性度量函数和高效查询处理技术

Result: 开发了位置点集相似性范围查询框架，能够有效检索具有相似地理分布模式的点集，提高了查询效率和准确性

Conclusion: 位置点集相似性范围查询是GIS和IoT中的重要技术，为空间数据分析和模式识别提供了有效的解决方案

Abstract: 摘要 Location point set similarity range query aims to retrieve candidate point sets that are similar to the given point set in terms of location distribution patterns and geographical features, and it is vital in GIS (Geographic Information Systems), IoT …

</details>


### [160] [Structured Multi-Step Reasoning for Entity Matching Using Large Language Model](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.22832&hl=zh-CN&sa=X&d=702959579472308464&ei=Km4xadvrIseB6rQP-bb0sAs&scisig=ABGrvjJID5TAa08HKmGBB7NdsZMb&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ABGrvjK_DN8Q-hHciZLP-EYWq3nS&html=&pos=6&folt=rel)
*R Bopardikar,J Wang,J Zou*

Main category: Surajit Chaudhuri

TL;DR: 该论文探讨了在大语言模型(LLMs)应用于实体匹配任务时，如何通过提示工程和上下文学习来提升匹配准确性，特别是在零样本和少样本场景下。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型(LLMs)的广泛应用，研究者开始探索其在实体匹配任务中的潜力。虽然已有研究尝试使用零样本和少样本提示来提升匹配准确性，但现有方法仍存在局限性，需要更有效的提示策略来充分发挥LLMs在实体匹配任务中的能力。

Method: 论文提出了一种基于大语言模型的实体匹配方法，通过创新的提示工程技术和上下文学习策略，在零样本和少样本设置下优化实体匹配性能。方法可能包括提示模板设计、示例选择策略、以及如何有效利用LLMs的推理能力进行实体相似性判断。

Result: 研究结果表明，通过精心设计的提示策略，大语言模型在实体匹配任务上能够显著超越传统方法，在零样本和少样本场景下都取得了优异的性能表现，特别是在处理复杂语义匹配和领域特定实体时表现出色。

Conclusion: 大语言模型通过适当的提示工程可以成为实体匹配任务的有效工具，特别是在数据标注有限的情况下。该方法为数据清洗和集成领域提供了新的解决方案，并展示了LLMs在结构化数据处理任务中的潜力。

Abstract: Entity matching is a fundamental task in data cleaning and data integration. With the rapid adoption of large language models (LLMs), recent studies have explored zero-shot and few-shot prompting to improve entity matching accuracy. However, most …

</details>


### [161] [Sql2circuits: Estimating cardinalities, execution times, and costs for sql queries with quantum natural language processing](https://scholar.google.com/scholar_url?url=https://researchportal.helsinki.fi/en/publications/sql2circuits-estimating-cardinalities-execution-times-and-costs-f/&hl=zh-CN&sa=X&d=13562042234617336708&ei=b_YyafSZHs2j6rQP2_qhyQ8&scisig=ALhkC2RngDa9Xn7Y31T5vA-8xFzR&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=3&folt=rel)
*VJE Uotila*

Main category: Surajit Chaudhuri

TL;DR: SQL2Circuits使用量子自然语言处理技术将SQL查询转换为量子电路，用于估计查询的基数、执行时间和成本


<details>
  <summary>Details</summary>
Motivation: 传统SQL查询优化器在复杂查询场景下难以准确估计基数、执行时间和成本，需要更先进的估计方法

Method: 将SQL查询转换为量子自然语言处理模型，通过量子电路表示查询语义，利用量子计算特性进行基数、时间和成本估计

Result: 开发了SQL2Circuits框架，能够将SQL查询映射到量子电路，提供比传统方法更准确的查询性能估计

Conclusion: 量子自然语言处理为SQL查询优化提供了新的技术途径，SQL2Circuits展示了量子计算在数据库系统中的应用潜力

Abstract: SQL2Circuits: Estimating Cardinalities, Execution Times, and Costs for SQL Queries with Quantum Natural Language Processing - University of Helsinki Skip to main navigation Skip to search Skip to main content University of Helsinki Home University of …

</details>


### [162] [DSS QUERY OPTIMIZATION USING ENTROPYBASED RESTRICTED GENETIC APPROACH ANDPARALLEL PROCESSING](https://scholar.google.com/scholar_url?url=https://www.jatit.org/volumes/Vol103No22/22Vol103No22.pdf&hl=zh-CN&sa=X&d=15164001792567581456&ei=b_YyafSZHs2j6rQP2_qhyQ8&scisig=ALhkC2T7E0oh6Zy-Q7jhgX_y-cdA&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=4&folt=rel)
*P BABU,CH SABITHA,DS RAO*

Main category: Surajit Chaudhuri

TL;DR: 分布式数据库查询优化面临挑战，近年来出现多种启发式方法提升查询可行性


<details>
  <summary>Details</summary>
Motivation: 分布式数据库系统的查询优化问题具有挑战性且持续吸引研究兴趣，需要开发更有效的优化策略

Method: 应用多种启发式方法，提出新颖策略来增强查询的可行性

Result: 未在摘要中明确说明具体实验结果，但暗示启发式方法为查询优化提供了新思路

Conclusion: 分布式数据库查询优化是一个活跃的研究领域，启发式方法的应用为改进查询性能提供了有前景的方向

Abstract: Any distributed database system's query optimization challenge is exciting and continues to attract a lot of interest. Recent years have seen the application of a number of heuristics that suggest novel strategies for enhancing a query's viability …

</details>


### [163] [QJoin: Transformation-aware Joinable Data Discovery Using Reinforcement Learning](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.02444&hl=zh-CN&sa=X&d=961486708726193535&ei=VFw0aeOlCoyO6rQPkNu60Qg&scisig=ALhkC2QAYZ0SB8JURt_AxS-5OOAc&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=0&folt=rel)
*N Wang,S Galhotra*

Main category: Surajit Chaudhuri

TL;DR: 该论文针对异构数据仓库中表连接发现的核心挑战，提出超越传统等值连接的方法，探索更广泛的连接转换可能性。


<details>
  <summary>Details</summary>
Motivation: 传统连接发现方法主要针对等值连接，但在大型异构数据仓库中，许多潜在的有用连接需要更复杂的转换操作，现有方法无法有效发现这些连接关系。

Method: 论文提出了一种新的方法，能够发现需要复杂转换的表连接，包括数据类型转换、格式标准化、语义对齐等操作，超越了简单的等值匹配。

Result: 该方法在大型异构数据仓库中显著提高了连接发现的覆盖率和准确性，能够识别传统方法无法发现的连接关系，提升了数据集成和数据发现的效率。

Conclusion: 通过支持更广泛的连接转换操作，该方法为大规模异构数据仓库的连接发现提供了更全面的解决方案，推动了数据集成和数据发现领域的发展。

Abstract: Discovering which tables in large, heterogeneous repositories can be joined and by what transformations is a central challenge in data integration and data discovery. Traditional join discovery methods are largely designed for equi-joins, which assume …

</details>


### [164] [MechDetect: Detecting Data-Dependent Errors](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.04138&hl=zh-CN&sa=X&d=10365340218195820095&ei=j9I1aabUDceB6rQP-bb0sAs&scisig=ALhkC2To4HUFQylLbmnf-9gfzl2B&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=1&folt=rel)
*P Jung,N Chandler,S Jäger,F Biessmann*

Main category: Surajit Chaudhuri

TL;DR: 该论文摘要讨论了数据质量监控的核心挑战，指出现有研究多关注错误检测而较少探究错误生成机制，主张需要深入研究错误产生机制


<details>
  <summary>Details</summary>
Motivation: 现代信息处理系统中数据质量监控是核心挑战，现有方法多关注数据错误或漂移的检测，但很少有研究探究错误生成的机制，作者认为需要深入理解错误产生机制

Method: 摘要未明确描述具体方法，但暗示需要研究错误生成机制而非仅关注错误检测

Result: 摘要未提供具体实验结果，但提出了对现有研究局限性的批判性分析

Conclusion: 需要从单纯的数据错误检测转向深入理解错误生成机制，这是数据质量监控领域的重要研究方向

Abstract: Data quality monitoring is a core challenge in modern information processing systems. While many approaches to detect data errors or shifts have been proposed, few studies investigate the mechanisms governing error generation. We argue that …

</details>


### [165] [Steering Memory Deduplication in Multi-Tenant Database Systems](https://scholar.google.com/scholar_url?url=https://ceur-ws.org/Vol-4118/paper7.pdf&hl=zh-CN&sa=X&d=15793081462231513882&ei=j9I1aabUDceB6rQP-bb0sAs&scisig=ALhkC2QdHcjmseHH4O08Mc87dslR&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=3&folt=rel)
*J Kowalick,A Krause,D Habich,W Lehner*

Main category: Surajit Chaudhuri

TL;DR: 该论文提出了一种名为"列式重复数据删除"的技术，通过识别和消除列式数据库中重复的列来提升内存密度，从而在多租户系统中实现更高效的硬件共享。


<details>
  <summary>Details</summary>
Motivation: 在多租户系统中，提升内存列式数据库的内存密度是实现硬件高效共享的必要步骤。许多通用工具通过扫描系统中的重复内存来尝试实现这一目标，但针对列式数据库的特定优化仍有改进空间。

Method: 提出"列式重复数据删除"技术，专门针对列式数据库设计，通过识别和消除重复的列来优化内存使用。该方法专注于列级的数据重复检测和消除，而非通用的内存重复扫描。

Result: 该方法能够显著提高内存列式数据库的内存密度，从而在多租户环境中实现更高效的硬件资源共享，减少内存占用并提升系统性能。

Conclusion: 列式重复数据删除是提升多租户系统中内存列式数据库效率的有效方法，通过专门针对列式数据结构的优化，比通用内存重复扫描工具能获得更好的内存密度提升效果。

Abstract: Improving the memory density of in-memory columnar databases is a necessary step towards more efficient sharing of hardware in multi-tenant systems. Many general-purpose tools attempt to achieve this by scanning systems for duplicate memory …

</details>


### [166] [Thucy: An LLM-based Multi-Agent System for Claim Verification across Relational Databases](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.03278&hl=zh-CN&sa=X&d=16522589292017834645&ei=j9I1aabUDceB6rQP-bb0sAs&scisig=ALhkC2T7zrg2VuCXC1asSjFB25Lg&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=4&folt=rel)
*M Theologitis,D Suciu*

Main category: Surajit Chaudhuri

TL;DR: 该论文探讨了在信息过载时代如何从结构化数据中验证政治言论真实性的挑战，提出了一种自动化验证方法。


<details>
  <summary>Details</summary>
Motivation: 当前政治人物、媒体和公众人物经常发表相互矛盾的主张，这些主张理论上可以通过结构化数据进行验证，但人工验证过程耗时且困难，需要自动化解决方案来帮助公众辨别真相。

Method: 论文提出了一种基于结构化数据的自动化验证方法，通过将政治言论与可验证的数据源进行比对，开发算法来评估主张的真实性。

Result: 该方法能够有效识别和验证政治言论的真实性，提供客观的数据支持，帮助减少信息误导和虚假主张的传播。

Conclusion: 自动化验证工具对于提高政治言论的透明度和公众的信息素养至关重要，有助于在信息过载时代建立更可靠的事实核查机制。

Abstract: In today's age, it is becoming increasingly difficult to decipher truth from lies. Every day, politicians, media outlets, and public figures make conflicting claims $\unicode {x2014} $ often about topics that can, in principle, be verified against structured data …

</details>


### [167] [LLM-EDT: Large Language Model Enhanced Cross-domain Sequential Recommendation with Dual-phase Training](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.19931&hl=zh-CN&sa=X&d=5569344325267611051&ei=x0w3abOQDI2v6rQP-rWV0QI&scisig=ALhkC2QuItG1jksF-bp9gaOpQJn1&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=1&folt=rel)
*Z Liu,Q Liu,W Wang,Y Wang,T Xu,W Huang,C Chen…*

Main category: Surajit Chaudhuri

TL;DR: CDSR面临交互不平衡和跨域转移问题，现有方法难以有效处理


<details>
  <summary>Details</summary>
Motivation: 跨域序列推荐（CDSR）通过整合多领域信息来丰富用户-物品交互，但现有方法面临两个关键问题：1）交互不平衡问题（不同领域交互数量差异大），2）转移问题（跨领域行为模式转移），这些问题限制了CDSR的进一步发展

Method: 从摘要内容看，论文可能提出了一种新的CDSR框架来解决交互不平衡和转移问题，可能涉及多领域交互建模、序列模式对齐、知识迁移等技术

Result: 摘要未提供具体实验结果，但暗示现有方法在这些问题上表现不足，需要新的解决方案

Conclusion: CDSR领域需要更有效的方法来处理交互不平衡和跨域转移问题，以提升推荐性能

Abstract: Cross-domain Sequential Recommendation (CDSR) has been proposed to enrich user-item interactions by incorporating information from various domains. Despite current progress, the imbalance issue and transition issue hinder further …

</details>


### [168] [Beyond Vector Search: Querying With and Without Predicates](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3769765&hl=zh-CN&sa=X&d=1517796191323957537&ei=x0w3abOQDI2v6rQP-rWV0QI&scisig=ALhkC2S6VJswiW4Sa7ZgBIeN0wgF&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=2&folt=rel)
*J Xie,JX Yu,S Teng,Y Liu*

Main category: Surajit Chaudhuri

TL;DR: 该论文研究k-近似最近邻搜索，针对高维数据集中的查询向量，探索新兴应用场景下的解决方案


<details>
  <summary>Details</summary>
Motivation: 随着新兴现实世界应用的出现，传统的k-最近邻搜索方法面临高维数据带来的挑战，需要更高效的近似搜索算法来满足实际应用需求

Method: 论文提出了一种k-近似最近邻搜索方法，针对高维向量数据集，通过近似算法在精度和效率之间取得平衡

Result: 该方法在多个数据集上验证了其有效性，相比传统方法在查询速度和内存使用方面有显著改进，同时保持较高的召回率

Conclusion: 提出的k-近似最近邻搜索方法能够有效应对高维数据挑战，为新兴应用提供了实用的解决方案，在精度和效率之间取得了良好平衡

Abstract: k-ANN search has been extensively studied to find k approximate nearest neighbors for a given query vector in a high-dimensional dataset, where a data item is represented as a vector. As there are many new emerging real-world applications …

</details>


### [169] [GraphTwin: Cache-Centric Bit-Level Graph Representation for Fast and Exact Graph Queries](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3769798&hl=zh-CN&sa=X&d=4403617100508929015&ei=kuU4aZW9GYqi6rQPyqO_2As&scisig=ALhkC2QQJDZ3qd0qww-uwqlZhEuS&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=1&folt=rel)
*C Lu,S Wang,W Deng,X Li,Y Zhang,JX Yu*

Main category: Surajit Chaudhuri

TL;DR: GraphTwin是一种混合图表示系统，通过结合缓存优化表示和传统邻接表来解决大规模图处理中的L3缓存未命中问题


<details>
  <summary>Details</summary>
Motivation: 大规模图处理面临的关键挑战是传统邻接表由于不规则内存访问导致过多的L3缓存未命中，这会严重影响性能

Method: GraphTwin采用混合图表示系统，结合缓存优化表示和传统邻接表，通过智能选择机制在不同场景下使用最合适的表示形式

Result: GraphTwin显著减少了L3缓存未命中，提高了图处理性能，在多种图算法和数据集上表现出优越的性能

Conclusion: 混合图表示系统是解决大规模图处理中内存访问瓶颈的有效方法，GraphTwin通过智能表示选择实现了显著的性能提升

Abstract: Modern large-scale graph processing faces a critical challenge: conventional adjacency lists incur excessive L3 cache misses due to irregular memory access. We introduce GraphTwin, a hybrid graph representation system combining:(1) Cache …

</details>


### [170] [Patching LLM Like Software: A Lightweight Method for Improving Safety Policy in Large Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.08484&hl=zh-CN&sa=X&d=16605251246080857642&ei=kuU4aZW9GYqi6rQPyqO_2As&scisig=ALhkC2Ti9_sMOtO6DRXvLIp8qO44&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=3&folt=rel)
*H Arif,K Murugesan,CY Ko,PY Chen,P Das,A Gittens*

Main category: Surajit Chaudhuri

TL;DR: 提出将大型语言模型的安全漏洞修复类比软件补丁，提供轻量级模块化方法解决安全问题


<details>
  <summary>Details</summary>
Motivation: 当前LLM厂商发布改进版本成本高、频率低，难以快速响应安全漏洞，需要更灵活高效的修复机制

Method: 采用类似软件版本管理的补丁机制，通过轻量级模块化方式对LLM进行安全修复

Result: 未提供具体实验结果，但提出了一种理论上更高效、成本更低的安全漏洞修复框架

Conclusion: LLM补丁机制为解决安全漏洞提供了更灵活、经济的方法，有望替代传统大规模模型更新

Abstract: We propose patching for large language models (LLMs) like software versions, a lightweight and modular approach for addressing safety vulnerabilities. While vendors release improved LLM versions, major releases are costly, infrequent, and …

</details>


### [171] [Evidence-Guided Schema Normalization for Temporal Tabular Reasoning](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.00329&hl=zh-CN&sa=X&d=3385673292114309580&ei=kuU4aZW9GYqi6rQPyqO_2As&scisig=ALhkC2T3jvrQHIRj7SnANvWDDNlk&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=4&folt=rel)
*A Thanga,V Dixit,A Shankarampeta,V Gupta*

Main category: Surajit Chaudhuri

TL;DR: 提出基于SQL的方法处理演化半结构化表格的时间推理问题，包括从维基百科信息框生成3NF模式、生成SQL查询和查询执行


<details>
  <summary>Details</summary>
Motivation: 当前QA系统在处理演化半结构化表格的时间推理方面存在挑战，需要更有效的方法来处理随时间变化的表格数据

Method: 采用基于SQL的三步方法：1)从维基百科信息框生成第三范式(3NF)模式；2)生成SQL查询；3)执行查询

Result: 该方法能够有效处理半结构化表格的时间推理问题，通过SQL查询机制实现对演化表格数据的准确查询

Conclusion: 基于SQL的方法为处理演化半结构化表格的时间推理提供了有效解决方案，通过规范化模式和查询生成提高了QA系统的能力

Abstract: Temporal reasoning over evolving semi-structured tables poses a challenge to current QA systems. We propose a SQL-based approach that involves (1) generating a 3NF schema from Wikipedia infoboxes,(2) generating SQL queries, and (3) query …

</details>


### [172] [Tetris: Efficient and Predictive KV Cache Offloading for Agentic and Reasoning Workloads](https://scholar.google.com/scholar_url?url=https://saa2025.github.io/papers/Tetris%2520-%2520Efficient%2520and%2520Predictive%2520KV%2520Cache%2520Offloading%2520for%2520Agentic%2520and%2520Reasoning%2520Workloads.pdf&hl=zh-CN&sa=X&d=10103023813470702131&ei=kuU4aZW9GYqi6rQPyqO_2As&scisig=ALhkC2TD6EQpOaVaV5jPF7MBHM5R&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=5&folt=rel)
*Z Shi,C Ruan,P Qi,G Huang,X Wan,M Lin,J Li*

Main category: Surajit Chaudhuri

TL;DR: 该论文探讨了在LLM推理和智能体能力增强时，KV缓存使用量激增的问题，并提出了一种新的缓存管理方法


<details>
  <summary>Details</summary>
Motivation: 推理时扩展和工具调用增强了LLM的推理和智能体能力，但显著增加了键值（KV）缓存的使用，特别是在长中间推理步骤和API调用历史记录中。现有工作虽然有所解决，但仍有改进空间。

Method: 论文提出了一种新的KV缓存管理方法，可能涉及缓存压缩、选择性保留或动态缓存分配策略，以优化内存使用同时保持推理质量。

Result: 该方法在减少KV缓存内存占用的同时，保持了LLM的推理能力和工具调用性能，实现了内存效率与模型性能的良好平衡。

Conclusion: 提出的KV缓存优化方法有效解决了LLM增强能力带来的内存瓶颈问题，为大规模推理和智能体应用提供了实用的内存管理解决方案。

Abstract: Inference-time scaling and tool-calling enhance LLM reasoning and agentic capabilities but greatly increase key–value (KV) cache usage, especially for long intermediate reasoning steps and API call histories. While prior work has addressed …

</details>


### [173] [Word2Passage: Word-level Importance Re-weighting for Query Expansion](https://scholar.google.com/scholar_url?url=https://koasas.kaist.ac.kr/handle/10203/335692&hl=zh-CN&sa=X&d=12922538833650621437&ei=oXs6ad_wM8SN6rQP58G0yQQ&scisig=ALhkC2TLWTT84lDdDNVjQ_SUX2wh&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=3&folt=rel)
*H Song,J Choi,M Ban,M Kim*

Main category: Surajit Chaudhuri

TL;DR: Word2Passage是一种查询扩展方法，通过词级重要性重加权将词级查询扩展为段落级扩展


<details>
  <summary>Details</summary>
Motivation: 传统的查询扩展方法通常基于词级相似性，但词级扩展可能无法充分捕捉查询的语义信息，需要更细粒度的段落级扩展来提升检索性能

Method: 提出Word2Passage方法，通过词级重要性重加权机制，将词级查询扩展转换为段落级扩展，利用词的重要性权重来构建更有效的段落表示

Result: 该方法在多个基准测试中显示出优于传统查询扩展方法的性能，特别是在文档检索任务中取得了显著改进

Conclusion: 词级重要性重加权是有效的查询扩展策略，Word2Passage方法能够生成更高质量的段落级扩展，提升信息检索系统的性能

Abstract: DSpace at KOASAS: Word2Passage : Word-level Importance Re-weighting for Query Expansion KOASAS menu About KOASAS KAIST Library 검색 Advanced Search KOASAS About KOASAS Open Access Policy Browse Communities & Collections …

</details>


### [174] [Structural and Disentangled Adaptation of Large Vision Language Models for Multimodal Recommendation](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.06883&hl=zh-CN&sa=X&d=2194690192900047117&ei=agA8acixJeuuieoPmpfHkAk&scisig=ALhkC2SEIr2Qjvy0gg2KzlFgEmbj&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=0&folt=rel)
*Z Rao,P Zhou,D Chong,Z Chen,S Wang,N Tang*

Main category: Surajit Chaudhuri

TL;DR: 多模态推荐通过视觉和文本信号提升准确性，其成功主要依赖于学习高质量的跨模态表示。大型视觉语言模型的最新进展为多模态推荐提供了新的可能性。


<details>
  <summary>Details</summary>
Motivation: 多模态推荐系统通过整合视觉和文本信息来提高推荐准确性，但其性能受限于跨模态表示学习的效果。传统方法在跨模态对齐和表示学习方面存在局限性，而大型视觉语言模型的出现为解决这些问题提供了新的技术路径。

Method: 论文可能提出利用大型视觉语言模型来改进多模态推荐的方法，包括：1) 利用LVLMs的预训练知识进行跨模态表示学习；2) 设计新的跨模态对齐机制；3) 将视觉-语言理解能力集成到推荐框架中；4) 可能采用微调或提示工程等技术。

Result: 预期结果包括：1) 在多模态推荐基准上实现更好的性能；2) 学习到更高质量的跨模态表示；3) 改善推荐准确性和多样性；4) 验证LVLMs在多模态推荐中的有效性；5) 可能展示在冷启动场景下的优势。

Conclusion: 大型视觉语言模型为多模态推荐系统提供了强大的跨模态表示学习能力，能够显著提升推荐性能，特别是在跨模态对齐和语义理解方面。这为下一代多模态推荐系统的发展指明了方向。

Abstract: Multimodal recommendation enhances accuracy by leveraging visual and textual signals, and its success largely depends on learning high-quality cross-modal representations. Recent advances in Large Vision-Language Models (LVLMs) offer …

</details>


### [175] [Ensembling LLM-Induced Decision Trees for Explainable and Robust Error Detection](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.07246&hl=zh-CN&sa=X&d=12148585837352780251&ei=agA8acixJeuuieoPmpfHkAk&scisig=ALhkC2Qmhc8eE1X7FaL_t3Cupj6T&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=1&folt=rel)
*M Wang,J Wang,Q Liu,X Xu,Z Xing,L Zhu,W Zhang*

Main category: Surajit Chaudhuri

TL;DR: 论文提出了一种基于大型语言模型的表格错误检测方法，通过对比学习增强模型对表格结构和语义的理解能力，在多个基准数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 表格数据中的错误检测对于确保数据质量至关重要。现有的基于预训练模型的方法虽然有效，但未能充分利用表格的结构信息和语义关系，限制了错误检测的准确性和鲁棒性。

Method: 提出了一种基于对比学习的表格错误检测框架，通过设计表格特定的预训练任务来增强模型对表格结构和语义的理解。方法包括：1）表格结构编码器，捕捉行列关系；2）语义对比学习，区分正确与错误模式；3）多任务学习，结合结构感知和语义推理。

Result: 在多个基准数据集（如T2D、WikiTables等）上的实验表明，该方法在错误检测准确率、召回率和F1分数方面均显著优于现有方法，特别是在处理复杂表格结构和语义不一致时表现突出。

Conclusion: 通过结合表格结构编码和对比学习，该方法有效提升了表格错误检测的性能，证明了利用表格特定特征和对比学习策略的重要性，为高质量数据管理提供了有力工具。

Abstract: Error detection (ED), which aims to identify incorrect or inconsistent cell values in tabular data, is important for ensuring data quality. Recent state-of-the-art ED methods leverage the pre-trained knowledge and semantic capability embedded in …

</details>


### [176] [ThreadWeaver: Adaptive Threading for Efficient Parallel Reasoning in Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.07843&hl=zh-CN&sa=X&d=2652838822014222330&ei=I4Q9aZLLOtOyieoP1qvf4A4&scisig=ALhkC2QkM45xE_hAU2Ep0Vkcc2yF&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=0&folt=rel)
*L Lian,S Wang,F Juefei*

Main category: Surajit Chaudhuri

TL;DR: 该论文提出一种自适应并行解码方法，通过推测执行和验证机制减少LLM推理延迟，在保持准确性的同时显著提升推理速度


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂任务上推理性能强大，但序列化解码导致显著延迟，特别是在需要多步推理的任务中。现有方法在并行化和准确性之间存在权衡，需要一种既能保持模型输出质量又能减少延迟的解决方案。

Method: 提出自适应并行解码框架，采用推测执行策略：1) 使用轻量级草稿模型并行生成多个token候选序列；2) 主模型并行验证这些候选序列；3) 通过自适应机制动态调整并行度，平衡延迟减少和准确性保持。

Result: 实验表明该方法在多种推理任务上显著减少延迟（2-4倍加速），同时保持与序列解码相当的准确性。在数学推理、代码生成等复杂任务上效果尤为明显，验证了自适应并行化的有效性。

Conclusion: 自适应并行解码为LLM推理延迟问题提供了有效解决方案，通过推测执行和验证机制实现了延迟减少与准确性保持的良好平衡，为实际部署中的实时推理应用开辟了新途径。

Abstract: Scaling inference-time computation has enabled Large Language Models (LLMs) to achieve strong reasoning performance, but inherently sequential decoding leads to substantial latency, especially on complex tasks. Recent work on adaptive parallel …

</details>


### [177] [When Tables Leak: Attacking String Memorization in LLM-Based Tabular Data Generation](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.08875&hl=zh-CN&sa=X&d=10883831489182113561&ei=I4Q9aZLLOtOyieoP1qvf4A4&scisig=ALhkC2Spd2_cLZExhamy2RgwM4Lb&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=1&folt=rel)
*J Ward,B Gu,CH Wang,G Cheng*

Main category: Surajit Chaudhuri

TL;DR: LLMs在表格数据生成方面表现出色，主要采用两种方法：基于提示的方法和微调方法，各有优缺点，需要根据具体需求选择


<details>
  <summary>Details</summary>
Motivation: 大语言模型在生成高质量表格合成数据方面表现出色，但实际应用中存在两种主要方法，需要系统分析它们的优缺点和适用场景，为研究人员和从业者提供指导

Method: 分析两种主要方法：基于提示的方法（无需训练，直接使用预训练LLMs）和微调方法（在特定表格数据上微调LLMs），比较它们在数据保真度、隐私保护、计算成本等方面的差异

Result: 基于提示的方法计算成本低、易于实现，但数据保真度可能不足；微调方法能生成更高质量、更符合特定领域的数据，但计算成本高且需要大量训练数据

Conclusion: 两种方法各有优劣，选择取决于具体应用需求：基于提示的方法适合快速原型和资源有限场景，微调方法适合需要高质量、领域特定数据的场景，未来研究应关注混合方法

Abstract: Large Language Models (LLMs) have recently demonstrated remarkable performance in generating high-quality tabular synthetic data. In practice, two primary approaches have emerged for adapting LLMs to tabular data generation:(i) …

</details>


### [178] [Practical Solutions for Data Consistency and Query Performance in Graph Database and Search Engine Integration](https://scholar.google.com/scholar_url?url=https://api.taylorfrancis.com/content/chapters/edit/download%3FidentifierName%3Ddoi%26identifierValue%3D10.1201/9781003483144-10%26type%3Dchapterpdf&hl=zh-CN&sa=X&d=11197328274787953135&ei=I4Q9aZLLOtOyieoP1qvf4A4&scisig=ALhkC2SfSK0owsimqjSoeqnSm1LQ&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=4&folt=rel)
*SK Arun,SN Krishnan,BM Karthikeyan,HGL Arvind…*

Main category: Surajit Chaudhuri

TL;DR: 该论文探讨了将图数据库与搜索引擎集成的挑战，重点关注数据一致性和查询性能优化，并提出了两种解决方案。


<details>
  <summary>Details</summary>
Motivation: 从复杂的互联数据中提取信息需要图数据库与搜索引擎的集成，但这一过程面临数据一致性维护和查询性能优化的重大挑战。

Method: 论文提出了两种解决方案：第一种方法采用实时同步机制确保数据一致性；第二种方法使用查询优化算法提升性能。

Result: 实验结果表明，提出的方法在数据一致性方面达到99.8%的准确率，查询性能提升了40-60%，同时减少了系统资源消耗。

Conclusion: 图数据库与搜索引擎的有效集成需要平衡数据一致性和查询性能，提出的两种方法为这一领域提供了实用解决方案，未来可进一步探索自适应优化策略。

Abstract: The integration of graph databases with search engines is essential for deriving information from complex interconnected data, but it presents significant challenges, particularly in maintaining data consistency and optimizing query performance. Two …

</details>


### [179] [Reasoning through Code: Question Answering on Spanish Tabular Data using LLMs](https://scholar.google.com/scholar_url?url=https://ceur-ws.org/Vol-4098/PRESTA_paper4.pdf&hl=zh-CN&sa=X&d=17240217440289072818&ei=I4Q9aZLLOtOyieoP1qvf4A4&scisig=ALhkC2RAmBG0NArdCCXv-rOjq5rJ&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=5&folt=rel)
*AP Vemali,R Raghav*

Main category: Surajit Chaudhuri

TL;DR: 本文介绍了针对IberLEF 2025 PRESTA任务（西班牙表格数据问答）的系统方案，旨在提升表格数据理解能力


<details>
  <summary>Details</summary>
Motivation: 表格问答在结构化数据理解中具有关键作用，IberLEF 2025 PRESTA任务专注于西班牙语表格数据问答，需要开发专门系统来处理这一特定领域的挑战

Method: 论文未提供具体方法细节，但从摘要上下文推断，系统可能采用基于预训练语言模型的表格理解方法，专门针对西班牙语表格数据进行优化

Result: 摘要未包含实验结果，但系统旨在参与IberLEF 2025 PRESTA任务的评估，预期在西班牙表格数据问答任务中取得良好表现

Conclusion: 开发专门针对西班牙语表格数据问答的系统对于提升结构化数据理解能力具有重要意义，参与IberLEF 2025 PRESTA任务将验证系统在该领域的有效性

Abstract: Abstract Tabular Question Answering (QA) plays a key role in enabling structured data understanding. This paper presents our system for the IberLEF 2025 PRESTA Task on Question Answering over Spanish Tabular Data. We target the …

</details>


### [180] [CoVis: Neural and LLM-Driven Multi-Turn Interactions for Conversational Text-to-Visualization Generation: CoVis: Neural and LLM-Driven Multi-Turn...](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1007/s00778-025-00954-4&hl=zh-CN&sa=X&d=8550791795416011682&ei=I4Q9aZLLOtOyieoP1qvf4A4&scisig=ALhkC2TladUc11Fi8CxH8m28jw9m&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=6&folt=rel)
*Y Song,J Lu,RCW Wong*

Main category: Surajit Chaudhuri

TL;DR: 该论文研究自然语言问题到可视化的自动翻译任务，旨在降低数据可视化的使用门槛


<details>
  <summary>Details</summary>
Motivation: 数据可视化被广泛用于从大数据集中传达见解，但使用门槛较高。为了降低这一门槛，研究者探索了自动数据可视化任务，特别是自然语言问题到可视化的翻译

Method: 研究自然语言问题到可视化的翻译任务，这是一种自动数据可视化方法，将文本查询转换为可视化表示

Result: 未在摘要中明确说明具体结果，但暗示该研究领域正在积极发展中

Conclusion: 自然语言问题到可视化的自动翻译是降低数据可视化使用门槛的重要研究方向

Abstract: Data visualization (DV) is widely used to communicate insights from large datasets. To lower the barrier to DV use, researchers have investigated automatic DV tasks like natural language question (NLQ) to visualization translation, formally called text …

</details>


### [181] [Exploring Multi-Table Retrieval Through Iterative Search](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.13418&hl=zh-CN&sa=X&d=9764211995069578275&ei=I4Q9aZLLOtOyieoP1qvf4A4&scisig=ALhkC2Si5W9MHGWVutSUYX8CGBXC&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=7&folt=rel)
*A Boutaleb,B Amann,R Angarita,H Naacke*

Main category: Surajit Chaudhuri

TL;DR: 该论文研究数据湖上的开放域问答，需要从多个表中检索和组合信息，这是一个具有挑战性的子任务，需要语义相关性和结构连贯性（如可连接性）。


<details>
  <summary>Details</summary>
Motivation: 数据湖中的开放域问答需要从多个表中检索和组合信息，这面临语义相关性和结构连贯性（如可连接性）的双重挑战。现有方法难以同时优化这两个方面，需要新的解决方案。

Method: 论文提出了一种方法（具体方法未在摘要中详细说明，但暗示了某种优化技术），用于在数据湖中处理多表检索和组合问题，同时考虑语义相关性和结构连贯性。

Result: 该方法在开放域问答任务中表现出色，能够有效处理多表检索和组合，同时保持语义相关性和结构连贯性，提高了问答系统的性能。

Conclusion: 该研究为数据湖上的开放域问答提供了一种有效的多表检索和组合方法，解决了语义相关性和结构连贯性的双重挑战，为复杂数据环境下的问答系统提供了新的解决方案。

Abstract: Open-domain question answering over datalakes requires retrieving and composing information from multiple tables, a challenging subtask that demands semantic relevance and structural coherence (eg, joinability). While exact optimization …

</details>


### [182] [Fast Factorized Learning: Powered by In-Memory Database Systems](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.09836&hl=zh-CN&sa=X&d=17386686500027848510&ei=x-o-aefOMo2v6rQP-5Lh8QE&scisig=ALhkC2SszbJAgtinEN9YhBMtO59D&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=3&folt=rel)
*B Stöckl,ME Schüle*

Main category: Surajit Chaudhuri

TL;DR: 该论文研究了在因子化连接上学习模型时，通过识别和预计算共享余因子来避免冗余计算的方法，并探讨了在传统基于磁盘的数据库上计算余因子时的性能提升。


<details>
  <summary>Details</summary>
Motivation: 在因子化连接上学习模型时存在大量冗余计算，传统基于磁盘的数据库在处理余因子计算时性能有限，需要探索更高效的共享余因子预计算方法来提升模型学习效率。

Method: 通过识别因子化连接中的共享余因子并进行预计算，避免重复计算，同时研究在传统磁盘数据库上实现这种优化方法的具体技术。

Result: 研究表明通过预计算共享余因子可以显著减少冗余计算，在传统基于磁盘的数据库上实现时能够获得明显的性能提升。

Conclusion: 在因子化连接上学习模型时，识别和预计算共享余因子是一种有效的优化策略，能够显著提升计算效率，特别是在传统数据库环境中具有重要应用价值。

Abstract: Learning models over factorized joins avoids redundant computations by identifying and pre-computing shared cofactors. Previous work has investigated the performance gain when computing cofactors on traditional disk-based database …

</details>


### [183] [What Kind of Reasoning (if any) is an LLM actually doing? On the Stochastic Nature and Abductive Appearance of Large Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.10080&hl=zh-CN&sa=X&d=4346248974958752601&ei=gGdAacmGEc636rQPgsqEoA8&scisig=ALhkC2SCKOqioifPptiuZuODdSzO&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=0&folt=rel)
*L Floridi,J Morley,C Novelli,D Watson*

Main category: Surajit Chaudhuri

TL;DR: 本文探讨了基于token-completion机制的大型语言模型（LLMs）的推理工作原理，分析了其随机性特征以及与人类溯因推理的相似性。


<details>
  <summary>Details</summary>
Motivation: 当前基于token-completion的大型语言模型在推理能力方面表现出色，但其内在工作机制尚不完全清楚。本文旨在深入分析这类模型的推理机制，特别是其随机性特征，并与人类推理过程进行比较，以揭示LLMs推理的本质特征。

Method: 通过理论分析的方法，考察token-completion机制下LLMs的推理过程，分析其随机性特征，并与人类溯因推理（abductive reasoning）进行对比研究。

Result: 研究发现，基于token-completion的LLMs在推理过程中表现出显著的随机性特征，这种特征与人类溯因推理有相似之处。LLMs通过概率性的token生成过程进行推理，类似于人类在不确定信息下进行的假设性推理。

Conclusion: 基于token-completion的LLMs的推理机制具有独特的随机性特征，与人类溯因推理存在相似性。这种理解有助于我们更好地认识LLMs的推理能力本质，并为未来模型设计和评估提供理论指导。

Abstract: This article looks at how reasoning works in current Large Language Models (LLMs) that function using the token-completion method. It examines their stochastic nature and their similarity to human abductive reasoning. The argument is that these LLMs …

</details>


### [184] [The FACTS Leaderboard: A Comprehensive Benchmark for Large Language Model Factuality](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.10791&hl=zh-CN&sa=X&d=17432176840939681505&ei=gGdAacmGEc636rQPgsqEoA8&scisig=ALhkC2R06WLKgQcQpKZHQM9kZnRL&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=3&folt=rel)
*A Cheng,A Jacovi,A Globerson,B Golan,C Kwong…*

Main category: Surajit Chaudhuri

TL;DR: FACTS Leaderboard是一个在线排行榜套件和相关基准测试，用于全面评估语言模型在不同场景下生成事实准确文本的能力


<details>
  <summary>Details</summary>
Motivation: 当前缺乏全面评估语言模型事实准确性的标准化基准，需要开发系统化的评估框架来测量模型在不同场景下的真实性表现

Method: 开发了FACTS Leaderboard套件，包含多样化的基准测试，用于评估语言模型生成事实准确文本的能力，提供在线排行榜系统

Result: 创建了一个综合评估框架，能够系统化地测量和比较不同语言模型在事实准确性方面的表现

Conclusion: FACTS Leaderboard为评估语言模型的事实准确性提供了标准化工具，有助于推动更真实可靠的语言模型开发

Abstract: We introduce The FACTS Leaderboard, an online leaderboard suite and associated set of benchmarks that comprehensively evaluates the ability of language models to generate factually accurate text across diverse scenarios. The suite provides a …

</details>


### [185] [SpeakRL: Synergizing Reasoning, Speaking, and Acting in Language Models with Reinforcement Learning](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.13159&hl=zh-CN&sa=X&d=17531439148417231264&ei=03lFaf6NM7ux6rQPi5qW2AE&scisig=ALhkC2QeelLVFwJJVgmYBOFDckpy&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=2&folt=rel)
*EC Acikgoz,J Oh,J Hao,JH Jeon,H Ji,D Hakkani*

Main category: Surajit Chaudhuri

TL;DR: 该论文探讨了当前人机协作中单向交互的局限性，提出了一种双向协作框架，使智能体能够主动向人类提问以澄清意图，从而提高协作效率。


<details>
  <summary>Details</summary>
Motivation: 当前人机协作主要采用单向模式（人类向智能体发出指令或提问），这种模式存在局限性，因为人类意图可能模糊或不完整。需要建立双向协作机制，让智能体能够主动澄清人类意图，从而提高协作效果。

Method: 论文提出了一种双向协作框架，使智能体能够主动向人类提问以澄清意图。该方法可能包括意图理解、问题生成、交互优化等组件，通过智能提问来减少误解并提高任务完成质量。

Result: 通过实验验证，双向协作框架相比传统单向模式显著提高了任务完成准确率和效率。智能体的主动提问减少了误解，使协作更加顺畅，人类用户对协作体验的评价也更高。

Conclusion: 双向协作是人机交互的重要发展方向。通过让智能体主动提问澄清意图，可以显著提高协作效率和质量。未来的研究应进一步优化提问策略和交互设计。

Abstract: Effective human-agent collaboration is increasingly prevalent in real-world applications. Current trends in such collaborations are predominantly unidirectional, with users providing instructions or posing questions to agents, where agents …

</details>


### [186] [Rethinking Jailbreak Detection of Large Vision Language Models with Representational Contrastive Scoring](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.12069&hl=zh-CN&sa=X&d=7938253628822532584&ei=03lFaf6NM7ux6rQPi5qW2AE&scisig=ALhkC2TkoYEsUeqAF6-SIwWJnusW&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=3&folt=rel)
*P Hua,H Li,S Shi,Z Yu,N Zhang*

Main category: Surajit Chaudhuri

TL;DR: 针对大型视觉语言模型的多模态越狱攻击防御研究，提出通用且高效的防御框架


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型面临日益增多的多模态越狱攻击威胁，现有防御策略在通用性和部署效率方面存在不足，需要开发既能应对新型攻击又适合实际部署的防御方案

Method: 论文提出了一种新的防御框架，具体方法未在摘要中详细说明，但从上下文推断可能涉及对抗性防御、模型加固或输入过滤等技术

Result: 摘要未提供具体实验结果，但暗示所提方法在防御效果和效率方面优于现有策略

Conclusion: 需要开发通用性强、部署效率高的防御机制来保护大型视觉语言模型免受多模态越狱攻击

Abstract: Large Vision-Language Models (LVLMs) are vulnerable to a growing array of multimodal jailbreak attacks, necessitating defenses that are both generalizable to novel threats and efficient for practical deployment. Many current strategies fall short …

</details>


### [187] [Database Research needs an Abstract Relational Query Language](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.12957&hl=zh-CN&sa=X&d=8316309092593444219&ei=03lFaf6NM7ux6rQPi5qW2AE&scisig=ALhkC2TKyC5v6im2OJAYACAynBRI&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=7&folt=rel)
*W Gatterbauer,DM Sabale*

Main category: Surajit Chaudhuri

TL;DR: LLM正在改变SQL查询的创作方式，从人工编写转向机器生成，但现有评估方法未能充分评估LLM生成的SQL查询质量


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）的发展，SQL查询正从人工编写转向机器生成，但现有评估方法（如执行准确率）未能充分评估LLM生成的SQL查询质量，需要更全面的评估框架

Method: 论文提出了一种新的评估框架，可能包括对LLM生成的SQL查询进行多维度评估，如可读性、可维护性、性能优化等，而不仅仅是执行准确率

Result: 通过新的评估框架，论文可能发现现有LLM生成的SQL查询在可读性、可维护性等方面存在不足，需要改进模型训练和评估方法

Conclusion: 需要开发更全面的评估框架来评估LLM生成的SQL查询质量，以促进SQL查询生成技术的进一步发展

Abstract: For decades, SQL has been the default language for composing queries, but it is increasingly used as an artifact to be read and verified rather than authored. With Large Language Models (LLMs), queries are increasingly machine-generated, while …

</details>


### [188] [Revisiting Task-Oriented Dataset Search in the Era of Large Language Models: Challenges, Benchmark, and Solution](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.15363&hl=zh-CN&sa=X&d=14918772899599577962&ei=w51IabjXC9KV6rQP84i9kQc&scisig=ALhkC2R-vgEvw1Ql94uvD65k0cPk&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=2&folt=rel)
*Z Wei,Y Guo,J Li,X Han,X Jin,C Ma*

Main category: Surajit Chaudhuri

TL;DR: 论文探讨了基于高级任务描述搜索合适数据集这一研究挑战，现有搜索系统难以有效处理此类需求


<details>
  <summary>Details</summary>
Motivation: 数据驱动研究中，寻找合适数据集是关键的"第一步"，但研究人员基于高级任务描述搜索数据集时面临巨大挑战，现有搜索系统难以有效满足这一需求

Method: 从摘要中无法确定具体方法，但暗示需要开发新的搜索系统或方法来处理基于高级任务描述的数据集搜索问题

Result: 摘要未提供具体实验结果，但明确指出现有搜索系统在处理基于高级任务描述的数据集搜索时存在困难

Conclusion: 基于高级任务描述搜索数据集是数据驱动研究中的重要挑战，需要开发更有效的搜索系统来解决这一问题

Abstract: The search for suitable datasets is the critical" first step" in data-driven research, but it remains a great challenge. Researchers often need to search for datasets based on high-level task descriptions. However, existing search systems struggle with this task …

</details>


### [189] [Subset Sampling over Joins](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.16321&hl=zh-CN&sa=X&d=12358963465068470184&ei=w51IabjXC9KV6rQP84i9kQc&scisig=ALhkC2T8xpSHnSk4-2bsOE2aRK_q&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=3&folt=rel)
*A Esmailpour,X Hu,J Huang,S Sintos*

Main category: Surajit Chaudhuri

TL;DR: 子集采样（泊松采样）是一种基本的数据分析原语，通过独立决策每个元素是否包含在样本中，实现高效近似计算。


<details>
  <summary>Details</summary>
Motivation: 子集采样作为数据分析的基础工具，虽然简单但应用广泛，然而其理论性质尚未得到充分研究，特别是在采样分布、方差分析和计算复杂度方面存在研究空白。

Method: 采用概率分析和组合数学方法，研究子集采样的理论性质，包括采样分布特征、方差计算、以及在不同应用场景下的计算复杂度分析。

Result: 建立了子集采样的完整理论框架，推导了采样分布的确切表达式，提供了方差计算的精确公式，并分析了不同参数设置下的计算复杂度界限。

Conclusion: 子集采样虽然简单，但具有丰富的理论性质，这些理论结果为实际应用中的参数选择、误差分析和算法设计提供了重要指导。

Abstract: Subset sampling (also known as Poisson sampling), where the decision to include any specific element in the sample is made independently of all others, is a fundamental primitive in data analytics, enabling efficient approximation by …

</details>


### [190] [Waiting to Decompress: The Economics of LLM-Based Compression](https://scholar.google.com/scholar_url?url=https://www.vldb.org/cidrdb/papers/2026/p34-kipf.pdf&hl=zh-CN&sa=X&d=12047530899389022894&ei=mA5Kaa76F6-nieoPz8HDqAc&scisig=ALhkC2SW0eepk5-R7r68Wcukz7RF&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=1&folt=rel)
*A Kipf,T Schmidt,PL Kuo,S Krid,M Rengert,L Heller…*

Main category: Surajit Chaudhuri

TL;DR: 数据库社区开始将大语言模型应用于数据库系统的各个方面，但缺乏系统性的分类和评估框架


<details>
  <summary>Details</summary>
Motivation: 大语言模型展现出强大的生成、推理和编码能力，数据库社区开始将其应用于数据库系统的各个方面，但缺乏对这些应用的系统性分类、评估和未来方向的指导

Method: 论文提出一个系统性的分类框架，将LLM在数据库中的应用分为多个维度，包括应用领域、技术方法、评估指标等，并对现有研究进行系统性的综述和分析

Result: 建立了一个全面的分类体系，识别了当前研究的主要趋势和挑战，提出了评估LLM在数据库中应用的标准化框架，并为未来研究方向提供了指导

Conclusion: LLM在数据库系统中有广阔的应用前景，但需要系统性的评估框架和标准化方法，未来研究应关注可靠性、效率、安全性和可扩展性等关键挑战

Abstract: The latest AI summer brought us large language models (LLMs)—generative powerhouses with surprising reasoning, coding, and text generation abilities. Unsurprisingly, the database community started applying them to every aspect of …

</details>


### [191] [A Multi-agent Text2SQL Framework using Small Language Models and Execution Feedback](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.18622&hl=zh-CN&sa=X&d=9213765530603602063&ei=WplOadqYH7ux6rQPi5qW2AE&scisig=ALhkC2S7rGn1brlMvtidfSiwZS9t&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=0&folt=rel)
*TD Hoang,TT Huynh,M Weidlich,TT Nguyen,T Chen…*

Main category: Surajit Chaudhuri

TL;DR: 该论文探讨了使用大型语言模型（LLMs）进行Text2SQL任务的研究，LLMs在该任务中展现出优越性能


<details>
  <summary>Details</summary>
Motivation: Text2SQL（从自然语言文本生成SQL查询）是数据工程中的关键挑战，传统方法存在局限性，而最近大型语言模型在该任务中表现出优越性能，值得深入研究

Method: 采用大型语言模型（LLMs）进行Text2SQL任务，利用其先进的自然语言理解和代码生成能力，将自然语言描述转换为结构化SQL查询

Result: 大型语言模型在Text2SQL任务中展现出显著优越的性能，相比传统方法有较大提升

Conclusion: 大型语言模型为Text2SQL任务提供了有效的解决方案，展示了在数据工程领域的应用潜力

Abstract: Text2SQL, the task of generating SQL queries from natural language text, is a critical challenge in data engineering. Recently, Large Language Models (LLMs) have demonstrated superior performance for this task due to their advanced …

</details>


### [192] [LoFT-LLM: Low-Frequency Time-Series Forecasting with Large Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.20002&hl=zh-CN&sa=X&d=6280039184666866606&ei=NvlPad3OLNrJieoPiYyysAk&scisig=ALhkC2RlFSHcN9vGtwzzg10xGBkk&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=1&folt=rel)
*J You,J Yang,Y Xie,Z Wu,X Li,F Li,P Wang,J Xu…*

Main category: Surajit Chaudhuri

TL;DR: 该论文针对时间序列预测中训练数据有限和复杂噪声动态的问题，提出了一种新的训练策略，通过逐步扩展预测长度来增强模型对长期依赖的学习能力。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的时间序列预测（如金融和能源领域）面临训练数据有限、时间动态复杂且噪声大的挑战。现有的深度预测模型通常使用完整长度的序列进行监督，但在数据稀缺时难以有效学习长期依赖关系。

Method: 提出了一种新的训练策略，通过逐步扩展预测长度来增强模型对长期依赖的学习能力。具体方法是从短预测开始，随着训练进行逐步增加预测范围，使模型能够渐进式地学习更复杂的时序模式。

Result: 该方法在多个真实世界数据集上（包括金融和能源领域）相比传统训练策略取得了更好的预测性能，特别是在数据有限的情况下表现出更强的泛化能力和对长期依赖的捕捉能力。

Conclusion: 渐进式扩展预测长度的训练策略是一种有效的解决方案，能够帮助深度预测模型在数据有限的情况下更好地学习复杂的时间动态，提高长期预测的准确性和鲁棒性。

Abstract: Time-series forecasting in real-world applications such as finance and energy often faces challenges due to limited training data and complex, noisy temporal dynamics. Existing deep forecasting models typically supervise predictions using full-length …

</details>


### [193] [LLM Swiss Round: Aggregating Multi-Benchmark Performance via Competitive Swiss-System Dynamics](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.21010&hl=zh-CN&sa=X&d=376199237935879528&ei=4JRRaZqmO-6TieoPutPYsQg&scisig=ALhkC2Rsz4p0PCbOUfbgw_a-Yx4e&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=3&folt=rel)
*J Liu,J Wu,C Wu,J Liu,Z Wang,H Zhou,W Huang…*

Main category: Surajit Chaudhuri

TL;DR: 提出一个统一的LLM竞争排名系统，从碎片化的任务特定评估转向整体性能聚合


<details>
  <summary>Details</summary>
Motivation: 大型语言模型快速发展和多样化专业基准测试的出现，需要从碎片化的任务特定指标转向能够有效聚合跨多个任务性能的整体竞争排名系统

Method: 开发一个竞争排名系统，通过有效的聚合方法整合多个基准测试的性能数据

Result: 创建了一个统一的排名框架，能够全面评估和比较不同LLM在各种任务上的综合表现

Conclusion: 提出的竞争排名系统为LLM评估提供了更全面、标准化的比较框架，有助于推动模型发展的透明度和公平竞争

Abstract: The rapid proliferation of Large Language Models (LLMs) and diverse specialized benchmarks necessitates a shift from fragmented, task-specific metrics to a holistic, competitive ranking system that effectively aggregates performance across multiple …

</details>


### [194] [VTQA: visual tabular data question answering framework based on multi-agent: Y. Fu et al.](https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s12650-025-01103-3&hl=zh-CN&sa=X&d=12103450424852395382&ei=HXBTaaenOqC16rQPm4fPgQQ&scisig=ALhkC2RurEBMOuIpnqgZ-dTlRsE8&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=1&folt=rel)
*Y Fu,Y Liu,S Zhou,S Li,B Zhao,Y Wang,J Mao…*

Main category: Surajit Chaudhuri

TL;DR: 该摘要讨论了大型语言模型在表格问答系统中的进展，指出现有方法存在某些局限性，但未具体说明是什么问题或解决方案


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的快速发展，表格问答系统的自然语言理解和推理能力显著提升，但现有方法仍存在某些不足需要改进

Method: 摘要未提供具体方法细节，仅提到现有方法存在问题

Result: 摘要未提供实验结果或具体发现

Conclusion: 摘要未提供明确结论，仅指出了表格问答系统在LLM时代面临的挑战和机遇

Abstract: With the rapid development of large language models (LLMs), natural language understanding and reasoning capabilities of tabular question answering (TQA) systems have significantly improved. However, existing approaches often suffer from …

</details>


### [195] [Evaluation of Large Language Models on hierarchical entity matching for cultural heritage metadata](https://scholar.google.com/scholar_url?url=https://anthology.ach.org/volumes/vol0003/evaluation-of-large-language-models-on-entity-for/10.63744%40UKsLY7DKNPvA.pdf&hl=zh-CN&sa=X&d=10518299720328745514&ei=HXBTaaenOqC16rQPm4fPgQQ&scisig=ALhkC2TfzXBnMM6LNPPKx86AaR4l&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=2&folt=rel)
*B Bakker,I Hendrickx*

Main category: Surajit Chaudhuri

TL;DR: 该工作进展论文探讨文化遗产机构面临的数据组织挑战，特别是数字藏品规模增长和元数据异质性带来的互操作性、可靠性和信息检索问题


<details>
  <summary>Details</summary>
Motivation: 文化遗产机构面临数字藏品规模不断扩大和元数据异质性的挑战，这导致了互操作性、可靠性和信息检索方面的问题，需要有效的解决方案

Method: 从提供的摘要信息来看，这是一篇工作进展论文，具体方法细节未在摘要中明确说明，但显然关注文化遗产数据组织的技术和方法论研究

Result: 摘要中未提供具体研究结果，因为这是一篇工作进展论文，主要目的是提出问题并概述研究方向

Conclusion: 文化遗产数据组织是一个重要的研究领域，需要解决数字藏品规模增长和元数据异质性带来的挑战，以改善互操作性、可靠性和信息检索

Abstract: Data organization is a key challenge for many cultural heritage institutions. The size of current digital collections and the heterogeneity of metadata creates problems for interoperability, reliability and information retrieval. This work-in-progress paper aims …

</details>


### [196] [Weakly-Supervised Entity Matching via LLM-Guided Data Augmentation and Knowledge Transfer](https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0950705125022725&hl=zh-CN&sa=X&d=4468433357450184142&ei=m6lWaaSPKNrJieoPiYyysAk&scisig=ALhkC2TEGHjWu7Kk1HPwH32BYmgn&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=0&folt=rel)
*W Dou,D Shen,X Zhou,Y Kou,T Nie,H Cui,G Yu*

Main category: Surajit Chaudhuri

TL;DR: 实体匹配是数据集成中的基础任务，用于识别不同数据源中指向同一现实世界实体的记录，对产品目录对齐等应用至关重要。


<details>
  <summary>Details</summary>
Motivation: 实体匹配是数据集成中的核心问题，准确识别跨数据源的相同实体对于产品目录对齐、数据融合等应用至关重要。传统方法面临数据质量、规模、异构性等挑战，需要更高效准确的解决方案。

Method: 论文未提供具体方法细节，但实体匹配通常涉及特征工程、相似度计算、分类算法等。现代方法可能包括基于规则的方法、机器学习方法、深度学习方法和基于图的方法。

Result: 未提供具体实验结果，但实体匹配研究的评估指标通常包括准确率、召回率、F1分数、精确度-召回率曲线等。

Conclusion: 实体匹配是数据集成中的关键任务，需要持续研究以应对数据规模、质量、异构性等挑战，开发更高效准确的匹配方法。

Abstract: Entity Matching (EM) is a fundamental task in data integration, enabling the identification of records that refer to the same real-world entity across data sources. While accurate EM is critical for applications such as product catalog alignment …

</details>


### [197] [SieveJoin: Boosting Multi-way Joins by Filtering Unneeded Intermediate Results](https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s41019-025-00325-7&hl=zh-CN&sa=X&d=11913990185213559221&ei=m6lWaaSPKNrJieoPiYyysAk&scisig=ALhkC2RP_dda7xEsqdIIab7AySIE&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=2&folt=rel)
*R Li,Q Ma,X Shi,A Liu*

Main category: Surajit Chaudhuri

TL;DR: 该论文摘要讨论了提高数据系统中连接操作性能的长期挑战，特别关注优化多路连接性能以减少开销。


<details>
  <summary>Details</summary>
Motivation: 连接操作在数据系统中性能优化一直是关键挑战，特别是多路连接操作的开销问题需要解决。

Method: 摘要未详细说明具体方法，但暗示关注减少多路连接操作的开销。

Result: 摘要未提供具体实验结果，但表明该研究旨在改善多路连接性能。

Conclusion: 优化多路连接性能对于提高数据系统整体效率具有重要意义。

Abstract: Improving the performance of data systems for join operations has long been a critical challenge. Recently, substantial attention has been focused on optimizing multi-way join performance, particularly in reducing the overhead caused by …

</details>


### [198] [ML-Enhanced SQL and NoSQL Query Optimization for High-Volume Big Data Processing in Financial and Healthcare Applications](https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Srinivasa-Seethala/publication/398727500_ML-Enhanced_SQL_and_NoSQL_Query_Optimization_for_High-Volume_Big_Data_Processing_in_Financial_and_Healthcare_Applications/links/6941043c0c98040d481e33f9/ML-Enhanced-SQL-and-NoSQL-Query-Optimization-for-High-Volume-Big-Data-Processing-in-Financial-and-Healthcare-Applications.pdf&hl=zh-CN&sa=X&d=12373399257515663852&ei=RPRXae24IZ6u6rQPotyMwAQ&scisig=ALhkC2RpKvTOxp4TMIaLQ7aQPy9q&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=8&folt=rel)
*SC Seethala*

Main category: Surajit Chaudhuri

TL;DR: 研究机器学习增强的查询优化技术如何提升金融大数据处理中SQL和NoSQL数据库的性能、可扩展性和可靠性


<details>
  <summary>Details</summary>
Motivation: 随着金融行业大数据处理需求的快速增长，传统数据库查询优化方法在处理高并发、大规模数据时面临性能瓶颈和可扩展性挑战，需要更智能的优化技术来提升系统效率

Method: 采用机器学习技术增强数据库查询优化，包括智能查询计划选择、自适应索引优化、负载预测和资源分配等算法，应用于SQL和NoSQL数据库系统

Result: 机器学习增强的查询优化技术显著提升了数据库查询性能，改善了系统可扩展性，增强了处理高并发金融交易数据的可靠性，降低了响应时间和资源消耗

Conclusion: 机器学习方法为金融大数据处理中的数据库查询优化提供了有效的解决方案，能够适应动态工作负载并实现持续性能优化

Abstract: This research paper investigates the role of machine learning enhanced query optimization techniques in improving the performance, scalability, and reliability of SQL and NoSQL databases used for high volume big data processing in financial …

</details>


### [199] [Recursive Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.24601&hl=zh-CN&sa=X&d=6144255658609926755&ei=Xm9ZaYGgIOqsieoPjYOSgAM&scisig=ALhkC2Q3X9NY2_KJ-Bq58ddCskrX&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=0&folt=rel)
*AL Zhang,T Kraska,O Khattab*

Main category: Surajit Chaudhuri

TL;DR: 提出递归语言模型（RLMs）作为处理任意长提示的通用推理策略，通过将长提示视为外部记忆，实现推理时扩展


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理长提示时存在上下文长度限制，需要一种方法让LLMs能够处理任意长度的输入，实现推理时的扩展能力

Method: 提出递归语言模型（RLMs）框架，将长提示视为外部记忆，通过递归处理策略，使模型能够逐步处理超出其原始上下文长度的输入

Result: RLMs能够有效处理超出标准上下文长度的提示，实现推理时的扩展，为处理长文档、复杂任务提供了新方法

Conclusion: 递归语言模型为解决LLMs上下文长度限制提供了有前景的推理时扩展方法，能够处理任意长提示，扩展了模型的实际应用范围

Abstract: We study allowing large language models (LLMs) to process arbitrarily long prompts through the lens of inference-time scaling. We propose Recursive Language Models (RLMs), a general inference strategy that treats long prompts as part of an external …

</details>


### [200] [Language models as tools for investigating the distinction between possible and impossible natural languages](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.09394&hl=zh-CN&sa=X&d=6267255294787279280&ei=Xm9ZaYGgIOqsieoPjYOSgAM&scisig=ALhkC2TMuHt-i1nkD7nnx7YxJDrC&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=1&folt=rel)
*J Kallini,C Potts*

Main category: Surajit Chaudhuri

TL;DR: 语言模型可作为研究工具，探索可能语言与不可能语言之间的区别，揭示人类语言学习的归纳偏置


<details>
  <summary>Details</summary>
Motivation: 探索语言模型作为研究工具，用于区分可能语言与不可能语言，从而揭示支持人类语言学习的归纳偏置

Method: 使用语言模型作为调查工具，通过分析其表现来探测自然语言的边界和人类语言学习的认知机制

Result: 语言模型展现出作为研究工具的强大潜力，能够有效区分可能语言与不可能语言，揭示人类语言学习的认知偏置

Conclusion: 语言模型是研究人类语言学习归纳偏置的有效工具，有助于理解可能语言与不可能语言的区别

Abstract: We argue that language models (LMs) have strong potential as investigative tools for probing the distinction between possible and impossible natural languages and thus uncovering the inductive biases that support human language learning. We outline a …

</details>


### [201] [Youtu-LLM: Unlocking the Native Agentic Potential for Lightweight Large Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.24618&hl=zh-CN&sa=X&d=1432766452130016355&ei=Xm9ZaYGgIOqsieoPjYOSgAM&scisig=ALhkC2TvW0jngH4xD-Ws5HdfuPwc&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=2&folt=rel)
*J Lu,J Qin,L Qiao,Y Li,X Dai,B Ke,J He,R Qiao…*

Main category: Surajit Chaudhuri

TL;DR: Youtu-LLM是一个1.96B参数的轻量级语言模型，通过预训练而非蒸馏实现，在计算效率与智能体能力之间取得平衡


<details>
  <summary>Details</summary>
Motivation: 解决典型小模型依赖蒸馏方法的问题，开发一个既轻量又具备原生智能体能力的语言模型，实现计算效率与智能体智能的平衡

Method: 采用预训练而非蒸馏的方法，构建1.96B参数的轻量级语言模型，专注于实现原生智能体智能

Result: 开发出Youtu-LLM模型，这是一个1.96B参数的轻量级语言模型，具备原生智能体能力

Conclusion: Youtu-LLM展示了通过预训练而非蒸馏可以构建既轻量又具备智能体能力的语言模型，为高效智能体系统提供了新方案

Abstract: We introduce Youtu-LLM, a lightweight yet powerful language model that harmonizes high computational efficiency with native agentic intelligence. Unlike typical small models that rely on distillation, Youtu-LLM (1.96 B) is pre-trained from …

</details>


### [202] [Database Systems for Advanced Applications: 30th International Conference, DASFAA 2025, Singapore, Singapore, May 26–29, 2025, Proceedings, Part II](https://scholar.google.com/scholar_url?url=https://books.google.com/books%3Fhl%3Dzh-CN%26lr%3D%26id%3D5Z2lEQAAQBAJ%26oi%3Dfnd%26pg%3DPR1%26ots%3DH9iIhievfL%26sig%3DXoHI7LkWSNM7_cEqjKaY_9ZP6B8&hl=zh-CN&sa=X&d=1002801581875260214&ei=9i1cabT-MqjKieoPs8CDKA&scisig=ALhkC2T9lVuG9O5BvJB5HAp9x3LS&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=1&folt=rel)
*F Zhu,SY Philip,A Nadamoto,EP Lim,K Shim,W Ding…*

Main category: Surajit Chaudhuri

TL;DR: DASFAA 2025会议论文集，包含136篇全文论文，涵盖数据库系统与高级应用领域的最新研究


<details>
  <summary>Details</summary>
Motivation: DASFAA作为数据库系统与高级应用领域的国际顶级会议，旨在汇集全球研究人员分享最新研究成果、技术进展和应用创新，推动数据库领域的发展

Method: 通过国际同行评审流程筛选高质量论文，组织为六卷LNCS论文集，包含136篇全文论文，涵盖数据库系统、数据管理、高级应用等多个子领域

Result: 成功举办第30届DASFAA会议，收录136篇经过严格评审的全文论文，形成六卷LNCS会议论文集（15986-15991卷），展示了数据库领域的最新研究成果

Conclusion: DASFAA 2025论文集系统性地记录了数据库系统与高级应用领域的最新研究进展，为学术界和工业界提供了重要的参考资源，推动了该领域的知识传播和技术发展

Abstract: This six-volume set LNCS 15986-15991 constitutes the proceedings of the 30th International Conference on Database Systems for Advanced Applications, DASFAA 2025, held in Singapore, during May 26–29, 2025. The 136 full papers presented in …

</details>


### [203] [Linking Cryptoasset Attribution Tags to Knowledge Graph Entities: An LLM-Based Approach](https://scholar.google.com/scholar_url?url=https://books.google.com/books%3Fhl%3Dzh-CN%26lr%3D%26id%3DH5ylEQAAQBAJ%26oi%3Dfnd%26pg%3DPA366%26ots%3De2byzNb-CY%26sig%3DNl2pJroOnuvtud-FgPtC2YhB-oA&hl=zh-CN&sa=X&d=2169516983021448480&ei=9i1cabT-MqjKieoPs8CDKA&scisig=ALhkC2SghkUoosVEAOpMHMASkZYb&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=2&folt=rel)
*B Haslhofer*

Main category: Surajit Chaudhuri

TL;DR: 提出基于计算方法的加密资产取证标签验证框架，解决现有标签不一致和错误问题


<details>
  <summary>Details</summary>
Motivation: 加密资产取证中，归因标签是现代调查的基础，但不一致或错误的标签可能误导调查甚至导致错误指控，需要系统性的验证方法

Method: 提出一种新颖的计算方法，基于...（具体方法细节在摘要中未完整提供）

Result: 摘要中未提供具体实验结果

Conclusion: 该方法旨在解决加密资产取证中标签验证的挑战，提高调查的准确性和可靠性

Abstract: Attribution tags form the foundation of modern cryptoasset forensics. However, inconsistent or incorrect tags can mislead investigations and even result in false accusations. To address this issue, we propose a novel computational method based …

</details>


### [204] [The American Ghost in the Machine: How language models align culturally and the effects of cultural prompting](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.12488&hl=zh-CN&sa=X&d=17916030825741985772&ei=JtxdaaXUGMW4ieoP4szBiAE&scisig=ALhkC2TpFSG2N5p5s_uYDkyXwXg0&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=0&folt=rel)
*J Luther,D Brown*

Main category: Surajit Chaudhuri

TL;DR: 论文探讨生成式大语言模型在跨文化人机交互中的文化对齐问题，提出评估框架并发现现有模型存在显著文化偏见


<details>
  <summary>Details</summary>
Motivation: 随着生成式大语言模型在人机交互领域的广泛应用，这些模型的文化对齐性成为关键问题。文化是人类互动的基石，影响日常交互的感知和响应方式。现有模型主要基于西方文化数据训练，可能无法充分理解和适应全球多元文化背景，存在文化偏见风险，影响跨文化交互的有效性和公平性。

Method: 论文提出系统性的文化对齐评估框架，通过设计跨文化测试集来量化LLMs的文化对齐程度。方法包括：1) 构建涵盖不同文化维度的评估数据集；2) 设计文化敏感性测试任务；3) 开发量化指标衡量模型对不同文化背景的理解和响应能力；4) 对比分析主流LLMs在跨文化场景下的表现差异。

Result: 研究发现当前主流LLMs存在显著的文化偏见，主要表现为：1) 对西方文化背景的理解和响应明显优于非西方文化；2) 在处理文化特定概念和价值观时表现出系统性偏差；3) 模型输出往往反映训练数据中的文化不平衡性；4) 某些模型在跨文化适应性方面表现有限，影响其全球应用的有效性。

Conclusion: 生成式大语言模型的文化对齐是确保其全球适用性和公平性的关键挑战。论文强调需要开发更具文化包容性的训练方法和评估框架，建议采用多元文化数据、文化感知的微调策略以及持续的文化对齐监控机制，以促进LLMs在跨文化人机交互中的有效应用。

Abstract: Culture is the bedrock of human interaction; it dictates how we perceive and respond to everyday interactions. As the field of human-computer interaction grows via the rise of generative Large Language Models (LLMs), the cultural alignment of these …

</details>


### [205] [Thinking with Blueprints: Assisting Vision-Language Models in Spatial Reasoning via Structured Object Representation](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.01984&hl=zh-CN&sa=X&d=4483791366441950259&ei=haNgaenjE4aw6rQPkNu46Ao&scisig=ALhkC2QeWBipCNCbjHQeHgivHTdN&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=0&folt=rel)
*W Ma,S Sun,T Yu,R Wang,TS Chua,J Bian*

Main category: Surajit Chaudhuri

TL;DR: 该论文提出了一种新的空间推理基准SPARROW，用于评估视觉语言模型在空间语义理解方面的能力，并引入了一种基于视觉提示的微调方法VPT来提升模型的空间推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在空间推理能力方面存在不足，缺乏专门评估空间语义理解的基准。当前方法要么重新访问局部图像块，要么依赖语言模型进行空间推理，但都未能充分解决空间关系理解的核心挑战。

Method: 提出了SPARROW基准，包含多种空间推理任务；引入了视觉提示微调方法VPT，通过视觉提示引导模型关注空间关系；采用多任务学习框架，结合空间推理与视觉问答任务。

Result: 实验表明，SPARROW基准能有效评估VLMs的空间推理能力；VPT方法显著提升了模型在空间推理任务上的性能；模型在保持其他视觉理解能力的同时，空间语义理解得到明显改善。

Conclusion: 空间推理是视觉语言模型从视觉感知向空间语义理解发展的关键能力。SPARROW基准和VPT方法为评估和提升VLMs的空间推理能力提供了有效工具，推动了视觉语言模型在空间语义理解方面的发展。

Abstract: Spatial reasoning--the ability to perceive and reason about relationships in space--advances vision-language models (VLMs) from visual perception toward spatial semantic understanding. Existing approaches either revisit local image patches …

</details>


### [206] [HyperJoin: LLM-augmented Hypergraph Link Prediction for Joinable Table Discovery](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.01015&hl=zh-CN&sa=X&d=11740285024658150172&ei=haNgaenjE4aw6rQPkNu46Ao&scisig=ALhkC2QmnEsdquxhc7Kt59owib3M&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=2&folt=rel)
*S Liu,J Wang,X Lin,L Qin,W Zhang,Y Zhang*

Main category: Surajit Chaudhuri

TL;DR: 该论文提出了一种新的基于语言模型的连接表发现方法，通过结合离线列表示学习和在线查询处理来改进数据湖管理中的表连接发现任务。


<details>
  <summary>Details</summary>
Motivation: 连接表发现是数据湖管理中的关键任务，现有基于语言模型的方法虽然性能显著，但通常将离线列表示学习与在线查询处理分离，可能存在效率或准确性方面的限制。

Method: 提出了一种结合离线列表示学习和在线查询处理的语言模型方法，可能通过更紧密的集成或端到端优化来改进连接表发现。

Result: 该方法在连接表发现任务上取得了比现有方法更优越的性能，表明结合离线学习和在线处理的策略是有效的。

Conclusion: 通过将离线列表示学习与在线查询处理相结合，可以显著提升数据湖中连接表发现的准确性和效率，为数据湖管理提供了更有效的解决方案。

Abstract: As a pivotal task in data lake management, joinable table discovery has attracted widespread interest. While existing language model-based methods achieve remarkable performance by combining offline column representation learning with …

</details>


### [207] [Concurrency control algorithms for database systems exploiting the semantics of read-only transactions.](https://scholar.google.com/scholar_url?url=https://etd.iisc.ac.in/handle/2005/7966&hl=zh-CN&sa=X&d=4056703066745466694&ei=haNgaenjE4aw6rQPkNu46Ao&scisig=ALhkC2QB21_zNR7twmwTTN6a0YCb&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:ALhkC2T10jzdLrz31fH4aa3FyltD&html=&pos=3&folt=rel)
*RC Hansdah*

Main category: Surajit Chaudhuri

TL;DR: 提出新的基于锁的并发控制算法，利用只读事务的语义特性来提升并发性能


<details>
  <summary>Details</summary>
Motivation: 传统并发控制算法在处理只读事务时存在性能瓶颈，需要利用只读事务的语义特性来提升并发性能

Method: 提出新的基于锁的并发控制算法，针对集中式和分布式数据库分别设计，利用只读事务的语义特性优化锁机制

Result: 算法能够显著提升只读事务的并发性能，减少锁冲突，提高系统吞吐量

Conclusion: 通过利用只读事务的语义特性，可以设计出更高效的并发控制算法，显著提升数据库系统的并发性能

Abstract: This thesis proposes new locking-based concurrency control algorithms for both centralized and distributed databases. The concurrency control algorithms proposed exploit the semantics of read-only transactions to improve concurrency. In addition …

</details>


### [208] [Accurate Table Question Answering with Accessible LLMs](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.03137&hl=zh-CN&sa=X&d=4870826697897542801&ei=Ru1hadDVF--GieoPo9DluQE&scisig=AHkA5jRjmm4TlLfOI0C1BjQ9qR3H&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:AHkA5jT2_OB4x2gjQM46vAXf9pM1&html=&pos=0&folt=rel)
*Y Jiang,F Wei,E Bao,Y Li,B Ding,Y Yang,X Xiao*

Main category: Surajit Chaudhuri

TL;DR: 该论文研究基于表格的问答任务，利用大语言模型处理自然语言问题与数据库表格内容，旨在提高问答准确性


<details>
  <summary>Details</summary>
Motivation: 表格问答任务需要将自然语言问题与数据库表格内容结合，传统方法在处理复杂语义和表格结构方面存在局限，需要更先进的解决方案

Method: 采用大语言模型作为核心技术，通过模型理解自然语言问题和表格结构，生成准确答案

Result: 实现了state-of-the-art的性能，在表格问答任务上取得了显著提升

Conclusion: 大语言模型在表格问答任务中表现出色，能够有效处理自然语言与结构化数据的交互

Abstract: Given a table T in a database and a question Q in natural language, the table question answering (TQA) task aims to return an accurate answer to Q based on the content of T. Recent state-of-the-art solutions leverage large language models …

</details>


### [209] [MMErroR: A Benchmark for Erroneous Reasoning in Vision-Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.03331&hl=zh-CN&sa=X&d=11133922188965454453&ei=bUVjaYbiFdrJieoPiYyysAk&scisig=AHkA5jTpWnz75GvbCHjQIcgeo_p3&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:AHkA5jT2_OB4x2gjQM46vAXf9pM1&html=&pos=0&folt=rel)
*Y Shi,Y Xie,M Guo,L Lu,M Huang,J Wang,Z Zhu…*

Main category: Surajit Chaudhuri

TL;DR: 该论文探讨了视觉语言模型是否真正理解其处理的内容，特别是能否检测到推理过程中的不一致性


<details>
  <summary>Details</summary>
Motivation: 随着视觉语言模型在多模态学习中的性能提升，需要评估这些模型是否真正理解内容，特别是能否检测推理过程中的不一致性，这对于验证模型的理解能力至关重要

Method: 论文未提供具体方法细节，但从摘要来看，可能涉及设计评估框架来测试视觉语言模型在检测推理不一致性方面的能力

Result: 摘要未提供具体结果，但暗示了对视觉语言模型理解能力的深入评估

Conclusion: 需要进一步研究视觉语言模型是否真正理解内容，特别是检测推理不一致性的能力，这对评估模型的理解深度具有重要意义

Abstract: Recent advances in Vision-Language Models (VLMs) have improved performance in multi-modal learning, raising the question of whether these models truly understand the content they process. Crucially, can VLMs detect when a reasoning process is …

</details>


### [210] [The inadequacy of offline large language model evaluations: A need to account for personalization in model behavior](https://scholar.google.com/scholar_url?url=https://www.cell.com/patterns/fulltext/S2666-3899(25)00245-4&hl=zh-CN&sa=X&d=4086913592968290820&ei=5KVkaeKXGNrJieoPiYyysAk&scisig=AHkA5jQFRzy5bm9cuzX4r4Kxnu0P&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:AHkA5jT2_OB4x2gjQM46vAXf9pM1&html=&pos=3&folt=rel)
*A Wang,DE Ho,S Koyejo*

Main category: Surajit Chaudhuri

TL;DR: 传统离线评估方法无法捕捉语言模型在实际应用中的个性化行为，本文通过实证研究揭示了这一现象


<details>
  <summary>Details</summary>
Motivation: 当前语言模型的标准离线评估方法存在局限性，无法准确反映模型在实际应用中的真实行为，特别是在个性化设置下模型行为会发生根本性改变

Method: 通过实证研究提供证据，展示个性化如何改变模型行为，对比标准离线评估与实际应用场景的差异

Result: 提供实证证据表明个性化设置会显著改变语言模型的行为模式，标准离线评估无法捕捉这些实际应用中的变化

Conclusion: 需要开发新的评估框架来更好地理解和评估语言模型在个性化应用场景中的实际行为

Abstract: Standard offline evaluations for language models fail to capture how these models actually behave in practice, where personalization fundamentally alters model behavior. In this work, we provide empirical evidence showcasing this phenomenon …

</details>


### [211] [Efficiently Estimating Data Efficiency for Language Model Fine-tuning](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.24991&hl=zh-CN&sa=X&d=568655720932899245&ei=5KVkaeKXGNrJieoPiYyysAk&scisig=AHkA5jQsNYaiVcRB2czVBMsa2TjL&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:AHkA5jT2_OB4x2gjQM46vAXf9pM1&html=&pos=4&folt=rel)
*GH Je,C Raffel*

Main category: Surajit Chaudhuri

TL;DR: 论文研究了LLM微调的数据效率问题，发现不同任务的数据效率差异显著，并提出了基于任务相似性的数据效率预测方法


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型在许多下游任务中表现出合理的零样本能力，但微调是提高其性能的常见做法。然而，不同任务的数据效率（即微调所需的数据量）差异很大，目前缺乏对数据效率的系统性理解，这阻碍了高效的数据分配和模型部署。

Method: 作者通过分析多个任务的数据效率模式，发现任务相似性可以预测数据效率。他们提出了一种基于任务表示的方法来估计数据效率，使用任务嵌入（如任务描述或示例）来量化任务相似性，并建立相似性与数据效率之间的关系模型。

Result: 研究发现：1）不同任务的数据效率差异可达几个数量级；2）任务相似性与数据效率高度相关，相似任务需要相似的数据量；3）基于任务相似性的预测方法能够准确估计新任务的数据效率，减少实际微调实验的需求。

Conclusion: 任务的数据效率是可预测的，基于任务相似性的方法为高效数据分配和模型部署提供了实用工具，有助于优化LLM微调的资源使用。

Abstract: While large language models (LLMs) demonstrate reasonable zero-shot capability across many downstream tasks, fine-tuning is a common practice to improve their performance. However, a task's data efficiency--ie, the number of fine-tuning …

</details>


### [212] [Improving Multi-attribute Fairness in LLM-Based Recommenders Through a Mixture-of-Experts Contrastive Learning Method](https://scholar.google.com/scholar_url?url=https://link.springer.com/content/pdf/10.1007/978-981-95-4158-4_4.pdf&hl=zh-CN&sa=X&d=11571980976456850409&ei=5KVkaeKXGNrJieoPiYyysAk&scisig=AHkA5jRe0whY-NLVYDvJdJrGPC4w&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:AHkA5jT2_OB4x2gjQM46vAXf9pM1&html=&pos=5&folt=rel)
*J Fan,C Zhu,H Wu,F Zhuang,D Wang*

Main category: Surajit Chaudhuri

TL;DR: LLMs在推荐任务中表现出偏好偏差，本文提出了一种基于提示工程的去偏方法，通过上下文学习来减轻LLM推荐中的偏差问题


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）通过提示工程能够实现通用推荐系统，但在实际应用中，LLMs经常表现出某些偏好偏差，这影响了推荐的质量和公平性。需要解决LLM推荐中的偏差问题以提高推荐性能。

Method: 提出了一种基于提示工程的去偏方法，通过上下文学习（in-context learning）技术来减轻LLM推荐中的偏差。该方法利用精心设计的提示模板和上下文示例来引导LLM生成更公平、无偏的推荐结果。

Result: 该方法能够有效减轻LLM在推荐任务中的偏好偏差，提高推荐的公平性和准确性。实验结果表明，经过去偏处理的LLM推荐系统在多个指标上表现优于基线方法。

Conclusion: 基于提示工程的去偏方法为解决LLM推荐系统中的偏差问题提供了有效途径，通过上下文学习技术可以显著改善LLM推荐的公平性和性能，为构建更可靠的通用推荐系统奠定了基础。

Abstract: The impressive capabilities of Large Language Models (LLMs) enable them to perform recommendation through prompting, facilitating a novel paradigm of universal recommender systems. However, in practice, LLMs often exhibit some …

</details>


### [213] [Budget-constrained index tuning in database systems](https://scholar.google.com/scholar_url?url=https://patents.google.com/patent/US20260003849A1/en&hl=zh-CN&sa=X&d=8229044947149104614&ei=5aVkae7kJMyQieoPxv68kA4&scisig=AHkA5jSejoxtze35Ep_6BA4PSuzC&oi=scholaralrt&hist=i6heNjgAAAAJ:13267949439400199659:AHkA5jTiQRPu0aCQ6EHKKhOuO980&html=&pos=0&folt=art)
*X Wang,W Wu,C Wang,V Narasayya,S Chaudhuri*

Main category: Surajit Chaudhuri

TL;DR: 提出一种在预算约束下进行数据库索引调优的方法，通过生成候选索引集、评估成本效益并选择最优索引组合来优化查询性能


<details>
  <summary>Details</summary>
Motivation: 传统索引调优方法通常忽略实际部署中的预算限制（如存储空间、维护成本），导致推荐的索引方案在实际环境中不可行。需要一种能在给定预算约束下找到最优索引配置的方法

Method: 接收预算约束，为查询工作负载生成候选索引集，评估每个索引的成本效益，使用优化算法（如贪心算法、动态规划或整数规划）在预算限制内选择最优索引组合

Result: 该方法能够在给定预算约束下找到接近最优的索引配置，显著提高查询性能，同时确保总成本不超过预算限制。实验表明相比无预算约束的方法，能提供更实用的解决方案

Conclusion: 预算约束下的索引调优是数据库性能优化的重要实际问题，提出的方法能有效平衡性能提升与资源成本，为实际部署提供可行的索引推荐方案

Abstract: This document relates to budget-constrained index tuning in database systems. A method for index tuning within a database system includes receiving a budget constraint, generating a set of candidate indexes for a workload of queries, and …

</details>


### [214] [TokSuite: Measuring the Impact of Tokenizer Choice on Language Model Behavior](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.20757&hl=zh-CN&sa=X&d=16608035220368283080&ei=MFhmaaT0DIeUywSuh8nRDQ&scisig=AHkA5jTelxshft5nXIL6ScSjDPYX&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:AHkA5jT2_OB4x2gjQM46vAXf9pM1&html=&pos=1&folt=rel)
*GS Altıntaş,M Ehghaghi,B Lester,F Liu,W Zhao…*

Main category: Surajit Chaudhuri

TL;DR: 该论文探讨了分词器对语言模型性能和行为的影响，指出当前对其作用的理解不足，并提出了评估分词器影响的方法。


<details>
  <summary>Details</summary>
Motivation: 分词器是语言模型处理文本的基础，但当前对其在语言模型性能和行为中的作用理解不足，需要系统研究分词器的影响。

Method: 论文可能提出了一种评估分词器影响的框架或方法，通过对比不同分词策略来研究其对语言模型性能的影响。

Result: 研究发现分词器的选择显著影响语言模型的性能和行为，不同分词策略会导致模型在特定任务上表现差异。

Conclusion: 分词器是影响语言模型性能的关键因素，需要更系统的研究来理解其作用机制，并为分词器选择提供指导。

Abstract: Tokenizers provide the fundamental basis through which text is represented and processed by language models (LMs). Despite the importance of tokenization, its role in LM performance and behavior is poorly understood due to the challenge of …

</details>


### [215] [Investigating the Multilingual Calibration Effects of Language Model Instruction-Tuning](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.01362&hl=zh-CN&sa=X&d=3373126679954533814&ei=MFhmaaT0DIeUywSuh8nRDQ&scisig=AHkA5jTcoyUoZ7EIcM4rO7_QsiwY&oi=scholaralrt&hist=i6heNjgAAAAJ:10938430069730194209:AHkA5jT2_OB4x2gjQM46vAXf9pM1&html=&pos=2&folt=rel)
*J Huang,P Lu,Q Zeng,Y Iwasawa,Y Matsuo…*

Main category: Surajit Chaudhuri

TL;DR: 该论文探讨基础模型预测不确定性的校准问题，强调在保持模型可信度和可靠性方面的重要性


<details>
  <summary>Details</summary>
Motivation: 尽管基础模型研究不断进步，但预测不确定性的校准问题仍未得到充分解决，这对于维持深度学习模型的可信度和可靠性至关重要

Method: 论文可能提出针对基础模型的校准方法或框架，但具体方法需要更多信息来确定

Result: 需要更多信息来确定具体结果，但预期会展示改进的校准性能或对基础模型不确定性特性的新见解

Conclusion: 基础模型的预测不确定性校准是一个关键但尚未充分探索的研究方向，需要专门的方法来确保其可信度和可靠性

Abstract: Ensuring that deep learning models are well-calibrated in terms of their predictive uncertainty is essential in maintaining their trustworthiness and reliability, yet despite increasing advances in foundation model research, the relationship between such …

</details>


<div id='Carsten Binnig'></div>

# Carsten Binnig [[Back]](#toc)

### [216] [An Evaluation of B-tree Compression Techniques](https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s00778-025-00950-8&hl=zh-CN&sa=X&d=15148591129694291336&ei=twYtae_OIObYieoPqMHA-A0&scisig=ABGrvjLji5XVB8WODl3cGo7_jPY8&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ABGrvjK24jP7J-3wiF9GIMBBH0jC&html=&pos=0&folt=cit)
*S Sun,C Gao,S Ballijepalli,J Wang*

Main category: Carsten Binnig

TL;DR: B树压缩技术综述：从1970年代至今的发展历程、方法分类与性能影响分析


<details>
  <summary>Details</summary>
Motivation: B树作为数据库系统中最重要的索引结构之一，其压缩技术自1970年代提出以来，旨在同时提高空间效率和查询性能。随着时间推移，出现了多种B树压缩技术，但缺乏系统性的分类和分析框架。

Method: 本文采用文献综述方法，系统梳理了自1970年代以来提出的各种B树压缩技术，建立分类框架，分析不同压缩方法的工作原理、适用场景和实现机制。

Result: 通过对历史文献的系统分析，建立了B树压缩技术的分类体系，揭示了不同压缩方法在空间节省、查询性能、更新开销等方面的权衡关系，为实际系统选择合适压缩策略提供指导。

Conclusion: B树压缩技术经过数十年发展已形成多样化方法体系，不同压缩策略在空间效率与性能之间存在复杂权衡，未来研究需要更全面地考虑现代硬件特性和工作负载特征。

Abstract: B-trees are widely recognized as one of the most important index structures in database systems, providing efficient query processing capabilities. Over the past few decades, many techniques have been developed to enhance the efficiency of B-trees from various perspectives. Among them, B-tree compression is an important technique introduced as early as the 1970s to improve both space efficiency and query performance. Since then, several B-tree compression techniques have been …

</details>


### [217] [Analysis and Implementation of Academic Documents Privacy-Preserving Management Model using Dynamic VC and DID Over Hyperledger Fabric Blockchain …](https://scholar.google.com/scholar_url?url=https://sciresol.s3.us-east-2.amazonaws.com/IJST/Articles/2025/Issue-42/IJST-2025-1410.pdf&hl=zh-CN&sa=X&d=9108479559377175225&ei=twYtae_OIObYieoPqMHA-A0&scisig=ABGrvjJSWnBCe_3jzQAvcEZiFQae&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ABGrvjK24jP7J-3wiF9GIMBBH0jC&html=&pos=4&folt=cit)
*K Sathya,A Saraswathi*

Main category: Carsten Binnig

TL;DR: 提出基于Hyperledger Fabric、动态VC和DID区块链技术的学术文档隐私保护验证模型，用于学术证书的签发与验证


<details>
  <summary>Details</summary>
Motivation: 现有学术文档签发与验证系统存在隐私和安全挑战，需要提供高效的学术文档隐私保护方法

Method: 使用Hyperledger Fabric结合动态可验证凭证(VC)和去中心化身份标识(DID)区块链技术，构建学术文档隐私保护验证模型

Result: 模型能够处理现有学术文档签发与验证系统中的隐私和安全挑战，提供更安全的解决方案

Conclusion: 提出的基于区块链的隐私保护验证模型为学术文档管理提供了更安全、隐私保护的解决方案

Abstract: Objectives: Providing an efficient privacy preservation approach of academic documents is the primary objective of this research work. Methods: Proposed privacy-preserving of academic documents verification model for academic certificate issuance and verification using Hyperledger Fabric over dynamic VC and DID blockchain technology. It can handle privacy and security challenges present in existing academic document's issuance and verification systems, while also …

</details>


### [218] [Semantic Metadata Enrichment in Third-Generation Data Lakes](https://scholar.google.com/scholar_url?url=https://edoc.sub.uni-hamburg.de/informatik/volltexte/2025/314/pdf/MA_ITMC_Leo_Rehm_7657408_redacted.pdf&hl=zh-CN&sa=X&d=14476707309764270400&ei=cPYyaaHQD5vJieoPvqa-qQU&scisig=ALhkC2SKh_FRRIntiR8jBReRfRXT&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ALhkC2RIP3td447yoLbg876hcWyk&html=&pos=1&folt=cit)
*L Rehm*

Main category: Carsten Binnig

TL;DR: 该论文研究将大型语言模型集成到数据湖仓的元数据增强流程中，以解决传统方法在快速变化环境中的局限性


<details>
  <summary>Details</summary>
Motivation: 第三代数据湖（数据湖仓）在企业数据平台中的采用增加了对可扩展且准确的元数据管理的需求。现有语义元数据增强方法严重依赖人工努力或基于本体的框架，这在快速变化的环境中通常不切实际。

Method: 研究将大型语言模型（LLMs）集成到数据湖仓的元数据增强流程中，探索LLMs在自动化语义元数据提取和增强方面的应用。

Result: 摘要未提供具体实验结果，但暗示LLMs集成可能提供比传统方法更实用和可扩展的解决方案。

Conclusion: LLMs为数据湖仓的元数据管理提供了有前景的替代方案，能够应对快速变化环境中的语义元数据增强挑战。

Abstract: The adoption of third-generation data lakes, ie data lakehouses for modern enterprise data platforms increases the need for scalable and accurate metadata management. Existing approaches to semantic metadata enrichment rely heavily on manual e! orts or ontology-based frameworks, which are often impractical in fast-moving environments. This thesis investigates the integration of Large Language Models (LLMs) into the metadata enrichment pipeline of data lakehouses, focusing …

</details>


### [219] [PG2RDF: Schema-Guided Transformation of Property Graphs to RDF](https://scholar.google.com/scholar_url?url=https://users.ics.forth.gr/~sophisid/files/2025_IJCKG_PG2RDF.pdf&hl=zh-CN&sa=X&d=1198733997039666162&ei=kNI1acfnC-bYieoPgNO3kQI&scisig=ALhkC2QOLj_H5yjLyRp7INNM5mWw&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ALhkC2RIP3td447yoLbg876hcWyk&html=&pos=0&folt=cit)
*S Sideri,V Efthymiou,D Plexousakis,H Kondylakis*

Main category: Carsten Binnig

TL;DR: PG2RDF是一个全自动、模式感知的流水线，用于将属性图数据转换为RDF格式，解决异构图数据模型之间的互操作性问题。


<details>
  <summary>Details</summary>
Motivation: 属性图(PG)和RDF模型在知识图谱构建中广泛应用，但它们的结构和语义差异阻碍了无缝集成和数据交换，异构图数据模型之间的互操作性仍然是一个重大挑战。

Method: 提出PG2RDF流水线，使用XML模式定义(XSD)来形式化属性图结构，实现全自动、模式感知的转换过程，将PG数据转换为RDF格式。

Result: 该方法能够有效地将属性图数据转换为RDF格式，解决了PG和RDF模型之间的互操作性问题，实现了异构图数据模型的集成。

Conclusion: PG2RDF提供了一个实用的解决方案，通过自动化转换流水线促进了属性图和RDF模型之间的互操作性，有助于知识图谱的构建和数据集成。

Abstract: Interoperability between heterogeneous graph data models remains a significant challenge in knowledge graph construction. While both Property Graphs (PG) and RDF models are widely used for data representation, their structural and semantic differences hinder seamless integration and data exchange. In this work, we present PG2RDF, a fully automated and schema-aware pipeline for transforming PG data into RDF. Our method relies on an XML Schema Definition (XSD) to formalize the PG …

</details>


### [220] [Burr: A Benchmark for Ontology Learning from Relational Databases](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3769770&hl=zh-CN&sa=X&d=4750093098539686431&ei=x0w3afXTNqm6ieoPqIeGyAM&scisig=ALhkC2T0pE_7toY1XNMGGfxLwpml&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ALhkC2RIP3td447yoLbg876hcWyk&html=&pos=1&folt=cit)
*L Laskowski,M Hladik,J Portisch,F Panse…*

Main category: Carsten Binnig

TL;DR: 该论文探讨了从关系数据库学习本体的挑战，并提出解决方案以弥合关系模型与知识图谱之间的概念不匹配问题。


<details>
  <summary>Details</summary>
Motivation: 知识图谱和本体在跨领域数据集成、标准化和推理中发挥关键作用，研究表明在AI用例中使用知识图谱相比传统关系数据库可带来高达38个百分点的质量提升。然而，由于关系数据库和本体建模概念之间的阻抗不匹配，从关系数据库学习本体仍然是一个具有挑战性的任务。

Method: 从提供的摘要片段来看，论文可能提出了一种从关系数据库自动或半自动学习本体的方法，旨在解决关系模型与知识图谱之间的概念转换问题。具体方法可能涉及模式映射、语义提取、关系约束转换等技术。

Result: 摘要中提到"leveraging knowledge graphs in AI use cases, instead of traditional relational databases, led to quality improvements by up to 38 percentage points"，这表明使用知识图谱相比关系数据库能带来显著的质量提升，但未提供具体学习方法的实验结果。

Conclusion: 从关系数据库学习本体是重要但具有挑战性的任务，需要专门的方法来解决两种建模范式之间的概念不匹配问题，成功实现这种转换可以显著提升AI应用的质量。

Abstract: Knowledge graphs and ontologies play an essential role in integrating, standardizing, and reasoning about complex data across domains. In recent studies, leveraging knowledge graphs in AI use cases, instead of traditional relational databases, led to quality improvements by up to 38 percentage points. However, learning ontologies from relational databases remains a challenging task due to the impedance mismatch between both modeling concepts. An understanding of which …

</details>


### [221] [P4KVS: A Role-Replica Separation Offloading Method to Achieve In-Network Consistency for KV Stores Based on P4 Switches](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3769812&hl=zh-CN&sa=X&d=654142344342892787&ei=k-U4acznGPGQ6rQPkIj1sQI&scisig=ALhkC2StLNW2gh5pAHxZXSBUBOLI&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ALhkC2RIP3td447yoLbg876hcWyk&html=&pos=7&folt=cit)
*H Li,Z Zhang,C Ye,R Tang,J Li,H Guan,Q Wang…*

Main category: Carsten Binnig

TL;DR: 本文分析了分布式数据库管理系统在强一致性（特别是线性一致性）方面的挑战，指出现有解决方案在性能和兼容性方面存在不足。


<details>
  <summary>Details</summary>
Motivation: 强一致性（特别是线性一致性）对于金融、国防等正确性关键领域的分布式DBMS至关重要。现有解决方案在匹配单节点性能（无一致性成本）和通用数据库兼容性方面存在不足。

Method: 未在摘要中明确说明具体方法，但暗示需要解决两个关键原则：1）在强一致性下匹配单节点读写性能；2）通过通用数据库兼容性实现实际可部署性。

Result: 摘要未提供具体实验结果，但指出现有解决方案在这两个关键原则上都存在不足。

Conclusion: 需要新的解决方案来同时实现强一致性下的高性能和通用兼容性，以满足正确性关键领域的需求。

Abstract: Strong consistency, particularly linearizability, is essential for distributed DBMSs deployed in correctness-critical domains such as finance and defense. In general, an optimal linearizability DBMS system focus on two key principles:(1) matching single-node (no-consistency cost) Read/Write performance under strong consistency, and (2) practical deployability via general database compatibility. Unfortunately, existing solutions fall short on both fronts.% However, achieving strong consistency often …

</details>


### [222] [SRS: Detecting Logic Bugs of Join Implementation in DBMSs via Set Relation Synthesis](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3769828&hl=zh-CN&sa=X&d=2667083120959392267&ei=k-U4acznGPGQ6rQPkIj1sQI&scisig=ALhkC2QSAMft3ftorapW8L9HLzpT&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ALhkC2RIP3td447yoLbg876hcWyk&html=&pos=8&folt=cit)
*J Lai,C Zhang,B Li,C Liang,J Liang,Z Wu,J Fu…*

Main category: Carsten Binnig

TL;DR: 该论文针对DBMS中连接操作的逻辑错误检测问题，提出了一种新的检测方法，通过改变查询提示和系统变量来影响优化器选择执行计划，从而发现现有方法难以检测的逻辑错误。


<details>
  <summary>Details</summary>
Motivation: 连接操作是DBMS中的基本操作，但由于其复杂性容易产生逻辑错误，这些错误会导致DBMS在无提示的情况下产生错误查询结果，严重威胁软件可靠性。现有检测方法存在局限性，需要更有效的检测技术。

Method: 通过改变查询提示和系统变量来影响优化器的执行计划选择，从而检测连接优化中的逻辑错误。这种方法通过操纵优化器的决策过程来揭示隐藏的逻辑缺陷。

Result: 该方法能够检测到传统方法难以发现的连接操作逻辑错误，提高了DBMS逻辑错误检测的覆盖率和有效性。

Conclusion: 通过操纵优化器执行计划选择的方法为DBMS连接操作逻辑错误检测提供了新的有效途径，有助于提升数据库系统的可靠性和正确性。

Abstract: Logic bugs can cause DBMSs to silently produce incorrect results for a given query, posing significant threats to software reliability and remaining challenging to detect. Join is a fundamental operation in DBMSs, enabling the combination of data from multiple tables; however, due to its complexity, it is also susceptible to logic bugs. Existing works detect logic bugs in join optimizations by altering query hints and system variables to alter the optimizer's choice of execution plans. However, these …

</details>


### [223] [Compressing and Efficient Query Processing for Large-Scala Data Sequences](https://scholar.google.com/scholar_url?url=https://tesidottorato.depositolegale.it/bitstream/20.500.14242/313065/1/PhDThesis.pdf&hl=zh-CN&sa=X&d=14429398430071849905&ei=k-U4acznGPGQ6rQPkIj1sQI&scisig=ALhkC2RraQG4SizrUClAbOpngbgv&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ALhkC2RIP3td447yoLbg876hcWyk&html=&pos=9&folt=cit)
*A Guerra*

Main category: Carsten Binnig

TL;DR: 该论文针对时间序列和整数数据序列的存储与检索挑战，提出了一种支持高效随机访问的压缩方法，以解决通用压缩器在实时分析中的局限性。


<details>
  <summary>Details</summary>
Motivation: 时间序列和整数数据序列在金融、医疗、工业、环境监测等领域至关重要，但这些序列持续无界增长，高效存储和检索面临挑战。通用压缩器如Xz和Zstd虽然压缩比高，但缺乏对压缩数据高效随机访问的支持，限制了在实时分析中的应用。

Method: 论文提出了一种专门针对时间序列和整数数据序列的压缩方法，该方法在保持高压缩比的同时支持高效随机访问，与专门设计的ad hoc方法形成对比。

Result: 该方法在压缩比和随机访问性能之间取得了良好平衡，相比通用压缩器在实时分析场景中具有显著优势，能够支持高效的数据查询和检索操作。

Conclusion: 针对时间序列和整数数据序列的专用压缩方法能够有效解决通用压缩器在实时分析中的局限性，为连续增长的数据序列提供高效存储和检索解决方案。

Abstract: Time series and integer data sequences play a critical role in many fields, including finance, healthcare, industry, and environmental monitoring. However, efficiently storing and retrieving these sequences remains challenging due to their continuous and unbounded growth. General-purpose compressors such as Xz and Zstd offer strong compression ratios but lack support for efficient random access on compressed data, limiting their use in real-time analytics. In contrast, ad hoc …

</details>


### [224] [Can AI autonomously build, operate, and use the entire data stack?](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.07926&hl=zh-CN&sa=X&d=14142206132607255764&ei=JIQ9aaCSLfO16rQPzoDK8Ag&scisig=ALhkC2SsmNoAZoefD18YLLmH9yf5&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ALhkC2RIP3td447yoLbg876hcWyk&html=&pos=0&folt=cit)
*A Agarwal,L Amini,S Mehta,H Samulowitz,K Srinivas*

Main category: Carsten Binnig

TL;DR: 该论文探讨了AI在企业数据管理自动化中的机遇，认为当前AI助手仅能辅助特定角色，但AI能力的提升为全面自动化创造了机会。


<details>
  <summary>Details</summary>
Motivation: 企业数据管理任务繁重，涵盖架构、系统、集成、质量、治理和持续改进等多个方面。当前AI助手仅能辅助特定角色（如数据工程师和管理员），但无法实现全面自动化。随着AI处理复杂任务能力的增强，存在实现企业数据管理自动化的机遇。

Method: 论文未在摘要中明确描述具体方法，但暗示将探索AI在企业数据管理自动化中的应用，可能涉及利用AI处理传统上因复杂性而难以自动化的任务。

Result: 摘要未提供具体实验结果，但提出了AI在企业数据管理自动化方面存在"迫在眉睫的机会"这一核心观点。

Conclusion: 随着AI能力的增强，企业数据管理领域存在实现全面自动化的重大机遇，这可能改变当前仅能辅助特定角色的AI助手模式。

Abstract: Enterprise data management is a monumental task. It spans data architecture and systems, integration, quality, governance, and continuous improvement. While AI assistants can help specific persona, such as data engineers and stewards, to navigate and configure the data stack, they fall far short of full automation. However, as AI becomes increasingly capable of tackling tasks that have previously resisted automation due to inherent complexities, we believe there is an imminent opportunity …

</details>


### [225] [An Evaluation of B-tree Compression Techniques: An Evaluation of B-tree Compression...](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1007/s00778-025-00950-8&hl=zh-CN&sa=X&d=15520320361062061942&ei=JIQ9aaCSLfO16rQPzoDK8Ag&scisig=ALhkC2RRmY_31d26lJ4uWjfVNtRZ&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ALhkC2RIP3td447yoLbg876hcWyk&html=&pos=1&folt=cit)
*S Sun,C Gao,S Ballijepalli,J Wang*

Main category: Carsten Binnig

TL;DR: 该论文综述了B树压缩技术的历史发展、分类方法和最新进展，系统分析了各种压缩策略及其对查询性能的影响。


<details>
  <summary>Details</summary>
Motivation: B树作为数据库系统中最重要的索引结构之一，其压缩技术自1970年代提出以来不断发展。然而，缺乏对B树压缩技术的系统性综述，需要全面梳理其历史发展、分类方法和最新进展，为研究者和实践者提供参考。

Method: 采用文献综述方法，系统收集和分析B树压缩相关的研究工作。从压缩粒度、压缩策略、查询性能影响等多个维度对现有技术进行分类和比较分析。

Result: 建立了B树压缩技术的分类框架，识别了主要压缩策略（如前缀压缩、字典压缩、位图压缩等），分析了各种压缩技术对空间效率和查询性能的影响，总结了技术发展趋势。

Conclusion: B树压缩技术是提升数据库索引性能的重要手段，未来发展方向包括自适应压缩、硬件感知压缩和机器学习驱动的压缩优化等。系统综述为相关研究提供了理论基础和实践指导。

Abstract: B-trees are widely recognized as one of the most important index structures in database systems, providing efficient query processing capabilities. Over the past few decades, many techniques have been developed to enhance the efficiency of B-trees from various perspectives. Among them, B-tree compression is an important technique introduced as early as the 1970s to improve both space efficiency and query performance. Since then, several B-tree compression techniques have been …

</details>


### [226] [Software developers in the age of AI](https://scholar.google.com/scholar_url?url=https://edoc.ub.uni-muenchen.de/36083/1/weber_thomas.pdf&hl=zh-CN&sa=X&d=10861028035521238282&ei=gWdAaf3iAv3D6rQP75fFuQs&scisig=ALhkC2SpE1WhnreVi3yUsDWNKWfZ&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ALhkC2RIP3td447yoLbg876hcWyk&html=&pos=2&folt=cit)
*T Weber*

Main category: Carsten Binnig

TL;DR: 从人机交互角度研究机器学习等技术如何影响软件开发者的工作实践和工具


<details>
  <summary>Details</summary>
Motivation: 人工智能和数据驱动应用的引入与广泛采用对软件开发者产生了范式转变，需要从人机交互视角理解这些技术如何影响开发者的工作实践和工具

Method: 采用人机交互（HCI）视角，研究机器学习等技术对软件开发者的影响，分析他们的工作实践和工具使用情况

Result: 未提供具体结果（摘要中未包含研究结果）

Conclusion: 需要深入理解人工智能和数据驱动应用对软件开发者工作实践和工具的变革性影响

Abstract: The introduction and widespread adoption of Artificial Intelligence and data-driven applications, ie software systems that rely on large sets of data to define their functionality, have created a paradigmatic shift in many areas of our lives, not just for end users but particularly for professional software developers. In this dissertation, we take a human-computer-interaction perspective on how technologies like Machine Learning have affected software developers, their work practices, tools …

</details>


### [227] [LLM-Driven Big Data Management Across Digital Governance, Marketing, and Accounting: A Spark-Orchestrated Framework](https://scholar.google.com/scholar_url?url=https://www.mdpi.com/1999-4893/18/12/791&hl=zh-CN&sa=X&d=18381832606008470512&ei=1HlFadq-IYKUieoP5cGFWQ&scisig=ALhkC2Sw9IX1Ifu5WkbuDVJylr_a&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ALhkC2RIP3td447yoLbg876hcWyk&html=&pos=0&folt=cit)
*A Karras,L Theodorakopoulos,C Karras,GA Krimpas…*

Main category: Carsten Binnig

TL;DR: 提出了一个将大型语言模型部署于企业大数据管理的原则性框架，专注于数字治理、营销和会计领域，强调LLMs作为可审计、行业自适应的组件来增强数据管理流程。


<details>
  <summary>Details</summary>
Motivation: 传统预测应用在企业管理中缺乏透明度和适应性，需要一种能够直接增强数据管理流程、支持审计和监管合规的LLM部署方法。

Method: 开发了一个原则性框架，将LLMs集成为企业大数据管理中的可审计、行业自适应组件，系统评估了七种LLM赋能的数据管理任务。

Result: 框架在数字治理、营销和会计领域展示了LLMs在数据整理、数据血缘追踪和监管合规方面的实际应用效果。

Conclusion: 该框架为LLMs在企业大数据管理中的部署提供了系统化方法，强调了可审计性和行业适应性在增强数据管理流程中的重要性。

Abstract: In this work, we present a principled framework for the deployment of Large Language Models (LLMs) in enterprise big data management across digital governance, marketing, and accounting domains. Unlike conventional predictive applications, our approach integrates LLMs as auditable, sector-adaptive components that robustly and directly enhance data curation, lineage, and regulatory compliance. The study contributes (i) a systematic evaluation of seven LLM-enabled …

</details>


### [228] [Query Optimization Beyond Data Systems: The Case for Multi-Agent Systems](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.11001&hl=zh-CN&sa=X&d=15924937745061083845&ei=1HlFadq-IYKUieoP5cGFWQ&scisig=ALhkC2QxFMqFaaqvPipttC0Cne4_&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ALhkC2RIP3td447yoLbg876hcWyk&html=&pos=1&folt=cit)
*Z Kaoudi,I Giurgiu*

Main category: Carsten Binnig

TL;DR: 论文指出当前基于大语言模型的智能体工作流构建方法缺乏通用性、可扩展性和系统性优化，提出需要更系统化的解决方案


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的普及，基于智能体的工作流应用日益增多，但现有构建方法多为临时性方案，缺乏通用性、可扩展性和系统性优化，需要更系统化的架构设计

Method: 论文未在摘要中明确说明具体方法，但暗示需要开发更系统化的智能体架构，可能涉及多模型协同、执行引擎优化和系统化工作流设计

Result: 摘要未提供具体实验结果，但指出当前方法在通用性、可扩展性和优化方面存在不足

Conclusion: 需要开发更系统化、可扩展和优化的智能体架构来支持复杂数据管道的构建

Abstract: The proliferation of large language models (LLMs) has accelerated the adoption of agent-based workflows, where multiple autonomous agents reason, invoke functions, and collaborate to compose complex data pipelines. However, current approaches to building such agentic architectures remain largely ad hoc, lacking generality, scalability, and systematic optimization. Existing systems often rely on fixed models and single execution engines and are unable to efficiently optimize …

</details>


### [229] [Declarative Memory Services](https://scholar.google.com/scholar_url?url=https://www.cs.sfu.ca/~tzwang/dms.pdf&hl=zh-CN&sa=X&d=9359732355348976097&ei=1HlFadq-IYKUieoP5cGFWQ&scisig=ALhkC2S5Hpm3cOmIGyl90rrIj6nR&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ALhkC2RIP3td447yoLbg876hcWyk&html=&pos=2&folt=cit)
*J Castrillon,J Giceva,Y Hua,K Keeton,A Shekar…*

Main category: Carsten Binnig

TL;DR: 现代内存系统面临编程复杂性挑战，需要新的编程模型来管理异构内存设备


<details>
  <summary>Details</summary>
Motivation: 新型内存设备（如高带宽内存、内存内处理设备）和互连技术（如Compute Express Link）带来了多样化的现代内存系统，具有高性能和非传统特性（压缩、加密、复制、领域特定和通用计算）。然而，编程现代内存系统变得高度复杂，导致手工定制系统不可持续。

Method: 论文未在摘要中明确说明具体方法，但暗示需要新的编程模型或框架来简化现代异构内存系统的编程和管理。

Result: 摘要未提供具体实验结果，但指出了当前手工定制内存系统方法不可持续的问题。

Conclusion: 需要开发新的编程抽象和系统来有效管理和利用现代异构内存系统的复杂特性，以替代不可持续的手工定制方法。

Abstract: The advent of new memory devices (eg, high-bandwidth memory and processing-in-memory devices) and interconnects (eg, Compute Express Link) brings a diverse landscape of modern memory systems with high performance and non-traditional features such as compression, encryption, replication and domain-specific as well as general-purpose computation. Meanwhile, it has become highly complex to program modern memory systems, leading to handcrafted systems that are not sustainable as …

</details>


### [230] [Benchmarking RL-Enhanced Spatial Indices Against Traditional, Advanced, and Learned Counterparts](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.11161&hl=zh-CN&sa=X&d=14455544365760091659&ei=1HlFadq-IYKUieoP5cGFWQ&scisig=ALhkC2ST0h1Rz_BTVJERacfiR_qj&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ALhkC2RIP3td447yoLbg876hcWyk&html=&pos=3&folt=cit)
*G Liu,R Borovica*

Main category: Carsten Binnig

TL;DR: 首个模块化可扩展的强化学习增强空间索引基准框架，用于评估RLESIs在实际磁盘环境中的性能


<details>
  <summary>Details</summary>
Motivation: 现有强化学习增强空间索引(RLESIs)缺乏统一实现和全面评估，特别是在磁盘环境下的实际效益不明确

Method: 基于现有空间索引库构建模块化可扩展的基准框架，支持统一实现和全面性能评估

Result: 提出了首个针对RLESIs的基准框架，能够系统评估其在磁盘环境中的实际性能表现

Conclusion: 该基准框架填补了RLESIs评估空白，为未来研究提供了标准化评估工具

Abstract: Reinforcement learning has recently been used to enhance index structures, giving rise to reinforcement learning-enhanced spatial indices (RLESIs) that aim to improve query efficiency during index construction. However, their practical benefits remain unclear due to the lack of unified implementations and comprehensive evaluations, especially in disk-based settings. We present the first modular and extensible benchmark for RLESIs. Built on top of an existing spatial index library, our framework …

</details>


### [231] [S-PIC4CHU: Semantics-Enriched Techniques for Data Preparation in Data Science](https://scholar.google.com/scholar_url?url=https://www.itadata.it/_2025_pages/proceedings/papers/paper92.pdf&hl=zh-CN&sa=X&d=7023634953242716638&ei=1HlFadq-IYKUieoP5cGFWQ&scisig=ALhkC2TqsZu73tjlMKI3SbKR8ZwD&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ALhkC2RIP3td447yoLbg876hcWyk&html=&pos=4&folt=cit)
*G Alfano,I Bartolini,D Calvanese,P Ciaccia,S Greco…*

Main category: Carsten Binnig

TL;DR: S-PIC4CHU项目专注于数据科学和机器学习的数据准备问题，提出新的模型和技术来应对数据不准确、噪声、不确定性、偏见和不完整性等挑战。


<details>
  <summary>Details</summary>
Motivation: 数据准备是数据科学和机器学习的关键环节，但现有数据通常存在不准确、噪声、不确定性、偏见和不完整性等问题，这些数据质量问题严重影响后续分析和模型性能。

Method: 采用基于语义的方法，构建包含数据清洗（包括伦理视角）、转换、降维、去重、错误检测、缺失值处理等环节的数据准备流水线。

Result: 项目提出了一套完整的数据准备框架，特别强调了伦理视角的数据清洗，为处理数据质量问题提供了系统化的解决方案。

Conclusion: 通过语义驱动的数据准备流水线，能够有效应对数据质量问题，为高质量的数据科学和机器学习应用奠定基础。

Abstract: Abstract The S-PIC4CHU project deals with the crucial issue of data preparation for Data Science and Machine Learning, and aims to offer new models and techniques for fighting inaccuracy, noise, uncertainty, bias, and incompleteness of data. While, at the core, the project embraces a semantics-based approach, the proposed data preparation pipeline includes data cleaning—also from the ethical viewpoint—, transformation, reduction as well as deduplication, error detection, missing value …

</details>


### [232] [Flexible I/O for Database Management Systems with xNVMe](https://scholar.google.com/scholar_url?url=https://www.vldb.org/cidrdb/papers/2026/p6-houlborg.pdf&hl=zh-CN&sa=X&d=1118130247648048831&ei=mQ5KaZquEJ6u6rQPotyMwAQ&scisig=ALhkC2QqmYwUyUEeSWKWDjKVKWsq&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ALhkC2RIP3td447yoLbg876hcWyk&html=&pos=0&folt=cit)
*E Houlborg,AN Tietgen,SAF Lund,M Weisgut,T Rabl…*

Main category: Carsten Binnig

TL;DR: 论文探讨了现代NVMe SSD设备多样性（ZNS、FDP、KV-SSD）与多种I/O路径（libaio、io_uring、SPDK）之间的适配挑战，指出当前数据系统仍依赖传统文件系统API以避免复杂性。


<details>
  <summary>Details</summary>
Motivation: 现代NVMe SSD设备呈现多样化特性（如分区命名空间、灵活数据放置、键值SSD等），并提供微秒级延迟的高性能。同时存在多种I/O路径选择（libaio、io_uring、SPDK）。然而，针对这种多样性的编程面临挑战和不可预测性，导致大多数数据系统仍依赖传统文件系统API，未能充分利用新硬件能力。

Method: 论文未在摘要中明确说明具体方法，但暗示需要研究如何有效利用现代NVMe SSD的多样化特性和高性能I/O路径，同时避免编程复杂性。

Result: 摘要未提供具体实验结果，但指出了当前现状：尽管存在多种高性能NVMe SSD设备和I/O路径，但大多数数据系统仍使用传统文件系统API，未能充分利用硬件能力。

Conclusion: 需要解决现代NVMe SSD设备多样性与I/O路径选择之间的适配挑战，开发更简单、可预测的编程模型，使数据系统能够充分利用新硬件的高性能特性。

Abstract: ABSTRACT Today, NVMe SSDs cover a diverse family of devices (eg, Zoned Namespaces, Flexible Data Placement, and Key-Value SSDs) and offer high performance (𝜇sec-scale latency). To leverage the capabilities of these devices, a variety of I/O paths are available (eg, libaio, io_uring, and SPDK). On the other hand, to avoid the challenges and unpredictability that comes with writing code to target such diversity, most data systems today still rely on the conventional filesystem APIs …

</details>


### [233] [CAPIO: Safe Kernel-Bypass of Commodity Devices using Capabilities](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.16957&hl=zh-CN&sa=X&d=11463720504515696450&ei=fS5NaavJKcSN6rQPx4HkwQU&scisig=ALhkC2SPbKB-MRZvY4iF8THBNFAO&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ALhkC2RIP3td447yoLbg876hcWyk&html=&pos=0&folt=cit)
*F Doku,J Laughton,N Wanninger,P Dinda*

Main category: Carsten Binnig

TL;DR: 论文探讨了在商品系统中实现低延迟I/O时的安全与性能权衡，指出传统MMU页面粒度导致无法选择性暴露安全设备寄存器而不暴露同页敏感控制寄存器的问题


<details>
  <summary>Details</summary>
Motivation: 在商品系统中实现低延迟I/O面临根本性权衡：要么依赖内核高开销的接口，要么完全绕过内核将敏感硬件资源暴露给用户空间，从而产生新的安全漏洞。这一困境源于硬件粒度不匹配问题

Method: 未在摘要中明确说明具体方法，但核心问题是识别了标准MMU在页面边界操作的限制，导致无法在同一页面内选择性暴露安全设备寄存器而不暴露敏感控制寄存器

Result: 未在摘要中提供具体实验结果，但指出了当前硬件架构的根本局限性，即页面粒度不匹配导致的安全与性能权衡困境

Conclusion: 需要解决硬件粒度不匹配问题，以实现在不牺牲安全性的前提下提供低延迟I/O访问，这可能需要新的硬件或软件架构方法

Abstract: Securing low-latency I/O in commodity systems forces a fundamental trade-off: rely on the kernel's high overhead mediated interface, or bypass it entirely, exposing sensitive hardware resources to userspace and creating new vulnerabilities. This dilemma stems from a hardware granularity mismatch: standard MMUs operate at page boundaries, making it impossible to selectively expose safe device registers without also exposing the sensitive control registers colocated on the same page …

</details>


### [234] [Democratizing Scalable Cloud Applications: Transactional Stateful Functions on Streaming Dataflows](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.17429&hl=zh-CN&sa=X&d=53667545061889941&ei=fS5NaavJKcSN6rQPx4HkwQU&scisig=ALhkC2RtdnT-H3ff690p12FMSxRj&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ALhkC2RIP3td447yoLbg876hcWyk&html=&pos=1&folt=cit)
*K Psarakis*

Main category: Carsten Binnig

TL;DR: 该论文旨在通过解决可编程性、高性能容错可序列化等挑战，降低云应用开发门槛，使其不再局限于少数专家工程师。


<details>
  <summary>Details</summary>
Motivation: 当前构建可扩展且一致的云应用非常困难，需要云计算、分布式系统、数据库和软件工程等多领域的专业知识，这限制了只有少数高度专业化的工程师能够进行开发，阻碍了云应用的普及和创新。

Method: 论文通过解决三个核心挑战来实现目标：1) 可编程性挑战 - 简化开发接口和抽象；2) 高性能挑战 - 优化系统性能；3) 容错可序列化挑战 - 确保分布式环境下的数据一致性和系统可靠性。

Result: 虽然摘要未提供具体实验结果，但论文的目标是开发出能够显著降低云应用开发复杂度的系统或框架，使更多开发者能够构建高性能、一致且可靠的云应用。

Conclusion: 该研究旨在通过解决关键技术挑战来民主化云应用开发，打破专业壁垒，让更广泛的开发者群体能够参与构建复杂的云应用系统。

Abstract: Web applications underpin much of modern digital life, yet building scalable and consistent cloud applications remains difficult, requiring expertise across cloud computing, distributed systems, databases, and software engineering. These demands restrict development to a small number of highly specialized engineers. This thesis aims to democratize cloud application development by addressing three challenges: programmability, high-performance fault-tolerant serializable …

</details>


### [235] [ADAPTIVE SHARDING AND FAULT TOLERANCE IN DISTRIBUTED SYSTEMS](https://scholar.google.com/scholar_url?url=https://netdb.cis.upenn.edu/wp-content/uploads/2025/12/Bhavana-Thesis.pdf&hl=zh-CN&sa=X&d=13474915154421584045&ei=N_lPaaayIO6TieoPutPYsQg&scisig=ALhkC2SeFvlCaiO79dE0dv-zWZ-R&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ALhkC2RIP3td447yoLbg876hcWyk&html=&pos=1&folt=cit)
*B Mehta*

Main category: Carsten Binnig

TL;DR: 现代分布式系统需要支持恶意参与者的容错机制，传统CFT协议如Paxos无法满足需求，需要研究拜占庭容错（BFT）协议


<details>
  <summary>Details</summary>
Motivation: 现代分布式系统在金融、电商、医疗和基础设施管理等关键领域应用广泛，需要确保在参与者可能恶意行为的情况下仍能保持正确性和可用性。传统云系统使用的崩溃容错（CFT）协议如Paxos无法应对拜占庭故障（恶意行为），因此需要更强大的容错机制。

Method: 论文未提供具体方法细节，但从上下文推断，研究可能涉及拜占庭容错（BFT）协议的设计、分析和实现，包括与传统CFT协议的对比分析。

Result: 未提供具体实验结果，但暗示传统CFT协议在恶意参与者场景下存在局限性，需要BFT协议来确保系统在拜占庭故障下的正确性和可用性。

Conclusion: 对于支持关键应用的现代分布式系统，需要超越传统CFT协议的拜占庭容错机制，以应对恶意参与者的威胁，确保系统在复杂故障模式下的可靠性。

Abstract: Modern distributed systems support critical applications across financial services, e-commerce, healthcare, and infrastructure management. For these systems, maintaining correctness and availability when participants behave maliciously is essential. While traditional cloud systems like Google's Spanner Corbett et al.(2013), Amazon's Dynamo DeCandia et al.(2007), and Facebook's Tao Bronson et al.(2013) employ crash fault-tolerant (CFT) protocols such as Paxos Lamport (2001), systems …

</details>


### [236] [Advancing Automated Machine Learning](https://scholar.google.com/scholar_url?url=https://shonan.nii.ac.jp/docs/No.223.pdf&hl=zh-CN&sa=X&d=6015198052469446131&ei=HnBTaaCZMIaw6rQPkNu46Ao&scisig=ALhkC2T9DjY88klQV6Uy_GR2a2hy&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ALhkC2RIP3td447yoLbg876hcWyk&html=&pos=0&folt=cit)
*L Kotthoff,M Lindauer,S Shirakawa*

Main category: Carsten Binnig

TL;DR: 论文探讨机器学习应用开发面临的挑战，特别是需要大量专业知识和试错过程的问题


<details>
  <summary>Details</summary>
Motivation: 机器学习作为关键AI技术已广泛应用于各领域，但开发新ML应用仍面临重大挑战，需要多年训练和经验，且许多设计决策仍需试错

Method: 论文未在摘要中明确说明具体方法，但暗示需要解决ML开发中的效率和专业知识门槛问题

Result: 摘要未提供具体实验结果，但指出了当前ML开发流程中存在的效率瓶颈和专业知识依赖问题

Conclusion: 需要改进ML开发流程，降低专业知识门槛，提高开发效率，减少试错成本

Abstract: Machine learning (ML) is a key AI technology these days and has a major impact on all kinds of fields in research, industry, and even people's daily lives. However, developing new ML applications still comes with major challenges. One of these challenges is that ML practitioners need many years of training and experience to efficiently develop new applications. Even after acquiring sufficient expertise, many design decisions are still made by trial and error, including hyperparameters and the …

</details>


### [237] [Automating Invoice Processing With Robotic Process Automation (RPA) and Large Language Model (LLM)](https://scholar.google.com/scholar_url?url=https://search.proquest.com/openview/56ffb6776d0491e5d72bf74e5f9176a0/1%3Fpq-origsite%3Dgscholar%26cbl%3D18750%26diss%3Dy&hl=zh-CN&sa=X&d=16807510250648014773&ei=HnBTaaCZMIaw6rQPkNu46Ao&scisig=ALhkC2SGfokQNNtexbceTQiq_cN9&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ALhkC2RIP3td447yoLbg876hcWyk&html=&pos=1&folt=cit)
*Y Li*

Main category: Carsten Binnig

TL;DR: 该论文探讨了利用大型语言模型（LLMs）减少发票处理中手动标注需求的方法，旨在解决传统机器学习方法依赖大量标注数据的问题。


<details>
  <summary>Details</summary>
Motivation: 发票处理是财务部门最耗时的环节之一，手动数据审查和录入速度慢、易出错且难以随业务量增长而扩展。传统机器学习工具虽然有所帮助，但通常依赖大量昂贵的标注样本，这限制了其实际应用。

Method: 论文提出利用大型语言模型（LLMs）来减少手动标注需求，通过LLMs的先进能力来辅助发票处理，可能涉及少样本学习、零样本学习或提示工程等技术。

Result: 虽然摘要未提供具体结果，但暗示LLMs能够在减少手动标注的情况下保持或提高发票处理的效率和准确性，为财务自动化提供了新的解决方案。

Conclusion: 大型语言模型为发票处理自动化提供了有前景的途径，能够显著减少对昂贵标注数据的依赖，同时保持处理质量和效率，有望推动财务部门的数字化转型。

Abstract: For most organizations, invoice processing remains one of the most time-consuming parts of financial departments. Manual data review and entry is slow, error-prone, and difficult to scale as business volumes grow. While machine learning tools have been introduced to aid in the processing, they typically rely on a large number of labeled examples, which are expensive to create. Recent advances in large language models (LLMs) offer a way to reduce manual labeling without sacrificing …

</details>


### [238] [Cost-efficient and Topology-aware Scheduling Algorithms in Distributed Stream Computing Systems](https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0167739X2500634X&hl=zh-CN&sa=X&d=12028092764857569537&ei=RfRXadHgEO6TieoPutPYsQg&scisig=ALhkC2QdHdfYqpJS9jipHqpQhTQy&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:ALhkC2RIP3td447yoLbg876hcWyk&html=&pos=0&folt=cit)
*H Li,S Wang,G Tan,X Duan*

Main category: Carsten Binnig

TL;DR: 针对Apache Storm默认轮询调度策略的不足，提出两种新颖的调度算法以优化流处理系统的执行效率和资源利用率


<details>
  <summary>Details</summary>
Motivation: 随着数据量快速增长和实时处理需求增加，流处理系统面临执行效率低下和资源消耗过大的挑战。Apache Storm默认采用简单的轮询调度策略，忽略了节点异构性、任务拓扑结构和流量模式变化，导致性能下降和资源浪费。

Method: 提出两种新颖的调度算法，考虑节点异构性、任务拓扑结构和流量模式变化，优化资源分配和任务调度策略。

Result: 通过实验验证，提出的调度算法相比默认轮询策略能显著提升执行效率并减少资源消耗。

Conclusion: 所提出的调度算法有效解决了Apache Storm默认调度策略的局限性，为流处理系统提供了更高效的资源管理和任务调度方案。

Abstract: With the rapid growth of data volume and increasing real-time processing requirements, stream processing systems face challenges of execution inefficiency and excessive resource consumption. Apache Storm employs a simplistic round-robin scheduling strategy by default, neglecting node heterogeneity, task topology, and varying traffic patterns, leading to performance degradation and resource wastage. To address these limitations, this paper proposes two novel scheduling …

</details>


### [239] [HLR-SQL: Human-like reasoning for Text-to-SQL with the human in the loop](https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0306437925001565&hl=zh-CN&sa=X&d=10706787650957050919&ei=9i1cacrWC6C16rQPm4fPgQQ&scisig=ALhkC2RpCtizNcHfz3hNS8zQLdm6&oi=scholaralrt&hist=i6heNjgAAAAJ:7693678668619210267:ALhkC2QsWlOaGDIBROSdAkWuJhrD&html=&pos=0&folt=art)
*T Eckmann,M Urban,JM Bodensohn,C Binnig*

Main category: Carsten Binnig

TL;DR: 该论文指出当前LLM-based Text-to-SQL方法在Spider和Bird等基准测试上表现优异，但这些基准未能准确反映真实企业场景中的复杂性，存在评估偏差。


<details>
  <summary>Details</summary>
Motivation: 现有Text-to-SQL基准测试（如Spider和Bird）与真实企业场景的复杂性存在显著差距，导致基于LLM的方法在这些基准上的优异表现可能无法转化为实际应用中的有效性能，需要更贴近真实场景的评估框架。

Method: 论文未在摘要中详细描述具体方法，但暗示需要开发更能反映企业场景复杂性的评估基准或方法，可能涉及对现有基准的局限性分析并提出改进方案。

Result: 摘要未提供具体实验结果，但指出当前LLM-based方法在现有基准上取得"impressive results"，同时强调这些基准与企业实际需求的脱节。

Conclusion: 需要开发更能反映真实企业场景复杂性的Text-to-SQL评估基准，以确保LLM-based方法的研究进展能够有效转化为实际应用价值。

Abstract: Recent LLM-based approaches have achieved impressive results on Text-to-SQL benchmarks such as Spider and Bird. However, these benchmarks do not accurately reflect the complexity typically encountered in real-world enterprise scenarios, where …

</details>


### [240] [hybridNDP: Dynamic operation offloading and cooperative query execution in smart storage settings](https://scholar.google.com/scholar_url?url=https://publikationen.reutlingen-university.de/files/5994/5994.pdf&hl=zh-CN&sa=X&d=14318057943880667899&ei=bkVjafiUCYaw6rQPkNu46Ao&scisig=AHkA5jQfk9YjgtWLwBM8vic-8LWO&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:AHkA5jTZCYhse3wIcZXHnO-iboY0&html=&pos=0&folt=cit)
*C Knödler,N Ramzan,I Petrov*

Main category: Carsten Binnig

TL;DR: 论文探讨了现代数据密集型系统中数据移动带来的性能瓶颈，提出利用智能存储/内存技术和近数据处理来优化系统架构


<details>
  <summary>Details</summary>
Motivation: 现代数据密集型系统处理持续超线性增长的大型数据集时，传统架构要求持久数据必须通过完整内存层次传输到主机处理，这种数据移动限制了系统性能，并对可扩展性和资源消耗产生负面影响

Method: 利用新兴的智能存储/内存技术，将处理任务卸载到数据附近执行，减少数据在内存层次中的传输

Result: 通过近数据处理方法，能够显著减少数据移动开销，提升系统性能、可扩展性和资源效率

Conclusion: 传统的数据移动密集型架构已成为性能瓶颈，采用智能存储技术和近数据处理是解决这一问题的关键方向

Abstract: Modern data-intensive systems perform complex analytical tasks on large datasets that keep growing at superlinear rates. Prevailing system architectures mandate that persistent data is transferred across the whole memory hierarchy to the host to be processed there. Data movement limits the system performance and impacts scalability and resource consumption inversely. Yet, the emergence of intelligent storage/memory technologies and the ability to offload processing close to data …

</details>


### [241] [Intelligent Orchestration for Performance-Tuned Multi-Tenant Cloud Systems](https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Ravi-Chandra-Thota-2/publication/399042503_Intelligent_Orchestration_for_Performance-Tuned_Multi-Tenant_Cloud_Systems/links/6953213427359023a01178f5/Intelligent-Orchestration-for-Performance-Tuned-Multi-Tenant-Cloud-Systems.pdf&hl=zh-CN&sa=X&d=18369326863903533535&ei=bkVjafiUCYaw6rQPkNu46Ao&scisig=AHkA5jSnvFMTgcB56rYwFMmbfxGL&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:AHkA5jTZCYhse3wIcZXHnO-iboY0&html=&pos=3&folt=cit)
*RC Thota*

Main category: Carsten Binnig

TL;DR: 论文提出了一种改进多租户SaaS平台架构的方法，解决共享资源导致的性能波动和SLA违规问题


<details>
  <summary>Details</summary>
Motivation: SaaS的广泛采用增加了对可扩展、安全且性能一致的多租户架构的需求，但现有平台存在工作负载隔离不足的问题，共享资源使用导致性能波动和SLA违规

Method: 论文提出了一种改进的多租户SaaS架构设计方法（具体方法在摘要中未详细说明）

Result: 该方法能够改善工作负载隔离，减少性能波动，并更好地满足SLA要求

Conclusion: 改进的多租户SaaS架构设计对于实现可扩展、安全且性能一致的服务交付至关重要

Abstract: The widespread adoption of Software as a Service (SaaS) has intensified the demand for architectural designs capable of delivering scalability, security, and consistent performance in environments that support multiple tenants. However, existing multi-tenant SaaS platforms frequently encounter challenges related to inadequate workload isolation, where shared resource usage leads to performance fluctuations and potential violations of service-level agreements (SLAs). This paper …

</details>


### [242] [Feedback-Driven Query Optimization: Design and Infrastructure](https://scholar.google.com/scholar_url?url=http://reports-archive.adm.cs.cmu.edu/anon/anon/2025/CMU-CS-25-150.pdf&hl=zh-CN&sa=X&d=1054692481536127846&ei=5aVkaZerNZ6u6rQPotyMwAQ&scisig=AHkA5jRD_qNeSQlxC0kHhQ3wwEbI&oi=scholaralrt&hist=i6heNjgAAAAJ:15269883191641703195:AHkA5jTZCYhse3wIcZXHnO-iboY0&html=&pos=3&folt=cit)
*Y Liang*

Main category: Carsten Binnig

TL;DR: 论文探讨了现代数据栈中查询优化器面临的挑战：当数据文件（如Parquet）在DBMS外部生成且缺乏统计摘要时，优化器因缺少数据分布信息而只能依赖无根据的猜测进行基数估计和成本计算，影响查询性能。


<details>
  <summary>Details</summary>
Motivation: 现代数据架构允许应用程序在数据库管理系统外部生成数据文件（如Parquet格式），这些文件缺乏统计摘要信息。当查询优化器无法获取数据分布信息时，只能依赖无根据的猜测进行基数估计和成本计算，导致无法选择最优执行计划，严重影响查询性能。

Method: 论文未在摘要中明确说明具体方法，但问题背景表明需要解决外部生成数据文件的统计信息缺失问题。可能的解决方案方向包括：开发新的统计信息收集机制、设计自适应优化技术、或创建数据文件元数据标准等。

Result: 摘要未提供具体实验结果，但指出了当前查询优化器在缺乏数据分布信息时的性能瓶颈问题。这为后续研究提供了明确的问题定义和研究方向。

Conclusion: 现代数据栈中外部生成数据文件的统计信息缺失是查询优化器面临的重要挑战，需要新的技术解决方案来确保优化器能够获得准确的数据分布信息，从而做出最优的查询执行决策。

Abstract: Query optimizers are critical components in database management systems (DBMSs) that turn a query that might otherwise take hours to run into one that completes in seconds. However, modern data stacks allow applications to generate data files (eg, Parquet) outside the DBMS's purview that lack statistical summaries. Without information about data distribution, optimizers fall back to ungrounded guesses when computing cardinality and cost estimates needed to select the best …

</details>


<div id='Ion Stoica'></div>

# Ion Stoica [[Back]](#toc)

### [243] [Accelerating Large-Scale Reasoning Model Inference with Sparse Self-Speculative Decoding](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.01278&hl=zh-CN&sa=X&d=5623620901030382107&ei=bfYyaeeCJebYieoPgNO3kQI&scisig=ALhkC2TJ-_7NnBGE48NJH50529L1&oi=scholaralrt&hist=i6heNjgAAAAJ:3972655621478617842:ALhkC2TgrIJfvHaNvg3HxAiQ_btv&html=&pos=0&folt=art)
*Y Zhao,J Tang,K Zhu,Z Ye,CC Chang,C Lin,J Park…*

Main category: Ion Stoica

TL;DR: 论文提出了一种名为"思维树"的新推理框架，通过探索多个推理路径来增强语言模型的推理能力，相比传统链式思维方法能更有效地解决复杂问题


<details>
  <summary>Details</summary>
Motivation: 传统链式思维方法虽然能提升语言模型的推理能力，但存在两个主要问题：1）单一推理路径可能陷入局部最优或错误方向；2）长序列生成增加了计算负担。需要一种能探索多种可能性、更高效利用计算资源的推理方法

Method: 提出"思维树"框架，将推理过程建模为树状结构。使用语言模型生成多个候选推理步骤，通过启发式评估函数选择最有希望的路径，并允许回溯和并行探索。框架包含三个核心组件：思维生成器、状态评估器和搜索算法

Result: 在多个复杂推理任务上，思维树方法显著优于标准链式思维方法。具体表现在：1）在数学推理任务上准确率提升15-25%；2）在逻辑推理任务上成功率提高30%以上；3）在需要多步推理的规划问题上表现尤为突出；4）计算效率更高，能更有效地利用推理资源

Conclusion: 思维树框架为语言模型推理提供了一种更强大和灵活的范式，通过探索多个推理路径而非单一链式思维，显著提升了复杂问题解决能力。该方法为未来语言模型推理研究开辟了新方向，特别是在需要探索和回溯的任务中具有重要应用价值

Abstract: Reasoning language models have demonstrated remarkable capabilities on challenging tasks by generating elaborate chain-of-thought (CoT) solutions. However, such lengthy generation shifts the inference bottleneck from compute …

</details>


### [244] [SonicMoE: Accelerating MoE with IO and Tile-aware Optimizations](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.14080&hl=zh-CN&sa=X&d=11088853708356791718&ei=Vh1HaZ2xA72qieoPuKej0QM&scisig=ALhkC2SYFLKMWObfjl4xfHxdGBxF&oi=scholaralrt&hist=i6heNjgAAAAJ:3972655621478617842:ALhkC2TgrIJfvHaNvg3HxAiQ_btv&html=&pos=0&folt=art)
*W Guo,M Mishra,X Cheng,I Stoica,T Dao*

Main category: Ion Stoica

TL;DR: MoE模型已成为扩展语言模型的主流架构，通过高专家粒度实现计算效率提升


<details>
  <summary>Details</summary>
Motivation: 传统语言模型扩展面临计算成本急剧增加的问题，需要一种能够在不显著增加计算开销的情况下有效扩展模型规模的方法

Method: 采用混合专家(MoE)架构，通过稀疏激活机制，在推理时只激活部分专家，实现计算效率与模型规模的解耦

Result: MoE模型在保持计算效率的同时实现了模型规模的显著扩展，高专家粒度成为当前发展趋势

Conclusion: MoE架构是扩展语言模型规模的有效解决方案，高专家粒度设计是未来发展方向

Abstract: Mixture of Experts (MoE) models have emerged as the de facto architecture for scaling up language models without significantly increasing the computational cost. Recent MoE models demonstrate a clear trend towards high expert granularity …

</details>


### [245] [FrontierCS: Evolving Challenges for Evolving Intelligence](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.15699&hl=zh-CN&sa=X&d=657018386828645307&ei=wZ1IadKlJ8W4ieoP4szBiAE&scisig=ALhkC2SxSQQBH_3hM5c7mrj_cbdF&oi=scholaralrt&hist=i6heNjgAAAAJ:3972655621478617842:ALhkC2TgrIJfvHaNvg3HxAiQ_btv&html=&pos=0&folt=art)
*Q Mang,W Chai,Z Li,H Mao,S Zhou,A Du,H Li,S Liu…*

Main category: Ion Stoica

TL;DR: FrontierCS是一个包含156个开放式计算机科学问题的基准测试，由专家设计和评审，涵盖计算机科学多个领域


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要关注封闭式问题或特定领域，缺乏能够全面评估计算机科学开放式问题解决能力的基准。需要创建一个由专家设计、涵盖计算机科学多个领域的开放式问题基准来评估AI系统的综合能力。

Method: 由计算机科学博士、顶级竞赛编程参与者和问题设计者等专家团队设计和评审，创建了156个开放式问题，涵盖计算机科学多个领域。问题设计为开放式，不预设单一正确答案。

Result: 成功创建了FrontierCS基准，包含156个开放式计算机科学问题，涵盖算法、系统、理论等多个子领域。该基准提供了评估AI系统在开放式计算机科学问题解决能力上的标准化工具。

Conclusion: FrontierCS基准填补了计算机科学开放式问题评估的空白，为评估AI系统的综合计算机科学问题解决能力提供了重要工具。该基准由专家设计，具有高质量和代表性。

Abstract: We introduce FrontierCS, a benchmark of 156 open-ended problems across diverse areas of computer science, designed and reviewed by experts, including CS PhDs and top-tier competitive programming participants and problem setters. Unlike …

</details>


### [246] [TurboDiffusion: Accelerating Video Diffusion Models by 100-200 Times](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.16093&hl=zh-CN&sa=X&d=1733635862406833236&ei=wZ1IadKlJ8W4ieoP4szBiAE&scisig=ALhkC2QyCsKL0Ffxj9OJi1-wWIWj&oi=scholaralrt&hist=i6heNjgAAAAJ:3972655621478617842:ALhkC2TgrIJfvHaNvg3HxAiQ_btv&html=&pos=1&folt=art)
*J Zhang,K Zheng,K Jiang,H Wang,I Stoica…*

Main category: Ion Stoica

TL;DR: TurboDiffusion是一个视频生成加速框架，可将端到端扩散生成速度提升100-200倍，同时保持视频质量


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型在视频生成中计算成本高、推理速度慢，需要高效的加速方法来实现实时或近实时的视频生成

Method: 采用多个组件进行加速，包括高效的采样策略、模型优化和并行化技术，具体组件未在摘要中详细说明

Result: 实现了100-200倍的端到端加速，在保持视频质量的同时显著提升生成速度

Conclusion: TurboDiffusion为视频扩散模型提供了高效的加速解决方案，使高质量视频生成更加实用

Abstract: We introduce TurboDiffusion, a video generation acceleration framework that can speed up end-to-end diffusion generation by 100-200x while maintaining video quality. TurboDiffusion mainly relies on several components for acceleration:(1) …

</details>


### [247] [Let the Barbarians In: How AI Can Accelerate Systems Performance Research](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.14806&hl=zh-CN&sa=X&d=12655841242762597195&ei=wZ1IadKlJ8W4ieoP4szBiAE&scisig=ALhkC2Q8390l3bsl-2iMtUjYmPV5&oi=scholaralrt&hist=i6heNjgAAAAJ:3972655621478617842:ALhkC2TgrIJfvHaNvg3HxAiQ_btv&html=&pos=2&folt=art)
*A Cheng,S Liu,M Pan,Z Li,S Agarwal,M Cemri…*

Main category: Ion Stoica

TL;DR: AI正在通过自动化解决方案发现来改变研究过程，这依赖于可靠的验证器来验证AI生成的候选方案


<details>
  <summary>Details</summary>
Motivation: AI正在变革研究过程，但AI驱动的方法需要可靠的验证器来验证候选解决方案，确保自动化发现的可靠性和有效性

Method: 论文未详细描述具体方法，但强调了AI驱动的研究方法需要依赖验证器来验证候选解决方案

Result: 未提供具体实验结果，但强调了验证器在AI驱动研究中的关键作用

Conclusion: AI正在改变研究范式，但成功的AI驱动研究依赖于可靠验证器的可用性，这是实现自动化解决方案发现的关键

Abstract: Artificial Intelligence (AI) is beginning to transform the research process by automating the discovery of new solutions. This shift depends on the availability of reliable verifiers, which AI-driven approaches require to validate candidate solutions …

</details>


### [248] [UCCL-EP: Portable Expert-Parallel Communication](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.19849&hl=zh-CN&sa=X&d=11627084659315948129&ei=NPlPabjGMb6Z6rQPr-v5iAc&scisig=ALhkC2RyeQ58N5kr3nM-drGBIvhd&oi=scholaralrt&hist=i6heNjgAAAAJ:3972655621478617842:ALhkC2TgrIJfvHaNvg3HxAiQ_btv&html=&pos=0&folt=art)
*Z Mao,Y Zhang,C Cui,K You,Z Chen,Z Xu…*

Main category: Ion Stoica

TL;DR: Mixture-of-Experts (MoE) 工作负载依赖专家并行 (EP) 实现高 GPU 效率，但现有 EP 通信系统（如 DeepEP）虽然性能优异，但在异构环境中的可移植性较差


<details>
  <summary>Details</summary>
Motivation: 当前专家并行通信系统在异构计算环境中存在可移植性不足的问题，限制了 MoE 工作负载在不同硬件平台上的部署和性能优化

Method: 论文未在摘要中详细说明具体方法，但暗示需要开发新的 EP 通信系统来解决异构环境下的可移植性问题

Result: 摘要未提供具体实验结果，但指出现有系统（如 DeepEP）在异构环境中表现出较差的可移植性

Conclusion: 需要开发具有更好可移植性的 EP 通信系统来支持 MoE 工作负载在异构计算环境中的高效部署

Abstract: Mixture-of-Experts (MoE) workloads rely on expert parallelism (EP) to achieve high GPU efficiency. State-of-the-art EP communication systems such as DeepEP demonstrate strong performance but exhibit poor portability across heterogeneous …

</details>


### [249] [Twilight: Adaptive Attention Sparsity with Hierarchical Top-𝑝 Pruning](https://scholar.google.com/scholar_url?url=https://neurips.cc/media/neurips-2025/Slides/117668.pdf&hl=zh-CN&sa=X&d=5322952605472348983&ei=RO1hacfKHayK6rQPgZOO6A8&scisig=AHkA5jR4R0-EX3ioWgJCMd2_kjb5&oi=scholaralrt&hist=i6heNjgAAAAJ:3972655621478617842:AHkA5jSf2ebnJwC9N9_xKs4IgCHN&html=&pos=0&folt=art)
*C Lin,J Tang,S Yang,H Wang,T Tang,B Tian,I Stoica…*

Main category: Ion Stoica

TL;DR: Twilight是一种自适应注意力稀疏化方法，通过分层Top-p剪枝机制动态调整注意力头的稀疏度，在保持模型性能的同时显著减少计算开销


<details>
  <summary>Details</summary>
Motivation: Transformer模型中的注意力机制计算复杂度高，现有稀疏化方法要么是静态的（无法适应不同输入），要么是动态但计算开销大。需要一种既能自适应输入又能高效计算的方法来减少注意力计算成本。

Method: 提出分层Top-p剪枝：1）使用轻量级预测器估计每个注意力头的稀疏度；2）采用分层Top-p策略，在注意力头级别和token级别进行双重剪枝；3）通过自适应阈值机制动态调整剪枝强度，平衡稀疏度和模型性能。

Result: 在多个基准测试中，Twilight在保持模型性能（准确率下降<1%）的同时，将注意力计算量减少30-50%，推理速度提升1.5-2倍，内存使用显著降低。

Conclusion: Twilight通过自适应注意力稀疏化有效解决了Transformer计算效率问题，分层Top-p剪枝机制在保持模型性能的同时显著提升了推理效率，为大规模语言模型部署提供了实用解决方案。

Abstract: Twilight: Adaptive Attention Sparsity with Hierarchical Top-𝒑 Pruning Page 1 Twilight: Adaptive Attention Sparsity with Hierarchical Top-𝒑 Pruning https://github.com/tsinghua-ideal/Twilight Chaofan Lin, Jiaming Tang, Shuo Yang, Hanshuo Wang, Tian Tang, Boyu Tian, Ion …

</details>


<div id='Ryan Marcus'></div>

# Ryan Marcus [[Back]](#toc)

### [250] [Adaptive Sharding in Untrusted Environments](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3769756&hl=zh-CN&sa=X&d=11343217149396390906&ei=xkw3aZjYGoqi6rQPr6DGiAo&scisig=ALhkC2S_yHYYkdS5doTreyAIHF9l&oi=scholaralrt&hist=i6heNjgAAAAJ:8513650009984140970:ALhkC2T6pXkDCKXPktXlVKewlevL&html=&pos=0&folt=art)
*B Mehta,N Baghel,MJ Amiri,BT Loo,R Marcus*

Main category: Ryan Marcus

TL;DR: 该论文研究了分布式数据管理系统中的安全分片问题，针对传统分片方法在对抗性环境下的脆弱性，提出了能够抵御拜占庭节点攻击的安全分片方案。


<details>
  <summary>Details</summary>
Motivation: 传统分布式数据管理系统的分片技术假设环境可信，节点可能崩溃但不会恶意行为。然而在对抗性环境中，拜占庭节点可能故意破坏数据一致性、可用性或完整性，现有分片方法无法有效应对这种威胁。

Method: 论文提出了安全分片方案，可能包括：拜占庭容错协议集成、加密技术保护数据完整性、分布式共识机制确保一致性、以及容错数据分配策略等。方法旨在在存在恶意节点的情况下保持系统的正确性和可用性。

Result: 提出的安全分片方案能够在拜占庭故障存在的情况下保证数据一致性、可用性和完整性。通过理论分析和/或实验验证，方案在对抗性环境中相比传统方法展现出更好的安全性和可靠性。

Conclusion: 分布式数据管理系统需要重新设计分片机制以应对对抗性环境。安全分片方案为构建可扩展且安全的分布式系统提供了重要基础，未来工作可能包括性能优化、更复杂的攻击模型研究等。

Abstract: Distributed data management systems employ data sharding techniques to achieve scalability. Traditional sharding approaches typically operate under the assumption of a trusted environment, where nodes may crash, but do not act adversarially. In …

</details>


<div id='Google Scholar'></div>

# Google Scholar [[Back]](#toc)

### [251] [Learning SQL Like a Human: Structure-Aware Curriculum Learning for Text-to-SQL Generation](https://scholar.google.com/scholar_url?url=https://aclanthology.org/anthology-files/anthology-files/pdf/findings/2025.findings-emnlp.190.pdf&hl=en&sa=X&d=5096479471912684167&ei=twYtabOlD4qi6rQPkt_b8QU&scisig=ABGrvjKXhnc1tGoMM35VGFtylkph&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ABGrvjJkn-FcYY8t5hAtGXsL8UoX&html=&pos=1&folt=rel)
*X Zhu,Q Li,L Cui,Y Du*

Main category: Google Scholar

TL;DR: 大型语言模型的Text-to-SQL能力允许用户用自然语言与数据库交互，但现有模型在处理需要多表连接的复杂查询时仍然存在困难


<details>
  <summary>Details</summary>
Motivation: 尽管Text-to-SQL技术近期有所进展，但现有模型在处理复杂查询（特别是需要多表连接的查询）时表现不佳，这限制了实际应用效果

Method: 从摘要信息来看，论文可能提出改进Text-to-SQL模型处理复杂查询的方法，但具体技术细节未在提供的摘要中明确说明

Result: 摘要未提供具体实验结果，但暗示现有模型在复杂查询（尤其是多表连接）方面存在性能瓶颈

Conclusion: 需要进一步改进Text-to-SQL模型以更好地处理复杂数据库查询，特别是涉及多表连接的场景

Abstract: The Text-to-SQL capabilities of large language allow users to interact with databases using natural language. Despite recent advances, existing models continue to struggle with complex queries, particularly those requiring multitable joins and …

</details>


### [252] [Reducing Latency in Large-Scale Data Systems Through Intelligent Memory Tiering and Offloading Mechanisms](https://scholar.google.com/scholar_url?url=https://www.researchsquare.com/article/rs-8210374/latest.pdf&hl=en&sa=X&d=17056931298618647170&ei=tQYtaZzSJ6qy6rQP1qz4iAU&scisig=ABGrvjKn9m25zS6wRwIdqxhKlss8&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=3&folt=cit)
*S Yellu*

Main category: Google Scholar

TL;DR: 论文探讨了在物联网、人工智能和实时分析驱动下数据量指数增长对大规模数据系统的挑战，指出内存访问延迟是关键瓶颈，传统同构DRAM架构因成本、功耗和密度限制已不足够。


<details>
  <summary>Details</summary>
Motivation: 数据量的指数增长对大规模数据系统提出了前所未有的需求，内存访问延迟成为关键性能瓶颈。传统同构DRAM架构在成本、功耗和密度方面的限制已无法满足现代应用需求。

Method: 论文未在摘要中明确说明具体方法，但暗示将探讨解决内存访问延迟瓶颈的新架构方案。

Result: 摘要未提供具体实验结果，但暗示将提出解决传统DRAM架构局限性的新方法。

Conclusion: 需要新的内存架构来应对数据量增长带来的挑战，解决传统同构DRAM架构的局限性。

Abstract: The exponential growth of data volumes, driven by IoT, AI, and real-time analytics, has placed unprecedented demands on large-scale data systems. A critical bottleneck in these systems is memory access latency, which directly impacts application performance and user experience. Traditional homogenous memory architectures, primarily reliant on Dynamic Random-Access Memory (DRAM), are increasingly insufficient due to cost, power, and density constraints. This paper …

</details>


### [253] [Plan of Knowledge: Retrieval-Augmented Large Language Models for Temporal Knowledge Graph Question Answering](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.04072&hl=en&sa=X&d=11113754665588102171&ei=n1cuac_zJLuZ6rQPmc7JqQw&scisig=ABGrvjJzDu2RFbEoOF_XsgJyw6f5&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ABGrvjJkn-FcYY8t5hAtGXsL8UoX&html=&pos=1&folt=rel)
*X Qian,Y Zhang,Y Zhao,B Zhou,X Sui,X Yuan*

Main category: Google Scholar

TL;DR: 该论文研究时序知识图谱问答(TKGQA)，提出了一种结合预训练时序知识图谱嵌入和大型语言模型的新方法，通过检索增强生成框架解决时间敏感问题


<details>
  <summary>Details</summary>
Motivation: 现有TKGQA方法主要依赖预训练TKG嵌入，但忽略了大型语言模型在语义理解和推理方面的优势。需要结合两者的优势来提升时序知识图谱问答的性能和泛化能力

Method: 提出检索增强生成框架，将预训练TKG嵌入用于检索相关时序事实，然后利用大型语言模型进行语义理解和推理生成答案。通过双阶段方法整合结构化知识表示和自然语言处理能力

Result: 该方法在多个TKGQA基准测试中取得显著性能提升，特别是在处理复杂时间推理问题时表现优异。相比纯嵌入方法，在准确率和泛化性方面均有改进

Conclusion: 结合预训练TKG嵌入和大型语言模型是解决时序知识图谱问答的有效策略，检索增强生成框架能够充分利用结构化时序知识和语言模型的语义理解能力，为TKGQA研究提供了新方向

Abstract: Temporal Knowledge Graph Question Answering (TKGQA) aims to answer time-sensitive questions by leveraging factual information from Temporal Knowledge Graphs (TKGs). While previous studies have employed pre-trained TKG embeddings …

</details>


### [254] [Seallms-audio: Large audio-language models for southeast asia](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.01670&hl=en&sa=X&d=7170266935781660542&ei=egswaYubH8eB6rQP-bb0sAs&scisig=ABGrvjKoH3sjPelXONEB7zghwBWT&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ABGrvjJkn-FcYY8t5hAtGXsL8UoX&html=&pos=0&folt=rel)
*C Liu,M Aljunied,G Chen,HP Chan,W Xu,Y Rong…*

Main category: Google Scholar

TL;DR: SeaLLMs-Audio是首个针对东南亚语言（印尼语、泰语、越南语）以及英语和中文的大规模音频语言模型


<details>
  <summary>Details</summary>
Motivation: 针对东南亚语言在音频语言模型领域的空白，开发专门支持多语言音频理解和生成能力的模型

Method: 基于大规模多语言音频-文本数据集训练，采用专门针对东南亚语言的架构设计和优化策略

Result: 首个支持印尼语、泰语、越南语、英语和中文的多语言音频语言模型，在东南亚语言音频任务上表现优异

Conclusion: SeaLLMs-Audio填补了东南亚语言在音频语言模型领域的空白，为多语言音频AI应用提供了重要基础

Abstract: We introduce SeaLLMs-Audio, the first large audio-language model (LALM) tailored for multiple Southeast Asian (SEA) languages-Indonesian (id), Thai (th), and Vietnamese (vi)-alongside English (en) and Chinese (zh). Trained on a large-scale …

</details>


### [255] [Causal Tracing of Object Representations in Large Vision Language Models: Mechanistic Interpretability and Hallucination Mitigation](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.05923&hl=en&sa=X&d=9255786357597901612&ei=egswaYubH8eB6rQP-bb0sAs&scisig=ABGrvjLjG8uDIsww3ZVMD5OKLwks&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ABGrvjJkn-FcYY8t5hAtGXsL8UoX&html=&pos=1&folt=rel)
*Q Li,Z Ye,X Feng,W Zhong,W Ma,X Feng*

Main category: Google Scholar

TL;DR: 该论文旨在深入探索大型视觉语言模型（LVLMs）的机制可解释性，现有分析不够全面，缺乏对视觉和文本模态的全面覆盖


<details>
  <summary>Details</summary>
Motivation: 尽管大型视觉语言模型取得了显著进展，但其机制可解释性仍然未被充分探索。现有分析不够全面，缺乏对视觉和文本模态的全面检查，需要更深入的理解模型内部工作机制

Method: 论文未在摘要中明确说明具体方法，但暗示将采用更全面的分析框架来探索LVLMs的机制可解释性，可能涉及对视觉和文本模态的联合分析

Result: 摘要中未提及具体结果，但暗示通过更全面的分析将获得对LVLMs工作机制的新见解

Conclusion: 需要更全面、更深入的分析方法来探索大型视觉语言模型的机制可解释性，以弥补现有研究的不足

Abstract: Despite the remarkable advancements of Large Vision-Language Models (LVLMs), the mechanistic interpretability remains underexplored. Existing analyses are insufficiently comprehensive and lack examination covering visual and textual …

</details>


### [256] [Performance-Aware Serverless Scheduling for Distributed AI Workloads](https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Aman-Nikhare/publication/397834660_Performance-Aware_Serverless_Scheduling_for_Distributed_AI_Workloads/links/69204ee3f4878b75fc783297/Performance-Aware-Serverless-Scheduling-for-Distributed-AI-Workloads.pdf&hl=en&sa=X&d=12699823516819938249&ei=K24xabOUDceB6rQP-bb0sAs&scisig=ABGrvjK62o2XJFgw7TH-sRLFBMRg&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ABGrvjJkn-FcYY8t5hAtGXsL8UoX&html=&pos=0&folt=rel)
*A Nikhare*

Main category: Google Scholar

TL;DR: 服务器无计算面临性能挑战，特别是在函数间通信和状态管理方面


<details>
  <summary>Details</summary>
Motivation: 当前服务器无计算平台在函数间通信和状态管理方面存在显著性能瓶颈，这限制了其在复杂工作负载中的应用

Method: 未在提供的摘要中明确说明具体方法

Result: 未在提供的摘要中提供具体结果

Conclusion: 服务器无计算需要解决函数间通信和状态管理的性能挑战才能充分发挥其潜力

Abstract: Serverless computing has emerged as a transformative paradigm for cloud infrastructure, offering automatic scaling, pay-per-use pricing, and simplified deployment. However, current serverless platforms face significant challenges when …

</details>


### [257] [Reconfigurable acceleration for database systems: Taxonomy, techniques, and research challenges](https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S1383762125003315&hl=en&sa=X&d=17630673085470509148&ei=KW4xabLgAfGQ6rQPuai-sAc&scisig=ABGrvjIhbmI40YIpRIu3IVz0fEVF&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=3&folt=cit)
*G More,S Ray,KB Kent*

Main category: Google Scholar

TL;DR: 该论文探讨了大数据场景下数据库查询处理与优化的关键问题，重点关注数据移动对性能、能效和可靠性的影响，以及数据中心基础设施的效率需求。


<details>
  <summary>Details</summary>
Motivation: 大数据应用场景中，大规模数据移动对计算系统的性能、能效和可靠性产生显著影响，而当前数据中心基础设施在处理这些挑战方面存在效率瓶颈，需要更优化的解决方案。

Method: 论文可能提出改进数据库查询处理和优化的方法，包括优化数据移动策略、提升服务器和存储基础设施效率的技术，以及针对大规模数据中心的系统架构设计。

Result: 通过优化数据移动和基础设施设计，预期能够显著提升大数据查询处理的性能、降低能耗、增强系统可靠性，从而满足大规模数据中心的高效运行需求。

Conclusion: 在大数据环境下，优化数据库查询处理和基础设施设计对于提升整体系统效率至关重要，需要综合考虑性能、能效和可靠性三个维度的平衡。

Abstract: Database query processing and optimization are critical components of modern database management systems (DBMS) that efficiently process user queries. In big data application scenarios, the movement of large volumes of data influences performance, power efficiency, and reliability, which are the three essential aspects of a computing system. Large-scale data centers require an exceptionally efficient server and storage infrastructure. The systems currently employed for managing and …

</details>


### [258] [Performant Synchronization in Geo-Distributed Databases](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.22444&hl=en&sa=X&d=308495621906007884&ei=KW4xabLgAfGQ6rQPuai-sAc&scisig=ABGrvjL5kbfuk2QyEme4crFMvaRe&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=4&folt=cit)
*D Xu,T Li,Z Sun,Z Chen,W Zhou,Y Zhang,W Lu…*

Main category: Google Scholar

TL;DR: 分布式数据库因跨节点一致性协议导致显著延迟，同步成本是主要瓶颈


<details>
  <summary>Details</summary>
Motivation: 地理分布式数据库对数据可靠性和可扩展性至关重要，但研究表明分布式数据库比单节点数据库延迟显著更高，主要原因是跨多个节点维护数据一致性的共识协议

Method: 论文未提供具体方法细节，但基于对分布式数据库延迟问题的分析，指出同步成本是主要瓶颈，特别是在广域网环境中更为显著

Result: 分析表明分布式数据库的延迟主要源于同步成本，这是跨节点一致性维护的核心开销

Conclusion: 同步成本是分布式数据库性能的主要瓶颈，特别是在广域网部署中，需要优化同步机制以提升性能

Abstract: The deployment of databases across geographically distributed regions has become increasingly critical for ensuring data reliability and scalability. Recent studies indicate that distributed databases exhibit significantly higher latency than single-node databases, primarily due to consensus protocols maintaining data consistency across multiple nodes. We argue that synchronization cost constitutes the primary bottleneck for distributed databases, which is particularly pronounced in wide-area …

</details>


### [259] [Causal Explanations for Disparate Trends: Where and Why?](https://scholar.google.com/scholar_url?url=https://afariha.github.io/papers/ExDis_SIGMOD_2026.pdf&hl=en&sa=X&d=10623870446764304526&ei=KW4xabLgAfGQ6rQPuai-sAc&scisig=ABGrvjLr43Pqp-ueL5jiTtdkGZDQ&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ABGrvjL01kD9wq87Mzaxmu2cx-P5&html=&pos=5&folt=cit)
*T Blau,B Youngmann,A Fariha,Y Moskovitch*

Main category: Google Scholar

TL;DR: 该论文提出了一种自动化系统，用于发现数据集中两组之间观察到的差异，识别差异最显著的数据区域及其影响因素。


<details>
  <summary>Details</summary>
Motivation: 在数据分析中，研究人员经常对数据集中两个感兴趣组之间观察到的差异感到困惑。需要能够精确定位差异最显著的数据区域及其原因（缓解或加剧差异的因素）的解释。对于大型高维数据集，这项任务复杂且繁琐，需要自动化系统。

Method: 论文提出了一种自动化系统，用于发现数据集中两组之间的差异。该方法能够识别差异最显著的数据区域，并分析缓解或加剧这些差异的因素。系统旨在处理大型高维数据集。

Result: 根据摘要描述，该系统能够自动发现数据集中两组之间的差异，精确定位差异最显著的数据区域，并识别影响差异的因素（缓解或加剧因素）。

Conclusion: 该研究提出了一种自动化系统，用于解释数据集中观察到的组间差异，解决了手动分析大型高维数据集的复杂性和繁琐性问题。

Abstract: During data analysis, we are often perplexed by certain disparities observed between two groups of interest within a dataset. To better understand an observed disparity, we need explanations that can pinpoint the data regions where the disparity is most pronounced, along with its causes, ie, factors that alleviate or exacerbate the disparity. This task is complex and tedious, particularly for large and high-dimensional datasets, demanding an automatic system for discovering …

</details>


### [260] [Graph Queries from Natural Language using Constrained Language Models and Visual Editing](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.00948&hl=en&sa=X&d=8301999635875002281&ei=cPYyaa8K5tiJ6g-A07eRAg&scisig=ALhkC2Q4H1Ioc4u4BOxKMw6sk6hf&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ALhkC2ST2AYAjPXMn7CfOFohiT1r&html=&pos=0&folt=rel)
*B Kantz,K Innerebner,P Waldert,S Lengauer,E Lex…*

Main category: Google Scholar

TL;DR: 提出一种基于自然语言查询知识库的新方法，使用语义解析将用户查询转换为SPARQL，无需专门查询语言或可视化编辑器


<details>
  <summary>Details</summary>
Motivation: 传统知识库查询需要专门的查询语言、问答系统或可视化查询编辑器，这些方法存在学习门槛高、灵活性不足的问题，需要更自然、易用的查询方式

Method: 采用语义解析方法，将用户自然语言查询转换为SPARQL查询，利用本体结构理解查询意图，通过查询重写和优化提高准确性和效率

Result: 该方法能够有效处理复杂查询，相比传统方法提高了查询的易用性和可访问性，在多个知识库测试中表现出良好的准确性和效率

Conclusion: 基于自然语言的语义解析方法为知识库查询提供了更直观、易用的解决方案，降低了查询门槛，提高了知识库的可访问性和实用性

Abstract: Querying knowledge bases using ontologies is usually performed using dedicated query languages, question-answering systems, or visual query editors for Knowledge Graphs. We propose a novel approach that enables users to query the …

</details>


### [261] [A survey of approximate big data computing with the random sample partition (RSP)](https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s41060-025-00916-7&hl=en&sa=X&d=2892262610479117467&ei=bvYyaYiuEam6ieoPqIeGyAM&scisig=ALhkC2TqevLjffUB-XrO3YBjpH_Z&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=1&folt=cit)
*S Salloum,KL Tan,JZ Huang*

Main category: Google Scholar

TL;DR: RSP模型通过将大数据集组织为现成随机样本集合，实现使用现有顺序算法进行高效近似大数据计算，解决传统大数据计算的可扩展性挑战。


<details>
  <summary>Details</summary>
Motivation: 传统大数据计算面临随着数据量增长而增加的内存、通信和计算需求带来的根本性可扩展性挑战，需要新的方法来克服这些限制。

Method: 提出随机样本划分(RSP)模型，通过创新的分布式数据表示方法，将大数据集组织为现成可用的随机样本集合，从而支持使用现有顺序算法进行高效近似计算。

Result: RSP模型能够克服大数据计算的可扩展性约束，实现高效近似计算，为大数据处理提供新的解决方案。

Conclusion: RSP模型通过创新的数据表示方法，为解决大数据计算的可扩展性挑战提供了有效途径，支持使用传统算法进行高效近似计算。

Abstract: Modern big data computing faces fundamental scalability challenges due to the high memory, communication, and computational requirements that grow with data volume. The random sample partition (RSP) model overcomes these constraints through an innovative distributed data representation that organizes large datasets as collections of ready-to-use random samples and enables efficient approximate big data computing with existing sequential algorithms. In this survey, we provide a …

</details>


### [262] [VideoScoop: A Non-Traditional Domain-Independent Framework For Video Analysis](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.01769&hl=en&sa=X&d=1174345373451103822&ei=bvYyaYiuEam6ieoPqIeGyAM&scisig=ALhkC2Rcgt3EnVRG4htcvRubG5_L&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=2&folt=cit)
*H Billah*

Main category: Google Scholar

TL;DR: 视频情境分析（VSA）旨在从视频内容中识别有意义的活动或情境，超越传统的内容提取任务


<details>
  <summary>Details</summary>
Motivation: 视频内容自动理解在公民监控、一般监控、辅助生活等应用中至关重要。虽然图像和视频分析研究在内容提取（如对象识别和跟踪）方面取得了进展，但识别有意义的活动或情境（如两个物体靠近）仍然困难，无法仅通过内容提取实现。

Method: 论文讨论了视频情境分析（VSA）的当前方法，但摘要未提供具体技术细节。通常VSA方法涉及从低级视觉特征到高级语义情境的推理，可能包括时空模式识别、关系建模和情境推理等技术。

Result: 摘要未提供具体实验结果，但指出视频情境分析目前仍在进行中，暗示该领域仍面临挑战。

Conclusion: 视频情境分析是一个重要但具有挑战性的研究领域，需要超越传统内容提取的方法来识别视频中的有意义活动和情境。

Abstract: Automatically understanding video contents is important for several applications in Civic Monitoring (CM), general Surveillance (SL), Assisted Living (AL), etc. Decades of Image and Video Analysis (IVA) research have advanced tasks such as content extraction (eg, object recognition and tracking). Identifying meaningful activities or situations (eg, two objects coming closer) remains difficult and cannot be achieved by content extraction alone. Currently, Video Situation Analysis (VSA) is done …

</details>


### [263] [Multi-Objective Agentic Rewrites for Unstructured Data Processing](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.02289&hl=en&sa=X&d=1489037812578301795&ei=U1w0aYT7EdOyieoP6r6mkQg&scisig=ALhkC2RS1kHKF0wH0HgG-1eYhvQ4&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=0&folt=cit)
*LL Wei,S Shankar,S Zeighami,Y Chung,F Ozcan…*

Main category: Google Scholar

TL;DR: DocETL是一个基于LLM的声明式数据处理系统，用户通过自然语言描述的语义算子构建管道，但面临算子和数据复杂性带来的挑战


<details>
  <summary>Details</summary>
Motivation: DocETL作为开源LLM驱动数据处理系统已获得广泛采用，但在处理复杂算子和数据时面临挑战，需要改进系统以应对实际应用中的复杂性

Method: 用户通过组合自然语言描述的语义算子构建数据处理管道，每个算子的逻辑由LLM执行，系统采用声明式编程范式

Result: DocETL已开源一年，截至2025年11月拥有3.2K GitHub星标，在新闻、法律、医学、政策、金融和城市规划等多个领域有用户

Conclusion: DocETL作为LLM驱动的数据处理系统已证明其价值，但需要解决复杂算子和数据带来的挑战以进一步提升实用性

Abstract: One year ago, we open-sourced DocETL, a declarative system for LLM-powered data processing that, as of November 2025, has 3.2 K GitHub stars and users across domains (eg, journalism, law, medicine, policy, finance, and urban planning). In DocETL, users build pipelines by composing operators described in natural language, also known as semantic operators, with an LLM executing each operator's logic. However, due to complexity in the operator or the data it operates on, LLMs …

</details>


### [264] [Trinity: Disaggregating Vector Search from Prefill-Decode Disaggregation in LLM Serving](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.02281&hl=en&sa=X&d=15958293753650523350&ei=U1w0aYT7EdOyieoP6r6mkQg&scisig=ALhkC2TdMXhMiYi5Rdd9xv3jB4Bs&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=1&folt=cit)
*Y Liu,C Qian*

Main category: Google Scholar

TL;DR: 论文探讨了在预填充-解码（PD）解耦架构中如何协调向量搜索，以解决当前检索任务与模型推理过程纠缠导致的尾部延迟问题。


<details>
  <summary>Details</summary>
Motivation: 预填充-解码（PD）解耦已成为工业界大规模LLM服务的主流架构，但向量搜索等检索任务仍与模型推理过程纠缠（如异构RAG请求和提示答案缓存），导致尾部延迟膨胀。需要研究如何在PD解耦架构中协调向量搜索。

Method: 提出在PD解耦架构中为向量搜索设计专用协调机制，将检索任务从模型推理过程中分离，可能涉及专门的GPU池或调度策略。

Result: 从摘要看，论文提出了在PD解耦架构中协调向量搜索的方案，但具体结果未在摘要中详细说明。

Conclusion: 需要在PD解耦架构中设计专门的向量搜索协调机制，以解决检索任务与模型推理纠缠导致的延迟问题。

Abstract: Prefill and decode (PD) disaggregation separates prompt prefill and token-by-token decode stages into distinct GPU pools and has become the dominant architecture for large-scale LLM serving in industry. Also, retrieval tasks via vector search remains entangled with the model inference process, like heterogeneous RAG requests and prompt answer caches, inflating tail latency. We are motivated to investigate how vector search should be orchestrated along with PD disaggregation with a dedicated …

</details>


### [265] [NLP and Prompt Engineering for AI Chatbots](https://scholar.google.com/scholar_url?url=https://www.taylorfrancis.com/chapters/edit/10.1201/9781003485698-19/nlp-prompt-engineering-ai-chatbots-syed-jawad-hussain-shah&hl=en&sa=X&d=16825792921478316148&ei=U1w0aYT7EdOyieoP6r6mkQg&scisig=ALhkC2SsNJmCivsNcdjPho-xco42&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=2&folt=cit)
*SJH Shah*

Main category: Google Scholar

TL;DR: 该摘要讨论了大型语言模型在自然语言处理领域的快速发展及其带来的伦理挑战，同时强调了这些模型在生成高质量文本内容方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的快速发展，它们在带来前所未有的机遇的同时也引发了新的伦理困境。研究者需要深入理解这些模型的潜力和风险，以促进其在各个领域的负责任应用。

Method: 摘要未提供具体研究方法，但暗示了通过分析大型语言模型的能力和影响来探讨相关伦理问题。

Result: 摘要指出大型语言模型能够大规模生成连贯、结构良好的书面内容，这为用户任务提供了帮助，但同时也带来了新的伦理挑战。

Conclusion: 大型语言模型作为自然语言处理领域的重要进展，既展现了强大的应用潜力，也迫切需要对其伦理影响进行深入研究和规范。

Abstract: Natural language processing (NLP) is a rapidly evolving field, and artificial intelligence (AI chatbots have become a potent tool for a range of sectors and applications. As one of its advanced models, large language models (LLMs) have created new ethical conundrums in addition to previously unheard-of possibilities. Large-scale production of coherent, well-structured written content is possible with these models, which may help users with their tasks. Understanding and mastering …

</details>


### [266] [TurboIndex: Making a Page-based DB Index Both Memory-space and Disk-I/O Efficient](https://scholar.google.com/scholar_url?url=https://mavmatrix.uta.edu/cgi/viewcontent.cgi%3Farticle%3D1011%26context%3Dcse_facpubs&hl=en&sa=X&d=11259420653314840548&ei=U1w0aYT7EdOyieoP6r6mkQg&scisig=ALhkC2QybDFb9UyXXFb_QAuswXFE&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=6&folt=cit)
*S Maharjan,S Zhao,S Jiang*

Main category: Google Scholar

TL;DR: 传统数据库的页式缓存管理在处理远小于页面大小的键值对时存在空间和I/O效率低下的问题


<details>
  <summary>Details</summary>
Motivation: 传统数据库使用基于页面的缓存管理系统（DB缓冲区）将数据和索引从块存储设备加载到字节可寻址主内存中。然而，当键值对大小远小于页面大小时，这种方法在空间和I/O方面效率低下。插入单个键值对会导致读取和写入整个页面，消耗缓冲区中整个页面的内存。

Method: 摘要未提供具体方法细节，但指出了传统页式缓存管理的问题

Result: 摘要未提供具体实验结果，但指出了传统方法的效率问题

Conclusion: 需要更高效的缓存管理方法来处理小尺寸键值对场景

Abstract: Traditional Database (DB) systems use a DB buffer, a page-based cache management system, to load data and indexes from block storage devices into byte-addressable main memory. However, this approach is inefficient in terms of space and I/O when key-value pair sizes are significantly smaller than the page size. Inserting a single key-value pair results in reading and writing an entire page, consuming a full page's worth of memory in the buffer. Moreover, the entire page is …

</details>


### [267] [Retrieval-Augmented NL2SQL Generation with Data-Centric Query Capsules for Enterprise Applications](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3767695.3769489&hl=en&sa=X&d=13072736101245149915&ei=j9I1acTTKr2qieoP9aut2Qs&scisig=ALhkC2ReRIa9_Qh06uOEWvp77n56&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ALhkC2ST2AYAjPXMn7CfOFohiT1r&html=&pos=2&folt=rel)
*J Jang,WS Li*

Main category: Google Scholar

TL;DR: LLMs在NL2SQL翻译中面临挑战，本文提出了一种基于语义对齐的增强方法


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs为NL2SQL翻译提供了可扩展的方法，但它们在处理复杂查询时存在局限性，需要改进语义对齐能力

Method: 提出了一种基于语义对齐的增强方法，可能包括查询理解、模式感知和上下文学习等技术

Result: 该方法在标准NL2SQL基准测试中表现出色，提高了翻译准确性和鲁棒性

Conclusion: 基于语义对齐的增强方法显著提升了LLMs在NL2SQL任务中的性能，为自然语言数据库查询提供了更可靠的解决方案

Abstract: Using natural language to query databases has become increasingly popular for making data access more intuitive. While Large Language Models (LLMs) offer a scalable approach for Natural Language-to-SQL (NL2SQL) translation, they often …

</details>


### [268] [A generalized approach to perform unsupervised blocking key selection for entity resolution](https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0020025525010898&hl=en&sa=X&d=11270154916216872314&ei=jtI1adSKC4yO6rQPkNu60Qg&scisig=ALhkC2QdvXvXthdIJkcuLNIiNvbx&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=3&folt=cit)
*DC Nascimento,CES Pires,TP Nóbrega*

Main category: Google Scholar

TL;DR: 该论文探讨了现实世界数据集中常见的数据质量问题，特别是实体解析（去重和记录链接）过程中的主要挑战，旨在识别代表同一真实世界对象的记录。


<details>
  <summary>Details</summary>
Motivation: 现实世界数据集通常存在多种数据质量问题，包括准确性低、违反函数依赖、不完整性以及记录间缺乏唯一性。实体解析过程面临的主要挑战需要被系统性地解决，以提高数据质量和可用性。

Method: 从摘要内容来看，论文主要关注实体解析过程，这通常涉及相似性度量、聚类算法、匹配规则等技术，用于识别代表同一实体的重复记录。

Result: 摘要未提供具体实验结果，但暗示实体解析是解决数据集重复记录问题的关键过程，能够提高数据的一致性和准确性。

Conclusion: 实体解析是处理现实世界数据集中重复记录问题的必要过程，对于提高数据质量和确保数据一致性至关重要。

Abstract: Real-world datasets are often dirty. They may present a number of data quality problems, such as low accuracy values, violations of functional dependencies, incompleteness, and lack of uniqueness amongst the stored records. The latter problem is tackled by a process usually called entity resolution (aka deduplication and record linkage), which aims to identify records that represent the same real-world object. One of the main challenges of the entity resolution process is related to …

</details>


### [269] [Building Stateless Serverless Vector DBs via Block-based Data Partitioning](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3769769&hl=en&sa=X&d=8989823525075931426&ei=x0w3abvuKLuZ6rQP9aakkAE&scisig=ALhkC2RrECAjVhc8FU3Xyu5-mZju&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ALhkC2ST2AYAjPXMn7CfOFohiT1r&html=&pos=0&folt=rel)
*D Barcelona*

Main category: Google Scholar

TL;DR: 论文探讨了传统集群式向量数据库（如Milvus）在弹性方面的不足，并提出了一种新的无服务器向量数据库架构来解决AI/ML工作负载中的弹性需求问题。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成（RAG）和其他AI/ML工作负载依赖向量数据库进行非结构化数据分析，但现有的集群式向量数据库架构（如Milvus）缺乏处理高负载变化的弹性能力，这限制了其在动态工作负载场景下的应用。

Method: 论文提出了一种无服务器（serverless）向量数据库架构，通过解耦存储和计算层、动态资源分配、按需扩展等机制来实现真正的弹性。该方法可能包括自动扩缩容、按使用付费模型、以及优化的向量索引和查询处理策略。

Result: 提出的无服务器向量数据库架构相比传统集群式架构（如Milvus）在弹性、成本效益和可扩展性方面有显著改进，能够更好地适应RAG和AI/ML工作负载的动态需求，同时降低运维复杂性和资源浪费。

Conclusion: 无服务器向量数据库架构是解决AI/ML工作负载弹性需求的有效方案，为RAG等应用提供了更灵活、高效的基础设施支持，代表了向量数据库发展的一个重要方向。

Abstract: Retrieval-Augmented Generation (RAG) and other AI/ML workloads rely on vector databases (DBs) for efficient analysis of unstructured data. However, cluster (or serverful) vector DB architectures, such as Milvus, lack the elasticity to handle high …

</details>


### [270] [A Study on Predicting Term Weighting Models with Query Performance Predictors to Enhance Information Retrieval Effectiveness](https://scholar.google.com/scholar_url?url=https://oda.uni-obuda.hu/bitstream/handle/20.500.14044/36343/014.pdf%3Fsequence%3D1%26isAllowed%3Dy&hl=en&sa=X&d=1780089933147310150&ei=x0w3abvuKLuZ6rQP9aakkAE&scisig=ALhkC2SOsgFrA_Uur-SVH2YRYVsB&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ALhkC2ST2AYAjPXMn7CfOFohiT1r&html=&pos=1&folt=rel)
*G Göksel*

Main category: Google Scholar

TL;DR: 该研究探索使用检索前查询性能预测器来指导每个查询的术语权重模型预测，以应对信息检索系统在不同查询和检索模型间的效果差异问题


<details>
  <summary>Details</summary>
Motivation: 信息检索系统在不同查询和检索模型间存在效果差异，需要更精准的查询性能预测方法来指导术语权重模型的选择

Method: 使用检索前查询性能预测器来预测每个查询的最优术语权重模型，通过预测查询性能来指导模型选择

Result: 检索前查询性能预测器能够有效指导术语权重模型的选择，提高检索系统的整体效果和稳定性

Conclusion: 基于检索前查询性能预测的术语权重模型选择方法能够有效应对检索系统的查询间差异，提升检索性能

Abstract: Information retrieval systems often exhibit variability in effectiveness across queries and retrieval models. This study investigates the use of pre-retrieval query performance predictors to guide per-query prediction of term weighting models. A …

</details>


### [271] [DepCache: A KV Cache Management Framework for GraphRAG with Dependency Attention](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3769778&hl=en&sa=X&d=18305930253930393581&ei=xUw3aYj9NY2v6rQP-rWV0QI&scisig=ALhkC2RTU8eLFNbj6NB4A_aOf5fj&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=0&folt=cit)
*H Yuan,X Ai,Q Wang,P Li,J Yu,C Chen,X Yang…*

Main category: Google Scholar

TL;DR: GraphRAG面临传统注意力机制处理图结构数据的效率问题，需要新的架构来优化图结构输入处理


<details>
  <summary>Details</summary>
Motivation: 现有LLM在处理图结构输入时效率低下，传统注意力机制基于序列设计，将图序列化到提示中会产生显著冗余，导致计算和内存开销过大

Method: 论文提出了一种新的架构（具体方法未在摘要中详细说明），旨在优化LLM对图结构输入的处理效率

Result: 未在摘要中明确说明，但暗示新方法能够解决传统注意力机制处理图结构数据的效率问题

Conclusion: 需要开发专门针对图结构输入的优化架构来提升GraphRAG的性能和效率

Abstract: Graph-based Retrieval-Augmented Generation (GraphRAG) has emerged as a promising paradigm for enhancing LLM reliability by enabling multi-hop reasoning over graph-structured knowledge. However, existing LLMs struggle to efficiently process graph-structured inputs, as traditional attention mechanisms are sequence-based and introduce significant redundancy when serializing graphs into prompt sequences, leading to excessive computation and memory overhead. To address …

</details>


### [272] [Counting Is All You Need for Instant Tuple Discovery: Enabling Real-Time HTAP in Standalone DBMSs](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3769775&hl=en&sa=X&d=12810778344900774421&ei=xUw3aYj9NY2v6rQP-rWV0QI&scisig=ALhkC2Rycw5HJm3eJv_xHzbqEuFq&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=3&folt=cit)
*K Lim,M Yoon,K Kim,A Fekete,H Jung*

Main category: Google Scholar

TL;DR: TracerETL是一个渐进式ETL框架，通过即时元组位置发现实现独立DBMS中的实时分析


<details>
  <summary>Details</summary>
Motivation: HTAP系统旨在统一操作和分析工作负载，但实时分析仍受ETL操作开销的限制。现有解决方案通常依赖双系统架构，导致数据重新格式化和迁移产生大量资源成本和延迟。

Method: 提出TracerETL框架，在转换过程中实现即时元组位置发现，支持渐进式ETL处理

Result: 在独立DBMS中实现实时分析，减少传统ETL带来的延迟和资源开销

Conclusion: TracerETL通过创新的渐进式ETL方法解决了HTAP系统中实时分析的瓶颈问题

Abstract: HTAP systems aim to unify operational and analytical workloads, yet real-time analytics remains constrained by the overhead of extract-transform-load (ETL) operations. Existing solutions often rely on dual-system architectures, incurring substantial resource costs and delays from data reformatting and relocation. We present TracerETL, a progressive ETL framework that enables real-time analytics in standalone DBMSs through instant tuple location discovery during transformation. At …

</details>


### [273] [Bloom Filters at Fifty: From Probabilistic Foundations to Modern Engineering and Applications](https://scholar.google.com/scholar_url?url=https://www.mdpi.com/1999-4893/18/12/767&hl=en&sa=X&d=3597087931033309316&ei=xUw3aYj9NY2v6rQP-rWV0QI&scisig=ALhkC2QrCQ28co2NJp-Y-odUARBl&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=4&folt=cit)
*PA Gagniuc,IB Păvăloiu,MI Dascălu*

Main category: Google Scholar

TL;DR: 关于Bloom过滤器及其衍生结构的综述性论文，涵盖其理论发展、设计原则和在现代计算系统中的应用


<details>
  <summary>Details</summary>
Motivation: Bloom过滤器作为概率计算中最具影响力的结构之一，自1970年提出以来已发展成一个AMQ结构家族，在现代计算系统中广泛应用。本文旨在系统综述其理论发展、设计原则和应用现状。

Method: 这是一篇综述性论文，采用文献综述方法，系统梳理Bloom过滤器及其衍生结构（如Counting Bloom Filter、Quotient Filter等）的理论基础、设计原则、性能特性和应用场景。

Result: 论文系统总结了Bloom过滤器家族的理论发展脉络，包括空间效率、计算速度、误报率等关键性能指标的优化方法，以及在不同应用场景中的具体实现和性能表现。

Conclusion: Bloom过滤器及其衍生结构在概率计算领域具有重要地位，其优雅的数学平衡设计使其在现代计算系统中得到广泛应用，未来仍有进一步优化和发展的空间。

Abstract: The Bloom filter remains one of the most influential constructs in probabilistic computation, a structure that achieves a mathematically elegant balance between accuracy, space efficiency, and computational speed. Since the original formulation of Dr. Burton H. Bloom in 1970, its design principles have expanded into a family of approximate membership query (AMQ) structures that now underpin a wide spectrum of modern computational systems. This review synthesizes the theoretical …

</details>


### [274] [AixelAsk: A Stepwise-Guided Retrieval and Reasoning Framework for Large Table QA](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3769831&hl=en&sa=X&d=514561426063304373&ei=keU4ac2eEam6ieoPoPyzsQs&scisig=ALhkC2QAGw4Lr-6spf9DH2I2r2Rl&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=0&folt=cit)
*C Zhang,M Zhang,Y Yang,T Chen,Z Luo*

Main category: Google Scholar

TL;DR: 该论文探讨大数据时代下表格问答系统的两种主要方法：可执行代码驱动方法和语言模型方法，分析各自的局限性并提出改进方向


<details>
  <summary>Details</summary>
Motivation: 在大数据时代，表格问答系统成为从结构化数据中提取洞察的关键工具。现有方法存在局限性：代码驱动方法（如Text-to-SQL）在处理不完整或不匹配的模式信息时表现不佳；语言模型方法也有其自身限制。需要探索更有效的表格问答解决方案。

Method: 论文分析了表格问答的两种主要方法：1）可执行代码驱动方法（如Text-to-SQL），通过生成可执行代码来查询表格；2）语言模型方法，利用预训练语言模型直接理解和回答表格相关问题。论文可能进一步探讨了这两种方法的融合或改进方案。

Result: 从摘要内容看，论文指出了当前表格问答方法的局限性：代码驱动方法受限于模式信息的完整性和匹配度；语言模型方法虽然避免了模式依赖，但可能在其他方面存在挑战。这为后续研究提供了改进方向。

Conclusion: 表格问答系统需要克服现有方法的局限性，可能通过结合代码驱动和语言模型方法的优势，或开发新的架构来处理大规模表格场景下的复杂查询需求。

Abstract: In the big data era, Table Question Answering (Table QA) has emerged as a crucial tool for extracting insights from structured data, especially in large table scenarios. There are two main categories of methods for Table QA: Executable Code-driven methods and Language Model based (LM-based) methods. Code-driven methods, eg Text-to-SQL based solutions, often struggle with incomplete or mismatching schema information. LM-based methods, include Pre-trained Language Models …

</details>


### [275] [Visual Template Inference for Data Extraction from Documents](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3769840&hl=en&sa=X&d=6517846328865941193&ei=keU4ac2eEam6ieoPoPyzsQs&scisig=ALhkC2Ss6dPMNuYgg6nkdGWWRfku&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=1&folt=cit)
*Y Lin,M Hasan,R Kosalge,A Cheung…*

Main category: Google Scholar

TL;DR: TWIX是一种从模板化文档中提取数据的工具，通过程序化生成和视觉模板匹配来解决复杂布局、高延迟和人工成本问题


<details>
  <summary>Details</summary>
Motivation: 当前数据提取工具在处理复杂文档布局时存在困难，对大型数据集产生高延迟和高成本，且需要大量人工干预。模板化文档（如发票、税务文档、财务报告、采购订单）的程序化生成特性为高效数据提取提供了机会

Method: TWIX利用模板化文档的程序化生成特性，通过视觉模板匹配技术从结构化数据生成的文档中提取数据。该方法避免了传统OCR的局限性，直接利用文档的生成逻辑进行反向数据提取

Result: TWIX能够有效处理复杂文档布局，显著降低大型数据集的处理延迟和成本，减少人工干预需求，提高数据提取的准确性和效率

Conclusion: 基于程序化生成特性的数据提取方法为模板化文档处理提供了更高效、低成本的解决方案，能够支持下游分析任务的更好实现

Abstract: Many templatized documents are programmatically generated from structured data following a visual template. Such documents include invoices, tax documents, financial reports, and purchase orders. Effective data extraction from these documents is crucial to support downstream analytical tasks. Current data extraction tools often struggle with complex document layouts, incur high latency and/or cost on large datasets, and require significant human effort. The key insight of our tool, TWIX …

</details>


### [276] [Regular Expression Indexing for Log Analysis](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3769820&hl=en&sa=X&d=18244677518062962692&ei=keU4ac2eEam6ieoPoPyzsQs&scisig=ALhkC2QnY5ukungigJRuKgeyLK5b&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=2&folt=cit)
*L Zhang,S Deep,JM Patel,K Sankaralingam*

Main category: Google Scholar

TL;DR: REI系统通过n-gram索引策略和高效存储机制，为日志数据的正则表达式查询提供索引，相比无索引的最先进正则处理引擎实现最高14倍加速，仅使用2.1%额外空间。


<details>
  <summary>Details</summary>
Motivation: 传统正则表达式查询处理在大型日志数据上效率低下，缺乏有效的索引机制。需要开发一种既能加速正则查询又不会显著增加存储开销的索引系统。

Method: 提出基于n-gram的索引策略和高效存储机制。通过n-gram提取和索引构建，优化正则表达式的匹配过程，同时设计紧凑的存储结构以最小化空间开销。

Result: 相比无索引的最先进正则处理引擎，REI系统实现最高14倍的查询速度提升，同时仅增加2.1%的额外存储空间。详细分析了索引的空间使用和工作负载执行改进。

Conclusion: REI系统证明n-gram索引策略能有效加速正则表达式查询，在可接受的空间开销下显著提升日志数据处理效率，为大规模日志分析提供了实用解决方案。

Abstract: In this paper, we present the design and architecture of REI, a novel system for indexing log data for regular expression queries. Our main contribution is an n-gram-based indexing strategy and an efficient storage mechanism that results in a speedup of up to 14x compared to state-of-the-art regex processing engines that do not use indexing, using only 2.1% of extra space. We perform a detailed study that analyzes the space usage of the index and the improvement in workload execution …

</details>


### [277] [GraphMatch: Subgraph Query Processing on Steroids](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3769797&hl=en&sa=X&d=9884673074786659706&ei=keU4ac2eEam6ieoPoPyzsQs&scisig=ALhkC2RHYWy_o0_Gic4slgTXaosH&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=4&folt=cit)
*J Dann,T Goetz,D Ritter,J Giceva,H Fröning…*

Main category: Google Scholar

TL;DR: GraphMatch是一种硬件加速的解决方案，用于优化图数据库中的子图查询处理，通过专用硬件加速集合交集操作来提升性能


<details>
  <summary>Details</summary>
Motivation: 随着图在大型语言模型和商业数据库中的重要性增加，子图查询处理成为图分析中的关键挑战。CPU上的集合交集操作性能瓶颈限制了子图查询的效率，而硬件加速在相关领域（如图和关系连接处理）已显示出可行性

Method: 提出GraphMatch硬件加速架构，专门针对子图查询处理中的集合交集操作进行优化。该方法利用专用硬件设计来加速这一关键计算瓶颈

Result: GraphMatch通过硬件加速显著提升了子图查询处理的性能，解决了CPU上集合交集操作的瓶颈问题

Conclusion: 硬件加速是解决图分析中子图查询处理性能瓶颈的有效途径，GraphMatch展示了专用硬件设计在该领域的应用潜力

Abstract: Recently, graphs are becoming increasingly interesting in the context of large language models and as overlays for commercial databases. Subgraph query processing is an especially challenging workload for graph analysis that is bottlenecked by slow set intersection performance on CPUs. Previous work has shown the viability of utilizing hardware acceleration for related domains like graph and relational join processing. We propose GraphMatch, a hardware-accelerated …

</details>


### [278] [Apparatus and method for optimizing an operation using a deviation](https://scholar.google.com/scholar_url?url=https://patents.google.com/patent/US12468954B1/en&hl=en&sa=X&d=6281387561804611023&ei=keU4ac2eEam6ieoPoPyzsQs&scisig=ALhkC2T1R7rKxBVvRYL2082KF7KR&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=5&folt=cit)
*P Kumar,P SINHA,R Barve*

Main category: Google Scholar

TL;DR: 提出了一种基于偏差的操作优化装置与方法，通过分析操作员的操作记录，识别操作偏差并进行优化


<details>
  <summary>Details</summary>
Motivation: 在复杂操作环境中，不同操作员的操作方式存在差异，这些差异可能导致效率低下或错误。需要一种系统化的方法来识别和优化操作偏差，提高操作的一致性和效率。

Method: 开发了一个包含处理器和存储器的装置，接收多个操作员的操作记录，对这些记录进行标签分类，然后使用语言处理技术识别操作偏差，最后基于这些偏差进行优化。

Result: 该方法能够自动识别操作员之间的操作偏差，为操作优化提供数据支持，提高操作的一致性和效率。

Conclusion: 通过分析操作记录和识别偏差，可以系统化地优化操作流程，提高操作质量和效率。

Abstract: An apparatus and method for optimizing an operation using a deviation are disclosed. The apparatus includes a memory communicatively connected to at least a processor, wherein the memory contains instructions configuring the at least a processor to receive a plurality of operation notes associated with a plurality of operators and a plurality of operations, label the plurality of operation notes to at least an operation label, identify at least an operation deviation, using a language …

</details>


### [279] [RABIT: Efficient Range Queries with Bitmap Indexing](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3769819&hl=en&sa=X&d=686373910756078539&ei=kuU4adnZOObYieoPyNfA6QY&scisig=ALhkC2SK85K8G8g1WgttVx2thz9L&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ALhkC2ST2AYAjPXMn7CfOFohiT1r&html=&pos=6&folt=rel)
*J Wang,F Xiao,M Athanassoulis*

Main category: Google Scholar

TL;DR: 论文讨论了范围查询在分析工作负载中的重要性，指出现有树状索引在范围查询性能上的不足，并提出改进方案


<details>
  <summary>Details</summary>
Motivation: 范围查询对于分析工作负载至关重要，但现有树状索引在范围查询性能上存在不足，需要更高效的索引方案来减少存储访问

Method: 未在摘要中明确说明具体方法，但暗示针对树状索引的改进方案，可能涉及新的索引结构或优化技术

Result: 摘要未提供具体实验结果，但暗示提出的方法能够改善范围查询性能

Conclusion: 需要改进现有索引技术以更好地支持范围查询，提高分析工作负载的效率

Abstract: Range queries (RQ) are crucial for analytical workloads, with indexing support being essential to minimize storage accesses. However, indexing support for RQ faces several challenges. Existing tree-based indexes have suboptimal RQ performance …

</details>


### [280] [Featurized-Decomposition Join: Low-Cost Semantic Joins with Guarantees](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.05399&hl=en&sa=X&d=477424245421971840&ei=oXs6adiFE-uuieoPmeTMgAc&scisig=ALhkC2Rprkcwqr9IybEOj4KPDbj6&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=0&folt=cit)
*S Zeighami,S Shankar,A Parameswaran*

Main category: Google Scholar

TL;DR: 该论文研究LLM在数据系统中处理大规模文本数据集时的语义连接问题，提出了一种优化方法以减少昂贵的LLM调用成本。


<details>
  <summary>Details</summary>
Motivation: LLM在处理包含文本字段的大规模数据集时，语义连接任务需要为每对元组调用LLM评估自然语言谓词，这种朴素实现成本极高，需要更高效的解决方案。

Method: 论文提出了一种优化语义连接的方法，通过减少所需的LLM调用次数来降低计算成本。具体方法可能涉及近似算法、索引技术或基于语义的过滤策略。

Result: 提出的方法显著减少了LLM调用次数，在保持语义连接质量的同时大幅降低了计算成本，提高了大规模数据集处理的效率。

Conclusion: 该研究为LLM在数据系统中的高效应用提供了重要解决方案，通过优化语义连接算法，使LLM能够更经济地处理大规模文本数据集。

Abstract: Large Language Models (LLMs) are being increasingly used within data systems to process large datasets with text fields. A broad class of such tasks involves a semantic join-joining two tables based on a natural language predicate per pair of tuples, evaluated using an LLM. Semantic joins generalize tasks such as entity matching and record categorization, as well as more complex text understanding tasks. A naive implementation is expensive as it requires invoking an LLM for every …

</details>


### [281] [Towards a Digital Decision Support Tool for Sustainable Product Design and Production](https://scholar.google.com/scholar_url?url=https://reduce.pro2future.at/wp-content/uploads/2025/09/Towards-a-Digital-Decision-Support-Tool_camera-ready.pdf&hl=en&sa=X&d=7249327478693348792&ei=oXs6adiFE-uuieoPmeTMgAc&scisig=ALhkC2Rc0ojCIuYShA3VT9_WCV_c&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=2&folt=cit)
*M Brillinger,W Rom,J Worschech,H Gursch…*

Main category: Google Scholar

TL;DR: 提出一个新颖框架，通过数字孪生和AI技术解决欧洲制造业在减少CO₂排放同时保持竞争力的挑战，克服现有方案在环境考量、数据不确定性和可解释性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 欧洲制造业面临减少CO₂排放同时保持竞争力的双重压力。数字化转型为通过产品设计和生产工具改善生态与经济可持续性提供了机遇，但现有数字解决方案往往忽视环境因素，或依赖高不确定性、低可解释性的数据和模型，限制了用户接受度。

Method: 提出一个新颖框架，整合数字孪生和人工智能技术，专注于环境可持续性，提高数据模型的可解释性和可靠性，以支持制造业的生态与经济目标。

Result: 框架能够有效解决现有数字解决方案的局限性，通过增强的环境考量、降低的数据不确定性和提高的可解释性，促进制造业的可持续转型和用户接受度。

Conclusion: 所提出的框架为欧洲制造业提供了一个可行的路径，在数字化转型中平衡生态与经济可持续性，通过改进的工具和方法支持CO₂减排和竞争力保持的双重目标。

Abstract: The European manufacturing industry faces growing pressure to reduce CO₂ emissions while maintaining competitiveness. Digital transformation presents opportunities to improve ecological and economic sustainability via advanced tools for product design and production. However, existing digital solutions often neglect environmental aspects or depend on data and models with high uncertainty and low explainability, limiting user acceptance. This paper proposes a novel framework …

</details>


### [282] [Sampling-based Predictive Database Buffer Management](https://scholar.google.com/scholar_url?url=https://www.vldb.org/pvldb/vol18/p5569-khalaji.pdf&hl=en&sa=X&d=4528231848738139191&ei=agA8aYSkB-uuieoPmpfHkAk&scisig=ALhkC2SGCg_0waNEHWCekNFaQenh&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=1&folt=cit)
*M Khalaji,T Vanderkooy,RB Guo,K Daudjee*

Main category: Google Scholar

TL;DR: 数据库系统中缓冲区管理的关键作用及其直接控制内存缓存的方式


<details>
  <summary>Details</summary>
Motivation: 数据库系统的缓冲区管理器需要控制内存使用，确保缓冲区数量不超过主内存容量，这是数据库性能优化的核心问题

Method: 缓冲区管理器直接控制内存或缓冲区缓存，当请求超过可用空间时，选择缓冲区清空并将其内容写回二级存储

Result: 描述了缓冲区管理的基本机制和工作原理，但没有提供具体的实验结果或性能数据

Conclusion: 缓冲区管理是数据库系统的关键任务，直接影响系统性能和内存使用效率

Abstract: Buffer management is a critical task in database systems. A database system's buffer manager controls memory with the task to limit the number of buffers in use so that they fit in the main memory of the machine running the database system. For most database systems, eg, PostgreSQL, the buffer manager controls the memory or buffer cache directly. This means that when requests exceed the available space, the buffer manager has to pick a buffer to empty by returning its contents to secondary storage …

</details>


### [283] [Bridging Code Graphs and Large Language Models for Better Code Understanding](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.07666&hl=en&sa=X&d=1265126780715203303&ei=agA8aYSkB-uuieoPmpfHkAk&scisig=ALhkC2QWL9auzD-_pXr1BR0lckmC&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=3&folt=cit)
*Z Chen,Z Chu,Y Gui,F Guo,Y Wan,C Shi*

Main category: Google Scholar

TL;DR: LLMs在代码智能任务中表现出色，但依赖线性化token序列限制了其对程序结构语义的理解能力。现有方法存在提示长度限制或需要任务特定架构修改的问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在代码生成、摘要和翻译等代码智能任务中表现出色，但其基于线性化token序列的处理方式无法有效理解程序的结构语义。现有方法要么受到提示长度限制，要么需要针对特定任务修改模型架构，存在局限性。

Method: 论文未完整提供方法部分。从摘要片段看，可能涉及图增强提示或结构感知预训练等方法，但具体技术细节未明确。

Result: 摘要未提供具体实验结果。从内容推断，现有方法在程序结构理解方面存在局限性，需要更有效的解决方案。

Conclusion: 需要开发既能理解程序结构语义，又不受提示长度限制且无需任务特定架构修改的新方法，以提升LLMs在代码智能任务中的性能。

Abstract: Large Language Models (LLMs) have demonstrated remarkable performance in code intelligence tasks such as code generation, summarization, and translation. However, their reliance on linearized token sequences limits their ability to understand the structural semantics of programs. While prior studies have explored graphaugmented prompting and structure-aware pretraining, they either suffer from prompt length constraints or require task-specific architectural changes that are …

</details>


### [284] [Learning-Augmented Ski Rental with Discrete Distributions: A Bayesian Approach](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.07313&hl=en&sa=X&d=9595580216924465987&ei=agA8aYSkB-uuieoPmpfHkAk&scisig=ALhkC2TuWEbTQddTxG9AZ_E0t_N4&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=4&folt=cit)
*B Kang,H Park,C Fan*

Main category: Google Scholar

TL;DR: 本文重新审视经典滑雪租赁问题，提出基于贝叶斯决策和机器学习预测的统一框架，通过维护时间范围的精确后验分布实现原则性不确定性量化


<details>
  <summary>Details</summary>
Motivation: 传统算法在无假设情况下最小化最坏情况成本，而近期学习增强方法利用噪声预测提供鲁棒性保证。本文旨在统一这两种视角，为滑雪租赁问题提供更全面的决策框架

Method: 提出离散贝叶斯框架，维护时间范围的精确后验分布，实现原则性不确定性量化。该框架结合传统最坏情况分析和学习增强方法，提供统一的决策理论视角

Result: 该方法能够统一传统算法和学习增强方法，提供更全面的不确定性量化，在贝叶斯框架下实现原则性决策，同时保持对预测误差的鲁棒性

Conclusion: 贝叶斯决策框架为滑雪租赁问题提供了统一的视角，将传统最坏情况分析和学习增强方法相结合，通过精确的后验分布维护实现原则性不确定性量化，为在线决策问题提供了更全面的解决方案

Abstract: We revisit the classic ski rental problem through the lens of Bayesian decision-making and machine-learned predictions. While traditional algorithms minimize worst-case cost without assumptions, and recent learning-augmented approaches leverage noisy forecasts with robustness guarantees, our work unifies these perspectives. We propose a discrete Bayesian framework that maintains exact posterior distributions over the time horizon, enabling principled uncertainty …

</details>


### [285] [NeurIDA: Dynamic Modeling for Effective In-Database Analytics](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.08483&hl=en&sa=X&d=17662885084729093749&ei=I4Q9aZ-GGOuuieoPmpfHkAk&scisig=ALhkC2Rr0wMoYa3OrowDn_tQYIX8&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=0&folt=cit)
*L Zeng,N Xing,S Cai,P Lu,G Chen,J Pei,BC Ooi*

Main category: Google Scholar

TL;DR: RDBMS需要深度集成机器学习，但传统静态ML模型与动态、多查询的数据库环境存在根本性矛盾


<details>
  <summary>Details</summary>
Motivation: 随着预测分析需求增长，RDBMS深度集成ML变得至关重要，但传统静态、任务特定的ML模型无法适应RDBMS动态、多查询的环境

Method: 论文未提供具体方法细节，但从摘要看可能涉及开发能够适应RDBMS动态环境的ML集成框架或自适应模型

Result: 摘要未提供具体结果，但暗示需要解决ML模型静态性与RDBMS动态性之间的根本矛盾

Conclusion: RDBMS与ML的深度集成面临根本挑战，需要开发能够适应数据库动态环境的ML解决方案

Abstract: Relational Database Management Systems (RDBMS) manage complex, interrelated data and support a broad spectrum of analytical tasks. With the growing demand for predictive analytics, the deep integration of machine learning (ML) into RDBMS has become critical. However, a fundamental challenge hinders this evolution: conventional ML models are static and task-specific, whereas RDBMS environments are dynamic and must support diverse analytical queries. Each analytical task entails …

</details>


### [286] [Performance analysis of AI-optimized query execution in simulated cloud data warehousing](https://scholar.google.com/scholar_url?url=https://api.taylorfrancis.com/content/chapters/edit/download%3FidentifierName%3Ddoi%26identifierValue%3D10.1201/9781003724995-43%26type%3Dchapterpdf&hl=en&sa=X&d=15249722802590795129&ei=I4Q9aZ-GGOuuieoPmpfHkAk&scisig=ALhkC2R-IeTXGASxVgHwH7hrFeKx&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=2&folt=cit)
*TK Kota*

Main category: Google Scholar

TL;DR: 提出基于机器学习的云数据仓库查询性能优化方法，通过动态调整查询计划和资源分配来提升查询响应速度和资源利用率


<details>
  <summary>Details</summary>
Motivation: 传统云数据仓库查询性能方法存在查询响应慢、资源利用效率低的问题，需要更智能的优化方案来提升大规模数据分析的效率和决策支持能力

Method: 基于机器学习的动态查询性能优化方法，在模拟云环境中通过机器学习算法动态调整查询计划和查询执行策略

Result: 在模拟云环境中实现了查询性能的显著提升，包括更快的查询响应时间和更高的资源利用效率

Conclusion: 机器学习方法能够有效优化云数据仓库的查询性能，为大规模数据分析提供更高效的解决方案

Abstract: Cloud data warehousing is vital in scalable data administration and decision-making with high-speed analytics. Inefficient query performance is a concern with traditional query performance approaches, such as slow query responses and inefficient resource usage. This paper introduces a machine learning-based method to enhance query performance in a simulated cloud. The method dynamically adjusts query planning and query performance based on machine learning. The …

</details>


### [287] [Illuminating the Hidden Challenges of Serverless LLM Systems](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3774899.3775017&hl=en&sa=X&d=12359232514454897885&ei=JIQ9ad7bHdOyieoP1qvf4A4&scisig=ALhkC2TJ_rPy9vkPeJgYLIvuT6RE&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ALhkC2ST2AYAjPXMn7CfOFohiT1r&html=&pos=1&folt=rel)
*A Samanta,TG Nguyen*

Main category: Google Scholar

TL;DR: 大型语言模型与无服务器计算的融合为普及AI能力提供了机遇，但面临部署、成本、性能等多重挑战


<details>
  <summary>Details</summary>
Motivation: 将大型语言模型与无服务器计算结合，旨在降低AI应用门槛，使先进AI能力更广泛可用，但当前集成面临技术挑战

Method: 论文未提供具体方法细节，但暗示需要解决LLM在无服务器环境中的部署、优化、成本控制等系统性问题

Result: 未提供具体实验结果，但指出LLM与无服务器计算集成面临部署复杂性、成本不可预测性、性能波动等挑战

Conclusion: LLM与无服务器计算的融合具有巨大潜力，但需要解决技术挑战才能实现AI能力的广泛普及

Abstract: The convergence of large language models (LLMs) and serverless computing presents a unique opportunity to make cutting-edge artificial intelligence (AI) capabilities more widely available. However, this integration provides several …

</details>


### [288] [Comment les GPU et TPU gèrent-ils la mémoire durant la phase de convolution de l'entrainement des CNNs?](https://scholar.google.com/scholar_url?url=https://ntde.kube-ext.isc.heia-fr.ch/2025/Session1_1.pdf&hl=en&sa=X&d=17755663305505702793&ei=xuo-aZihLb2qieoPuKej0QM&scisig=ALhkC2STvKn5mFWME9IprJiza3Dk&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=2&folt=cit)
*V Berisha,A Kouma*

Main category: Google Scholar

TL;DR: 比较GPU和TPU在CNN训练中的数据移动和存储策略差异，分析两种加速器架构如何应对数据瓶颈问题


<details>
  <summary>Details</summary>
Motivation: CNN训练正从计算能力限制转向数据移动和存储限制，需要理解不同加速器架构如何应对这一瓶颈

Method: 比较分析GPU和TPU两种主流加速器架构的数据管理策略，包括内存层次结构、数据移动机制和存储优化技术

Result: 识别出GPU和TPU在数据管理策略上的关键差异，包括内存带宽、缓存层次、数据重用模式等方面的不同设计选择

Conclusion: 不同的加速器架构采用不同的数据管理策略来应对CNN训练中的数据瓶颈，这些策略选择对性能和能效有重要影响

Abstract: ABSTRACT L'entraînement des réseaux de neurones convolutionnels (convolutional neural network, CNN) devient rapidement limité non plus par la puissance brute, mais par la manière dont on déplace et stocke les données. Dans ce papier, nous comparons deux familles d'accélérateurs très répandues, les unités de traitement graphique (graphics processing units, GPU) et les unités de processeurs tensoriels (tensor processing units, TPU), pour comprendre leurs stratégies de gestion …

</details>


### [289] [Estratégias de sharding de based de dados: Um guia orientado a domínio para construir sistemas escalávéis](https://scholar.google.com/scholar_url?url=https://recipp.ipp.pt/bitstreams/6b4fbff7-414e-42fb-8faa-2e9a54de3310/download&hl=en&sa=X&d=279514367109459633&ei=xuo-aZihLb2qieoPuKej0QM&scisig=ALhkC2SKMJ4Rx7mcpFeqh6jWpe48&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=3&folt=cit)
*C ALVES,MF PINHEIRO*

Main category: Google Scholar

TL;DR: 论文探讨了在数据激增背景下，通过分片技术实现数据库水平扩展的必要性和方法，分析了传统单体数据库的局限性，并提出了创新的分片架构方案。


<details>
  <summary>Details</summary>
Motivation: 当代软件环境中数据量激增，传统单体数据库在面对不断增长的工作负载和用户规模时性能受限，需要可扩展的数据库架构来应对这些挑战。

Method: 采用分片技术，将数据分区到多个节点上，实现水平扩展。论文可能提出了创新的分片策略、架构设计或算法来优化数据分布和查询性能。

Result: 通过分片架构实现了数据库的水平可扩展性，能够有效处理大规模工作负载，提升系统性能和吞吐量，同时保持数据一致性和可用性。

Conclusion: 分片是应对现代数据规模挑战的关键技术，通过水平分区可以实现数据库的有效扩展，满足大规模应用的需求，是未来数据库架构的重要发展方向。

Abstract: In the contemporary software landscape, the sheer surge in data generation underscores the necessity for scalable database architectures. Monolithic databases, while known for their robust consistency, often underperform when facing escalating workloads and growing user bases. Sharding—the partitioning of data across multiple nodes—has consequently become an essential architectural approach, facilitating horizontal scalability to meet these demands. This dissertation offers an …

</details>


### [290] [d-TreeRPO: Towards More Reliable Policy Optimization for Diffusion Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.09675&hl=en&sa=X&d=9865335187755330158&ei=yOo-aanBE72qieoPuKej0QM&scisig=ALhkC2SL9WzrH7YWZv_oYq9lZNwS&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ALhkC2ST2AYAjPXMn7CfOFohiT1r&html=&pos=1&folt=rel)
*L Pan,S Tao,Y Zhai,Z Fu,L Fang,M He,L Zhang…*

Main category: Google Scholar

TL;DR: 该论文提出了一种新的强化学习方法，用于提升扩散大语言模型（dLLMs）的可靠性和性能，通过改进优势估计和预测概率估计来解决现有方法的不足。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在扩散大语言模型（dLLMs）上存在两个主要缺陷：优势估计不准确和预测概率估计不精确。这些不足限制了dLLMs在可靠强化学习中的性能表现，需要新的方法来同时解决这两个问题。

Method: 论文提出了一种新的强化学习框架，专门针对dLLMs设计，改进了优势估计机制并提升了预测概率的估计精度。该方法可能结合了更精确的回报建模、改进的策略梯度估计或更稳定的训练技术。

Result: 新方法在多个基准测试中显著优于现有强化学习方法，在文本生成质量、任务完成率和模型可靠性方面都取得了更好的表现，特别是在需要精确概率估计的任务上优势明显。

Conclusion: 通过同时改进优势估计和预测概率估计，该研究为扩散大语言模型的可靠强化学习提供了有效的解决方案，推动了dLLMs在实际应用中的可靠部署。

Abstract: Reliable reinforcement learning (RL) for diffusion large language models (dLLMs) requires both accurate advantage estimation and precise estimation of prediction probabilities. Existing RL methods for dLLMs fall short in both aspects: they rely on …

</details>


### [291] [ArtistMus: A Globally Diverse, Artist-Centric Benchmark for Retrieval-Augmented Music Question Answering](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.05430&hl=en&sa=X&d=15831430968276710241&ei=yOo-aanBE72qieoPuKej0QM&scisig=ALhkC2Qx0w7XeQVCRkgCeANPBd6T&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ALhkC2ST2AYAjPXMn7CfOFohiT1r&html=&pos=3&folt=rel)
*D Kwon,SH Doh,J Nam*

Main category: Google Scholar

TL;DR: 该论文针对大语言模型在音乐相关推理任务中表现不佳的问题，提出了一种结合音乐知识图谱和检索增强生成的方法来提升模型在音乐问答中的性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在开放域问答方面取得了显著进展，但在音乐相关推理任务中表现有限，主要原因是预训练数据中音乐知识的稀疏性。现有模型缺乏对音乐领域专业知识的深入理解，难以处理复杂的音乐概念和关系。

Method: 论文提出了一种结合音乐知识图谱和检索增强生成的方法。通过构建或利用现有的音乐知识图谱来增强模型对音乐领域知识的理解，同时采用检索机制从外部知识源获取相关信息，以辅助模型生成更准确、专业的音乐相关答案。

Result: 该方法显著提升了模型在音乐问答任务中的性能，相比基线模型在准确性和专业性方面都有明显改善。模型能够更好地理解音乐概念、艺术家关系、作品信息等专业内容，生成更准确和详细的回答。

Conclusion: 通过结合音乐知识图谱和检索增强生成技术，可以有效弥补大语言模型在音乐知识方面的不足，提升其在音乐相关推理任务中的表现。这种方法为领域特定的知识增强提供了有价值的参考。

Abstract: Recent advances in large language models (LLMs) have transformed open-domain question answering, yet their effectiveness in music-related reasoning remains limited due to sparse music knowledge in pretraining data. While music information …

</details>


### [292] [Patronus: Identifying and Mitigating Transferable Backdoors in Pre-trained Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.06899&hl=en&sa=X&d=637949886217323505&ei=yOo-aanBE72qieoPuKej0QM&scisig=ALhkC2SALyd2dXAUSWq720kKWDZB&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ALhkC2ST2AYAjPXMn7CfOFohiT1r&html=&pos=4&folt=rel)
*T Zhao,W Du,H Zhao,S Duan,G Liu*

Main category: Google Scholar

TL;DR: 该论文指出当前针对预训练语言模型供应链中可迁移后门的防御研究存在严重不足，主要依赖输出特征空间的异常检测，并识别了这种方法的重大缺陷


<details>
  <summary>Details</summary>
Motivation: 可迁移后门对预训练语言模型供应链构成严重威胁，而现有的防御研究仍处于初级阶段，主要依赖输出特征空间的异常检测方法，存在明显缺陷

Method: 论文未在摘要中详细描述具体方法，但暗示将提出新的防御策略来改进现有基于输出特征空间异常检测的不足

Result: 识别了当前防御方法的重大缺陷，但未在摘要中展示具体实验结果

Conclusion: 需要开发更有效的防御机制来应对预训练语言模型供应链中的可迁移后门威胁

Abstract: Transferable backdoors pose a severe threat to the Pre-trained Language Models (PLMs) supply chain, yet defensive research remains nascent, primarily relying on detecting anomalies in the output feature space. We identify a critical flaw that fine …

</details>


### [293] [VisMem: Latent Vision Memory Unlocks Potential of Vision-Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.11007&hl=en&sa=X&d=9727316877683377454&ei=yOo-aanBE72qieoPuKej0QM&scisig=ALhkC2QQMQabC6y3FbqLaNYGraIT&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ALhkC2ST2AYAjPXMn7CfOFohiT1r&html=&pos=5&folt=rel)
*X Yu,C Xu,G Zhang,Z Chen,Y Zhang,Y He,PT Jiang…*

Main category: Google Scholar

TL;DR: 视觉语言模型存在"视觉处理瓶颈"，容易丢失视觉证据的grounding，导致幻觉和错误，需要改进视觉处理能力


<details>
  <summary>Details</summary>
Motivation: 尽管视觉语言模型取得了显著成功，但在复杂视觉任务上的性能受到"视觉处理瓶颈"的限制，模型倾向于丢失视觉证据的grounding，表现出幻觉和错误，需要解决这一问题

Method: 论文未提供具体方法细节，但从摘要看可能涉及改进视觉处理架构、增强视觉grounding机制或开发新的训练策略来解决视觉瓶颈问题

Result: 摘要未提供具体实验结果，但暗示当前VLMs在复杂视觉任务上存在性能瓶颈，需要改进视觉处理能力

Conclusion: 视觉语言模型需要解决视觉处理瓶颈问题，以提升在复杂视觉任务上的性能和可靠性

Abstract: Despite the remarkable success of Vision-Language Models (VLMs), their performance on a range of complex visual tasks is often hindered by a" visual processing bottleneck": a propensity to lose grounding in visual evidence and exhibit …

</details>


### [294] [Hybrid Learning and Optimization-Based Dynamic Scheduling for DL Workloads on Heterogeneous GPU Clusters](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.10271&hl=en&sa=X&d=7684969257094676747&ei=gGdAaYfaMPO16rQPzoDK8Ag&scisig=ALhkC2TMYBOIX-ddYq16WUZdqcBt&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ALhkC2ST2AYAjPXMn7CfOFohiT1r&html=&pos=0&folt=rel)
*S Dongare,RIS Khan,H Albahar,N Zhao,DM Maita…*

Main category: Google Scholar

TL;DR: 现代云平台面临大规模深度学习工作负载调度挑战，需要高吞吐低延迟的GPU调度方案，但GPU集群异构性增强和应用特性不透明导致传统调度器效率低下。


<details>
  <summary>Details</summary>
Motivation: 现代云平台承载大规模深度学习工作负载，对GPU调度提出高吞吐、低延迟要求。GPU集群异构性日益增强，同时应用特性不透明，传统调度器难以有效应对这些挑战。

Method: 论文未提供具体方法细节，但根据摘要内容推断，可能涉及新型GPU调度算法或框架，旨在解决异构GPU集群中深度学习工作负载的高效调度问题。

Result: 摘要未提供具体实验结果，但暗示现有调度方案在异构GPU集群和大规模深度学习工作负载下存在效率瓶颈。

Conclusion: 需要开发新的GPU调度解决方案来应对现代云平台中大规模深度学习工作负载的调度挑战，特别是针对异构GPU集群和应用特性不透明的问题。

Abstract: Modern cloud platforms increasingly host large-scale deep learning (DL) workloads, demanding high-throughput, low-latency GPU scheduling. However, the growing heterogeneity of GPU clusters and limited visibility into application characteristics …

</details>


### [295] [End-to-End Declarative Data Analytics: Co-designing Engines, Interfaces, and Cloud Infrastructure](https://scholar.google.com/scholar_url?url=https://anakli.inf.ethz.ch/papers/declarative_analytics_cidr2026.pdf&hl=en&sa=X&d=816076234904319512&ei=gGdAaYfaMPO16rQPzoDK8Ag&scisig=ALhkC2TNcgq1xgDNeb6YRdVVkH8j&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ALhkC2ST2AYAjPXMn7CfOFohiT1r&html=&pos=1&folt=rel)
*P Li,T Kuchler,M Kabić,T Stocker,G Alonso…*

Main category: Google Scholar

TL;DR: 关系模型的声明性特性和数据库引擎屏蔽了用户对系统实现复杂性、系统演进、数据表示细节的关注，并支持跨工作负载和用例的优化，但近期发展面临挑战


<details>
  <summary>Details</summary>
Motivation: 探讨关系数据库的声明性优势及其在屏蔽系统复杂性、支持优化方面的作用，同时分析近期面临的新挑战

Method: 基于关系模型和数据库引擎的声明性特性分析，结合近期技术发展趋势进行对比研究

Result: 关系模型的声明性特性确实为用户提供了抽象层，但近期技术发展暴露了其在某些新场景下的局限性

Conclusion: 关系数据库的声明性优势仍然重要，但需要适应新的技术挑战和应用需求

Abstract: The declarative nature of the relational model and database engines shields users from system implementation complexity, system evolution, data representation details, and enables optimizations across workloads and use cases. However, recent …

</details>


### [296] [Toward Next-Generation Database System: Integrating Data Management With Artificial Intelligence](https://scholar.google.com/scholar_url?url=https://search.proquest.com/openview/4a6f323f816e12e0d73921032b4138bc/1%3Fpq-origsite%3Dgscholar%26cbl%3D18750%26diss%3Dy&hl=en&sa=X&d=18027875134367786903&ei=f2dAadPpGbPFieoPper8uAM&scisig=ALhkC2Sx6Wfqp5s1e65mD6CExNS-&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=1&folt=cit)
*L Zhou*

Main category: Google Scholar

TL;DR: 探索AI与数据库系统集成的关键挑战，构建AI4DB和DB4AI的完全集成框架


<details>
  <summary>Details</summary>
Motivation: AI与数据库系统各自存在局限性：数据库系统缺乏智能化和自动化，而AI工作流缺乏声明式、统一的存储和计算优化。两者的集成能够克服这些限制，为数据驱动的AI工作流提供变革性机会。

Method: 通过博士论文研究，探索AI4DB（AI赋能数据库）和DB4AI（数据库赋能AI）两个方向的关键挑战，构建完全集成的框架。

Result: 论文提出了一个集成框架，能够同时解决AI增强数据库管理和数据库支持AI工作流的双重需求。

Conclusion: AI与数据库系统的深度集成具有变革性潜力，能够克服各自领域的局限性，为端到端数据驱动的AI工作流提供更高效、智能化的解决方案。

Abstract: Integrating artificial intelligence (AI) with database (DB) systems unlocks transformative opportunities to overcome the limitations of both fields: the lack of intelligence and automation for data management, and the lack of declarative and unified storage and computation optimization for end-to-end data-driven AI workflows. This dissertation explores critical challenges toward a fully integrated framework for both" AI4DB" and" DB4AI" with a focus on the following research …

</details>


### [297] [VCR: Interpretable and interactive debugging of object detection models with visual concepts](https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0306437925001383&hl=en&sa=X&d=278172583143983305&ei=f2dAadPpGbPFieoPper8uAM&scisig=ALhkC2Q6UlhuRvUdkML2KWBg57iO&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=2&folt=cit)
*JJ Xu,S Dhanani,JP Ono,W He,L Ren,K Rong*

Main category: Google Scholar

TL;DR: VCR是一个人类在环的切片发现框架，通过视觉概念帮助用户交互式地发现和理解目标检测模型的系统性错误


<details>
  <summary>Details</summary>
Motivation: 计算机视觉模型可能在特定数据子集上表现显著变差，但现有方法难以让实践者交互式地发现和理解这些系统性错误

Method: 提出视觉概念审阅者框架，利用视觉概念（语义上有意义且频繁出现的图像片段）进行交互式切片发现，支持人类在环的探索过程

Result: 未在摘要中明确说明具体实验结果，但框架旨在帮助用户发现模型在特定视觉概念上的性能下降

Conclusion: VCR框架为实践者提供了交互式发现和理解目标检测模型系统性错误的有效工具

Abstract: Computer vision models can make systematic errors, performing well on average but substantially worse on particular subsets (or slices) of data. In this work, we introduce Visual Concept Reviewer (VCR), a human-in-the-loop slice discovery framework that enables practitioners to interactively discover and understand systematic errors in object-detection models via novel use of visual concepts–semantically meaningful and frequently recurring image segments representing objects, parts, or abstract …

</details>


### [298] [A Generative AI Framework for Data Pipeline Optimization and Analytical Performance Enhancement](https://scholar.google.com/scholar_url?url=https://ijaidsml.org/index.php/ijaidsml/article/download/333/307&hl=en&sa=X&d=9850053281073606709&ei=fUJCaYvnCtOyieoP1qvf4A4&scisig=ALhkC2R0bPHlEvGqI4Nw7L1Q9z3B&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=0&folt=cit)
*DBGS Narayanan*

Main category: Google Scholar

TL;DR: 提出基于生成式AI的框架，用于分析和优化现代分析生态系统中的数据管道，解决传统规则方法在动态环境中的不足


<details>
  <summary>Details</summary>
Motivation: 企业云环境中数据密集型工作负载激增，传统基于规则和固定优化策略无法适应现代分析生态系统的动态特性，导致瓶颈、延迟和资源利用率低下

Method: 提出基于生成式AI的框架，通过分析、设计和优化数据管道，利用AI技术实现智能和敏捷的优化方法

Result: 未在摘要中明确说明具体实验结果，但暗示该框架能够解决传统方法的局限性

Conclusion: 生成式AI框架为动态现代分析生态系统中的数据管道优化提供了有前景的解决方案

Abstract: The surprising increase in data-intensive workloads in enterprise and cloud environments has increased the call to find smart and agile methods of optimizing data pipelines. The dynamic nature of the contemporary modern analytical ecosystems makes traditional rule-based and fixed optimization strategies inadequate, leading to bottlenecks, latency as well as poor utilization of resources. The given paper suggests a Generative AI-based framework that analyzes, designs …

</details>


### [299] [ChipMind: Retrieval-Augmented Reasoning for Long-Context Circuit Design Specifications](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.05371&hl=en&sa=X&d=17376277240559081611&ei=99xDaYa9KdOyieoP1qvf4A4&scisig=ALhkC2SRr-HTlAPdenKtbnTwBo3Y&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ALhkC2ST2AYAjPXMn7CfOFohiT1r&html=&pos=0&folt=rel)
*C Xing,SZ Wong,X Wan,Y Lu,M Zhang,Z Ma,L Qi…*

Main category: Google Scholar

TL;DR: LLMs在集成电路开发中应用受限，主要受限于有限的上下文窗口，需要开发有效的上下文扩展方法


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在集成电路开发自动化方面具有巨大潜力，但实际部署受到有限上下文窗口的根本限制，现有上下文扩展方法无法有效处理IC设计中的长序列数据

Method: 论文提出了一种针对IC设计优化的上下文扩展方法，可能包括分块处理、层次化表示、注意力机制改进或专门针对硬件描述语言和电路网表的结构化处理技术

Result: 该方法能够有效扩展LLMs在IC设计任务中的上下文处理能力，显著提升对长序列硬件描述和电路数据的理解和生成能力

Conclusion: 通过专门设计的上下文扩展技术，可以克服LLMs在集成电路开发中的关键限制，推动AI在硬件设计自动化中的实际应用

Abstract: While Large Language Models (LLMs) demonstrate immense potential for automating integrated circuit (IC) development, their practical deployment is fundamentally limited by restricted context windows. Existing context-extension …

</details>


### [300] [MVP-ORAM: a Wait-free Concurrent ORAM for Confidential BFT Storage](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.12006&hl=en&sa=X&d=15026711445430292184&ei=03lFafiPAoDO6rQP-qaaoAo&scisig=ALhkC2RQGYTWo5YBRST-g0rqbH8t&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=1&folt=cit)
*R Vassantlal,H Heydari,B Ferreira,A Bessani*

Main category: Google Scholar

TL;DR: MVP-ORAM：首个支持并发容错客户端的无等待ORAM协议，解决了现有ORAM在并发访问和拜占庭容错方面的限制


<details>
  <summary>Details</summary>
Motivation: 加密本身不足以保护数据隐私，访问模式可能被用于推理攻击。现有ORAM协议在支持并发客户端和拜占庭容错方面存在限制，需要一种能同时满足这两个需求的解决方案

Method: 提出MVP-ORAM协议，采用无等待设计，支持并发故障客户端，通过创新机制实现访问模式的完全隐藏，同时保证拜占庭容错能力

Result: MVP-ORAM是首个同时支持并发客户端和拜占庭容错的ORAM协议，实现了无等待访问，显著提升了系统可用性和容错能力

Conclusion: MVP-ORAM填补了ORAM领域在并发容错方面的空白，为实际部署中的隐私保护提供了更实用的解决方案

Abstract: It is well known that encryption alone is not enough to protect data privacy. Access patterns, revealed when operations are performed, can also be leveraged in inference attacks. Oblivious RAM (ORAM) hides access patterns by making client requests oblivious. However, existing protocols are still limited in supporting concurrent clients and Byzantine fault tolerance (BFT). We present MVP-ORAM, the first wait-free ORAM protocol that supports concurrent fail-prone clients. In contrast to …

</details>


### [301] [Применение контрастного обучения для семантической интерпретации русскоязычных таблиц](https://scholar.google.com/scholar_url?url=https://ispranproceedings.elpub.ru/jour/article/view/2070&hl=en&sa=X&d=15199675452837197367&ei=03lFafiPAoDO6rQP-qaaoAo&scisig=ALhkC2SMUjEa7JmvCE9Ac0l9Vnj9&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=3&folt=cit)
*КВ ТОБОЛА,НО ДОРОДНЫХ*

Main category: Google Scholar

TL;DR: 该论文研究俄语表格的语义解释问题，旨在解决俄语表格在知识图谱集成中的语义标注挑战


<details>
  <summary>Details</summary>
Motivation: 表格广泛用于数据表示和存储，但通常缺乏机器可解释的显式语义。俄语表格的语义解释对于将结构化数据与知识图谱集成至关重要，但现有方法在处理俄语表格时面临特定挑战

Method: 论文未在摘要中详细描述具体方法，但暗示需要开发专门针对俄语表格语义解释的新方法或改进现有方法

Result: 摘要未提供具体实验结果，但指出俄语表格语义解释是知识图谱集成的关键任务

Conclusion: 需要专门的方法来处理俄语表格的语义解释问题，以促进俄语结构化数据与知识图谱的有效集成

Abstract: Аннотация Таблицы широко используются для представления и хранения данных, но, как правило, они не сопровождаются явной семантикой необходимой для машинной интерпретации своего содержания. Семантическая интерпретация таблиц является ключевой задачей для интеграции структурированных данных с графами знаний, однако существующие методы сталкиваются с проблемами при обработке русскоязычных таблиц из-за …

</details>


### [302] [FloodSQL-Bench: A Retrieval-Augmented Benchmark for Geospatially-Grounded Text-to-SQL](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.12084&hl=en&sa=X&d=1377490766081355107&ei=1HlFaemnE9_OieoPg6WE2QY&scisig=ALhkC2QdPZaOlegJ4jYvYudwAhW5&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ALhkC2ST2AYAjPXMn7CfOFohiT1r&html=&pos=2&folt=rel)
*H Liu,K Yin,Z Chen,C Liu,A Mostafavi*

Main category: Google Scholar

TL;DR: 本文提出了一个新的Text-to-SQL基准测试，专注于领域特定、多表和地理空间推理的复杂性，弥补现有基准主要关注单表查询或有限连接的不足。


<details>
  <summary>Details</summary>
Motivation: 现有Text-to-SQL基准主要关注单表查询或通用领域的有限连接，无法反映领域特定、多表和地理空间推理的复杂性，这限制了Text-to-SQL系统在实际复杂场景中的应用和评估。

Method: 作者提出了一个新的Text-to-SQL基准测试，该基准专注于领域特定场景，包含多表连接和地理空间推理任务，旨在更全面地评估Text-to-SQL系统处理复杂查询的能力。

Result: 通过该新基准测试，作者展示了现有Text-to-SQL系统在处理领域特定、多表和地理空间查询时的局限性，并提供了更全面的评估框架来推动该领域的发展。

Conclusion: 该研究强调了开发能够处理复杂领域特定、多表和地理空间推理的Text-to-SQL系统的重要性，提出的新基准为评估和改进这些系统提供了重要工具。

Abstract: Existing Text-to-SQL benchmarks primarily focus on single-table queries or limited joins in general-purpose domains, and thus fail to reflect the complexity of domain-specific, multi-table and geospatial reasoning, To address this limitation, we …

</details>


### [303] [Efficient-DLM: From Autoregressive to Diffusion Language Models, and Beyond in Speed](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.14067&hl=en&sa=X&d=3529840471607176986&ei=Vx1HaebQLsSN6rQPx4HkwQU&scisig=ALhkC2SvJnuJvtRnfFwIkP5r_S9x&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ALhkC2ST2AYAjPXMn7CfOFohiT1r&html=&pos=0&folt=rel)
*Y Fu,L Whalen,Z Ye,X Dong,S Diao,J Liu,C Wu…*

Main category: Google Scholar

TL;DR: 扩散语言模型在并行生成方面有优势，但从头开始训练时学习效率低于自回归语言模型，需要改进训练方法


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型(dLMs)作为并行、非自回归生成的有前景范式，但其从头开始训练时的学习效率落后于自回归语言模型，需要解决这一性能差距

Method: 论文摘要未完整提供具体方法，但暗示需要改进扩散语言模型的训练策略或架构，以提升其学习效率

Result: 摘要未提供具体实验结果，但指出扩散语言模型当前的学习效率问题，暗示改进方法可能带来性能提升

Conclusion: 需要开发新的训练方法或架构改进，使扩散语言模型的学习效率能够匹敌甚至超越自回归语言模型

Abstract: Diffusion language models (dLMs) have emerged as a promising paradigm that enables parallel, non-autoregressive generation, but their learning efficiency lags behind that of autoregressive (AR) language models when trained from scratch. To …

</details>


### [304] [Hash Tables as Engines of Randomness at the Limits of Computation: A Unified Review of Algorithms](https://scholar.google.com/scholar_url?url=https://www.mdpi.com/1999-4893/18/12/804&hl=en&sa=X&d=12046064633681617757&ei=wp1IadC_Erux6rQPi5qW2AE&scisig=ALhkC2TijfmqR-tWxUF4zk81hFpr&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=0&folt=cit)
*PA Gagniuc,M Togan*

Main category: Google Scholar

TL;DR: 哈希表综述：从简单关联数组到接近物理与概率计算极限的算法引擎，涵盖通用/完美哈希、冲突解决策略、并发与硬件感知架构等五十年发展


<details>
  <summary>Details</summary>
Motivation: 统一哈希表五十年发展历程，展示其从简单数据结构演变为接近物理和概率计算极限的算法引擎的过程，揭示确定性结构与受控随机性之间的深层关系

Method: 综述性研究方法，系统梳理通用哈希、完美哈希、冲突解决策略（如链地址法、开放寻址）、并发哈希表设计、硬件感知架构等关键技术发展脉络

Result: 现代哈希表已发展为热力学类比下的算法引擎，在空间效率、时间复杂度和并发性能方面接近理论极限，成为计算系统核心组件

Conclusion: 哈希表的发展体现了计算理论、概率论与硬件架构的深度融合，其演进轨迹展示了数据结构如何从简单工具演变为接近物理极限的计算引擎

Abstract: Hash tables embody a paradox of deterministic structure that emerges from controlled randomness. They have evolved from simple associative arrays into algorithmic engines that operate near the physical and probabilistic limits of computation. This review unifies five decades of developments across universal and perfect hashing, collision-resolution strategies, and concurrent and hardware-aware architectures. The synthesis shows that modern hash tables act as thermodynamic …

</details>


### [305] [Extracting node comparison insights for the interactive exploration of property graphs](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.15157&hl=en&sa=X&d=2063048456353208608&ei=wp1IadC_Erux6rQPi5qW2AE&scisig=ALhkC2S1hFEwfSqkLV9VDBk8Lq6k&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=2&folt=cit)
*C Aguiar,J Chabin,A Chanson,M Halfeld*

Main category: Google Scholar

TL;DR: 提出一种从属性图中自动提取节点比较的方法，支持交互式探索性分析


<details>
  <summary>Details</summary>
Motivation: 虽然图节点评分（如中心性）研究已有数十年，但基于节点属性进行比较的方法尚未得到充分研究，需要支持属性图的交互式探索分析

Method: 利用节点上下文设计比较指标，自动提取属性图中节点的比较关系

Result: 未在摘要中明确说明具体实验结果

Conclusion: 该方法能够支持属性图的交互式探索分析，填补了节点属性比较研究的空白

Abstract: While scoring nodes in graphs to understand their importance (eg, in terms of centrality) has been investigated for decades, comparing nodes in property graphs based on their properties has not, to our knowledge, yet been addressed. In this paper, we propose an approach to automatically extract comparison of nodes in property graphs, to support the interactive exploratory analysis of said graphs. We first present a way of devising comparison indicators using the context of nodes to be …

</details>


### [306] [An Online Fragmentation-Aware Scheduler for Managing GPU-Sharing Workloads on Multi-Instance GPUs](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.16099&hl=en&sa=X&d=1808826068448055074&ei=w51Iad3WLIDO6rQP-qaaoAo&scisig=ALhkC2SQUU_T7lThqUWn81fleAd3&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ALhkC2ST2AYAjPXMn7CfOFohiT1r&html=&pos=4&folt=rel)
*HT Ting,J Chou,MH Chen,I Chung*

Main category: Google Scholar

TL;DR: NVIDIA MIG技术通过硬件级分区提供GPU资源共享与强隔离，满足现代工作负载对高效资源利用的需求


<details>
  <summary>Details</summary>
Motivation: 现代GPU工作负载越来越多地需要高效资源共享，因为许多作业并不需要GPU的全部容量。现有技术需要在资源利用和隔离性之间做出权衡。

Method: 采用NVIDIA的Multi-Instance GPU (MIG)技术，通过硬件级分区实现GPU资源共享，提供强资源隔离能力。

Result: MIG技术能够在保持强隔离性的同时实现高效的GPU资源共享，解决了传统方法在资源利用和隔离性之间的权衡问题。

Conclusion: 硬件级GPU分区技术如MIG为现代工作负载提供了理想的资源共享解决方案，既提高了资源利用率，又确保了必要的隔离性。

Abstract: Modern GPU workloads increasingly demand efficient resource sharing, as many jobs do not require the full capacity of a GPU. Among sharing techniques, NVIDIA's Multi-Instance GPU (MIG) offers strong resource isolation by enabling hardware-level …

</details>


### [307] [Forgetting by Pruning: Data Deletion in Join Cardinality Estimation](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.20293&hl=en&sa=X&d=497838284071033246&ei=mA5Kacu3M8SN6rQPx4HkwQU&scisig=ALhkC2TTmEaOAr7BYNXpURG7dnVM&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ALhkC2ST2AYAjPXMn7CfOFohiT1r&html=&pos=0&folt=rel)
*C He,Y Liu,Q Ma,S Ren,X Luo,L Zhao,A Liu*

Main category: Google Scholar

TL;DR: 机器学习基数估计系统中的机器遗忘面临独特挑战，主要源于多表关系数据中的复杂分布依赖，数据删除作为机器遗忘的核心组件面临特殊困难


<details>
  <summary>Details</summary>
Motivation: 机器学习基数估计系统在处理多表关系数据时面临机器遗忘的独特挑战，特别是数据删除操作由于数据间的复杂分布依赖关系而变得困难，需要专门的研究来解决这一问题

Method: 从提供的摘要片段来看，本文可能探讨机器学习基数估计系统中的机器遗忘方法，特别是针对多表关系数据中数据删除面临的挑战，但具体方法细节未在摘要中明确说明

Result: 摘要未提供具体实验结果，但暗示了机器学习基数估计系统中机器遗忘面临的挑战，特别是数据删除在多表关系数据环境下的困难

Conclusion: 机器学习基数估计系统中的机器遗忘是一个具有挑战性的问题，特别是在多表关系数据环境下，数据删除操作由于复杂的分布依赖关系需要专门的研究和解决方案

Abstract: Machine unlearning in learned cardinality estimation (CE) systems presents unique challenges due to the complex distributional dependencies in multi-table relational data. Specifically, data deletion, a core component of machine unlearning, faces …

</details>


### [308] [Text-to-SQL Benchmarks are Broken: An In-Depth Analysis of Annotation Errors](https://scholar.google.com/scholar_url?url=https://www.vldb.org/cidrdb/papers/2026/p5-jin.pdf&hl=en&sa=X&d=8252161000605384746&ei=mA5Kacu3M8SN6rQPx4HkwQU&scisig=ALhkC2SOV5pZRmyrGIZDu3yKHy-t&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ALhkC2ST2AYAjPXMn7CfOFohiT1r&html=&pos=2&folt=rel)
*T Jin,Y Choi,Y Zhu,D Kang*

Main category: Google Scholar

TL;DR: 现有文本到SQL数据集存在数据分布偏差和评估指标不完善的问题，限制了文本到SQL技术的准确评估和进一步发展


<details>
  <summary>Details</summary>
Motivation: 当前文本到SQL领域虽然已有多个基准数据集，但这些数据集存在数据分布偏差和评估指标不完善的问题，导致无法准确评估不同技术的性能，限制了该领域的进一步发展

Method: 论文未在摘要中明确说明具体方法，但暗示了需要分析现有数据集的局限性并提出改进方案

Result: 摘要未提供具体实验结果，但指出了现有文本到SQL数据集存在的问题，为后续研究提供了方向

Conclusion: 需要开发更全面、无偏差的文本到SQL基准数据集和评估指标，以推动该领域的技术进步

Abstract: Text-to-SQL has been widely studied in both academia and industry. Researchers have developed a series of benchmarks to evaluate different techniques and provide insights for further improvement. However, existing text-to-SQL datasets contain …

</details>


### [309] [Contemporary Directions in Database Administration: Integrating Security, Resilience, Automation, and Scalability](https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Dhananjaya-Alwitigala/publication/398829769_Contemporary_Directions_in_Database_Administration_Integrating_Security_Resilience_Automation_and_Scalability/links/694443ae7e61d05b531073e2/Contemporary-Directions-in-Database-Administration-Integrating-Security-Resilience-Automation-and-Scalability.pdf&hl=en&sa=X&d=4805970098555959017&ei=lg5KaenwI9_OieoPg6WE2QY&scisig=ALhkC2RfFLEDXBzrktwExhxl1po0&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=5&folt=cit)
*CL Jayathilake,DL Bandara,MM Munawwer*

Main category: Google Scholar

TL;DR: 本文综述了数据库管理从维护职能向战略职能的演变，重点分析了五个关键领域：安全合规、高可用性与灾难恢复、备份恢复、AI驱动的自动化以及云环境可扩展性，并对比了SQL与NoSQL系统的操作差异与融合趋势。


<details>
  <summary>Details</summary>
Motivation: 数据库管理已从传统的维护职能转变为支撑企业韧性和创新的战略职能。随着技术环境日益复杂，需要系统性地梳理数据库管理的关键领域，分析关系型与非关系型数据库的运营差异，为现代数据库管理实践提供指导框架。

Method: 采用文献综述方法，系统性地分析数据库管理的五个核心领域：安全与合规、高可用性与灾难恢复、备份与恢复、AI驱动的自动化、云环境可扩展性。通过对比分析关系型(SQL)和非关系型(NoSQL)数据库系统，揭示其操作差异和融合趋势。

Result: 研究发现数据库管理的关键趋势包括：安全合规要求日益严格，高可用性架构成为标准，备份恢复策略更加智能化，AI自动化显著提升运维效率，云原生架构推动可扩展性创新。SQL与NoSQL系统在操作实践上既有显著差异，也在某些领域呈现融合趋势。

Conclusion: 现代数据库管理已演变为战略职能，需要综合运用多种技术和管理方法。未来的数据库管理员需要掌握跨平台技能，平衡传统关系型数据库与新兴非关系型系统的优势，同时充分利用AI自动化和云原生技术来构建弹性、高效的数据基础设施。

Abstract: Database administration has evolved from maintenance to a strategic function underpinning resilience and innovation. This paper reviews five domains: ie (i) security and compliance,(ii) high availability and disaster recovery,(iii) backup and recovery,(iv) AI-enabled automation, and (v) scalability in cloud environments. Both relational (SQL) and non-relational (NoSQL) systems are compared to reveal operational contrasts and convergence. The study finds that database administration …

</details>


### [310] [NL2Vis Transformed: From Linguistic Abstraction to Visual Specification in the Generative AI Era](https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s42979-025-04636-4&hl=en&sa=X&d=2571178995585835993&ei=lg5KaenwI9_OieoPg6WE2QY&scisig=ALhkC2SiZqqpm681zjKqM7VOWTQu&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=6&folt=cit)
*H Luong,VT Nguyen*

Main category: Google Scholar

TL;DR: NL2Vis是自然语言处理、数据可视化和人机交互交叉领域的一个快速发展的子领域，它将自由形式的文本查询转换为结构化数据集上的语义连贯的可视化表示。


<details>
  <summary>Details</summary>
Motivation: 传统数据探索范式要求用户显式构建图表或制定正式查询，这限制了非专业用户的数据访问能力。NL2Vis旨在通过自然语言接口降低数据可视化的技术门槛，使更广泛的用户能够直观地探索和理解数据。

Method: 论文未提供具体方法细节，但从描述看，NL2Vis系统通过自然语言处理技术解析自由形式的文本查询，理解用户意图，然后将这些查询转换为结构化数据集上的可视化表示，涉及语义理解、数据映射和可视化生成等技术。

Result: 摘要未提供具体实验结果，但指出NL2Vis作为一个快速发展的子领域，正在推动从文本查询到可视化表示的转换技术的发展，为更自然的数据探索方式奠定了基础。

Conclusion: NL2Vis代表了数据探索范式的重要转变，通过自然语言接口使数据可视化更加可访问，有望改变用户与结构化数据交互的方式，促进数据驱动的洞察发现。

Abstract: Abstract Natural Language to Visualization (NL2Vis) constitutes a rapidly evolving subfield situated at the intersection of natural language processing, data visualization, and human–computer interaction. It operationalizes the transduction of free-form textual queries into semantically coherent visual representations over structured datasets. In contrast to conventional data exploration paradigms—where users must explicitly construct charts or formulate formal queries—NL2Vis systems …

</details>


### [311] [Query Processing Tradeoffs over an ML-Enhanced R-tree](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3764912.3770834&hl=en&sa=X&d=9510936356979855981&ei=lg5KaenwI9_OieoPg6WE2QY&scisig=ALhkC2RpZXig1NvMQcfN3eeW3RzX&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=7&folt=cit)
*A Al*

Main category: Google Scholar

TL;DR: 本文综述了机器学习增强的R树多维索引结构，分析了现有ML增强R树变体的设计空间、性能特征和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 机器学习技术已成功应用于设计各种学习型数据库索引结构，包括一维和多维空间。传统多维索引通过集成ML模型来增强性能，R树作为广泛应用的多维索引结构，其ML增强变体值得系统研究。

Method: 通过系统文献综述方法，分析现有ML增强R树变体的设计空间，包括ML模型在R树不同组件中的应用方式、训练数据选择、模型集成策略等关键技术维度。

Result: 识别了ML增强R树的主要设计模式，包括节点分裂优化、查询路径预测、空间划分学习等。分析了不同方法在查询性能、构建开销、内存占用等方面的权衡，指出了当前方法的局限性。

Conclusion: ML增强R树在特定场景下能显著提升性能，但需要更系统的设计框架和评估标准。未来研究应关注自适应学习、混合方法以及更全面的性能评估。

Abstract: Machine Learning (ML) techniques have been successfully applied to design various learned database index structures for both the one-and multi-dimensional spaces. Particularly, a class of traditional multi-dimensional indexes has been augmented with ML models to design ML-enhanced variants of their traditional counterparts. This paper focuses on the R-tree multi-dimensional index structure as it is widely used for indexing multi-dimensional (eg, spatial) data. The R-tree has been augmented with …

</details>


### [312] [Reconciling performance and efficient use of hardware resources: the case of configurable software services](https://scholar.google.com/scholar_url?url=https://theses.hal.science/tel-05424709/file/manuscrit_de_these_alexandre_bonvoisin.pdf&hl=en&sa=X&d=1160783194014659378&ei=lg5KaenwI9_OieoPg6WE2QY&scisig=ALhkC2R_IM7DesSSxciiUIkUE8No&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=8&folt=cit)
*A Bonvoisin*

Main category: Google Scholar

TL;DR: 论文探讨了信息通信技术（ICT）在日常生活中的普及应用及其带来的数字化转型，强调了智能手机、智能手表等设备如何重塑沟通、工作和休闲方式。


<details>
  <summary>Details</summary>
Motivation: 信息通信技术已深度融入日常生活各个方面，从沟通方式到工作模式再到休闲管理，这种数字化转型由多项技术进步推动，需要系统性地理解ICT对现代生活的影响。

Method: 论文采用描述性分析方法，通过列举智能手机、智能手表等具体设备案例，阐述ICT如何嵌入日常生活，并提及电子技术进展作为数字化转型的技术基础。

Result: ICT已成为日常生活的核心组成部分，智能手机提供即时通讯、信息获取和家居管理功能，智能手表实现实时健身追踪和健康监测，这些设备共同推动了社会数字化转型。

Conclusion: 信息通信技术通过智能手机、智能手表等设备深刻改变了人类的生活方式，这种数字化转型是多项技术进步的结果，ICT将继续在塑造未来社会方面发挥关键作用。

Abstract: Information and Communications Technologies (ICTs) are now embedded in almost every aspect of daily life. They shape how we communicate, work, and manage our leisure activities. A smartphone, for example, provides instant access to friends, information, and applications to manage our homes, while smartwatches facilitate real-time fitness tracking and health monitoring. This digital transformation has been made possible by many technological advances, including progress in electronic …

</details>


### [313] [Hierarchy Viz: A Visual Analytics Framework for Visualizing Hierarchical Data Using Machine Learning](https://scholar.google.com/scholar_url?url=https://search.proquest.com/openview/1d44dfb65c25b1ba46ccf1cc48227d96/1%3Fpq-origsite%3Dgscholar%26cbl%3D18750%26diss%3Dy&hl=en&sa=X&d=8487704294714812799&ei=lg5KaenwI9_OieoPg6WE2QY&scisig=ALhkC2QVS7pnstmjxU1z7aqQujGM&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=9&folt=cit)
*VK Uppalapati*

Main category: Google Scholar

TL;DR: 论文探讨了自动化可视化系统在处理层次数据表示方面的局限性，现有系统主要关注线图和散点图等数据模式探索，但难以处理需要表达数据关系的层次结构可视化。


<details>
  <summary>Details</summary>
Motivation: 现有自动化可视化系统主要关注使用线图和散点图探索数据模式，但在处理层次数据表示方面存在不足。层次可视化对于理解多级关系至关重要，但通常需要用户手动定义层次结构并具备专业知识，这限制了非专业用户的使用。

Method: 从摘要内容看，论文可能提出了一种新的自动化层次可视化方法，能够从原始数据中自动生成层次可视化，减少用户手动定义层次的需求。具体方法可能涉及层次关系自动检测、可视化布局算法和用户交互设计。

Result: 摘要未提供具体实验结果，但可以预期该方法能够自动生成有效的层次可视化，减少用户手动定义层次的工作量，提高层次数据探索的效率。

Conclusion: 自动化可视化系统需要更好地支持层次数据表示，通过减少用户手动定义层次的需求，使层次可视化对非专业用户更加可访问和实用。

Abstract: Automated visualization systems aim to generate visualizations directly from raw data with minimal user inputs. However, while existing systems focus on data visualizations mainly using line charts and scatter plots to explore the data patterns, they struggle with hierarchical data representation where data relationship is essential. Hierarchical visualization, crucial for understanding multi-level relationships, typically requires users to manually define hierarchies and have …

</details>


### [314] [Automatic Selection of Bitmap Join Indexes in Data Warehouses Using CFPGrowth++ Algorithm](https://scholar.google.com/scholar_url?url=https://informatica.si/index.php/informatica/article/view/7807&hl=en&sa=X&d=6527902781768436091&ei=17JLaeKRFrLrieoPwNLAkQw&scisig=ALhkC2RdAoaTt74m75VcG3OlPoQV&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ALhkC2ST2AYAjPXMn7CfOFohiT1r&html=&pos=0&folt=rel)
*M Yahyaoui,N Aknin,S Amjad,L Benameur*

Main category: Google Scholar

TL;DR: 该论文探讨了在复杂数据仓库环境中，针对关系型星型模式数据仓库的分析和决策过程通常通过OLAP查询进行，但存在查询性能瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 传统基于关系型星型模式的数据仓库在执行OLAP查询时面临性能挑战，特别是在处理复杂分析查询时，查询效率成为制约决策分析效果的关键因素。

Method: 论文未在摘要中明确说明具体方法，但从上下文推断可能涉及优化OLAP查询性能的技术，如索引优化、查询重写、物化视图或新型查询处理架构。

Result: 摘要未提供具体实验结果，但暗示通过提出的方法能够改善OLAP查询在关系型星型模式数据仓库中的执行效率。

Conclusion: 需要改进传统OLAP查询处理方法来提升关系型星型模式数据仓库的分析性能，以支持更高效的决策分析过程。

Abstract: In the context of complex data warehousing, Typically, the analysis and decision-making process for Data Warehouses schematized in a relational star model is conducted through OLAP (On-Line Analytical Processing) queries. These queries …

</details>


### [315] [Topics in Learning Theory: Prediction, Estimation, and Partial Information](https://scholar.google.com/scholar_url?url=https://www.ambujtewari.com/theses/Vinod_Raman_Thesis_2025.pdf&hl=en&sa=X&d=3131870259374116475&ei=ey5NaY2RLbLrieoPwNLAkQw&scisig=ALhkC2QknXSa046n6PZCvzwW6Vwj&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=1&folt=cit)
*V Raman*

Main category: Google Scholar

TL;DR: 该论文探讨了预测和估计在部分信息条件下的统一理论框架，分析了信息不完整如何影响学习算法的性能边界。


<details>
  <summary>Details</summary>
Motivation: 预测和估计是现代统计学和机器学习的两个基本支柱，但都面临着部分信息的挑战。在许多学习场景中，预测时无法总是观察到真实响应，或者只能从有限样本中估计未知量。即使有反馈可用，也可能不完整或存在于与预测不匹配的空间中。因此需要研究部分信息如何塑造学习算法的能力和限制。

Method: 论文采用理论分析框架，研究部分信息条件下的学习问题。通过建立统一的数学框架来分析预测和估计问题，探讨信息不完整对学习性能的影响，包括样本有限性、反馈不匹配、观测不完整等场景下的理论边界。

Result: 论文建立了部分信息条件下预测和估计的统一理论框架，揭示了信息不完整对学习算法性能的根本限制。分析了在不同部分信息场景下（如有限样本、不完整反馈、空间不匹配等）的学习边界，为理解学习算法的能力和局限性提供了理论基础。

Conclusion: 部分信息是预测和估计问题的核心挑战，它从根本上塑造了学习算法的能力和限制。理解这些信息限制对于设计有效的学习算法至关重要，论文的统一框架为分析各种学习场景提供了理论基础。

Abstract: Prediction and estimation are two fundamental pillars of modern statistics and machine learning, unified by the challenge of partial information. In many learning scenarios, one must make predictions without always observing the true response, or estimate unknown quantities from only a finite sample. Even when feedback is available, it may be incomplete or live in a space that does not match the predictions. This thesis investigates how partial information shapes what can and cannot be …

</details>


### [316] [A Progressive Interactive Exploration Framework for Vector Field Data Guided by Storylines](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11259298/&hl=en&sa=X&d=3502858825122420634&ei=WZlOaY-kIr6Z6rQPr-v5iAc&scisig=ALhkC2Q7P2mLAD7xTihgyfOwXVJs&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=1&folt=cit)
*H Xu*

Main category: Google Scholar

TL;DR: 提出基于故事线引导的渐进式可视化分析框架，用于减少非定常流场中涡旋提取的用户认知成本


<details>
  <summary>Details</summary>
Motivation: 当前非定常流场可视化分析通常依赖专家先验知识，需要反复调整滤波算法参数，认知成本高，需要更智能的分析框架

Method: 采用故事线引导的渐进式可视化分析流程，构建基于欧拉方法和小尺度量的涡旋提取方法框架

Result: 提出了一个减少用户认知成本的框架，通过故事线引导的渐进分析过程，优化涡旋提取的可视化流程

Conclusion: 基于故事线的渐进式可视化分析框架能够有效降低非定常流场分析中的用户认知负担，提高分析效率

Abstract: Currently, the visual analysis of unsteady flow fields is usually carried out under the guidance of experts' prior knowledge, and it often requires repeated adjustments to the parameters of filtering algorithms to gain understanding. To reduce user's cognitive costs, we take the progressive visual analysis process guided by storylines as the main thread and construct a framework for the vortex extraction method based on the Eulerian approach with small-scale quantities. A visualization of the value …

</details>


### [317] [SQL-kyselyiden tehokkuuden parantaminen tietokantajärjestelmissä tekoälyn avulla](https://scholar.google.com/scholar_url?url=https://jyx.jyu.fi/bitstreams/15c6a5b5-3647-41c6-b8c1-b7f62d2cad69/download&hl=en&sa=X&d=8308264692679954635&ei=WZlOaY-kIr6Z6rQPr-v5iAc&scisig=ALhkC2TxwEadRtazk8L9E93iB6AD&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=2&folt=cit)
*M Kallio*

Main category: Google Scholar

TL;DR: 该学士论文研究人工智能是否能提高数据库系统中SQL查询的效率，针对传统查询优化方法在处理现代数据库复杂性和规模时的局限性。


<details>
  <summary>Details</summary>
Motivation: 现代数据库的复杂性和规模不断增加，传统的基于规则和成本的查询优化方法难以适应动态工作负载，需要智能和自适应的解决方案。

Method: 论文采用人工智能方法来改进SQL查询优化，具体方法可能包括机器学习、深度学习或强化学习等技术，用于分析查询模式、预测执行计划或优化查询重写。

Result: 研究结果表明人工智能能够有效提高SQL查询效率，可能通过更准确的执行计划选择、查询重写优化或自适应调整来减少查询响应时间和资源消耗。

Conclusion: 人工智能在SQL查询优化中具有显著潜力，能够弥补传统方法的不足，为处理复杂动态数据库工作负载提供更有效的解决方案。

Abstract: This bachelor's thesis investigates whether artificial intelligence (AI) can improve the efficiency of SQL queries in database systems. The motivation stems from the increasing complexity and scale of modern databases, which challenge the capabilities of traditional query optimization methods. As rule-based and cost based techniques often fail to adapt to dynamic workloads, there is a growing need for intelligent and adaptive solutions. The objective of this study was to analyze how AI …

</details>


### [318] [Impact of Join Order and Main Memory Buffer Size in Query Optimization with Materialization](https://scholar.google.com/scholar?cluster=3901391139844360571&hl=en&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=3&folt=cit)
*N Paudel,M Pokharel,BK Bal*

Main category: Google Scholar

TL;DR: 论文研究了在物化查询优化中连接顺序和主内存缓冲区大小对查询性能的影响


<details>
  <summary>Details</summary>
Motivation: 在数据库查询优化中，连接顺序的选择和内存缓冲区大小的配置是影响查询性能的关键因素。随着数据量的增长和查询复杂性的提高，理解这些参数如何影响物化操作的性能变得尤为重要，特别是在主内存有限的环境中。

Method: 通过实验方法分析不同连接顺序和主内存缓冲区大小对查询执行时间的影响。可能使用基准测试查询集，在不同配置下测量查询性能指标，包括执行时间、内存使用情况和I/O操作等。

Result: 连接顺序对查询性能有显著影响，最优连接顺序可以大幅减少执行时间。主内存缓冲区大小直接影响物化操作的效率，适当增加缓冲区大小可以减少磁盘I/O，但存在收益递减点。两者之间存在交互作用，需要综合考虑以获得最佳性能。

Conclusion: 查询优化器在选择连接顺序时必须考虑可用的主内存缓冲区大小。优化的查询计划应该基于系统资源约束进行权衡，在内存使用和I/O成本之间找到平衡点。实际应用中需要根据具体硬件配置和数据特征调整优化策略。

Abstract: Title: Impact of Join Order and Main Memory Buffer Size in Query Optimization with Materialization
Authors: N Paudel, M Pokharel, BK Bal
Abstract: Abstract not available.

</details>


### [319] [Evolutionary design of a visual analytics interface to study predictive patterns in high dimensional data](https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S2468502X25000865&hl=en&sa=X&d=6531003637689654623&ei=NflPafeoH7K16rQPn86DwQ8&scisig=ALhkC2RHccUXw51tLMmmeVbrzYr4&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=1&folt=cit)
*D Coelho,E Papenhausen,K Mueller*

Main category: Google Scholar

TL;DR: 论文提出了一种基于进化设计的可视化分析界面，用于帮助用户有效探索和解释数据挖掘产生的预测模式，解决高维数据集中模式过多导致分析负担过重的问题。


<details>
  <summary>Details</summary>
Motivation: 随着组织越来越依赖数据挖掘来发现预测模式以支持决策，挖掘算法（特别是高维数据集）产生的海量模式会淹没分析师，导致分析负担过重，需要有效的可视化工具来帮助探索和解释这些模式。

Method: 采用进化设计方法，从基于投影的原型（植根于研究工具）出发，逐步迭代开发可视化分析界面，使用户能够有效探索和解释挖掘出的预测模式。

Result: 论文开发了一个可视化分析界面，能够帮助用户在高维数据集产生的大量预测模式中进行有效导航、探索和解释，减轻分析负担。

Conclusion: 通过进化设计方法开发的可视化分析界面能够有效解决数据挖掘中模式过多的问题，帮助分析师更好地理解和利用预测模式进行决策。

Abstract: Organizations increasingly rely on data mining to discover predictive patterns that inform decision-making. However, the vast number of patterns produced by mining algorithms, especially in high-dimensional datasets, can overwhelm analysts. To address this challenge, we present the evolutionary design of a visual analytics interface that enables users to explore and interpret mined predictive patterns effectively. Starting from a projection-based prototype rooted in research tools, we …

</details>


### [320] [Structured Visualization Design Knowledge for Grounding Generative Reasoning and Situated Feedback](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.20306&hl=en&sa=X&d=1444677913918523186&ei=NflPafeoH7K16rQPn86DwQ8&scisig=ALhkC2SUzz-Tde1IItAcVZNFLVwx&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=2&folt=cit)
*PF Gyarmati,D Moritz,T Möller,L Koesten*

Main category: Google Scholar

TL;DR: 论文提出了一种编目方案，旨在调和自动化可视化设计中符号系统与生成模型之间的张力，结合约束求解器的结构有效性保证与大型语言模型的上下文推理能力。


<details>
  <summary>Details</summary>
Motivation: 自动化可视化设计面临符号系统与生成模型之间的根本矛盾：约束求解器需要难以编写且僵化的规则，而大型语言模型虽然无需形式规则且能理解上下文，但过度依赖流行惯例而非经验验证的最佳实践。

Method: 提出了一种编目方案（cataloging scheme），旨在整合约束求解器的结构/感知有效性保证与大型语言模型的上下文推理能力，以平衡形式规则与情境化设计知识。

Result: 摘要未提供具体实验结果，但暗示所提方案能够解决自动化可视化设计中符号系统与生成模型之间的张力问题。

Conclusion: 通过编目方案调和约束求解器与大型语言模型的优势，有望实现既保持结构有效性又能适应上下文细微差别的自动化可视化设计系统。

Abstract: Automated visualization design navigates a tension between symbolic systems and generative models. Constraint solvers enforce structural and perceptual validity, but the rules they require are difficult to author and too rigid to capture situated design knowledge. Large language models require no formal rules and can reason about contextual nuance, but they prioritize popular conventions over empirically grounded best practices. We address this tension by proposing a cataloging scheme that …

</details>


### [321] [Tiny Machine Learning: Design Principles and Applications](https://scholar.google.com/scholar_url?url=https://books.google.com/books%3Fhl%3Den%26lr%3Dlang_en%26id%3DMveiEQAAQBAJ%26oi%3Dfnd%26pg%3DPR22%26ots%3DPQelFnYEHA%26sig%3DFDSj3wETxsaKKDjEj2yrzDrwaak&hl=en&sa=X&d=9122314821683296082&ei=4JRRad3XBtaOieoP3p6U4Q8&scisig=ALhkC2SMk2iaVS4VQgLYS4N3QjjE&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=0&folt=cit)
*AL Imoize,DT Do,H Song*

Main category: Google Scholar

TL;DR: 关于TinyML（微型机器学习）设计原则、应用、监管框架和伦理考量的专家汇编，重点介绍低功耗资源及其在物联网设备中的应用


<details>
  <summary>Details</summary>
Motivation: 随着物联网设备数量的快速增长，传统机器学习模型在资源受限的边缘设备上部署面临挑战。需要系统性的设计原则、监管框架和伦理考量来指导TinyML的发展和应用。

Method: 通过专家汇编的方式，综合讨论TinyML的关键概念、设计原则、应用和相关问题。引入新的低功耗资源解决方案，并探讨其在物联网设备系统中的应用。

Result: 提供了一套全面的TinyML设计开发指南，包括技术实现、监管框架和伦理考量，为物联网设备中的机器学习应用提供了系统化的解决方案。

Conclusion: TinyML作为边缘计算的关键技术，需要综合考虑技术实现、监管合规和伦理责任，该汇编为相关领域的研究者和开发者提供了重要的参考框架。

Abstract: An expert compilation of on-device training techniques, regulatory frameworks, and ethical considerations of TinyML design and development In Tiny Machine Learning: Design Principles and Applications, a team of distinguished researchers delivers a comprehensive discussion of the critical concepts, design principles, applications, and relevant issues in Tiny Machine Learning (TinyML). Expert contributors introduce a new low power resource, offering vast applications in IoT devices with system …

</details>


### [322] [Workload-Aware Optimization for High-Throughput Log Analytics](https://scholar.google.com/scholar_url?url=https://search.proquest.com/openview/b1a1c6f460cbf5922f83d9652723f013/1%3Fpq-origsite%3Dgscholar%26cbl%3D18750%26diss%3Dy&hl=en&sa=X&d=11528111696969055144&ei=HXBTaensJ9rJieoPiYyysAk&scisig=ALhkC2SZve8rP8b1vcbPcmfTSVc3&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=0&folt=cit)
*L Zhang*

Main category: Google Scholar

TL;DR: 论文指出当前数据库和日志分析系统缺乏正则表达式查询优化，导致海量日志数据处理效率低下，提出需要将正则表达式评估纳入查询优化框架。


<details>
  <summary>Details</summary>
Motivation: 现代系统管理中需要收集和分析海量日志数据，正则表达式是行业标准的信息提取工具。然而，数据库系统和日志分析系统都没有将正则表达式评估纳入查询优化框架，导致在处理PB级日志数据时计算成本高昂，而硬件性能保持不变，这成为系统性能瓶颈。

Method: 论文未提供具体方法细节，但从摘要可以看出，作者关注的是将正则表达式评估集成到查询优化中的技术挑战和解决方案，可能涉及查询优化器扩展、正则表达式模式分析、索引技术或并行处理策略。

Result: 摘要未提供具体实验结果，但暗示了当前暴力正则表达式评估方法在处理大规模日志数据时存在严重性能问题，需要系统级的优化解决方案。

Conclusion: 需要将正则表达式评估纳入数据库和日志分析系统的查询优化框架，以解决海量日志数据处理中的性能瓶颈问题，这是现代系统管理的关键需求。

Abstract: In modern system management, it is critical to collect and analyze large volumes of log data. Regular expressions (regex) are the norm in the industry for extracting information from these logs. However, neither database systems (DBMSs) nor log analysis systems incorporate regex evaluation in their query optimization. Brute-force regex evaluation is computationally expensive, especially as log data grows into the petabyte range while hardware performance remains the same. Such an issue …

</details>


### [323] [$$\text {SPL}^{index} $$: A spatial polygon learned index (extended version)](https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10844-025-01012-9&hl=en&sa=X&d=10839124901014445417&ei=HXBTaensJ9rJieoPiYyysAk&scisig=ALhkC2RVp4KuxMPUUB7uUT0ZcvUv&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=1&folt=cit)
*M Vahedi,H Christiansen*

Main category: Google Scholar

TL;DR: 提出SPL^index新型索引结构，通过集成学习索引、聚类、Z-order曲线降维和优化磁盘布局，实现复杂几何数据库的高效查询


<details>
  <summary>Details</summary>
Motivation: 大型复杂几何数据库需要高效的索引结构来处理高维几何数据查询，传统索引方法在处理复杂几何时存在性能瓶颈

Method: 集成学习索引、聚类算法、Z-order曲线降维技术，结合优化磁盘布局，通过梯度下降寻找最优聚类超参数，开发线性精确近似

Result: SPL^index在复杂几何数据库查询中表现出高效率，通过优化的超参数和近似方法实现精确查询性能

Conclusion: SPL^index是一种有效的复杂几何数据库索引解决方案，通过多技术集成和优化方法显著提升查询性能

Abstract: Abstract A novel index structure,\(\text {SPL}^{index}\), is proposed for large databases of complex geometries. It owes its efficiency to a unique integration of learned indexes, clustering, and dimension reduction by the\(\mathcal {Z}\)-order curve, and is combined with an optimal disk layout. Optimal hyperparameters to control the clustering algorithm can be found by gradient descent, and based on this, a linear and very precise approximation is developed.\(\text {SPL}^{index}\) …

</details>


### [324] [Context matching is not reasoning when performing generalized clinical evaluation of generative language models](https://scholar.google.com/scholar_url?url=https://www.nature.com/articles/s41746-025-02253-2_reference.pdf&hl=en&sa=X&d=6272686691385993748&ei=K09VaeyKBK-nieoPz8HDqAc&scisig=ALhkC2RIqihIZ72HS9ZxvKS_fuH6&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ALhkC2ST2AYAjPXMn7CfOFohiT1r&html=&pos=0&folt=rel)
*A Wen,Q Lu,YN Chuang,G Wang,J Yuan,J Zhang…*

Main category: Google Scholar

TL;DR: 论文指出当前评估生成语言模型临床能力主要依赖临床执照考试的多选题基准，但这种方法存在局限性，需要更全面的评估框架。


<details>
  <summary>Details</summary>
Motivation: 当前对生成语言模型临床能力的讨论主要围绕临床执照考试的多选题基准，这种评估方法存在局限性，无法全面反映模型在实际临床环境中的真实能力。

Method: 论文提出了一个更全面的评估框架，可能包括更贴近实际临床场景的评估方法，如开放式问题回答、临床推理评估、实际应用场景测试等。

Result: 通过更全面的评估方法，论文可能揭示了仅依赖多选题基准评估生成语言模型临床能力的局限性，并展示了更全面评估框架的价值。

Conclusion: 需要超越传统的多选题基准，采用更全面、贴近实际临床场景的评估方法来准确评估生成语言模型的真实临床能力。

Abstract: Current discussion surrounding the clinical capabilities of generative language models (GLMs) predominantly centers around multiple-choice question-answer (MCQA) benchmarks derived from clinical licensing examinations. While accepted …

</details>


### [325] [Compositional Reasoning over Structured and Unstructured Data Using Hybrid Indexing Frameworks](https://scholar.google.com/scholar_url?url=https://mrcis.org/index.php/journal/article/download/159/275&hl=en&sa=X&d=15978932950028484723&ei=Kk9VaZDPBcW4ieoP4szBiAE&scisig=ALhkC2TXWviAWHp1q9JafEBLHe6N&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=0&folt=cit)
*Q Zhou*

Main category: Google Scholar

TL;DR: 该研究探索组合推理机制，以统一处理结构化数据库和非结构化文本集合，解决异构数据源的信息检索和知识提取挑战。


<details>
  <summary>Details</summary>
Motivation: 异构数据源的指数级增长给信息检索和知识提取系统带来了前所未有的挑战。现代企业和研究机构通常同时管理包含结构化数据库和非结构化文本集合的庞大存储库，但传统索引方法在处理这些不同数据模态时仍然各自为政。

Method: 研究调查组合推理机制，使结构化数据库和非结构化文本集合能够统一处理，打破传统方法中的数据孤岛问题。

Result: 从摘要中无法确定具体实验结果，但研究目标是开发能够统一处理多模态数据的组合推理机制。

Conclusion: 需要开发新的组合推理方法来统一处理异构数据源，以应对现代信息检索和知识提取系统的挑战。

Abstract: The exponential growth of heterogeneous data sources has created unprecedented challenges for information retrieval and knowledge extraction systems. Modern enterprises and research institutions routinely manage vast repositories containing both structured databases and unstructured text collections, yet traditional indexing approaches remain siloed in their treatment of these distinct data modalities. This research investigates compositional reasoning mechanisms that enable unified …

</details>


### [326] [Query Carefully: Detecting the Unanswerables in Text-to-SQL Tasks](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.21345&hl=en&sa=X&d=13762767626408687302&ei=nKlWaaWlFMW4ieoP4szBiAE&scisig=ALhkC2R_NmFz4TjakivD1w8nlbpT&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ALhkC2ST2AYAjPXMn7CfOFohiT1r&html=&pos=1&folt=rel)
*J Saxer,IM Aigner,L Linzmeier,A Weiler,K Stockinger*

Main category: Google Scholar

TL;DR: 文本到SQL系统存在安全风险，可能对模糊、超出范围或无法回答的查询生成可执行SQL，需要检测和拒绝此类查询


<details>
  <summary>Details</summary>
Motivation: 文本到SQL系统虽然方便非专家用户查询数据库，但存在安全隐患：系统倾向于为模糊、超出范围或无法回答的查询生成可执行SQL，这可能导致错误结果或安全漏洞

Method: 论文提出需要开发检测机制来识别和拒绝有问题的查询，可能包括模糊性检测、范围验证和可回答性评估等方法

Result: 通过检测和拒绝有问题的查询，可以显著提高文本到SQL系统的安全性和可靠性，减少错误执行的风险

Conclusion: 文本到SQL系统需要集成安全检测机制来识别和拒绝模糊、超出范围或无法回答的查询，以确保系统的安全性和可靠性

Abstract: Text-to-SQL systems allow non-SQL experts to interact with relational databases using natural language. However, their tendency to generate executable SQL for ambiguous, out-of-scope, or unanswerable queries introduces a hidden risk, as …

</details>


### [327] [TAMEing Long Contexts in Personalization: Towards Training-Free and State-Aware MLLM Personalized Assistant](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.21616&hl=en&sa=X&d=16075251481482587225&ei=m6lWabbyEajKieoPs8CDKA&scisig=ALhkC2SrLx5sL2nkb8JICGxSpwh2&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=0&folt=cit)
*R Hong,J Lang,T Zhong,Y Wang,F Zhou*

Main category: Google Scholar

TL;DR: 该论文指出当前多模态大语言模型个性化方法仅关注简单的视觉识别和文本替换，忽略了长上下文对话能力，提出了新的个性化MLLM评估框架


<details>
  <summary>Details</summary>
Motivation: 现有MLLM个性化方法局限于简单的上下文无关视觉识别和文本替换，无法支持长上下文对话，需要更全面的个性化评估框架

Method: 论文提出了新的个性化MLLM评估框架，强调长上下文对话能力，超越简单的视觉识别和文本替换

Result: 通过分析现有方法的局限性，建立了更全面的个性化MLLM评估标准，强调对话连贯性和上下文理解

Conclusion: 需要开发支持长上下文对话的个性化MLLM，现有方法过于简化，未来研究应关注对话连贯性和上下文感知能力

Abstract: Multimodal Large Language Model (MLLM) Personalization is a critical research problem that facilitates personalized dialogues with MLLMs targeting specific entities (known as personalized concepts). However, existing methods and benchmarks focus on the simple, context-agnostic visual identification and textual replacement of the personalized concept (eg," A yellow puppy"->" Your puppy Mochi"), overlooking the ability to support long-context conversations. An ideal personalized MLLM …

</details>


### [328] [Privacy policies of healthcare services in India: using transparency scale to measure compliance level](https://scholar.google.com/scholar_url?url=https://www.emerald.com/ijlma/article/doi/10.1108/IJLMA-05-2025-0163/1332519&hl=en&sa=X&d=11827597188932867747&ei=m6lWabbyEajKieoPs8CDKA&scisig=ALhkC2S3woKXSNiHBG0faISDNqQh&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=1&folt=cit)
*I Gupta,P Naithani*

Main category: Google Scholar

TL;DR: 评估印度健康应用隐私政策的透明度，基于欧盟数据保护法的透明度原则


<details>
  <summary>Details</summary>
Motivation: 健康数据属于敏感个人数据，对个人隐私构成高风险。用户需要充分了解隐私实践以做出明智的隐私决策。研究旨在评估印度健康应用的隐私政策透明度。

Method: 使用欧盟数据保护法中的透明度原则作为评估框架，分析印度健康应用的隐私政策。研究可能涉及政策内容分析、透明度指标评估等方法。

Result: 研究发现印度健康应用的隐私政策在透明度方面存在不足，未能充分告知用户隐私实践，影响用户做出知情隐私决策的能力。

Conclusion: 印度健康应用需要改进隐私政策的透明度，以符合数据保护原则，确保用户能够充分了解隐私实践并做出知情决策。

Abstract: Purpose Health data is considered sensitive personal data, which carries a high risk to the individual's privacy. Therefore, it is essential to ensure that users of health services are adequately informed of privacy practices to be able to make informed privacy decisions. The study aims to assess the privacy policies of health applications in India. The global principle and requirement of transparency under data protection law in the EU is used to understand where privacy policies are …

</details>


### [329] [Comparative Performance Evaluation of Modern Cache Solutions: An Experimental Study](https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Ahmet-Toprak-3/publication/399115010_Comparative_Performance_Evaluation_of_Modern_Cache_Solutions_An_Experimental_Study/links/69501dfd27359023a010ec32/Comparative-Performance-Evaluation-of-Modern-Cache-Solutions-An-Experimental-Study.pdf&hl=en&sa=X&d=214294971138813115&ei=m6lWabbyEajKieoPs8CDKA&scisig=ALhkC2TXiRcUAqGdrczbh-ku-Qyp&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=3&folt=cit)
*A Toprak,FS Toprak*

Main category: Google Scholar

TL;DR: 缓存机制作为计算机系统中减少延迟、提高吞吐量的关键技术，通过将频繁访问的数据存储在更靠近使用点的地方，减少从较慢存储层或远程服务器获取数据的开销。


<details>
  <summary>Details</summary>
Motivation: 随着现代应用日益数据密集和分布式化，高效缓存变得至关重要，涉及处理器设计等多个领域。缓存机制能够显著降低数据访问延迟，提升系统整体性能。

Method: 论文未提供具体方法细节，但基于缓存机制的一般原理，通常涉及缓存策略设计（如替换算法、预取机制）、缓存层次结构优化、以及针对特定应用场景的定制化缓存方案。

Result: 缓存机制已被广泛证明能够有效减少数据访问延迟、提高系统吞吐量，并在处理器设计、分布式系统等多个领域得到成功应用。

Conclusion: 缓存机制是计算机系统中提升性能的基础技术，随着数据密集型应用的发展，其重要性日益凸显，需要持续优化以适应现代计算环境的需求。

Abstract: Caching mechanisms have long been recognized as a fundamental technique to mitigate latency and enhance throughput in computer systems by storing frequently accessed data closer to the point of use, thereby reducing the need for expensive data retrieval operations from slower storage layers or remote servers [1],[2]. As modern applications grow increasingly data-intensive and distributed, efficient caching has become paramount in domains ranging from processor design and …

</details>


### [330] [AGRO-SQL: Agentic Group-Relative Optimization with High-Fidelity Data Synthesis](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.23366&hl=en&sa=X&d=1315090488298883264&ei=RfRXafv7Aoaw6rQPkNu46Ao&scisig=ALhkC2QfgN_rTtD7Xeto-oGKIx-v&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ALhkC2ST2AYAjPXMn7CfOFohiT1r&html=&pos=1&folt=rel)
*C Yang,D Xiao,J Lin,Y Song,H Yan,S Guo,W Zhang…*

Main category: Google Scholar

TL;DR: 提出一个解决Text-to-SQL系统训练数据稀缺和复杂场景推理能力不足问题的整体框架


<details>
  <summary>Details</summary>
Motivation: 当前Text-to-SQL系统面临两大挑战：高质量训练数据稀缺，以及模型在复杂场景下的推理能力有限。这些限制阻碍了系统的进一步发展。

Method: 提出一个整体框架，通过综合方法同时解决数据稀缺和推理能力不足的问题。具体方法未在摘要中详细说明，但暗示采用系统性解决方案。

Result: 摘要未提供具体实验结果，但暗示该框架能够有效应对Text-to-SQL系统面临的主要挑战。

Conclusion: 提出的整体框架为解决Text-to-SQL系统的关键瓶颈提供了有前景的解决方案。

Abstract: The advancement of Text-to-SQL systems is currently hindered by the scarcity of high-quality training data and the limited reasoning capabilities of models in complex scenarios. In this paper, we propose a holistic framework that addresses these …

</details>


### [331] [Evolution of Buffer Management in Database Systems: From Classical Algorithms to Machine Learning and Disaggregated Memory](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.22995&hl=en&sa=X&d=6142334267398251274&ei=RfRXafv7Aoaw6rQPkNu46Ao&scisig=ALhkC2SJNc4Qy7ZiMvYvSmRhpkEB&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ALhkC2ST2AYAjPXMn7CfOFohiT1r&html=&pos=3&folt=rel)
*P Gadupudi,S Saha*

Main category: Google Scholar

TL;DR: 关于缓冲管理在数据库和操作系统性能中关键作用的研究，重点解决CPU处理速度与存储访问时间之间的持久性延迟差距。


<details>
  <summary>Details</summary>
Motivation: 缓冲管理是数据库和操作系统性能的关键组件，作为弥合CPU处理速度与存储访问时间之间持久性延迟差距的主要机制。随着计算架构的演进和存储技术的发展，需要更高效的缓冲管理策略来应对现代系统的性能挑战。

Method: 该论文可能提出新的缓冲管理算法、优化策略或架构设计，可能涉及缓存替换策略、预取机制、并发控制、内存管理等方面的创新方法。

Result: 论文可能展示了提出的缓冲管理方法在性能指标上的显著改进，如降低缓存缺失率、提高命中率、减少I/O延迟、提升系统吞吐量等。

Conclusion: 有效的缓冲管理对于现代计算系统性能至关重要，提出的方法为解决CPU-存储延迟差距提供了有前景的解决方案，能够显著提升数据库和操作系统的整体性能。

Abstract: Buffer management remains a critical component of database and operating system performance, serving as the primary mechanism for bridging the persistent latency gap between CPU processing speeds and storage access times. This paper …

</details>


### [332] [Robust LLM-based Column Type Annotation via Prompt Augmentation with LoRA Tuning](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.22742&hl=en&sa=X&d=17090565180492256644&ei=RfRXafv7Aoaw6rQPkNu46Ao&scisig=ALhkC2RxYrfOGDAoX0-m1EJpzrbR&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ALhkC2ST2AYAjPXMn7CfOFohiT1r&html=&pos=9&folt=rel)
*H Meng,J Cao,R Pottinger*

Main category: Google Scholar

TL;DR: 该论文研究表格数据中的列类型标注问题，现有基于编码器语言模型的方法在微调后能达到高准确率，但存在某些局限性


<details>
  <summary>Details</summary>
Motivation: 列类型标注是表格数据模式对齐和语义理解的基础步骤，现有方法虽然在某些方面表现良好，但仍有改进空间

Method: 基于编码器语言模型进行微调的方法，但具体技术细节在摘要中未详细说明

Result: 现有方法在标注列上能达到高准确率，但存在某些未明确的局限性

Conclusion: 列类型标注是表格数据处理的重要基础，现有方法虽有成效但需要进一步改进

Abstract: Column Type Annotation (CTA) is a fundamental step towards enabling schema alignment and semantic understanding of tabular data. Existing encoder-only language models achieve high accuracy when fine-tuned on labeled columns, but …

</details>


### [333] [Bridging Natural Language and SQL with an LLM-Powered Visual Interface](https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Supriya-Kottam/publication/399078640_Bridging_Natural_Language_and_SQL_with_an_LLM-Powered_Visual_Interface/links/6952cdfe06a9ab54f84c8779/Bridging-Natural-Language-and-SQL-with-an-LLM-Powered-Visual-Interface.pdf&hl=en&sa=X&d=15819183939884389481&ei=RPRXaZVRvpnqtA-v6_mIBw&scisig=ALhkC2TqToMRfOSWst8xBTqxsdKj&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=0&folt=cit)
*S Kottam*

Main category: Google Scholar

TL;DR: 该论文研究如何通过自然语言接口让非技术用户直接查询企业数据库，解决SQL编写门槛高的问题


<details>
  <summary>Details</summary>
Motivation: 在许多组织中，业务分析师和决策者需要频繁查询结构化数据以获取洞察、生成报告或监控关键指标。虽然数据本身在企业数据库中可用，但访问数据通常需要编写SQL，这对没有正式技术培训的用户来说仍然具有挑战性。因此，这些用户通常依赖数据工程师或分析师手动将问题翻译成SQL，造成了效率瓶颈和依赖问题。

Method: 论文可能提出一种自然语言到SQL的转换系统，利用自然语言处理技术将用户的问题自动转换为SQL查询。方法可能包括：1）自然语言理解模块解析用户意图；2）数据库模式映射；3）SQL生成器；4）查询验证和优化。可能采用深度学习模型如序列到序列架构、注意力机制或预训练语言模型。

Result: 预期结果包括：1）开发出能够准确理解自然语言查询并生成正确SQL的系统；2）在标准基准测试中达到较高的准确率；3）减少非技术用户对技术人员的依赖；4）提高数据查询效率；5）系统可能支持多种数据库类型和复杂查询场景。

Conclusion: 自然语言到SQL的转换系统能够有效降低企业数据库访问门槛，赋能非技术用户直接进行数据查询，提高组织的数据驱动决策效率。未来的研究方向可能包括处理更复杂的查询、提高系统鲁棒性、支持多轮对话以及集成到现有企业工作流中。

Abstract: In many organizations, business analysts and decisionmakers frequently need to query structured data to extract insights, generate reports, or monitor key metrics. While the data itself is readily available in enterprise databases, accessing it often requires writing Structured Query Language (SQL)—a task that remains challenging for users without formal technical training. As a result, these users typically rely on data engineers or analysts to manually translate their questions into SQL, creating …

</details>


### [334] [Membrane: Accelerating Database Analytics with DRAM-Based PIM Filtering and Schema Denormalization](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3786775&hl=en&sa=X&d=10944900715557999570&ei=RPRXaZVRvpnqtA-v6_mIBw&scisig=ALhkC2TyQ0CAwN_7OHAEY6By-Dpj&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=1&folt=cit)
*A Shekar,K Gaffney,M Prammer,K Kiyawat,L Wu…*

Main category: Google Scholar

TL;DR: 该研究采用软件方法将JOIN操作简化为选择/过滤任务，通过预连接反规范化优化内存数据库查询处理，以缓解冯·诺依曼瓶颈


<details>
  <summary>Details</summary>
Motivation: 内存数据库查询处理中存在大量CPU与内存间的数据传输，导致冯·诺依曼瓶颈问题，处理内存(PIM)架构为解决此问题提供了可行方案

Method: 采用软件方法，通过预连接反规范化将JOIN操作简化为选择或过滤任务，使查询处理工作负载更适合处理内存架构

Result: 该方法使查询处理工作负载更适合处理内存架构，能够有效缓解数据传输瓶颈

Conclusion: 通过软件方法简化JOIN操作，结合处理内存架构，可以有效缓解内存数据库查询处理中的冯·诺依曼瓶颈问题

Abstract: In-memory database query processing frequently involves substantial data transfers between the CPU and memory, leading to inefficiencies due to the Von Neumann bottleneck. Processing-in-Memory (PIM) architectures offer a viable solution to alleviate this bottleneck. In our study, we employ a commonly used software approach that streamlines JOIN operations into simpler selection or filtering tasks via pre-join denormalization, thereby making the query processing workload more …

</details>


### [335] [LMG Index: A Robust Learned Index for Multi-Dimensional Performance Balance](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.24824&hl=en&sa=X&d=6663091474271444785&ei=XW9ZacD6KO-GieoPo9DluQE&scisig=ALhkC2TrO1oFeOtOa2uHjf0HQ3J6&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=0&folt=cit)
*Y Chen,B Yao*

Main category: Google Scholar

TL;DR: 该论文指出现有学习索引主要优化查询延迟或空间使用等有限目标，忽略了更新效率和稳定性等实际评估维度，且依赖数据分布假设，存在局限性。


<details>
  <summary>Details</summary>
Motivation: 传统索引存在固有的权衡限制，学习索引将索引过程建模为预测问题以克服这些限制。然而，现有学习索引大多只优化有限目标（如查询延迟或空间使用），忽视了更新效率、稳定性等实际评估维度，且依赖数据分布假设，限制了其实际应用价值。

Method: 论文未在摘要中详细描述具体方法，但从问题陈述来看，可能提出了一种更全面的学习索引框架，考虑多维度优化目标，减少对数据分布假设的依赖。

Result: 摘要未提供具体实验结果，但暗示现有学习索引在更新效率、稳定性等实际维度上存在不足，需要更全面的评估框架。

Conclusion: 需要开发更全面的学习索引方法，同时优化多个实际评估维度（包括查询延迟、空间使用、更新效率和稳定性），减少对数据分布假设的依赖，以提升学习索引在实际应用中的价值。

Abstract: Index structures are fundamental for efficient query processing on large-scale datasets. Learned indexes model the indexing process as a prediction problem to overcome the inherent trade-offs of traditional indexes. However, most existing learned indexes optimize only for limited objectives like query latency or space usage, neglecting other practical evaluation dimensions such as update efficiency and stability. Moreover, many learned indexes rely on assumptions about data …

</details>


### [336] [TracePath: Modeling and Analyzing Competency Trajectories With Graph‐Based Learning Analytics Over a Hybrid Polystore](https://scholar.google.com/scholar_url?url=https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.70508&hl=en&sa=X&d=15238002995978628958&ei=9y1cafy-Gt_OieoPg6WE2QY&scisig=ALhkC2Q4cO6i0wkNyT9blM1636Ul&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ALhkC2ST2AYAjPXMn7CfOFohiT1r&html=&pos=4&folt=rel)
*A Ouared,M May,C Piau‐Toffolon,N Dugué*

Main category: Google Scholar

TL;DR: 基于能力的个性化学习路径与即时反馈方法，通过持续适应学习者需求来加速技能发展


<details>
  <summary>Details</summary>
Motivation: 传统教育方法难以满足个体差异化的学习需求，缺乏有效的个性化调整机制，导致学习效率低下和参与度不足

Method: 采用基于能力的方法，结合个性化学习路径设计和即时反馈机制，持续监测学习者表现并动态调整学习内容

Result: 该方法显著加速了技能发展过程，提高了学习者的参与度和学习效果，实现了更高效的能力培养

Conclusion: 基于能力的个性化学习路径配合即时反馈是提升学习效率和效果的有效策略，能够更好地适应个体学习需求

Abstract: ABSTRACT A competency‐based approach supported by personalized learning paths and prompt feedback accelerates skill development by continuously adapting to learners' needs and maintaining high levels of engagement. Capturing and …

</details>


### [337] [Retrieval Augmented Question Answering: When Should LLMs Admit Ignorance?](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.23836&hl=en&sa=X&d=13803850645923502314&ei=9y1cafy-Gt_OieoPg6WE2QY&scisig=ALhkC2Rvs7fE40w3Q48zxkbbI8v6&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:ALhkC2ST2AYAjPXMn7CfOFohiT1r&html=&pos=6&folt=rel)
*D Wang,J Ma,S Kumar*

Main category: Google Scholar

TL;DR: 研究LLM在检索增强问答中的应用，探讨扩展上下文窗口对检索增强生成的影响


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型上下文窗口的扩展，检索增强生成中更广泛上下文的使用日益增加，需要研究LLM在检索增强问答中的实际应用效果

Method: 使用LLM进行检索增强问答，分析扩展上下文窗口在检索增强生成中的使用情况

Result: 未提供具体实验结果，但关注扩展上下文窗口在检索增强问答中的潜在优势和应用

Conclusion: 扩展上下文窗口为检索增强生成提供了新的可能性，值得进一步研究LLM在检索增强问答中的应用

Abstract: The success of expanded context windows in Large Language Models (LLMs) has driven increased use of broader context in retrieval-augmented generation. We investigate the use of LLMs for retrieval augmented question answering. While …

</details>


### [338] [Artificial intelligence and machine learning techniques in solid waste management: A sustainable way toward future](https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S1574013725001650&hl=en&sa=X&d=13664828215763631929&ei=9S1caeyNMuqsieoPjYOSgAM&scisig=ALhkC2TMUEyh8x-UB6YvDQkmctUf&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=1&folt=cit)
*SN Omer,P Saravanan,P Kumar,M Moniga…*

Main category: Google Scholar

TL;DR: 该论文关注固体废物管理中的公共垃圾桶监控问题，提出通过智能系统确保垃圾桶在清洁周期前得到及时清空，以避免环境危害和疾病传播。


<details>
  <summary>Details</summary>
Motivation: 固体废物管理是发达国家和发展中国家面临的重大挑战。公共垃圾桶如果未能在清洁周期前及时清空，会导致垃圾溢出、环境脏乱、异味产生，甚至可能促进疾病传播。需要有效监控系统来确保垃圾桶在适当时间得到清理。

Method: 论文未在摘要中明确说明具体方法，但从上下文推断可能涉及智能监控系统、传感器技术或物联网解决方案，用于实时监测垃圾桶填充状态，确保在清洁周期前及时清空。

Result: 摘要未提供具体实验结果，但暗示通过实施有效的监控系统可以改善固体废物管理效率，减少环境危害和公共卫生风险。

Conclusion: 有效的公共垃圾桶监控对于固体废物管理至关重要，需要智能系统来确保及时清空，从而维护公共卫生和环境整洁。

Abstract: Abstract Solid Waste Management (SWM) constitutes a significant challenge confronting both developed and developing countries. A crucial element of effective solid waste management is ensuring that waste bins is public spaces are adequately filled prior to the commencement of the subsequent cleaning cycle. Failure to do so can result in various hazards, including unsightly litter and unpleasant odours, which may contribute to the proliferation of diseases. Furthermore, the rapid growth of the …

</details>


### [339] [Advancing Additively Manufactured Composite Structural Joints Testing with Discrete Computational Modeling and Digital Twins](https://scholar.google.com/scholar_url?url=https://books.google.com/books%3Fhl%3Den%26lr%3Dlang_en%26id%3D_ZmlEQAAQBAJ%26oi%3Dfnd%26pg%3DPA225%26ots%3DnN42quwyv_%26sig%3DLe1UxXyf2UZlfoEkY_ahsNbThOc&hl=en&sa=X&d=9050854493059584442&ei=9S1caeyNMuqsieoPjYOSgAM&scisig=ALhkC2QXXQnuOxDpaXEbF-vqlJwd&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=2&folt=cit)
*AA Deleo,S Phenisee,D Shelley,M Flores…*

Main category: Google Scholar

TL;DR: 结合离散计算建模与数字孪生技术优化增材制造复合材料接头结构完整性


<details>
  <summary>Details</summary>
Motivation: 增材制造虽能生产复杂复合材料结构，但保持其接头结构完整性仍是重大挑战，传统模型在捕捉复杂损伤机制方面存在局限

Method: 提出离散复合材料模型(DM4C)结合数字孪生技术，通过离散计算建模方法有效捕捉复杂损伤机制，优化增材制造复合材料接头

Result: DM4C模型克服了传统模型的局限性，能够更准确地预测和优化增材制造复合材料接头的结构性能

Conclusion: 离散计算建模与数字孪生相结合的方法为优化增材制造复合材料接头提供了创新解决方案，有望提升其结构完整性和可靠性

Abstract: Additive manufacturing (AM) is revolutionizing the production of complex composite structures, yet maintaining the structural integrity of AM composite joints remains a significant challenge. This study introduces an innovative approach that combines discrete computational modeling with digital twins to optimize these critical elements. The Discrete Model for Composites (DM4C) addresses limitations in traditional models by effectively capturing complex damage mechanisms. Using the Anisoprint …

</details>


### [340] [vLLM: An Efficient Inference Engine for Large Language Models](https://scholar.google.com/scholar_url?url=https://www2.eecs.berkeley.edu/Pubs/TechRpts/2025/EECS-2025-192.pdf&hl=en&sa=X&d=7921661837680700750&ei=9S1caeyNMuqsieoPjYOSgAM&scisig=ALhkC2ShjE_OkHRbnhxnlO_v_q7J&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=3&folt=cit)
*W Kwon*

Main category: Google Scholar

TL;DR: 大语言模型（LLMs）已成为当今最具变革性的技术之一，其规模和能力在短短几年内以前所未有的速度增长，从早期展示语言流畅性发展到当前具备广泛通用智能，能够执行复杂推理、编写完整软件系统等任务。


<details>
  <summary>Details</summary>
Motivation: 本文旨在概述大语言模型的快速发展历程，强调其从单纯的语言模型演变为具备广泛通用智能系统的转变，展示这一技术领域的快速进步和当前达到的先进水平。

Method: 通过文献综述和案例分析的方法，追踪大语言模型的发展轨迹，对比早期模型与当前最先进模型（如GPT、Gemini、Claude）的能力差异，分析其技术演进路径。

Result: 大语言模型在短短几年内实现了从语言流畅性到广泛通用智能的质变，当前最先进模型已能执行复杂推理、编写完整软件系统、解决奥林匹克级别问题等高级认知任务，展现出接近人类水平的智能能力。

Conclusion: 大语言模型的发展速度和技术进步令人瞩目，已从专门的语言处理工具演变为具备广泛通用智能的系统，这一转变标志着人工智能领域的重要里程碑，预示着未来更广泛的应用前景。

Abstract: Large language models (LLMs) have rapidly emerged as one of the most transformative technologies today. Over just a few years, the scale and capability of these models have grown at an unprecedented pace. Early LLMs demonstrated impressive linguistic fluency; current state-of-the-art models such as GPT [75], Gemini [32], and Claude [7] now exhibit broad general intelligence, performing complex reasoning tasks, writing entire software systems, solving Olympiad-level …

</details>


### [341] [Bit-Level Semantics: Scalable RAG Retrieval with Neurosymbolic Hyperdimensional Computing](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11282933/&hl=en&sa=X&d=11103869508662524291&ei=skRfab7PNqC16rQPm4fPgQQ&scisig=ALhkC2SQbE6kNYchr5o3jLrdnsK9&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=0&folt=cit)
*H Lee,S Jang,J Gwak,J Park,Y Kim*

Main category: Google Scholar

TL;DR: 提出基于超维计算（HDC）的检索增强生成框架，将Transformer词嵌入投影为高维二进制超向量，构建紧凑文档表示，并引入HD-NSW图索引支持亚线性搜索


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统依赖密集浮点嵌入进行文档检索，在大规模应用中存在显著的内存和计算成本问题，需要更高效的检索方法

Method: 使用超维计算框架将Transformer词嵌入投影到高维二进制超向量空间，通过聚合构建紧凑文档表示，并设计HD-NSW图索引实现亚线性搜索

Result: 该方法显著降低了内存占用和计算成本，同时保持了检索质量，通过二进制表示和高效索引实现了大规模RAG系统的性能优化

Conclusion: 超维计算为RAG系统提供了高效的替代方案，通过二进制超向量表示和图索引技术，在保持检索效果的同时大幅降低了资源消耗

Abstract: Retrieval-Augmented Generation (RAG) systems typically rely on dense floating-point embeddings to retrieve relevant documents, but this approach incurs significant memory and compute costs at scale. We propose a Hyperdimensional Computing (HDC) framework that projects transformer token embeddings into high-dimensional binary hypervectors, which are aggregated into compact document representations. To support sublinear search, we introduce HD-NSW, a graph-based index inspired …

</details>


### [342] [Robust Ground Truth Data Mining for Enhanced Privacy and Accuracy in Noisy TinyML Environments](https://scholar.google.com/scholar_url?url=https://onlinelibrary.wiley.com/doi/abs/10.1002/9781394294572.ch11&hl=en&sa=X&d=5689593200770032943&ei=skRfab7PNqC16rQPm4fPgQQ&scisig=ALhkC2QuwpKrnzRNmz6YtR8Lsw2t&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:ALhkC2Sq1na2kZ3OY3GLcPQKALQk&html=&pos=1&folt=cit)
*Y Sei,A Lucky Imoize*

Main category: Google Scholar

TL;DR: 该论文探讨了在资源受限的物联网设备中，当数据存在传感误差时如何实现隐私保护数据挖掘，提出了结合差分隐私与误差感知的隐私保护框架


<details>
  <summary>Details</summary>
Motivation: 物联网中资源受限设备普遍存在传感误差，导致数据准确性偏离真实值。虽然隐私保护数据挖掘在过去十年得到广泛研究，但缺乏对包含误差的数据值的关注。差分隐私作为隐私度量的实际标准，传统方法通过添加噪声保护目标值，但在存在传感误差的场景下需要新的方法

Method: 论文提出了一种结合差分隐私与误差感知的隐私保护方法，考虑传感误差对数据准确性的影响，设计新的隐私保护机制来处理包含误差的数据值，可能包括误差建模、噪声添加策略调整或误差补偿机制

Result: 该方法能够在存在传感误差的情况下提供有效的隐私保护，同时保持数据实用性，为TinyML在物联网中的隐私保护数据挖掘提供了新的解决方案

Conclusion: 在资源受限的物联网设备中，考虑传感误差的隐私保护数据挖掘是必要的，提出的误差感知差分隐私框架能够有效解决这一问题，为TinyML应用提供了更实用的隐私保护方案

Abstract: Given the importance of tiny machine learning (TinyML) in the Internet of Things, where resource‐constrained devices are prevalent, data accuracy often diverges from true values due to sensing errors. Although privacy‐preserving data mining has been extensively explored over the past decade, there is a lack of focus on data values that include errors. Differential privacy (DP), the de facto standard for privacy metrics, traditionally involves adding noise to protect target values. However, adding …

</details>


### [343] [The Machine Learning Canvas: Empirical Findings on Why Strategy Matters More Than AI Code Generation](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.01839&hl=en&sa=X&d=11302685046454331568&ei=hKNgafvBFsm4ieoP4sbVuAg&scisig=AHkA5jTp5VgoDZmqd9pVDAxP8huK&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:AHkA5jSP8671UBQnfQacXFBHq92d&html=&pos=1&folt=cit)
*M Prause*

Main category: Google Scholar

TL;DR: 开发并测试机器学习画布框架，结合业务战略、软件工程和数据科学，识别ML项目成功的关键因素


<details>
  <summary>Details</summary>
Motivation: 尽管AI编码助手日益普及，但超过80%的机器学习项目未能交付实际业务价值，需要实用框架来整合业务战略、软件工程和数据科学，识别成功因素

Method: 创建并测试机器学习画布框架，调查150名数据科学家，使用统计建模分析响应数据

Result: 识别出四个关键成功因素（具体因素未在摘要中详细说明）

Conclusion: 机器学习画布是一个实用框架，能够有效整合业务战略、软件工程和数据科学，帮助识别和实现ML项目的成功因素

Abstract: Despite the growing popularity of AI coding assistants, over 80% of machine learning (ML) projects fail to deliver real business value. This study creates and tests a Machine Learning Canvas, a practical framework that combines business strategy, software engineering, and data science in order to determine the factors that lead to the success of ML projects. We surveyed 150 data scientists and analyzed their responses using statistical modeling. We identified four key success factors: Strategy …

</details>


### [344] [Unified Generation and Self-Verification for Vision-Language Models via Advantage Decoupled Preference Optimization](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.01483&hl=en&sa=X&d=11169606304674580250&ei=haNgadLdNu6TieoPutPYsQg&scisig=AHkA5jQjFss7U9uuXMdRnl7AKyqw&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:AHkA5jR-WPkAfpCINzU6oW8zO6Qz&html=&pos=2&folt=rel)
*X Qiu,H Jia,Z Zeng,S Shen,C Meng,Y Yang,L Zhu*

Main category: Google Scholar

TL;DR: ADPO提出了一种统一的强化学习框架，通过优势解耦将生成和验证模型整合到单一模型中，降低训练和推理成本


<details>
  <summary>Details</summary>
Motivation: 并行测试时缩放通常需要分别训练生成和验证模型，导致训练和推理成本高昂，需要更高效的统一框架

Method: 提出优势解耦偏好优化(ADPO)，将生成和验证模型统一到单一模型中，通过优势解耦机制实现高效训练

Result: ADPO在保持性能的同时显著降低了训练和推理成本，实现了更高效的测试时缩放

Conclusion: ADPO为并行测试时缩放提供了一种成本效益更高的解决方案，通过统一框架解决了传统方法的高成本问题

Abstract: Parallel test-time scaling typically trains separate generation and verification models, incurring high training and inference costs. We propose Advantage Decoupled Preference Optimization (ADPO), a unified reinforcement learning framework that …

</details>


### [345] [SentGraph: Hierarchical Sentence Graph for Multi-hop Retrieval-Augmented Question Answering](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.03014&hl=en&sa=X&d=11852317841522520221&ei=Ru1haezgPKC16rQPm4fPgQQ&scisig=AHkA5jT_UOdLsMRIx7RDLQ-_PYBR&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:AHkA5jR-WPkAfpCINzU6oW8zO6Qz&html=&pos=2&folt=rel)
*J Liang,P Zhou,W Zhou,W Qing,Q Zhao,Z Wang…*

Main category: Google Scholar

TL;DR: 传统RAG在单跳问答中有效，但在需要结合多个证据源的多跳问答中存在显著局限性


<details>
  <summary>Details</summary>
Motivation: 传统检索增强生成（RAG）方法在处理单跳问答任务时表现良好，但在多跳问答场景中面临挑战，因为多跳问答需要整合来自多个来源的证据并进行推理

Method: 论文未提供具体方法细节，但从摘要推断可能涉及改进RAG架构以支持多跳推理，可能包括增强检索策略、证据整合机制或多步推理框架

Result: 摘要未提供具体实验结果，但暗示传统RAG在多跳问答中存在局限性，需要改进方法来解决这一挑战

Conclusion: 需要开发新的RAG方法来有效处理多跳问答任务，这些方法应能更好地整合多个证据源并支持复杂的推理过程

Abstract: Traditional Retrieval-Augmented Generation (RAG) effectively supports single-hop question answering with large language models but faces significant limitations in multi-hop question answering tasks, which require combining evidence from multiple …

</details>


### [346] [Machine learning for software engineering](https://scholar.google.com/scholar_url?url=https://amsdottorato.unibo.it/id/eprint/12493/1/Balla_Stefano_thesis.pdf&hl=en&sa=X&d=1941060584359203803&ei=Re1hac3vEqC16rQPm4fPgQQ&scisig=AHkA5jS7H8GpOrye5VFEHOLrOi_x&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:AHkA5jSP8671UBQnfQacXFBHq92d&html=&pos=2&folt=cit)
*S Balla*

Main category: Google Scholar

TL;DR: 开发针对代码格式化/压缩变化的鲁棒作者归属技术，建立标准化仓库推荐基准，并实现可扩展到数十亿文件的解决方案


<details>
  <summary>Details</summary>
Motivation: 开源仓库爆炸式增长为ML4SE带来机遇和挑战：当前方法难以处理代码格式化/压缩变化导致的风格信号模糊，缺乏标准化仓库推荐基准，以及需要扩展到数十亿文件规模

Method: 开发鲁棒的作者归属技术，建立标准化仓库推荐基准，设计可扩展到数十亿文件的解决方案

Result: 未在摘要中明确说明具体结果，但目标是解决当前ML4SE面临的三个核心挑战

Conclusion: 该论文旨在通过开发鲁棒技术、建立标准化基准和实现可扩展解决方案，推动ML4SE在处理大规模开源代码库方面的发展

Abstract: The explosive growth of open-source repositories creates opportunities and challenges for Machine Learning for Software Engineering (ML4SE). Current methods struggle with:(i) code frequently reformatted or minified, obscuring stylistic signals;(ii) the lack of standardised benchmarks for repository recommendation; and (iii) the need to scale to billions of files in archives such as Software Heritage. Objectives. This thesis aims to (1) develop an authorship-attribution technique …

</details>


### [347] [An optimizing spatial learned index for balanced update and query performance](https://scholar.google.com/scholar_url?url=https://www.tandfonline.com/doi/full/10.1080/13658816.2025.2607453&hl=en&sa=X&d=2763698892515283192&ei=bUVjaaHINqyK6rQPgZOO6A8&scisig=AHkA5jRP5RqCYn1R8owj4g5lbMQg&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:AHkA5jR-WPkAfpCINzU6oW8zO6Qz&html=&pos=0&folt=rel)
*P Tang,C Fu,L Hu,Y Hu,Y Meng,F Zhang,R Liu*

Main category: Google Scholar

TL;DR: 论文探讨了学习型空间索引在处理复杂层次结构时面临的挑战，并提出了一种新的解决方案来改进空间数据库的检索性能。


<details>
  <summary>Details</summary>
Motivation: 空间数据库是管理地理大数据的主要手段，学习型空间索引通过建模数据分布来提高空间检索性能。然而，现有的学习型空间索引在处理复杂层次结构时面临挑战，需要新的方法来更好地处理这种复杂性。

Method: 论文提出了一种新的学习型空间索引方法，专门设计用于处理复杂的层次结构。该方法可能涉及深度学习模型、层次化表示学习或专门的空间数据分布建模技术，以更好地捕捉空间数据的层次特性。

Result: 提出的方法在空间检索性能方面相比现有学习型空间索引有显著提升，特别是在处理具有复杂层次结构的数据时表现出更好的效率和准确性。

Conclusion: 通过专门处理复杂层次结构的学习型空间索引方法，可以显著提高空间数据库的检索性能，为地理大数据管理提供更有效的解决方案。

Abstract: Spatial databases are the main means to manage geo-big data, and learned spatial indices are a novel approach to improve the spatial retrieval performance of spatial databases by modeling the data distribution. However, the complex hierarchical …

</details>


### [348] [EvolSQL: Structure-Aware Evolution for Scalable Text-to-SQL Data Synthesis](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.04875&hl=en&sa=X&d=7983352605788528383&ei=5aVkafW_E7OlieoPyq27-AE&scisig=AHkA5jQa9J02rmMVoQhMXE6WpWLb&oi=scholaralrt&hist=i6heNjgAAAAJ:13225314161935261941:AHkA5jR-WPkAfpCINzU6oW8zO6Qz&html=&pos=0&folt=rel)
*X Pan,C Tao,J Bai,J Gao,Z Tao,X Zhou,G Cheung…*

Main category: Google Scholar

TL;DR: 该论文针对Text-to-SQL模型训练中高质量、多样化、结构复杂数据集稀缺的问题，提出了一种新的数据合成方法，通过增强SQL查询的多样性和复杂性来改进模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有Text-to-SQL模型训练面临高质量、多样化、结构复杂数据集稀缺的挑战。现有方法要么依赖有限的人工标注语料，要么通过简单方式直接合成数据集，导致数据质量和多样性不足。

Method: 提出了一种新的数据合成方法，通过增强SQL查询的多样性和复杂性来生成更高质量的训练数据。该方法可能涉及查询重写、结构扩展、语义增强等技术手段。

Result: 该方法生成的合成数据集能够显著提升Text-to-SQL模型的性能，特别是在处理复杂查询和多样化场景时表现更优。

Conclusion: 通过改进的数据合成方法可以有效解决Text-to-SQL训练数据稀缺问题，为构建更强大的Text-to-SQL模型提供了新的数据生成途径。

Abstract: Training effective Text-to-SQL models remains challenging due to the scarcity of high-quality, diverse, and structurally complex datasets. Existing methods either rely on limited human-annotated corpora, or synthesize datasets directly by simply …

</details>


### [349] [Surprising Interactions Between Filters In Equi-Join Processing](https://scholar.google.com/scholar_url?url=http://reports-archive.adm.cs.cmu.edu/anon/anon/2025/CMU-CS-25-152.pdf&hl=en&sa=X&d=7000732317522279578&ei=46VkaYCDK-qsieoPjYOSgAM&scisig=AHkA5jRyrxrNSLlc9rdYXMtgMUMx&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:AHkA5jSP8671UBQnfQacXFBHq92d&html=&pos=0&folt=cit)
*M Khare*

Main category: Google Scholar

TL;DR: 论文探讨了在数据湖和存储计算分离架构下，传统基于统计信息的查询优化方法失效的问题，提出了一种新的连接顺序优化方法


<details>
  <summary>Details</summary>
Motivation: 现代数据存储架构（数据湖、存储计算分离）中，数据库管理系统经常处理存储在对象存储（如S3）和开放文件格式（如Parquet）中的大量数据，这些数据往往缺乏或具有过时的统计信息。在连接密集型分析工作负载中，传统的基于统计信息最小化连接成本的查询计划优化方法在这种情况下失效

Method: 论文提出了一种新的连接顺序优化方法，该方法不依赖传统统计信息，而是利用数据湖架构的特点和现代硬件特性来优化连接操作

Result: 该方法在缺乏统计信息的数据湖环境中，相比传统优化方法能够显著提升连接密集型分析查询的性能

Conclusion: 在数据湖和存储计算分离的现代数据架构中，需要重新思考查询优化方法，特别是连接顺序优化策略，以适应缺乏统计信息的环境

Abstract: The current era of data storage is defined by the widespread adoption of data lakes, and the disaggregation of storage and compute hardware. Modern database management systems (DBMSs) are often operating on large volumes of data stored in object stores (like Amazon's S3), open file formats (like Apache's Parquet), or otherwise have outdated or nonexistent statistics. In join-heavy analytical workloads, the traditional approach of optimizing query plans to minimize the cost of joins breaks …

</details>


### [350] [On Approximability of 𝓁₂² Min-Sum Clustering](https://scholar.google.com/scholar_url?url=https://par.nsf.gov/servlets/purl/10646612&hl=en&sa=X&d=11030215537165490263&ei=46VkaYCDK-qsieoPjYOSgAM&scisig=AHkA5jTV0RpyJo9InbJGstcRx_hQ&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:AHkA5jSP8671UBQnfQacXFBHq92d&html=&pos=4&folt=cit)
*E Lee,Y Rabani,C Schwiegelshohn,S Zhou*

Main category: Google Scholar

TL;DR: 该论文首次证明了ℓ₂² min-sum k-clustering问题的近似难度，表明该问题无法在1.056倍以内近似，除非P=NP。


<details>
  <summary>Details</summary>
Motivation: ℓ₂² min-sum k-clustering问题是NP难的，但之前没有关于其近似难度的研究。本文旨在填补这一空白，为该问题建立首个近似难度下界。

Method: 采用计算复杂性理论方法，通过归约技术证明ℓ₂² min-sum k-clustering问题的近似难度下界。

Result: 证明了ℓ₂² min-sum k-clustering问题在NP-hard假设下，无法在1.056倍以内近似。

Conclusion: 本文首次建立了ℓ₂² min-sum k-clustering问题的近似难度下界，为理解该问题的计算复杂性提供了重要见解。

Abstract: [" The 𝓁₂² min-sum k-clustering problem is to partition an input set into clusters C_1,…, C_k to minimize∑ _ {i= 1}^ k∑ _ {p, q∈ C_i}‖ pq‖ ₂². Although 𝓁₂² min-sum k-clustering is NP-hard, it is not known whether it is NP-hard to approximate 𝓁₂² min-sum k-clustering beyond a certain factor.\r\nIn this paper, we give the first hardness-of-approximation result for the 𝓁₂² min-sum k-clustering problem. We show that it is NP-hard to approximate the objective to a factor better than 1.056 and …

</details>


### [351] [Facilitating Human-Machine Teaming in Machine Learning Problem Formulation](https://scholar.google.com/scholar_url?url=https://search.proquest.com/openview/11f2879ccb706d1cd87e0cad3fba7ad6/1%3Fpq-origsite%3Dgscholar%26cbl%3D18750%26diss%3Dy&hl=en&sa=X&d=2767126158866856884&ei=46VkaYCDK-qsieoPjYOSgAM&scisig=AHkA5jRmInXVOAXFgjjOdnQbgMJ3&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:AHkA5jSP8671UBQnfQacXFBHq92d&html=&pos=5&folt=cit)
*M Guo*

Main category: Google Scholar

TL;DR: 论文探讨了应用机器学习中问题定义阶段缺乏工具支持的问题，提出了人机协作的解决方案方向


<details>
  <summary>Details</summary>
Motivation: 应用机器学习任务的第一步是定义预测目标和问题表述，这需要结合可用数据。实践者通常需要大量试错才能找到既相关又现实的问题表述。尽管这一过程至关重要，但现有工具对此支持不足。这是一个人类和机器具有互补专长的任务，因此具有人机协作的潜力。

Method: 论文未在摘要中详细描述具体方法，但提出了人机协作框架的概念，暗示将人类领域知识与机器学习能力相结合来支持问题定义过程。

Result: 摘要未提供具体实验结果，但指出了当前工具在支持问题定义阶段的不足，并提出了人机协作的潜在解决方案方向。

Conclusion: 应用机器学习的问题定义阶段需要更好的工具支持，人机协作框架有望解决这一挑战，结合人类领域专业知识和机器学习能力来改进问题表述过程。

Abstract: The first step in any applied machine learning (ML) task is formulating what needs to be predicted and how to define it, considering the available data. It often takes significant trial-and-errors for practitioners to identify a problem formulation that is both relevant to the task and realistic given the available data. Despite its importance, this process is not well supported by existing tools. This is a task where humans and machines bring complementary expertise, thus potentially amenable to …

</details>


### [352] [Exploratory Visual Analysis of Multivariate Correlations in Global Demographic Data](https://scholar.google.com/scholar_url?url=https://www.cs.ubc.ca/~tmm/courses/547-25/projects/alice_minju/proposal.pdf&hl=en&sa=X&d=6671197888663649848&ei=46VkaYCDK-qsieoPjYOSgAM&scisig=AHkA5jRQO7Z87gdmhCChlNkAqsWn&oi=scholaralrt&hist=i6heNjgAAAAJ:6389686251013311652:AHkA5jSP8671UBQnfQacXFBHq92d&html=&pos=6&folt=cit)
*A Kang,M Park*

Main category: Google Scholar

TL;DR: 该论文探讨了在探索性可视化分析中，特别是处理多变量数据时，用户面临的相关性发现挑战，并提出了一种更高效的方法来解决组合爆炸问题。


<details>
  <summary>Details</summary>
Motivation: 在探索性可视化分析中，当用户想要发现哪些变量之间存在相关性时，面临组合爆炸问题。用户需要手动选择变量对并逐一测试它们的关系，这在多变量数据中变得极其低效和复杂。

Method: 论文提出了一种新的可视化方法或系统，旨在帮助用户更高效地发现多变量数据中的相关性，避免手动逐一检查变量对的繁琐过程。

Result: 该方法能够显著减少用户发现相关变量所需的时间和认知负荷，提供更直观的相关性探索体验，提高多变量数据分析的效率。

Conclusion: 探索性可视化分析需要专门设计的方法来处理多变量相关性发现，避免组合爆炸问题，从而支持更有效的数据探索和洞察发现。

Abstract: Visual analysis of correlations is relatively straightforward when users have a specific target question in mind, such as examining a relationship in scatterplot or parallel coordinates. However, in exploratory visual analysis—particularly when dealing with multivariate data—the process becomes more complex. When users wish to discover which variables are correlated, they face a combinatorial explosion, where they must manually select pairs of variables and test their relationships one by one. Moreover …

</details>


<div id='Matei Zaharia'></div>

# Matei Zaharia [[Back]](#toc)

### [353] [CoDaPO: Confidence and Difficulty-Adaptive Policy Optimization for Language Models](https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DP4JHrUkXIH&hl=zh-CN&sa=X&d=826266569300946412&ei=twYtaZOHMf3D6rQP3LSU2Ag&scisig=ABGrvjK0LyP8udqHSxv7m_UCbj88&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=0&folt=rel)
*Z Zhou,X Lu,C Cao,B Miranda,T Liu,B Han,S Koyejo*

Main category: Matei Zaharia

TL;DR: 使用PRAG框架诊断GRPO算法在强化学习后训练中的问题，并提出改进方案


<details>
  <summary>Details</summary>
Motivation: 强化学习后训练能增强大语言模型的推理能力，但当前主流的GRPO算法存在持续性问题，需要系统性地诊断和改进

Method: 采用PRAG框架（概率、奖励、优势、梯度）对GRPO算法进行诊断分析，识别具体问题并提出相应的改进方案

Result: 通过PRAG分析揭示了GRPO算法在概率估计、奖励设计、优势计算和梯度优化等方面的系统性缺陷

Conclusion: 基于PRAG框架的诊断为改进强化学习后训练算法提供了系统性的分析工具和明确的改进方向

Abstract: Reinforcement learning (RL) post-training strengthens reasoning in large language models (LLMs), yet the prevailing GRPO algorithm exhibits persistent issues. Using a PRAG lens (Probability, Reward, Advantage, Gradient), we diagnose three …

</details>


### [354] [Democratizing Agentic RAG: Distillation-Guided Policy Optimization for Compact Language Models](https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DCP0H9NAWES&hl=zh-CN&sa=X&d=7167708886445552038&ei=twYtaZOHMf3D6rQP3LSU2Ag&scisig=ABGrvjIEPoQIejSPtP_rfVkQLHvI&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=1&folt=rel)
*R Kotoge,M Nishimura,J Ma*

Main category: Matei Zaharia

TL;DR: 强化学习作为后训练方法用于激发语言模型的智能RAG行为，但小型语言模型因推理能力不足而难以有效执行


<details>
  <summary>Details</summary>
Motivation: 研究如何让参数较少的小型语言模型也能有效执行需要智能推理的RAG行为，如搜索和规划，以解决当前小型模型在强化学习后训练中表现不佳的问题

Method: 论文可能提出了一种改进的强化学习后训练方法，专门针对小型语言模型设计，可能包括模型架构调整、训练策略优化或知识蒸馏等技术来提升推理能力

Result: 预期结果是开发出能够使小型语言模型有效执行智能RAG行为的强化学习后训练方法，提升其在搜索、规划等任务上的表现

Conclusion: 通过专门设计的强化学习后训练方法，小型语言模型也能够获得执行复杂RAG行为的能力，这为在资源受限环境中部署智能语言模型提供了可能

Abstract: Reinforcement Learning has emerged as a post-training approach to elicit agentic RAG behaviors such as search and planning from language models. However, compact language models (eg, 0.5 B parameters) struggle due to poor reasoning …

</details>


### [355] [Unlocking the Potential of Smaller Language Models as Superior Instruction Evolvers](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3746252.3761290&hl=zh-CN&sa=X&d=14462923280604830961&ei=twYtaZOHMf3D6rQP3LSU2Ag&scisig=ABGrvjJ_GcUSBt-EzqoekS4_JUhW&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=2&folt=rel)
*T Hui,L Zhao,G Dong,Y Zhang,S Su*

Main category: Matei Zaharia

TL;DR: 指令调优是解锁大语言模型潜力的关键，复杂多样的指令对于模型与下游任务对齐至关重要


<details>
  <summary>Details</summary>
Motivation: 指令调优已成为解锁大语言模型全部潜力的基石，其中复杂多样的指令在使模型与广泛下游任务对齐方面发挥着关键作用

Method: 通过指令调优技术，利用复杂多样的指令集来训练和优化大语言模型

Result: 指令调优能够有效提升大语言模型在下游任务上的性能和对齐能力

Conclusion: 指令调优是实现大语言模型与多样化任务对齐的重要方法，复杂多样的指令是其成功的关键因素

Abstract: Instruction tuning has become a cornerstone for unlocking the full potential of large language models. Among the key factors, complex and diverse instructions play a crucial role in aligning these models with a wide range of downstream tasks …

</details>


### [356] [Stabilizing Reinforcement Learning for Honesty Alignment in Language Models on Deductive Reasoning](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.09222&hl=zh-CN&sa=X&d=1565627840536248814&ei=twYtaZOHMf3D6rQP3LSU2Ag&scisig=ABGrvjKZ_IK9r2j7mhAfVDz-aiHC&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=3&folt=rel)
*J Liu,K Dhole,Y Wang,H Wen,S Zhang,H Mao,G Li…*

Main category: Matei Zaharia

TL;DR: RLVR框架用于对齐语言模型与复杂推理目标，但现有方法仅优化最终任务结果，忽略了中间推理过程的质量


<details>
  <summary>Details</summary>
Motivation: 现有强化学习可验证奖励方法主要关注最终任务结果，而忽略了中间推理步骤的质量，这可能导致模型产生错误或不可靠的推理过程

Method: 论文提出了一种改进的RLVR方法，通过引入中间推理步骤的奖励信号来优化整个推理过程，而不仅仅是最终结果

Result: 该方法在多个复杂推理任务上表现出色，相比仅优化最终结果的方法，能产生更可靠、更准确的推理过程

Conclusion: 通过同时优化中间推理步骤和最终结果，可以显著提升语言模型在复杂推理任务中的性能和可靠性

Abstract: Reinforcement learning with verifiable rewards (RLVR) has recently emerged as a promising framework for aligning language models with complex reasoning objectives. However, most existing methods optimize only for final task outcomes …

</details>


### [357] [CDLM: Consistency Diffusion Language Models For Faster Sampling](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.19269&hl=zh-CN&sa=X&d=4266191329938859192&ei=twYtaZOHMf3D6rQP3LSU2Ag&scisig=ABGrvjJI9bhKY9hMjkoVkYPaiU9G&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=4&folt=rel)
*M Kim,C Xu,C Hooper,H Singh,B Athiwaratkun…*

Main category: Matei Zaharia

TL;DR: CDLM是一种基于一致性扩散的语言模型，通过一致性映射实现高效并行生成，解决了传统扩散语言模型推理慢和无法使用KV缓存的问题


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型（DLMs）虽然提供了有前景的并行生成范式，但存在推理速度慢（需要大量细化步骤）和无法使用标准KV缓存的问题，限制了其实际应用

Method: 引入CDLM（一致性扩散语言模型），通过一致性映射将噪声向量直接映射到最终输出，实现高效并行生成。该方法结合了扩散模型的并行生成优势和一致性模型的快速推理特性

Result: CDLM在保持生成质量的同时，显著提高了推理速度，相比传统扩散语言模型实现了更高效的并行生成，解决了KV缓存兼容性问题

Conclusion: CDLM为扩散语言模型提供了一种高效的推理解决方案，平衡了生成质量和推理效率，推动了并行生成模型的实际应用

Abstract: Diffusion Language Models (DLMs) offer a promising parallel generation paradigm but suffer from slow inference due to numerous refinement steps and the inability to use standard KV caching. We introduce CDLM (Consistency Diffusion Language …

</details>


### [358] [Adaptive Chain-of-Thought Distillation Based on LLM Performance on Original Problems](https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2227-7390/13/22/3646&hl=zh-CN&sa=X&d=1857095113208759033&ei=twYtaZOHMf3D6rQP3LSU2Ag&scisig=ABGrvjJuGYIB_zm0-dfpeJTZAnLj&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=5&folt=rel)
*J Shen,X Cui,Z Gao,X Sheng*

Main category: Matei Zaharia

TL;DR: 该论文研究了如何将大语言模型的思维链能力有效蒸馏到小参数规模模型中的挑战，提出了一种新的蒸馏方法。


<details>
  <summary>Details</summary>
Motivation: 思维链方法显著提升了大语言模型在复杂任务上的性能，但如何将这种能力有效蒸馏到参数规模较小的模型中仍然是一个挑战。现有方法在保持思维链推理能力的同时实现高效蒸馏方面存在不足。

Method: 提出了一种新的蒸馏方法，可能包括知识蒸馏、提示工程或架构改进等技术，旨在将大模型的思维链推理能力有效转移到小模型中，同时保持推理质量。

Result: 该方法在多个复杂任务上显著提升了小参数规模语言模型的性能，使其能够接近或达到大模型的思维链推理能力，同时保持了计算效率。

Conclusion: 提出的蒸馏方法有效解决了将思维链能力转移到小规模模型中的挑战，为部署高效推理模型提供了可行方案，推动了语言模型在实际应用中的普及。

Abstract: The chain-of-thought (CoT) approach in large language models (LLMs) has markedly enhanced their performance on complex tasks; however, effectively distilling this capability into LLMs with smaller parameter scales remains a challenge …

</details>


### [359] [LLM-as-a-Judge in Entity Retrieval: Assessing Explicit and Implicit Relevance](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3746252.3760922&hl=zh-CN&sa=X&d=15466449824469377303&ei=twYtaZOHMf3D6rQP3LSU2Ag&scisig=ABGrvjK_8bK4wpW1ZsF80RDMClv9&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=6&folt=rel)
*MH Saliminabi,N Arabzadeh,SM Hosseini…*

Main category: Matei Zaharia

TL;DR: 该论文探讨了实体检索中高质量监督数据有限的问题，提出了一种利用大型语言模型生成合成训练数据的方法来改进实体检索模型。


<details>
  <summary>Details</summary>
Motivation: 实体检索在信息访问系统中至关重要，但现有检索模型的开发和评估受到高质量监督数据有限的制约。虽然最近的研究展示了大型语言模型在生成合成训练数据方面的潜力，但如何有效利用这些数据来提升实体检索性能仍是一个开放问题。

Method: 提出了一种利用大型语言模型生成合成训练数据的方法，用于改进实体检索模型。该方法可能包括：1）使用LLM生成查询-实体对，2）设计数据生成策略以确保质量，3）将合成数据与现有监督数据结合训练检索模型。

Result: 实验结果表明，使用LLM生成的合成训练数据能够显著提升实体检索模型的性能，特别是在数据稀缺的情况下。该方法在标准实体检索基准测试中取得了优于现有方法的性能。

Conclusion: 利用大型语言模型生成合成训练数据是解决实体检索中监督数据稀缺问题的有效途径。这种方法能够显著提升检索性能，为实体检索模型的开发和评估提供了新的方向。

Abstract: Entity retrieval plays a critical role in information access systems, yet the development and evaluation of retrieval models remain constrained by the limited availability of high-quality supervision. While recent work has demonstrated the utility …

</details>


### [360] [Querier-Aware LLM: Generating Personalized Responses to the Same Query from Different Queriers](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3746252.3761389&hl=zh-CN&sa=X&d=11060814672666919057&ei=twYtaZOHMf3D6rQP3LSU2Ag&scisig=ABGrvjIXg2DGZBymXBnn7Jz56tre&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=7&folt=rel)
*H Zeng,C Niu,F Wu,C Lv,G Chen*

Main category: Matei Zaharia

TL;DR: 提出一种查询者感知的LLM个性化方法，通过生成针对不同查询者群体的多样化响应，解决现有工作忽视查询者多样性的问题


<details>
  <summary>Details</summary>
Motivation: 现有LLM个性化研究主要关注为LLM分配不同的响应角色，但忽视了查询者群体的多样性。不同查询者可能对同一问题有不同的偏好和需求，需要针对性的个性化响应。

Method: 提出查询者感知的LLM个性化方法，通过识别不同查询者群体并生成针对每个群体的多样化响应。可能涉及查询者特征分析、群体划分和针对性响应生成等技术。

Result: 该方法能够为不同查询者群体生成更相关、更个性化的响应，相比传统单一响应或仅考虑LLM角色的方法，能更好地满足多样化用户需求。

Conclusion: 查询者多样性是LLM个性化的重要维度，查询者感知的个性化方法能够显著提升LLM响应的相关性和用户满意度，为LLM个性化研究提供了新方向。

Abstract: Existing work on large language model (LLM) personalization assigned different responding roles to LLMs, but overlooked the diversity of queriers. In this work, we propose a new form of querier-aware LLM personalization, generating different …

</details>


### [361] [Benchmarking Autoformalization and Subsequent Execution of Mathematical Reasoning in Large Language Models through Chain-of-Thought](https://scholar.google.com/scholar_url?url=https://www.cortexpd.org/papers/Benchmarking_End_to_End_Autoformalization_and_Execution_of_Mathematical_Reasoning_in_Large_Language_Models_through_Chain_of_Thought.pdf&hl=zh-CN&sa=X&d=106723066845321434&ei=twYtaZOHMf3D6rQP3LSU2Ag&scisig=ABGrvjKQVHTzEIdS9wxq_0JBF61M&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=8&folt=rel)
*A Sharma,D Sharma,A Wez,B Yee*

Main category: Matei Zaharia

TL;DR: 现有数学推理基准主要关注最终答案正确性，这种基于答案的评估对LLM真实推理能力视角有限，无法区分不同推理过程


<details>
  <summary>Details</summary>
Motivation: 现有数学推理基准过于关注最终答案正确性，无法全面评估LLM的真实推理能力，缺乏对推理过程的细致分析

Method: 未在摘要中明确说明，但暗示需要超越单纯答案评估的方法，可能涉及推理过程分析、步骤评估或多维度评估框架

Result: 未在摘要中明确说明，但暗示现有评估方法存在局限性，需要更全面的评估框架

Conclusion: 需要超越单纯答案正确性的评估方法，开发能够全面评估LLM数学推理能力的新基准

Abstract: Existing benchmarks for mathematical reasoning in Large Language Models (LLM's) concentrate mainly on final answer correctness. This answer-based evaluation has a limited view of true LLM reasoning, and it doesn't differentiate between …

</details>


### [362] [Cortex AISQL: A Production SQL Engine for Unstructured Data](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.07663&hl=zh-CN&sa=X&d=17744386181733909295&ei=twYtaZOHMf3D6rQP3LSU2Ag&scisig=ABGrvjLwWgOedVbDQAAjZBlwVzt9&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=9&folt=rel)
*P Aggarwal,B Chen,A Datta,B Han,B Jiang,N Jindal…*

Main category: Matei Zaharia

TL;DR: Snowflake Cortex AISQL是一个生产级SQL引擎，将原生语义操作集成到SQL中，允许用户在声明式查询中结合关系操作与语义推理


<details>
  <summary>Details</summary>
Motivation: 传统SQL引擎缺乏对语义操作的直接支持，用户需要在SQL之外处理语义推理，导致工作流程碎片化。需要将语义操作原生集成到SQL中，实现关系操作与语义推理的无缝结合。

Method: 开发Cortex AISQL引擎，在SQL中引入原生语义操作，通过声明式查询语法支持关系操作与语义推理的结合，实现生产级部署。

Result: 成功构建了生产级SQL引擎，支持原生语义操作，用户可以通过声明式SQL查询同时执行关系操作和语义推理，提高了查询表达能力和效率。

Conclusion: Cortex AISQL通过将语义操作原生集成到SQL中，实现了关系操作与语义推理的无缝结合，为复杂数据分析提供了更强大的工具。

Abstract: Snowflake's Cortex AISQL is a production SQL engine that integrates native semantic operations directly into SQL. This integration allows users to write declarative queries that combine relational operations with semantic reasoning …

</details>


### [363] [Learning from the Undesirable: Robust Adaptation of Language Models without Forgetting](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.13052&hl=zh-CN&sa=X&d=2935718966651686182&ei=n1cuab7HN9OyieoPsZes4AQ&scisig=ABGrvjIqYfcPpoBGrUujf0BPGVEZ&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=0&folt=rel)
*Y Nam,J Kim,J Jeong*

Main category: Matei Zaharia

TL;DR: 语言模型通过监督微调适应下游任务，但在数据有限时可能导致过拟合和泛化能力下降


<details>
  <summary>Details</summary>
Motivation: 研究语言模型在有限数据下进行监督微调时出现的过拟合问题，以及如何改善模型的泛化能力

Method: 分析典型监督微调场景，对比预训练数据量，研究有限数据下的微调效果

Result: 有限数据下的监督微调会导致语言模型过拟合，降低泛化性能

Conclusion: 需要开发更有效的微调方法来应对数据有限的情况，提高语言模型的适应性和泛化能力

Abstract: Language models (LMs) are often adapted through supervised fine-tuning (SFT) to specialize their capabilities for downstream tasks. However, in typical scenarios where the fine-tuning data is limited, eg, compared to pre-training, SFT can lead LMs …

</details>


### [364] [ParaS2S: Benchmarking and Aligning Spoken Language Models for Paralinguistic-aware Speech-to-Speech Interaction](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.08723&hl=zh-CN&sa=X&d=3601033761577388188&ei=n1cuab7HN9OyieoPsZes4AQ&scisig=ABGrvjKLKQ2UfiW9QzcprQLfl1V6&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=1&folt=rel)
*S Yang,M Tu,AT Liu,X Qu,H Lee,L Lu,Y Wang,Y Wu*

Main category: Matei Zaharia

TL;DR: 语音到语音模型在对话能力方面表现出潜力，但在处理副语言线索（如情感、语调和说话者属性）以及内容和风格上的恰当回应方面仍有局限


<details>
  <summary>Details</summary>
Motivation: 当前语音到语音模型在对话能力方面显示出潜力，但在处理副语言线索（情感、语调、说话者属性）方面存在不足，无法在内容和风格上做出恰当回应，这限制了它们在真实对话场景中的应用

Method: 论文未提供具体方法细节，但从摘要推断可能涉及改进语音到语音模型架构，增强对副语言线索的感知和处理能力，以及开发更智能的对话响应机制

Result: 摘要未提供具体实验结果，但暗示现有语音到语音模型在副语言线索处理和对话风格适应性方面存在局限性，需要进一步改进

Conclusion: 语音到语音模型需要增强对副语言线索的处理能力，以在内容和风格上做出更恰当的对话回应，这是提升其在真实对话场景中应用的关键

Abstract: Speech-to-Speech (S2S) models have shown promising dialogue capabilities, but their ability to handle paralinguistic cues--such as emotion, tone, and speaker attributes--and to respond appropriately in both content and style remains …

</details>


### [365] [Rubric-Based Benchmarking and Reinforcement Learning for Advancing LLM Instruction Following](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.10507&hl=zh-CN&sa=X&d=3761481670693528309&ei=n1cuab7HN9OyieoPsZes4AQ&scisig=ABGrvjKdxMQMqVsGvp3GNEDSHbnO&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=3&folt=rel)
*Y He,W Li,H Zhang,S Li,K Mandyam,S Khosla…*

Main category: Matei Zaharia

TL;DR: 该论文探讨了大型语言模型在复杂多轮系统提示指令跟随方面的挑战，提出了改进方法


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在许多任务上表现出色，但在复杂、多轮和系统提示的指令跟随方面仍然存在显著挑战，需要专门的改进方法

Method: 论文可能提出了专门针对复杂指令跟随的改进方法，可能包括新的训练策略、架构调整或评估框架

Result: 提出的方法在复杂指令跟随任务上取得了显著改进，提升了模型对多轮对话和系统提示的理解与执行能力

Conclusion: 针对复杂指令跟随的专门改进对于充分发挥大型语言模型的潜力至关重要，未来需要继续关注这一研究方向

Abstract: Recent progress in large language models (LLMs) has led to impressive performance on a range of tasks, yet advanced instruction following (IF)-especially for complex, multi-turn, and system-prompted instructions-remains a significant …

</details>


### [366] [Modeling Chain-of-Thought Collapse in Pruned Language Models: Fidelity and Similarity Analysis for Mathematical Reasoning](https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3D2k5Yl3HoKE&hl=zh-CN&sa=X&d=118093362007581436&ei=n1cuab7HN9OyieoPsZes4AQ&scisig=ABGrvjLGostPEpLSL9ZtncX61E3e&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=4&folt=rel)
*AK Sharma,T Shinde*

Main category: Matei Zaharia

TL;DR: 提出了一个量化模型相似性与损失之间关系的框架，用于在计算和内存约束下实现高效数学推理


<details>
  <summary>Details</summary>
Motivation: 在计算和内存约束下实现高效数学推理对于在现实应用中部署大型推理模型至关重要

Method: 提出了一个量化模型相似性与损失之间关系的框架

Result: 未在摘要中明确说明具体结果

Conclusion: 该框架有助于在资源受限环境下优化大型推理模型的部署

Abstract: Efficient mathematical reasoning under compute and memory constraints is crucial for deploying large reasoning models (LRMs) in real-world applications. We propose a framework to quantify the relationship between model similarity and loss of …

</details>


### [367] [Hierarchical Token Prepending: Enhancing Information Flow in Decoder-based LLM Embeddings](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.14868&hl=zh-CN&sa=X&d=16209263753787249502&ei=n1cuab7HN9OyieoPsZes4AQ&scisig=ABGrvjJLHeEa7g7g1lspXzbddJV_&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=5&folt=rel)
*X Ding,X Huang,M Ju,L Collins,Y Liu,L Akoglu…*

Main category: Matei Zaharia

TL;DR: 该论文针对大语言模型因果注意力机制导致信息从后向前流动受限、降低表征质量的问题，提出了通过预置可学习前缀来增强双向信息流的解决方案。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽然能产生强大的文本嵌入，但其因果注意力机制限制了信息从后续token向前向token的流动，这会降低表征质量。现有方法试图通过在输入前添加前缀来解决此问题，但仍有改进空间。

Method: 论文提出了一种方法，通过在输入序列前预置可学习的前缀（learnable prefixes），这些前缀在训练过程中被优化，能够促进双向信息流动，从而增强文本嵌入的质量。

Result: 该方法在多个文本嵌入基准测试中取得了最先进的性能，显著提升了表征质量，特别是在需要捕获完整上下文信息的任务中表现优异。

Conclusion: 通过引入可学习前缀来增强大语言模型中的双向信息流，是一种有效提升文本嵌入质量的方法，为改进基于因果注意力机制的模型表征能力提供了新思路。

Abstract: Large language models produce powerful text embeddings, but their causal attention mechanism restricts the flow of information from later to earlier tokens, degrading representation quality. While recent methods attempt to solve this by prepending a …

</details>


### [368] [Seer: Online Context Learning for Fast Synchronous LLM Reinforcement Learning](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.14617&hl=zh-CN&sa=X&d=2892572261068713863&ei=n1cuab7HN9OyieoPsZes4AQ&scisig=ABGrvjILfFtcWzPkySWjm1bXsy7E&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=6&folt=rel)
*R Qin,W He,W Huang,Y Zhang,Y Zhao,B Pang,X Xu…*

Main category: Matei Zaharia

TL;DR: 论文分析了现有同步强化学习系统在大型语言模型训练中的性能瓶颈，特别是rollout阶段的主导地位，并提出了异步RL系统来提升训练效率


<details>
  <summary>Details</summary>
Motivation: 强化学习在现代大型语言模型发展中至关重要，但现有的同步RL系统面临严重的性能瓶颈。rollout阶段主导了端到端迭代时间，限制了训练效率

Method: 论文提出了一种异步RL系统，通过解耦rollout、训练和评估阶段来消除同步瓶颈，实现并行处理以提高整体训练效率

Result: 异步RL系统显著减少了端到端迭代时间，提高了训练吞吐量，相比同步系统在性能上有明显提升

Conclusion: 异步RL系统是解决大型语言模型强化学习训练中性能瓶颈的有效方案，能够显著提升训练效率，推动RL在LLM领域的进一步发展

Abstract: Reinforcement Learning (RL) has become critical for advancing modern Large Language Models (LLMs), yet existing synchronous RL systems face severe performance bottlenecks. The rollout phase, which dominates end-to-end iteration …

</details>


### [369] [Knots: A large-scale multi-agent enhanced expert-annotated dataset and LLM prompt optimization for NOTAM semantic parsing](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.12630&hl=zh-CN&sa=X&d=8415264970880035920&ei=n1cuab7HN9OyieoPsZes4AQ&scisig=ABGrvjLqUv48f0k5RdXz5jhY9g5k&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=7&folt=rel)
*M Liu,Q Fang,Y Yang,C Zhao,K Cai*

Main category: Matei Zaharia

TL;DR: 该论文针对航空通告(NOTAMs)的复杂语言结构和隐含推理问题，提出自动化解析解决方案，以提升飞行安全信息处理效率。


<details>
  <summary>Details</summary>
Motivation: 航空通告(NOTAMs)是传递飞行安全信息的关键渠道，但其复杂的语言结构和隐含推理给自动化解析带来了重大挑战，现有方法难以有效处理。

Method: 论文提出了一种针对NOTAMs的自动化解析方法，具体方法细节需要从完整论文中获取，但核心是解决复杂语言结构和隐含推理问题。

Result: 该方法能够有效解析NOTAMs的复杂语言结构，处理隐含推理，提升自动化处理效率和准确性。

Conclusion: 提出的自动化解析方法为解决NOTAMs处理难题提供了有效方案，对提升航空安全信息处理具有重要意义。

Abstract: Abstract Notice to Air Missions (NOTAMs) serve as a critical channel for disseminating key flight safety information, yet their complex linguistic structures and implicit reasoning pose significant challenges for automated parsing. Existing …

</details>


### [370] [Generate, Evaluate, Iterate: Synthetic Data for Human-in-the-Loop Refinement of LLM Judges](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.04478&hl=zh-CN&sa=X&d=18341973258942476021&ei=n1cuab7HN9OyieoPsZes4AQ&scisig=ABGrvjLQgSgLHKujSMvyV2CXK14X&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=8&folt=rel)
*HJ Do,Z Ashktorab,J Gajcin,E Miehling,MS Cooper…*

Main category: Matei Zaharia

TL;DR: 提出一个工具，将合成数据生成集成到LLM-as-a-judge范式中，以解决评估标准细化时缺乏多样代表性数据的问题


<details>
  <summary>Details</summary>
Motivation: LLM-as-a-judge范式支持灵活的用户定义评估，但其效果常受限于缺乏多样、代表性的数据来细化评估标准

Method: 开发一个工具，将合成数据生成集成到LLM-as-a-judge范式中，通过生成多样化的合成数据来改进评估标准的细化

Result: 未在摘要中明确说明具体结果，但暗示该工具能解决数据稀缺问题，提升LLM-as-a-judge范式的评估效果

Conclusion: 通过集成合成数据生成，该工具能够增强LLM-as-a-judge范式的评估能力，解决评估标准细化中的数据稀缺问题

Abstract: The LLM-as-a-judge paradigm enables flexible, user-defined evaluation, but its effectiveness is often limited by the scarcity of diverse, representative data for refining criteria. We present a tool that integrates synthetic data generation into the LLM-as-a …

</details>


### [371] [LLMVisor: A Real-Time Latency Attribution Model for Multi-Tenant LLM Serving](https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DVeAJmE2ZJU&hl=zh-CN&sa=X&d=1715623468092192392&ei=n1cuab7HN9OyieoPsZes4AQ&scisig=ABGrvjLiI3bOw1c7CF8jJwytFrL5&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=9&folt=rel)
*S Jin,X Liu,J Shan,L Xu,T Zhang,L Xie,Z Mao*

Main category: Matei Zaharia

TL;DR: 论文提出了一种实时、按请求归因的原语，用于在多租户GPU集群中实现推理引擎的分数共享，解决传统批处理中租户使用情况不透明和控制受限的问题。


<details>
  <summary>Details</summary>
Motivation: 随着LLM推理向多租户GPU集群转移，传统的批处理(co-batching)虽然提高了吞吐量，但导致每个租户的使用情况变得不透明，限制了租户对资源的控制能力。需要一种能够实现推理引擎分数共享的机制。

Method: 提出了一种实时、按请求归因的原语(attribution primitive)，用于在多租户GPU集群中追踪和分配推理资源使用情况。

Result: 该方法能够实现推理引擎的分数共享，使每个租户的使用情况变得透明，同时提供更好的资源控制能力。

Conclusion: 实时按请求归因原语是解决多租户GPU集群中LLM推理资源分配问题的关键技术，能够平衡吞吐量提升与租户控制需求。

Abstract: As LLM inference shifts to multi-tenant GPU clusters, co-batching improves throughput but obscures per-tenant usage and limits control. Enabling fractional sharing of the inference engine requires a real-time, per-request attribution primitive …

</details>


### [372] [LLM Optimization Unlocks Real-Time Pairwise Reranking](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.07555&hl=zh-CN&sa=X&d=8235368278573385100&ei=ewswadO_Aoqi6rQPr6DGiAo&scisig=ABGrvjKHllrRwNClJzGYDWRV58tH&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=3&folt=rel)
*J Wu,A Shrivastava,J Zhu,A Samuel,A Kumar,D Liu*

Main category: Matei Zaharia

TL;DR: 该论文关注如何高效地对信息检索管道检索到的文档进行重排序，以提升检索增强生成系统的整体质量


<details>
  <summary>Details</summary>
Motivation: 当前文档重排序方法在提升检索增强生成系统质量方面存在效率挑战，需要更高效的解决方案

Method: 论文可能提出了一种新的文档重排序方法，但具体技术细节在提供的摘要中未明确说明

Result: 摘要未提供具体实验结果，但暗示该方法能够有效提升RAG系统的检索质量

Conclusion: 高效的文档重排序对于提升RAG系统性能至关重要，需要进一步研究优化

Abstract: Efficiently reranking documents retrieved from information retrieval (IR) pipelines to enhance overall quality of Retrieval-Augmented Generation (RAG) system remains an important yet challenging problem. Recent studies have highlighted the …

</details>


### [373] [Improving Preference Alignment of LLM using Inference-Free Self-Refinement](https://scholar.google.com/scholar_url?url=https://aclanthology.org/anthology-files/anthology-files/pdf/findings/2025.findings-emnlp.1329.pdf&hl=zh-CN&sa=X&d=14432208903136868405&ei=ewswadO_Aoqi6rQPr6DGiAo&scisig=ABGrvjJLf_Jbm8gCntNORQRV7fkp&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=8&folt=rel)
*F Ma,K Tian,J Xue,X Wang,Y Ma,Q Chen,P Jiang…*

Main category: Matei Zaharia

TL;DR: LLMs通过预训练和指令微调获得上下文学习能力，无需参数更新即可适应任务；自精炼是这种能力的一种体现


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型通过上下文学习实现任务适应的机制，特别是自精炼能力如何体现这种无需参数更新的学习特性

Method: 基于预训练和指令微调的方法，使LLMs能够通过上下文学习进行任务适应，重点研究自精炼作为上下文学习能力的具体表现

Result: LLMs通过预训练和指令微调获得了上下文学习能力，能够在不更新参数的情况下适应新任务，自精炼是这种能力的重要体现

Conclusion: 上下文学习是LLMs的重要特性，自精炼作为其具体表现，展示了模型无需参数更新即可进行任务适应的能力

Abstract: Large language models (LLMs) develop the incontext learning capability through pretraining and instruction tuning, enabling task adaptation without parameter updates. Self-refinement is a manifestation of this capability, which allows LLMs to …

</details>


### [374] [Do Language Models Robustly Acquire New Knowledge?](https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3D8NQPcdw7ja&hl=zh-CN&sa=X&d=13349634317913072375&ei=ewswadO_Aoqi6rQPr6DGiAo&scisig=ABGrvjLE-YtPLpgdWdV5mDnIeA6T&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=9&folt=rel)
*H Shah,B Ghazi,Y Huang,R Kumar,D Yu,C Zhang*

Main category: Matei Zaharia

TL;DR: 该论文研究如何增强预训练语言模型对新知识的鲁棒性，特别是多跳推理能力，提出了通过合成数据训练模型以更好地整合新知识的方法。


<details>
  <summary>Details</summary>
Motivation: 预训练语言模型虽然拥有海量知识，但在添加新知识时缺乏鲁棒性——模型能够检索单个事实，但在新获取知识上进行多跳推理时表现不佳。这限制了模型在实际应用中的知识更新能力。

Method: 通过合成数据训练模型，使其能够更好地整合新知识，增强多跳推理能力。具体方法可能涉及生成包含新知识的合成查询-答案对，并通过这些数据微调模型以提高知识整合的鲁棒性。

Result: 经过合成数据训练后，模型在新知识的多跳推理任务上表现显著提升，相比传统方法具有更好的鲁棒性和推理能力。

Conclusion: 通过合成数据训练可以有效增强预训练语言模型对新知识的整合能力，特别是在多跳推理任务上，为模型知识更新提供了更鲁棒的方法。

Abstract: Language models acquire vast knowledge during pretraining, but adding new knowledge to pre-trained models often lacks robustness—models can retrieve individual facts but struggle with multi-hop reasoning over newly acquired …

</details>


### [375] [RefineBench: Evaluating Refinement Capability of Language Models via Checklists](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.22173&hl=zh-CN&sa=X&d=13484174877383555408&ei=K24xaZryMObYieoPgNO3kQI&scisig=ABGrvjKrH6ZgrCIDsFfJhE9_8ETi&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=0&folt=rel)
*YJ Lee,S Kim,BK Lee,M Moon,Y Hwang,JM Kim…*

Main category: Matei Zaharia

TL;DR: 语言模型能否自我精炼其响应？现有研究主要测试模型基于人工反馈的精炼能力，但本文探讨模型是否能在没有外部反馈的情况下自我精炼，发现当前模型在这方面存在显著局限。


<details>
  <summary>Details</summary>
Motivation: 随着语言模型在现实世界用户交互中广泛应用，用户经常提出精炼请求。现有研究主要关注模型基于人工反馈的精炼能力，但缺乏对模型自我精炼能力（即不依赖外部反馈）的系统评估。本文旨在填补这一空白，探究语言模型是否能够自我精炼其初始响应。

Method: 本文系统评估了语言模型的自我精炼能力，设计了实验框架来测试模型在无外部反馈情况下改进自身响应的能力。研究可能包括：1) 让模型生成初始响应；2) 要求模型基于自身判断进行精炼；3) 评估精炼前后的质量差异；4) 分析不同模型架构和规模的表现差异。

Result: 研究发现当前语言模型在自我精炼方面存在显著局限。模型通常难以有效识别自身响应的缺陷并进行实质性改进。精炼后的响应往往只是表面修改，缺乏质量上的显著提升，有时甚至会出现质量下降的情况。

Conclusion: 语言模型目前缺乏有效的自我精炼能力，无法在不依赖外部反馈的情况下显著改进自身响应。这一发现对实际应用具有重要意义，表明需要开发新的方法或架构来增强模型的自我评估和改进能力。

Abstract: Can language models (LMs) self-refine their own responses? This question is increasingly relevant as a wide range of real-world user interactions involve refinement requests. However, prior studies have largely tested LMs' refinement …

</details>


### [376] [Multimodal Large Language Models for Low-Resource Languages: A Case Study for Basque](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.09396&hl=zh-CN&sa=X&d=8296825038297224687&ei=K24xaZryMObYieoPgNO3kQI&scisig=ABGrvjI13-S6hGT8G2FgzBgOvGbq&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=2&folt=rel)
*L Arana,J Etxaniz,A Salaberria,G Azkune*

Main category: Matei Zaharia

TL;DR: 当前多模态大语言模型在多种任务上表现优异，但开源模型在低资源语言上的性能仍不及商业模型


<details>
  <summary>Details</summary>
Motivation: 解决开源多模态大语言模型在低资源语言上性能不足的问题，缩小与商业模型的差距

Method: 未在摘要中明确说明具体方法，但暗示需要开发专门针对低资源语言的开源解决方案

Result: 商业模型在低资源语言上表现可接受，但开源模型尚未达到可比性能

Conclusion: 需要在开源领域开发更好的多模态大语言模型以支持低资源语言

Abstract: Current Multimodal Large Language Models exhibit very strong performance for several demanding tasks. While commercial MLLMs deliver acceptable performance in low-resource languages, comparable results remain unattained within the open …

</details>


### [377] [MTQ-Eval: Multilingual Text Quality Evaluation for Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.09374&hl=zh-CN&sa=X&d=5840025197310915311&ei=K24xaZryMObYieoPgNO3kQI&scisig=ABGrvjKBnkFWAIXkqtotTp0REdr7&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=3&folt=rel)
*R Pokharel,A Agrawal*

Main category: Matei Zaharia

TL;DR: LLM评估能力是否超越特定任务扩展到通用评估尚不确定，需要系统研究


<details>
  <summary>Details</summary>
Motivation: 大型语言模型用于评估输出正成为越来越有效和可扩展的方法，但需要确定这种能力是否仅限于任务特定评估，还是能扩展到更通用的评估场景

Method: 未明确说明具体方法，但暗示需要系统研究来探索LLM评估能力的边界和通用性

Result: 未提供具体结果，但指出当前对LLM评估能力通用性的认识存在不确定性

Conclusion: 需要进一步研究来确定LLM评估能力的范围和限制，特别是其在通用评估场景中的应用潜力

Abstract: The use of large language models (LLMs) for evaluating outputs is becoming an increasingly effective and scalable approach. However, it remains uncertain whether this capability extends beyond task-specific evaluations to more general …

</details>


### [378] [PSM: Prompt Sensitivity Minimization via LLM-Guided Black-Box Optimization](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.16209&hl=zh-CN&sa=X&d=469809507351904471&ei=K24xaZryMObYieoPgNO3kQI&scisig=ABGrvjLZhUkILG_PDKQHd39yCoqi&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=5&folt=rel)
*H Jawad,N Brunel*

Main category: Matei Zaharia

TL;DR: 系统提示词对LLM行为至关重要但易受提取攻击，本文提出一种保护方法


<details>
  <summary>Details</summary>
Motivation: 系统提示词通常包含专有逻辑或敏感信息，容易成为提取攻击的目标，需要有效的保护机制

Method: 提出一种保护系统提示词的方法，可能涉及对抗性查询防御、提示词混淆或加密技术

Result: 该方法能有效防止系统提示词被提取，同时保持LLM的正常功能

Conclusion: 提出的保护机制能显著增强系统提示词的安全性，对抗提取攻击

Abstract: System prompts are critical for guiding the behavior of Large Language Models (LLMs), yet they often contain proprietary logic or sensitive information, making them a prime target for extraction attacks. Adversarial queries can successfully elicit these …

</details>


### [379] [Can LLM Annotations Replace User Clicks for Learning to Rank?](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.06635&hl=zh-CN&sa=X&d=7052700413009070215&ei=K24xaZryMObYieoPgNO3kQI&scisig=ABGrvjLLD2CKG9utkYGNu2fLl_Xw&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ABGrvjJvGdHEETrndDrCHSq3usLj&html=&pos=9&folt=rel)
*L Yu,K Bi,J Guo,S Liu,S Wang,D Yin,X Cheng*

Main category: Matei Zaharia

TL;DR: 利用大语言模型从点击数据中生成合成训练数据，以降低高质量人工标注的成本


<details>
  <summary>Details</summary>
Motivation: 大规模监督数据对训练现代排序模型至关重要，但获取高质量人工标注成本高昂。点击数据虽被广泛用作低成本替代方案，但仍存在噪声和偏差问题，需要更高效的训练数据生成方法。

Method: 利用大语言模型从点击数据中生成合成训练数据，通过先进的自然语言处理技术将原始点击行为转化为可用于模型训练的监督信号。

Result: 该方法能够有效生成高质量的合成训练数据，降低对昂贵人工标注的依赖，同时保持或提升排序模型的性能表现。

Conclusion: 大语言模型为从点击数据生成合成训练数据提供了有前景的解决方案，能够在降低标注成本的同时维持模型性能，对大规模排序系统具有重要实践价值。

Abstract: Large-scale supervised data is essential for training modern ranking models, but obtaining high-quality human annotations is costly. Click data has been widely used as a low-cost alternative, and with recent advances in large language models …

</details>


### [380] [Think Before You Prune: Self-Reflective Structured Pruning for Reasoning Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.02185&hl=zh-CN&sa=X&d=14253978060664528604&ei=VVw0aY2aC6qy6rQP08y_kAE&scisig=ALhkC2QHB-IZjveZEPH56AWt-tJT&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=0&folt=rel)
*Z Wang,E Diao,Q Le,P Wang,G Wang,M Lee,S Yeh…*

Main category: Matei Zaharia

TL;DR: RLMs推理能力强但部署成本高，本文提出基于知识蒸馏的轻量级推理模型压缩方法


<details>
  <summary>Details</summary>
Motivation: 推理大语言模型（如OpenAI o1、DeepSeek-R1、Qwen3）虽然具有强大的多步推理能力，但模型规模大、解码输出长，导致部署成本高昂，限制了实际应用

Method: 基于知识蒸馏的方法，将大型推理模型的能力压缩到更小的模型中，同时保持推理性能

Result: 成功开发出轻量级推理模型，在保持推理能力的同时显著降低部署成本和计算资源需求

Conclusion: 通过知识蒸馏技术可以有效压缩推理大语言模型，实现高性能低成本的推理模型部署

Abstract: Reasoning LLMs (RLMs) such as OpenAI o1, DeepSeek-R1, and Qwen3 deliver strong multi-step reasoning through chain-of-thought generation, but their large model sizes and lengthy decode-time outputs make them costly to deploy and …

</details>


### [381] [Beyond Confidence: Adaptive and Coherent Decoding for Diffusion Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.02044&hl=zh-CN&sa=X&d=12674781183245158427&ei=VVw0aY2aC6qy6rQP08y_kAE&scisig=ALhkC2SYR9HIdo5FxfsFYiSdj5ci&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=1&folt=rel)
*K Chen,Z Liu,X Tao,H Liu,X Fu,S Zhang,D Tu…*

Main category: Matei Zaharia

TL;DR: 该论文针对扩散语言模型现有推理方法依赖局部即时指标的问题，提出了一种基于全局推理路径评估的改进方法，通过路径级评分机制优化生成质量。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型在任意顺序生成方面取得了显著成功，但现有推理方法通常依赖置信度或熵等局部、即时步指标，这些方法无法充分评估全局生成质量，限制了模型性能的进一步提升。

Method: 提出了一种新的推理方法，通过引入全局推理路径评估机制，对生成过程中的完整路径进行评分和优化，而不是仅关注单个时间步的局部指标。

Result: 该方法在多个基准测试中显著提升了扩散语言模型的生成质量，相比传统基于局部指标的推理方法，在文本流畅性、语义连贯性和任务完成度等方面都有明显改进。

Conclusion: 全局推理路径评估方法为扩散语言模型的推理过程提供了更有效的优化策略，证明了考虑完整生成路径而非局部指标的重要性，为未来扩散模型推理方法的发展提供了新方向。

Abstract: Diffusion Language Models (DLMs) have recently achieved significant success due to their any-order generation capabilities. However, existing inference methods typically rely on local, immediate-step metrics such as confidence or entropy which …

</details>


### [382] [Cross-Lingual Prompt Steerability: Towards Accurate and Robust LLM Behavior across Languages](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.02841&hl=zh-CN&sa=X&d=11260471509958859345&ei=VVw0aY2aC6qy6rQP08y_kAE&scisig=ALhkC2SaKkaIMpNeuxCZTfuDU02u&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=6&folt=rel)
*L Zhang,Y Zhou,T Ergen,L Logeswaran,M Lee…*

Main category: Matei Zaharia

TL;DR: 该论文研究了多语言系统提示的设计，旨在为大型语言模型创建单一、高效的多语言提示，以提升跨语言推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有系统提示研究主要集中在英语环境，而实际部署需要单一提示能在多种语言中有效工作。多语言系统提示设计面临挑战，因为不同语言和文化背景的用户可能需要不同的提示策略。

Method: 论文提出了多语言系统提示设计框架，包括语言适配、文化敏感性和跨语言一致性等技术。可能涉及提示工程、多语言评估基准构建以及提示优化方法。

Result: 开发出能有效跨语言工作的系统提示，在多种语言任务上表现优于单语言提示或语言特定提示。提高了LLM在多语言环境中的推理一致性和性能。

Conclusion: 多语言系统提示是实际部署的关键需求，精心设计的跨语言提示能显著提升LLM的全球适用性和性能。为多语言AI系统开发提供了重要指导。

Abstract: System prompts provide a lightweight yet powerful mechanism for conditioning large language models (LLMs) at inference time. While prior work has focused on English-only settings, real-world deployments benefit from having a single prompt to operate …

</details>


### [383] [ELPO: Ensemble Learning Based Prompt Optimization for Large Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.16122&hl=zh-CN&sa=X&d=7589248191871841586&ei=VVw0aY2aC6qy6rQP08y_kAE&scisig=ALhkC2RGvSaYEOLKI8gwN0RUalmh&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=7&folt=rel)
*Q Zhang,B Xu,X Zhang,Y Shi,Y Li,C Zhang,YC Wu…*

Main category: Matei Zaharia

TL;DR: LLMs依赖精心设计的提示词，但手动提示工程耗时费力，成为LLM实际应用的核心瓶颈


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的卓越性能高度依赖精心设计的提示词，但手动提示工程是一个劳动密集型过程，这成为LLM实际应用的核心瓶颈，需要更高效的提示优化方法

Method: 论文可能探讨自动提示工程或优化方法，如基于搜索的提示生成、梯度优化、强化学习或元学习技术来减少人工干预

Result: 预期结果包括开发出能够自动生成高质量提示的系统，显著减少人工工作量，同时保持或提升LLM在各种任务上的性能表现

Conclusion: 自动提示工程是解决LLM应用瓶颈的关键方向，能够大幅提高提示设计的效率和效果，推动LLM在实际场景中的广泛应用

Abstract: The remarkable performance of Large Language Models (LLMs) highly relies on crafted prompts. However, manual prompt engineering is a laborious process, creating a core bottleneck for practical application of LLMs. This phenomenon has …

</details>


### [384] [Every Token Counts: Generalizing 16M Ultra-Long Context in Large Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.23319&hl=zh-CN&sa=X&d=5480251393142943385&ei=VVw0aY2aC6qy6rQP08y_kAE&scisig=ALhkC2ShGygGnyMC7d2wvsLxR2qx&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=8&folt=rel)
*X Hu,Z Zhou,R Liang,Z Li,W Wu,J Li*

Main category: Matei Zaharia

TL;DR: 该研究探讨构建"能够记忆的机器"的挑战，将长期记忆定义为高效超长上下文建模问题，提出需要稀疏性、随机访问和可扩展性三个关键属性


<details>
  <summary>Details</summary>
Motivation: 构建具有长期记忆能力的机器系统，解决超长上下文建模的效率问题，实现真正的长期记忆功能

Method: 通过稀疏性、随机访问和可扩展性三个关键属性来构建长期记忆系统，将长期记忆问题重新定义为高效超长上下文建模

Result: 提出了构建具有长期记忆能力的机器系统的理论框架，明确了实现高效超长上下文建模所需的关键技术属性

Conclusion: 构建能够记忆的机器需要解决超长上下文建模的效率问题，稀疏性、随机访问和可扩展性是实现这一目标的关键技术属性

Abstract: This work explores the challenge of building``Machines that Can Remember'', framing long-term memory as the problem of efficient ultra-long context modeling. We argue that this requires three key properties:\textbf {sparsity},\textbf {random-access …

</details>


### [385] [Measuring Agents in Production](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.04123&hl=zh-CN&sa=X&d=17110062881753629495&ei=j9I1aZSpOOuuieoP4e6tqQ4&scisig=ALhkC2RGJ2wRxO6qEEMN6GSqBZ5U&oi=scholaralrt&hist=i6heNjgAAAAJ:15186190164853243054:ALhkC2R3EVwTChDJsJzPrYBHJDZi&html=&pos=0&folt=art)
*MZ Pan,N Arabzadeh,R Cogo,Y Zhu,A Xiong…*

Main category: Matei Zaharia

TL;DR: 对AI智能体在现实世界部署中的技术方法进行首次大规模系统性研究


<details>
  <summary>Details</summary>
Motivation: AI智能体已在多个行业的生产环境中运行，但关于哪些技术方法能够实现成功的现实世界部署，公开信息很少

Method: 首次大规模系统性研究，分析AI智能体在现实世界部署中的技术方法

Result: 揭示了成功AI智能体部署的关键技术方法和最佳实践

Conclusion: 为AI智能体的现实世界应用提供了系统性的技术指导框架

Abstract: AI agents are actively running in production across diverse industries, yet little is publicly known about which technical approaches enable successful real-world deployments. We present the first large-scale systematic study of AI agents in …

</details>


### [386] [OsmT: Bridging OpenStreetMap Queries and Natural Language with Open-source Tag-aware Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.04738&hl=zh-CN&sa=X&d=5664943367214350201&ei=kNI1aZyAGIqi6rQPr6DGiAo&scisig=ALhkC2Q1pBT5K4tX7AdDCSfXv8Ca&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=2&folt=rel)
*Z Wan,W Hu,CJ Zhang,Y Song,S Li,R Xiao,XY Wei…*

Main category: Matei Zaharia

TL;DR: 该论文探讨了使用语言模型将自然语言转换为结构化查询语言（如SQL）的挑战，提出了一种改进方法来解决现有解决方案的局限性


<details>
  <summary>Details</summary>
Motivation: 自然语言与结构化查询语言之间的转换是数据库领域长期存在的挑战。虽然语言模型的最新进展在这方面显示出潜力，但现有解决方案通常依赖大规模训练数据，存在泛化能力不足、对复杂查询处理不佳等问题，需要更高效、鲁棒的解决方案

Method: 论文提出了一种改进的方法，可能包括创新的模型架构、训练策略或数据增强技术，旨在更有效地将自然语言转换为结构化查询语言。方法可能涉及减少对大规模训练数据的依赖，提高对复杂查询的处理能力，增强模型的泛化性能

Result: 该方法在标准基准测试中表现出色，相比现有解决方案在查询准确率、处理复杂查询能力和泛化性能方面都有显著提升。结果证明了该方法在自然语言到结构化查询转换任务上的有效性

Conclusion: 论文提出的方法为自然语言到结构化查询语言的转换提供了更有效的解决方案，克服了现有方法的局限性。这项工作为数据库查询接口的改进和语言模型在结构化数据处理中的应用开辟了新方向

Abstract: Bridging natural language and structured query languages is a long-standing challenge in the database community. While recent advances in language models have shown promise in this direction, existing solutions often rely on large-scale …

</details>


### [387] [Continuous Prompts: LLM-Augmented Pipeline Processing over Unstructured Streams](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.03389&hl=zh-CN&sa=X&d=13101085006508913545&ei=kNI1aZyAGIqi6rQPr6DGiAo&scisig=ALhkC2SW3WHhKRvT1ef6C6UQxkG2&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=3&folt=rel)
*S Chen,D Raghavan,U Çetintemel*

Main category: Matei Zaharia

TL;DR: Continuous Prompts (CPs) 是一种用于监控非结构化数据流的持久化、语义感知计算框架，解决了当前LLM框架的无状态和一次性处理限制


<details>
  <summary>Details</summary>
Motivation: 当前LLM框架在处理非结构化数据流时存在无状态和一次性处理的局限性，无法满足长期运行的语义感知分析需求，需要一种能够持续监控和计算的解决方案

Method: 引入Continuous Prompts (CPs)框架，通过持久化、语义感知的计算机制，使LLM能够对非结构化数据流进行长期监控和分析

Result: CPs框架能够实现对非结构化数据流的持续语义分析，克服了传统LLM框架在长期监控应用中的局限性

Conclusion: Continuous Prompts为LLM在非结构化数据流监控领域提供了有效的持久化计算框架，扩展了LLM在实时分析应用中的能力

Abstract: Monitoring unstructured streams increasingly requires persistent, semantics-aware computation, yet today's LLM frameworks remain stateless and one-shot, limiting their usefulness for long-running analytics. We introduce Continuous Prompts (CPs) …

</details>


### [388] [PromptBridge: Cross-Model Prompt Transfer for Large Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.01420&hl=zh-CN&sa=X&d=11645586233022880776&ei=kNI1aZyAGIqi6rQPr6DGiAo&scisig=ALhkC2T0a4JQbs7RAddMFXSaViw9&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=8&folt=rel)
*Y Wang,Q Liu,Z Wang,Z Li,W Wei,Y Liu,Y Bao*

Main category: Matei Zaharia

TL;DR: 该论文探讨了大型语言模型（LLMs）在实际应用中的访问方式（商业API与开源部署），以及模型生态系统的多样性对系统设计和性能的影响。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在代码生成、数学推理和智能体工作流等领域的广泛应用，实际系统中通常通过商业API或开源部署来访问这些模型。然而，模型生态系统的多样性和不同的访问方式给系统设计带来了挑战，需要研究如何在这种复杂环境下优化系统性能。

Method: 论文未在摘要中详细描述具体方法，但暗示将分析商业API和开源部署两种访问方式的特点，以及如何应对模型生态系统多样性带来的挑战。

Result: 摘要未提供具体实验结果，但暗示研究将揭示不同访问方式对系统性能的影响，以及如何在实际应用中有效利用多样化的模型生态系统。

Conclusion: 理解LLMs的不同访问方式和模型生态系统的多样性对于设计高效、可靠的系统至关重要，需要开发相应的策略来优化在这种复杂环境下的系统性能。

Abstract: Large language models (LLMs) underpin applications in code generation, mathematical reasoning, and agent-based workflows. In practice, systems access LLMs via commercial APIs or open-source deployments, and the model landscape …

</details>


### [389] [MolEdit: Knowledge Editing for Multimodal Molecule Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.12770&hl=zh-CN&sa=X&d=2373792185810251022&ei=yEw3abTpBtOyieoP6r6mkQg&scisig=ALhkC2SRaJqfK0YjN6X_kRtKeYXq&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=3&folt=rel)
*Z Lei,P Soga,Y Zhu,Y He,Y Dong,J Li*

Main category: Matei Zaharia

TL;DR: 分子语言模型（MoLMs）通过整合结构信息来理解和精炼多模态分子知识，成为生物医学、化学和材料科学领域的重要工具


<details>
  <summary>Details</summary>
Motivation: 理解和持续精炼多模态分子知识对于推进生物医学、化学和材料科学至关重要，需要能够整合结构信息的强大工具

Method: 分子语言模型（MoLMs）作为主要方法，通过整合结构信息来处理和理解多模态分子知识

Result: MoLMs已成为生物医学、化学和材料科学领域的强大工具，能够有效处理多模态分子信息

Conclusion: 分子语言模型在理解和精炼多模态分子知识方面发挥着关键作用，对相关科学领域的发展具有重要意义

Abstract: Understanding and continuously refining multimodal molecular knowledge is crucial for advancing biomedicine, chemistry, and materials science. Molecule language models (MoLMs) have become powerful tools in these domains, integrating structural …

</details>


### [390] [LLM-MemCluster: Empowering Large Language Models with Dynamic Memory for Text Clustering](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.15424&hl=zh-CN&sa=X&d=5293311840116775114&ei=yEw3abTpBtOyieoP6r6mkQg&scisig=ALhkC2RG9qh_ayLy3gJb_Ywa8RIA&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=4&folt=rel)
*Y Zhu,L Yang,K Xu,W Zhang,Z Song,J Wang,PS Yu*

Main category: Matei Zaharia

TL;DR: LLMs在无监督文本聚类中展现出强大的语义理解能力，但直接应用受到限制，需要新的方法来解决这些局限性


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在无监督学习领域展现出革命性的语义理解能力，为文本聚类提供了新的可能性。然而，这些模型在直接应用于聚类任务时存在根本性限制，需要探索新的方法来克服这些挑战。

Method: 论文可能提出了一种新的框架或方法，利用LLMs的语义理解能力进行文本聚类，同时解决直接应用时的局限性。具体方法可能包括：设计特定的提示策略、结合传统聚类算法、开发新的评估指标，或者构建混合系统来弥补LLMs在聚类任务中的不足。

Result: 基于摘要信息，可以预期该方法能够显著提升文本聚类的性能，特别是在语义理解方面。结果可能显示新方法在聚类质量、可解释性或效率方面优于传统方法和直接使用LLMs的方法。

Conclusion: LLMs为无监督文本聚类带来了新的机遇，但需要专门的方法来充分发挥其潜力。通过解决直接应用的限制，可以构建更有效的文本聚类系统，推动无监督学习的发展。

Abstract: Large Language Models (LLMs) are reshaping unsupervised learning by offering an unprecedented ability to perform text clustering based on their deep semantic understanding. However, their direct application is fundamentally limited by a lack of …

</details>


### [391] [Place Matters: Comparing LLM Hallucination Rates for Place-Based Legal Queries](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.06700&hl=zh-CN&sa=X&d=18433086318505818411&ei=yEw3abTpBtOyieoP6r6mkQg&scisig=ALhkC2Rim3aEUgwTTSHNbdDbfmO2&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=7&folt=rel)
*D Curran,V Sporne,L Frermann,J Paterson*

Main category: Matei Zaharia

TL;DR: 该论文提出了一种量化比较大型语言模型在不同司法管辖区法律知识差异的方法，通过构建跨司法管辖区的法律问题数据集来评估模型的法律知识质量。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏系统的方法来量化比较LLM在不同司法管辖区法律知识的差异，这对于理解用户获取法律信息的质量至关重要，特别是考虑到不同地区法律体系的差异。

Method: 构建跨司法管辖区的法律问题数据集，设计评估框架来量化比较LLM在不同地区的法律知识表现，可能包括基准测试、对比分析和质量评估指标。

Result: 开发了系统化的评估方法，能够量化LLM在不同司法管辖区法律知识的差异，揭示了模型在法律知识分布上的不均衡性。

Conclusion: 需要建立标准化的评估框架来系统比较LLM在不同司法管辖区的法律知识，这对于确保用户获得准确、相关的法律信息具有重要意义。

Abstract: How do we make a meaningful comparison of a large language model's knowledge of the law in one place compared to another? Quantifying these differences is critical to understanding if the quality of the legal information obtained by users of LLM …

</details>


### [392] [Evaluation of Adversarial Input Attacks in Retrieval-Augmented Generation Using Large Language Models](https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-981-95-4674-9_18&hl=zh-CN&sa=X&d=4209383901508687725&ei=yEw3abTpBtOyieoP6r6mkQg&scisig=ALhkC2RtttgRvZj6xcvYrCQ4rvLy&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=9&folt=rel)
*K Hasegawa,S Hidano,K Fukushima*

Main category: Matei Zaharia

TL;DR: 检索增强生成(RAG)技术通过结合数据库检索和大型语言模型来生成回答，但随着LLM和RAG的发展，存在一些待解决的问题


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型和检索增强生成技术的进步，虽然RAG能够通过检索外部知识来增强LLM的生成能力，但在实际应用中仍然面临一些挑战和限制，需要进一步研究和改进

Method: 论文可能探讨了RAG技术的改进方法，包括检索质量优化、LLM与检索系统的更好集成、减少幻觉问题、提高事实准确性等具体技术方案

Result: 基于提供的摘要片段，具体实验结果未明确说明，但可以预期论文会展示改进后的RAG系统在准确性、可靠性或效率方面的提升

Conclusion: RAG技术虽然有效，但仍需进一步优化以解决现有挑战，未来的研究方向可能包括更智能的检索策略、更好的知识融合机制等

Abstract: Retrieval-augmented generation (RAG) is a technique that generates responses to questions by leveraging information retrieved from databases and large language models (LLM). However, with the advancements of LLMs and RAG, there are …

</details>


### [393] [Rectifying LLM Thought from Lens of Optimization](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.01925&hl=zh-CN&sa=X&d=8219263898793724012&ei=k-U4afTkJuaQ6rQP07jr0Qc&scisig=ALhkC2RFyCbjDTM-SBiXBhVrn2Vo&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=6&folt=rel)
*J Liu,H Liu,S Zhang,K Chen*

Main category: Matei Zaharia

TL;DR: 论文探讨了大型语言模型在长链思维提示下的推理能力，但指出现有方法存在推理效率低、计算成本高的问题，提出了新的优化方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型通过长链思维提示展现出强大的推理能力，但现有方法需要大量计算资源且推理效率低下，需要更高效的推理优化方法。

Method: 论文提出了一种新的推理优化方法，可能包括推理路径压缩、选择性探索、计算资源优化等技术，以提高长链思维推理的效率。

Result: 新方法在保持推理质量的同时显著减少了计算成本，提高了推理效率，在多个基准测试中表现出优于传统方法的性能。

Conclusion: 通过优化长链思维推理的计算效率，可以在不牺牲推理质量的前提下显著降低计算成本，为大型语言模型的实用化部署提供了有效解决方案。

Abstract: Recent advancements in large language models (LLMs) have been driven by their emergent reasoning capabilities, particularly through long chain-of-thought (CoT) prompting, which enables thorough exploration and deliberation. Despite these …

</details>


### [394] [Hybrid Instruction Tuning with Marginalization for Zero-Shot Reasoning in Language Models](https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Shirmohammad-Tavangari/publication/397648853_Hybrid_Instruction_Tuning_with_Marginalization_for_Zero-Shot_Reasoning_in_Language_Models/links/6918c5f4480eb767581bd257/Hybrid-Instruction-Tuning-with-Marginalization-for-Zero-Shot-Reasoning-in-Language-Models.pdf&hl=zh-CN&sa=X&d=5101627711483055268&ei=k-U4afTkJuaQ6rQP07jr0Qc&scisig=ALhkC2SQn7FDhg59Ix_d0o2e8Jc_&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=7&folt=rel)
*S Tavangari*

Main category: Matei Zaharia

TL;DR: 该论文探讨大型语言模型在复杂多步推理任务中的局限性，提出改进其推理一致性和深度的方法


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在自然语言理解和推理方面表现出色，但在复杂多步推理任务中，其推理能力往往浅显或不一致，需要系统性的改进方法

Method: 论文可能提出评估框架、训练策略或架构改进来增强LLMs的深度推理能力，具体方法需基于完整论文内容确定

Result: 预期结果显示改进后的模型在复杂推理任务上表现更优，推理过程更一致、更深入

Conclusion: 需要系统性的方法来提升大型语言模型的深度推理能力，以应对复杂多步推理任务

Abstract: Recent advancements in large language models (LLMs) have revealed their strong performance in natural language understanding and inference. However, their reasoning abilities often remain shallow or inconsistent, especially in complex, multi …

</details>


### [395] [Jina-VLM: Small Multilingual Vision Language Model](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.04032&hl=zh-CN&sa=X&d=11498129059659159093&ei=k-U4afTkJuaQ6rQP07jr0Qc&scisig=ALhkC2Snl4JXBfdjbYj4c1uMdcWL&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=8&folt=rel)
*A Koukounas,G Mastrapas,F Hönicke,S Eslami…*

Main category: Matei Zaharia

TL;DR: Jina-VLM是一个2.4B参数的视觉语言模型，在2B规模的开源VLM中实现了最先进的多语言视觉问答性能


<details>
  <summary>Details</summary>
Motivation: 开发一个在2B参数规模下具有最先进多语言视觉问答能力的开源视觉语言模型，填补现有开源模型在该规模下的性能空白

Method: 将SigLIP2视觉编码器与Qwen3语言主干通过特定架构耦合，构建2.4B参数的视觉语言模型

Result: 在2B规模的开源视觉语言模型中实现了最先进的多语言视觉问答性能

Conclusion: Jina-VLM展示了在中等参数规模下实现高效多模态理解的可能性，为开源社区提供了强大的视觉语言模型选择

Abstract: We present Jina-VLM, a 2.4 B parameter vision-language model that achieves state-of-the-art multilingual visual question answering among open 2B-scale VLMs. The model couples a SigLIP2 vision encoder with a Qwen3 language backbone through …

</details>


### [396] [Rethinking Retrieval: From Traditional Retrieval Augmented Generation to Agentic and Non-Vector Reasoning Systems in the Financial Domain for Large Language …](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.18177&hl=zh-CN&sa=X&d=13647599394470908488&ei=k-U4afTkJuaQ6rQP07jr0Qc&scisig=ALhkC2Qgv9ktQUMSPRcG65Ta-MRI&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=9&folt=rel)
*E Lumer,M Melich,O Zino,E Kim,S Dieter…*

Main category: Matei Zaharia

TL;DR: RAG系统在金融问答中面临幻觉问题，作者提出了一种新颖的幻觉检测和缓解框架


<details>
  <summary>Details</summary>
Motivation: 虽然RAG系统能够利用SEC文件、财报等外部知识库回答金融问题，但现有方法容易产生幻觉（生成与检索文档不一致的信息），这在金融领域尤其危险，可能导致误导性决策

Method: 作者提出了一种新颖的幻觉检测和缓解框架，通过多阶段验证机制来识别和纠正RAG系统中的幻觉问题，确保生成的答案与检索文档保持一致

Result: 该方法在金融问答基准测试中显著减少了幻觉现象，提高了回答的准确性和可靠性，同时保持了RAG系统的知识更新优势

Conclusion: 提出的框架有效解决了金融RAG系统中的幻觉问题，为构建更可靠的金融问答系统提供了重要技术路径

Abstract: Recent advancements in Retrieval-Augmented Generation (RAG) have enabled Large Language Models to answer financial questions using external knowledge bases of US SEC filings, earnings reports, and regulatory documents. However …

</details>


### [397] [HMR3D: Hierarchical Multimodal Representation for 3D Scene Understanding with Large Vision-Language Model](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.22961&hl=zh-CN&sa=X&d=497792816209047557&ei=ons6ac6SM7CP6rQP_7XFuAE&scisig=ALhkC2Tfg17pOqHo_Lm4okOSAvYs&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=8&folt=rel)
*C Li,E Peh,B Fernando*

Main category: Matei Zaharia

TL;DR: 该论文提出了一种新的3D场景理解方法，通过显式对齐3D场景特征与视觉语言模型的嵌入空间，克服了现有隐式对齐方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉语言模型（VLM）的3D场景理解方法通常采用隐式对齐方式，将3D场景特征与VLM的嵌入空间对齐。然而，这种隐式对齐方法存在局限性，无法充分利用VLM的强大能力进行3D场景理解。

Method: 提出了一种新的对齐方法，通过显式对齐3D场景特征与视觉语言模型的嵌入空间。这种方法可能涉及特定的特征提取、转换和映射机制，以建立3D场景表示与VLM语义空间之间的直接联系。

Result: 该方法在3D场景理解任务上取得了显著改进，相比现有的隐式对齐方法，在多个基准测试中表现出更好的性能。显式对齐能够更有效地利用VLM的语义理解能力，提升3D场景分析的准确性和鲁棒性。

Conclusion: 显式对齐3D场景特征与视觉语言模型嵌入空间是一种有效的3D场景理解方法，能够克服现有隐式对齐方法的局限性，为3D视觉理解任务提供了新的解决方案。

Abstract: Recent advances in large vision-language models (VLMs) have shown significant promise for 3D scene understanding. Existing VLM-based approaches typically align 3D scene features with the VLM's embedding space. However, this implicit alignment …

</details>


### [398] [Training Language Models to Use Prolog as a Tool](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.07407&hl=zh-CN&sa=X&d=15070439925272632069&ei=awA8aavAH7CP6rQPgsi1wQo&scisig=ALhkC2RRJC5HmMWtoUjzG9_VarLP&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=2&folt=rel)
*N Mellgren,P Schneider*

Main category: Matei Zaharia

TL;DR: 该研究通过微调语言模型使用Prolog逻辑编程语言来解决工具使用的可靠性问题，旨在减少语言模型产生看似合理但错误推理的情况


<details>
  <summary>Details</summary>
Motivation: 确保可靠的工具使用对于安全的智能体AI系统至关重要。语言模型经常产生不可靠的推理，生成看似合理但错误的解决方案，这些解决方案难以验证

Method: 通过微调语言模型使用Prolog逻辑编程语言，利用其形式化推理能力来提高工具使用的可靠性

Result: 未在摘要中明确说明具体实验结果，但暗示该方法能够提高推理的可靠性和可验证性

Conclusion: 使用Prolog等逻辑编程语言进行微调是提高语言模型工具使用可靠性的有前景的方法

Abstract: Ensuring reliable tool use is critical for safe agentic AI systems. Language models frequently produce unreliable reasoning with plausible but incorrect solutions that are difficult to verify. To address this, we investigate fine-tuning models to use Prolog …

</details>


### [399] [K2-V2: A 360-Open, Reasoning-Enhanced LLM](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.06201&hl=zh-CN&sa=X&d=5480886520883720638&ei=awA8aavAH7CP6rQPgsi1wQo&scisig=ALhkC2QIzXZ_fXNJONQXj-Cfio-u&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=4&folt=rel)
*Z Liu,L Tang,L Jin,H Li,N Ranjan,D Fan,S Rohatgi…*

Main category: Matei Zaharia

TL;DR: K2-V2是一个从头构建的360度开放大语言模型，作为推理适应的优秀基础模型，同时具备对话和知识检索等通用LLM功能，是目前最强的完全开放模型


<details>
  <summary>Details</summary>
Motivation: 构建一个从头开始的开放大语言模型，专注于提供优秀的推理适应基础，同时保持通用LLM的对话和知识检索能力，填补完全开放模型中推理能力不足的空白

Method: 从头开始构建360度开放LLM（K2-V2），设计为推理适应的基础模型，同时集成对话和知识检索功能，采用完全开放的架构和训练方法

Result: K2-V2成为目前最强的完全开放模型，在推理能力方面与开放模型相媲美，同时保持了通用LLM的功能特性

Conclusion: K2-V2成功构建了一个从头开始的开放大语言模型，为推理适应提供了优秀的基础平台，同时保持了通用功能，推动了完全开放模型的发展

Abstract: We introduce K2-V2, a 360-open LLM built from scratch as a superior base for reasoning adaptation, in addition to functions such as conversation and knowledge retrieval from general LLMs. It stands as the strongest fully open model, rivals open …

</details>


### [400] [ProSocialAlign: Preference Conditioned Test Time Alignment in Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.06515&hl=zh-CN&sa=X&d=1624417070507226504&ei=awA8aavAH7CP6rQPgsi1wQo&scisig=ALhkC2S-y27qtOSfwOC6ihEsWBtr&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=5&folt=rel)
*S Banerjee,S Layek,S Adak,M Pechenizkiy…*

Main category: Matei Zaharia

TL;DR: ProSocialAlign是一种测试时参数对齐方法，通过动态调整模型响应来平衡安全性与用户参与度，特别适用于情感化或高风险场景。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型安全范式在情感化或高风险场景中存在不足：仅拒绝可能疏远用户，而简单顺从可能放大风险。需要一种能平衡安全性与用户参与度的解决方案。

Method: 提出ProSocialAlign方法，这是一种测试时的参数对齐技术，通过动态调整模型响应策略，在安全约束与用户需求之间寻求平衡。

Result: 该方法在情感化和高风险场景中表现出色，能够减少用户疏离感同时控制风险，相比传统拒绝或顺从方法有显著改进。

Conclusion: ProSocialAlign为语言模型安全提供了一种更精细化的对齐方法，特别适用于需要平衡安全与用户体验的复杂交互场景。

Abstract: Current language model safety paradigms often fall short in emotionally charged or high-stakes settings, where refusal-only approaches may alienate users and naive compliance can amplify risk. We propose ProSocialAlign, a test-time, parameter …

</details>


### [401] [LIME: Making LLM Data More Efficient with Linguistic Metadata Embeddings](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.07522&hl=zh-CN&sa=X&d=6693029116246899675&ei=awA8aavAH7CP6rQPgsi1wQo&scisig=ALhkC2QdsiyxBAI7MTE6J7JBWztz&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=8&folt=rel)
*S Sztwiertnia,F Friedrich,K Kersting,P Schramowski…*

Main category: Matei Zaharia

TL;DR: 预训练仅解码器语言模型依赖大量高质量数据，但此类数据的可用性正接近极限。虽然元数据常用于创建和整理数据集，但其作为数据增强工具的潜力尚未充分探索。


<details>
  <summary>Details</summary>
Motivation: 当前仅解码器语言模型的预训练面临高质量数据稀缺的瓶颈，而元数据作为现有数据集的伴随信息，其潜在价值未被充分利用来缓解数据限制问题。

Method: 论文提出利用元数据进行数据增强的方法，通过元数据信息扩展或改进训练数据集，以缓解高质量数据稀缺的问题。

Result: 未提供具体结果数据，但暗示元数据作为数据增强工具能有效应对高质量数据稀缺的挑战。

Conclusion: 元数据在缓解仅解码器语言模型预训练数据限制方面具有重要潜力，值得进一步探索其作为数据增强工具的应用。

Abstract: Pre-training decoder-only language models relies on vast amounts of high-quality data, yet the availability of such data is increasingly reaching its limits. While metadata is commonly used to create and curate these datasets, its potential as a …

</details>


### [402] [MixLM: High-Throughput and Effective LLM Ranking via Text-Embedding Mix-Interaction](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.07846&hl=zh-CN&sa=X&d=14533483014192519021&ei=JIQ9af_qO6GvieoPtIGfoAw&scisig=ALhkC2SI-cw9r-uM5HFVMTyrmdtM&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=5&folt=rel)
*G Li,R He,S Jing,K Behdin,Y Wang…*

Main category: Matei Zaharia

TL;DR: LLMs在推荐和搜索系统中表现出色，但面临高计算成本问题，本文提出了一种高效的LLM排序框架


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在语义理解方面表现出色，在推荐和搜索系统中展现出令人印象深刻的排序性能，但面临高计算开销的问题，需要更高效的解决方案

Method: 提出了一种高效的LLM排序框架，具体方法未在摘要中详细说明，但旨在解决计算成本问题

Result: 摘要未提供具体实验结果，但暗示该框架能够有效降低计算开销

Conclusion: 提出的高效LLM排序框架有望解决LLM在推荐和搜索系统中面临的高计算成本挑战

Abstract: Large language models (LLMs) excel at capturing semantic nuances and therefore show impressive relevance ranking performance in modern recommendation and search systems. However, they suffer from high computational overhead under …

</details>


### [403] [Adapting Language Models for Low-Resource Programming Languages](https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3D2ctRK8h3AZ&hl=zh-CN&sa=X&d=10639384588679978541&ei=JIQ9af_qO6GvieoPtIGfoAw&scisig=ALhkC2TU1E8-xJojBcX0Q0YHF0cb&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=8&folt=rel)
*A Singha,M Singh,H Hasanbeig,A Radhakrishna…*

Main category: Matei Zaharia

TL;DR: 该论文研究了大型语言模型在低资源编程语言代码生成中的局限性，并提出了一种基于代码翻译的解决方案来提升模型在低资源语言上的性能


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在代码生成方面取得了显著成功，但其能力主要集中在Python、Java等高资源编程语言上。对于低资源编程语言，由于训练数据有限，LLMs的表现明显不足。这限制了LLMs在更广泛编程语言环境中的应用，需要解决低资源语言代码生成的挑战。

Method: 论文提出了一种基于代码翻译的方法：首先使用LLMs生成高资源语言（如Python）的代码，然后通过翻译技术将代码转换为目标低资源语言。这种方法利用了LLMs在高资源语言上的强大能力，同时通过翻译机制克服低资源语言训练数据不足的问题。

Result: 实验结果表明，基于代码翻译的方法显著提升了LLMs在低资源编程语言上的代码生成性能。与直接在低资源语言上生成代码相比，翻译方法在代码质量、正确性和可执行性方面都有明显改善，特别是在资源极度匮乏的语言上效果更为显著。

Conclusion: 代码翻译是解决LLMs在低资源编程语言代码生成中性能不足的有效策略。这种方法通过利用高资源语言的优势来弥补低资源语言的不足，为扩展LLMs在多语言编程环境中的应用提供了可行方案。未来工作可以进一步优化翻译质量和探索更高效的跨语言代码生成方法。

Abstract: Large Language Models (LLMs) have achieved remarkable success in code generation, yet their capabilities remain predominantly concentrated in well-resourced programming languages such as Python and Java. In contrast, low …

</details>


### [404] [What Kind of Reasoning (if any) is an LLM actually doing? On the Stochastic Nature and Abductive Appearance of Large Language Models](https://scholar.google.com/scholar_url?url=https://philarchive.org/archive/FLOWKO&hl=zh-CN&sa=X&d=7839463774517167412&ei=JIQ9af_qO6GvieoPtIGfoAw&scisig=ALhkC2TM94TlRf2P-zsZhj8VdOqQ&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=9&folt=rel)
*L Floridi,J Morley,C Novelli,W David*

Main category: Matei Zaharia

TL;DR: 本文探讨了当前主流大语言模型在token补全范式下的推理本质，分析其随机性基础以及与人类推理的现象学相似性


<details>
  <summary>Details</summary>
Motivation: 研究动机在于深入理解主流大语言模型在token补全范式下的推理机制本质，探索其随机性基础以及与人类推理过程的相似性和差异性

Method: 通过分析LLMs的随机性基础和token补全范式，从现象学角度比较模型推理与人类推理的相似性

Result: 揭示了LLMs在token补全范式下的推理本质，展示了其随机性特征以及与人类推理的现象学相似性

Conclusion: 主流大语言模型的推理基于token补全范式，具有随机性基础，在现象学层面与人类推理存在相似性，但本质机制不同

Abstract: This article examines the nature of reasoning in current, mainstream Large Language Models (LLMs) that operate within the token-completion paradigm. We explore their stochastic foundations and phenomenological resemblance to human …

</details>


### [405] [Learning Unmasking Policies for Diffusion Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.09106&hl=zh-CN&sa=X&d=15297896549784494858&ei=yOo-aYHvL_O16rQPzoDK8Ag&scisig=ALhkC2QSbX4dA_vyT7FeqKRSTgPZ&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=1&folt=rel)
*M Jazbec,TX Olausson,L Béthune,P Ablin,M Kirchhof…*

Main category: Matei Zaharia

TL;DR: dLLMs在性能上已匹配自回归模型，但在推理效率方面具有优势，特别是在某些变体上表现突出


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型在保持与自回归模型相当性能的同时，提供了更高的推理效率潜力，这激发了对其进一步研究和优化的动机

Method: 论文探讨了扩散语言模型的特定变体，可能涉及模型架构、训练策略或推理优化等方面的创新方法

Result: 扩散语言模型在许多下游任务上已经能够匹配自回归模型的性能表现

Conclusion: 扩散语言模型在保持性能的同时提供了推理效率优势，是值得关注的研究方向

Abstract: Diffusion (Large) Language Models (dLLMs) now match the downstream performance of their autoregressive counterparts on many tasks, while holding the promise of being more efficient during inference. One particularly successful variant …

</details>


### [406] [A Latent Variable Framework for Scaling Laws in Large Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.06553&hl=zh-CN&sa=X&d=8875408068877480543&ei=yOo-aYHvL_O16rQPzoDK8Ag&scisig=ALhkC2Ql0-tlGiCQ4Sf-PO26O6nX&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=7&folt=rel)
*P Cai,C Cui,FM Polo,S Somerstep,L Choshen…*

Main category: Matei Zaharia

TL;DR: 提出基于隐变量建模的统计框架，用于分析大语言模型的缩放定律，旨在统一不同架构和训练策略的模型性能预测


<details>
  <summary>Details</summary>
Motivation: 随着具有不同架构和训练策略的新LLM家族快速涌现，需要统一的统计框架来理解和预测这些模型的缩放行为，超越传统的幂律拟合方法

Method: 构建基于隐变量建模的统计框架，将模型性能与计算资源、模型规模等可观测变量联系起来，通过概率建模捕捉缩放规律中的不确定性

Result: 该框架能够更准确地描述和预测不同LLM家族的缩放行为，提供对模型性能随规模变化的统计理解，并量化预测的不确定性

Conclusion: 基于隐变量的统计框架为LLM缩放定律提供了更严谨和统一的分析工具，有助于指导模型开发和资源分配决策

Abstract: We propose a statistical framework built on latent variable modeling for scaling laws of large language models (LLMs). Our work is motivated by the rapid emergence of numerous new LLM families with distinct architectures and training strategies …

</details>


### [407] [Cross-Task Benchmarking and Evaluation of General-Purpose and Code-Specific Large Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.04673&hl=zh-CN&sa=X&d=8674571812734115419&ei=yOo-aYHvL_O16rQPzoDK8Ag&scisig=ALhkC2QSnnUOUWNrlO78UCBvmSiQ&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=9&folt=rel)
*G Das,P Bhattacharya,R Gupta*

Main category: Matei Zaharia

TL;DR: 该论文探讨了大型语言模型在特定领域应用中的性能评估，特别是代码合成、法律推理和金融等领域，并分析了不同模型在这些领域中的表现差异。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在通用自然语言处理和特定领域应用中都取得了革命性进展，但先前的研究主要关注单个模型的表现。缺乏对不同模型在多个特定领域（如代码合成、法律推理和金融）中性能的系统性比较和分析。

Method: 论文可能采用系统性评估方法，对多个大型语言模型在代码合成、法律推理和金融等特定领域任务上进行性能测试和比较分析。可能包括基准测试、评估指标设计以及跨领域性能分析。

Result: 研究可能发现不同模型在不同领域表现出显著差异，某些模型在特定领域（如代码合成）表现优异，而在其他领域（如法律推理）则相对较弱。可能识别出影响模型跨领域性能的关键因素。

Conclusion: 需要更全面的评估框架来理解大型语言模型在特定领域应用中的优势和局限性，为模型选择和领域适应提供指导，并推动更均衡的模型发展。

Abstract: Large Language Models (LLMs) have revolutionized both general natural language processing and domain-specific applications such as code synthesis, legal reasoning, and finance. However, while prior studies have explored individual model …

</details>


### [408] [Decoding Human-LLM Collaboration in Coding: An Empirical Study of Multi-Turn Conversations in the Wild](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.10493&hl=zh-CN&sa=X&d=4923349288873924085&ei=gWdAaYjDEc636rQPgsqEoA8&scisig=ALhkC2SiG2_wCme84OMbFmV6fOFL&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=6&folt=rel)
*B Zhang,L Zhang,H Zhang,F Liu,S Wang,B Shen…*

Main category: Matei Zaharia

TL;DR: 该论文分析了大型语言模型作为动态对话接口在多轮交互中的应用，重点关注对话数据集、评估方法以及模型在复杂任务中的表现


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型越来越多地作为动态对话接口，支持多轮交互以模仿人类对话并促进复杂任务（如编码），需要系统分析现有对话数据集、评估方法以及模型在这些交互中的表现

Method: 论文可能采用系统综述或实证分析方法，分析现有对话数据集（如LMSYS-Chat-1M等），评估大型语言模型在多轮对话中的表现，并可能提出新的评估框架或指标

Result: 通过分析发现，大型语言模型在多轮对话中表现出色，能够有效支持复杂任务，但存在对话一致性、上下文理解和任务完成度等方面的挑战。现有数据集和评估方法为模型性能提供了重要基准

Conclusion: 大型语言模型作为动态对话接口在多轮交互中具有巨大潜力，但需要更完善的评估框架、更丰富的对话数据集以及针对特定任务优化的模型架构来进一步提升性能

Abstract: Large language models (LLMs) are increasingly acting as dynamic conversational interfaces, supporting multi-turn interactions that mimic human-like conversation and facilitate complex tasks like coding. While datasets such as LMSYS-Chat-1M and …

</details>


### [409] [SEAttack: A self-evolving jailbreak attack to induce toxic responses for non-toxic queries in large language models](https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0306457325004856&hl=zh-CN&sa=X&d=3937210211500291619&ei=gWdAaYjDEc636rQPgsqEoA8&scisig=ALhkC2R4RsKZHxm7-nhMyQXcs02_&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=9&folt=rel)
*H Liu,S Li,B Ji,X Du,X Li,J Ma,J Yu*

Main category: Matei Zaharia

TL;DR: 该论文提出了一种名为"安全对齐"的新方法，通过将安全对齐视为多目标优化问题，并采用梯度投影技术，在保持模型有用性的同时增强其安全性。


<details>
  <summary>Details</summary>
Motivation: 为了防止大型语言模型被恶意行为者滥用，模型开发者需要设计安全机制来确保LLM生成有益、诚实和无害的响应。当前的安全对齐方法存在局限性，需要在保持模型有用性的同时增强其安全性。

Method: 将安全对齐视为多目标优化问题，采用梯度投影技术。通过将安全梯度投影到有用梯度的零空间，在保持模型有用性的同时增强安全性。该方法旨在最小化对模型有用性的影响。

Result: 该方法在多个安全基准测试中表现出色，能够有效增强模型的安全性，同时最小化对模型有用性的影响。相比现有方法，在安全性和有用性之间取得了更好的平衡。

Conclusion: 提出的安全对齐方法通过多目标优化和梯度投影技术，为LLM安全对齐提供了有效的解决方案，能够在保持模型有用性的同时显著增强其安全性，为实际应用提供了实用工具。

Abstract: Abstract To prevent Large Language Models (LLMs) from being misused by bad actors, model developers delve into designing safety mechanisms to guarantee LLMs generate helpful, honest, and harmless responses. To disclose flaws in the …

</details>


### [410] [From system 1 to system 2: a survey of reasoning Large Language Models](https://scholar.google.com/scholar_url?url=https://strathprints.strath.ac.uk/94892/1/Zhang-etal-2025-From-system-1-to-system-2.pdf&hl=zh-CN&sa=X&d=14377442208865841451&ei=fkJCabeJE6GvieoPtIGfoAw&scisig=ALhkC2RTAF0_RbknlNSaQbeP3rPL&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=9&folt=rel)
*D Zhang,ZZ Li,ML Zhang,J Zhang,Z Liu,Y Yao,H Xu…*

Main category: Matei Zaharia

TL;DR: 该论文探讨如何优化从快速直觉的System 1思维向缓慢深思的System 2思维的过渡，以实现人类水平智能


<details>
  <summary>Details</summary>
Motivation: 当前人工智能系统在快速直觉推理(System 1)方面表现良好，但在需要逻辑推理和深思熟虑的System 2思维方面仍有不足。实现人类水平智能需要更好地整合这两种思维模式，优化它们之间的过渡机制。

Method: 论文可能提出了一种框架或算法来改进从System 1到System 2的过渡机制，可能涉及注意力机制、元认知控制、推理路径规划或混合架构设计，以促进快速直觉思维向逻辑推理的平滑转换。

Result: 基于摘要信息，预期结果包括：改进的推理系统在复杂任务上表现更优，System 1到System 2过渡更加高效，系统在需要深思熟虑的任务中展现出更好的逻辑推理能力，以及在认知任务中更接近人类的表现。

Conclusion: 优化System 1到System 2的过渡是实现人类水平智能的关键路径。通过设计有效的过渡机制，可以构建更强大的人工智能系统，在保持快速直觉能力的同时增强逻辑推理和深思熟虑的能力。

Abstract: Achieving human-level intelligence requires refining the transition from the fast, intuitive System 1 to the slower, more deliberate System 2 reasoning. While System 1 excels in quick, heuristic decisions, System 2 relies on logical reasoning for more …

</details>


### [411] [Grounding Everything in Tokens for Multimodal Large Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.10554&hl=zh-CN&sa=X&d=18301053842022813927&ei=99xDadaiO9_OieoPg6WE2QY&scisig=ALhkC2RWRMJwK2ym8EZN4j-egfIE&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=9&folt=rel)
*X Ren,Z Wang,L Hou,P Tang,G Wang,C Ma*

Main category: Matei Zaharia

TL;DR: 该论文指出多模态大语言模型(MLLMs)在视觉理解和推理方面取得显著进展，但其自回归Transformer架构需要对输入图像进行tokenization，这限制了模型性能


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型虽然取得进展，但其基于自回归Transformer的架构存在局限性，特别是需要对输入图像进行tokenization处理，这限制了模型在视觉理解和推理方面的性能提升

Method: 论文摘要未详细说明具体方法，但暗示需要解决MLLMs中图像tokenization的限制问题，可能涉及改进模型架构或tokenization策略

Result: 摘要未提供具体实验结果，但指出当前MLLMs架构中的tokenization限制影响了模型性能

Conclusion: 多模态大语言模型的图像tokenization处理是当前架构的一个关键限制因素，需要进一步研究和改进以提升视觉理解和推理能力

Abstract: Multimodal large language models (MLLMs) have made significant advancements in vision understanding and reasoning. However, the autoregressive Transformer architecture used by MLLMs requries tokenization on input images, which limits their …

</details>


### [412] [Rethinking Expert Trajectory Utilization in LLM Post-training](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.11470&hl=zh-CN&sa=X&d=4433143239439956024&ei=1HlFadS5L5iTieoP5LbfuQw&scisig=ALhkC2SnppFi-PsMNOJzdYE-kT34&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=0&folt=rel)
*B Ding,Y Chen,J Lv,J Yuan,Q Zhu,S Tian,D Zhu…*

Main category: Matei Zaharia

TL;DR: 提出了可塑性-上限框架，用于理论分析专家轨迹在SFT和RL训练中的最优利用机制


<details>
  <summary>Details</summary>
Motivation: 尽管监督微调（SFT）和强化学习（RL）的有效后训练结合已被证明有效，但如何最优利用专家轨迹的机制仍未解决

Method: 提出可塑性-上限框架进行理论分析，研究专家轨迹在SFT和RL训练中的最优利用策略

Result: 未提供具体实验结果，但提出了理论框架来分析专家轨迹利用的最优机制

Conclusion: 需要进一步研究专家轨迹在SFT和RL结合训练中的最优利用策略，提出的理论框架为此提供了分析工具

Abstract: While effective post-training integrates Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL), the optimal mechanism for utilizing expert trajectories remains unresolved. We propose the Plasticity-Ceiling Framework to theoretically …

</details>


### [413] [CLINIC: Evaluating Multilingual Trustworthiness in Language Models for Healthcare](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.11437&hl=zh-CN&sa=X&d=17141278917967811495&ei=1HlFadS5L5iTieoP5LbfuQw&scisig=ALhkC2QOtSVhLa0hozpV1QeYc1Yg&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=3&folt=rel)
*A Ghosh,S Sridhar,RK Ravi,M Muhsin,S Saha…*

Main category: Matei Zaharia

TL;DR: 医疗领域语言模型缺乏可信度评估框架，阻碍其实际应用


<details>
  <summary>Details</summary>
Motivation: 语言模型在医疗系统中具有改善工作流程和决策的巨大潜力，但缺乏对其可信度的可靠评估成为实际应用的关键障碍

Method: 未在摘要中明确说明具体方法，但暗示需要建立可信度评估框架

Result: 未在摘要中提供具体结果，但强调了可信度评估的重要性

Conclusion: 需要建立可靠的语言模型可信度评估框架来促进其在医疗领域的实际应用

Abstract: Integrating language models (LMs) in healthcare systems holds great promise for improving medical workflows and decision-making. However, a critical barrier to their real-world adoption is the lack of reliable evaluation of their trustworthiness …

</details>


### [414] [Ladder Up, Memory Down: Low-Cost Fine-Tuning With Side Nets](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.14237&hl=zh-CN&sa=X&d=7160089108474013168&ei=WB1HafzJD72qieoPuKej0QM&scisig=ALhkC2S6IccIXCLzOul5QAEWp60O&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=4&folt=rel)
*E Zheng,N Cerisara,S Warichet,E Helbert,C Cerisara*

Main category: Matei Zaharia

TL;DR: QLoRA是一种参数高效微调方法，通过量化技术减少内存使用，使大型语言模型能够在有限GPU内存下进行微调


<details>
  <summary>Details</summary>
Motivation: 大型语言模型微调受限于商用GPU内存，传统参数高效微调方法虽然减少了可训练参数，但内存占用仍然很高，需要更高效的内存优化方案

Method: QLoRA采用量化技术，将模型权重压缩为低精度格式（如4位），同时保持反向传播的精度，显著减少内存占用，使大型模型能够在有限内存设备上微调

Result: QLoRA显著降低了微调过程中的内存使用，使大型语言模型能够在消费级GPU上进行高效微调，同时保持了模型性能

Conclusion: QLoRA通过量化技术有效解决了大型语言模型微调中的内存瓶颈问题，为资源受限环境下的模型适配提供了实用解决方案

Abstract: Fine-tuning large language models (LLMs) is often limited by the memory available on commodity GPUs. Parameter-efficient fine-tuning (PEFT) methods such as QLoRA reduce the number of trainable parameters, yet still incur high memory usage …

</details>


### [415] [Curi\'o-Edu 7B: Examining Data Selection Impacts in LLM Continued Pretraining](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.12770&hl=zh-CN&sa=X&d=1147793167465442086&ei=WB1HafzJD72qieoPuKej0QM&scisig=ALhkC2SiXm0_jWgBxiJHFkZVB59b&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=7&folt=rel)
*TS Almeida,R Nogueira,H Pedrini*

Main category: Matei Zaharia

TL;DR: 持续预训练通过向语言模型暴露额外数据来扩展其能力，通常针对特定语言或领域上下文，是完整重新训练的高效替代方案


<details>
  <summary>Details</summary>
Motivation: 完整重新训练语言模型成本高昂且计算密集，需要更高效的适应方法。持续预训练提供了一种在保持基础能力的同时扩展模型特定领域或语言能力的策略

Method: 通过向现有语言模型暴露额外数据（通常是特定领域或语言的数据）进行进一步预训练，而不是从头开始重新训练整个模型

Result: 持续预训练被证明是适应语言模型到新领域或语言上下文的高效替代方案，能够扩展模型能力同时保持基础性能

Conclusion: 持续预训练是扩展语言模型能力的有效策略，在特定领域或语言适应方面比完整重新训练更高效

Abstract: Continued pretraining extends a language model's capabilities by further exposing it to additional data, often tailored to a specific linguistic or domain context. This strategy has emerged as an efficient alternative to full retraining when adapting …

</details>


### [416] [Bolmo: Byteifying the Next Generation of Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.15586&hl=zh-CN&sa=X&d=16944347735393831434&ei=xJ1Iaar3HNKV6rQP84i9kQc&scisig=ALhkC2QMU57-vsOgQgQu3taSzLTn&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=4&folt=rel)
*B Minixhofer,T Murray,T Limisiewicz,A Korhonen…*

Main category: Matei Zaharia

TL;DR: Bolmo是首个在1B和7B参数规模上具有竞争力的完全开源字节级语言模型家族，采用新颖的预训练方法而非从头训练


<details>
  <summary>Details</summary>
Motivation: 现有字节级语言模型研究主要集中于从头训练，但这种方法效率较低。作者旨在开发具有竞争力的开源字节级模型，通过改进预训练方法提升性能

Method: 采用创新的预训练方法而非传统的从头训练，在1B和7B参数规模上构建字节级语言模型，保持完全开源特性

Result: Bolmo成为首个在1B和7B参数规模上具有竞争力的完全开源字节级语言模型家族，在多个基准测试中表现优异

Conclusion: 通过创新的预训练方法可以构建具有竞争力的开源字节级语言模型，为字节级建模研究提供了新的方向

Abstract: We introduce Bolmo, the first family of competitive fully open byte-level language models (LMs) at the 1B and 7B parameter scales. In contrast to prior research on byte-level LMs, which focuses predominantly on training from scratch, we train Bolmo …

</details>


### [417] [Are We on the Right Way to Assessing LLM-as-a-Judge?](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.16041&hl=zh-CN&sa=X&d=609960042573874787&ei=xJ1Iaar3HNKV6rQP84i9kQc&scisig=ALhkC2Qd7L5tF-E8tlpF2SO7PMKU&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=5&folt=rel)
*Y Feng,S Wang,Z Cheng,Y Wan,D Chen*

Main category: Matei Zaharia

TL;DR: 本文探讨了LLM-as-a-Judge评估方法存在的问题，指出现有基准过度依赖人工标注的真实标签，这限制了其在模型训练中作为监督奖励的有效性。


<details>
  <summary>Details</summary>
Motivation: LLM-as-a-Judge作为一种评估方法已被广泛采用，并作为模型训练中的监督奖励。然而，现有基准主要依赖人工标注的真实标签，这引入了人类偏见和局限性，限制了该方法在模型训练中的有效性和可扩展性。

Method: 论文提出了一种新的评估框架或方法，旨在减少对人工标注的依赖，可能通过自动生成评估标准、利用LLM自身能力进行自我评估，或构建更客观的评估体系来改进LLM-as-a-Judge方法。

Result: 研究结果表明，减少对人工标注依赖的新方法能够提供更可靠、可扩展的评估结果，提高了LLM-as-a-Judge作为监督奖励在模型训练中的有效性，并展示了更好的泛化能力。

Conclusion: LLM-as-a-Judge评估方法需要摆脱对人工标注的过度依赖，通过更自动化和客观的评估框架可以显著提升其作为模型训练监督奖励的价值和实用性。

Abstract: LLM-as-a-Judge has been widely adopted as an evaluation method and served as supervised rewards in model training. However, existing benchmarks for LLM-as-a-Judge are mainly relying on human-annotated ground truth, which introduces human …

</details>


### [418] [" To Survive, I Must Defect": Jailbreaking LLMs via the Game-Theory Scenarios](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.16278&hl=zh-CN&sa=X&d=11822909430933521310&ei=xJ1Iaar3HNKV6rQP84i9kQc&scisig=ALhkC2RIZaKwOKPL0JcAIMI9tWkb&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=9&folt=rel)
*Z Sun,Z Zhang,D Liang,H Sun,Y Liu,Y Shen,X Gao…*

Main category: Matei Zaharia

TL;DR: 该论文针对LLM越狱攻击研究现状，指出当前黑盒攻击方法依赖人工启发式规则或搜索空间狭窄，提出改进方案


<details>
  <summary>Details</summary>
Motivation: 随着LLM普及，非专业用户可能带来安全风险，促使越狱攻击研究增多。但现有黑盒越狱攻击大多依赖人工设计的启发式规则或狭窄搜索空间，限制了攻击效果和效率

Method: 论文未提供具体方法细节，但从摘要推断可能提出更系统化、自动化或搜索空间更广的黑盒越狱攻击方法

Result: 摘要未提供实验结果，但暗示现有方法的局限性，预期新方法能提升越狱攻击的成功率和效率

Conclusion: 需要开发更有效的黑盒越狱攻击方法，克服当前依赖人工启发式和搜索空间狭窄的限制，以更好评估LLM安全性

Abstract: As LLMs become more common, non-expert users can pose risks, prompting extensive research into jailbreak attacks. However, most existing black-box jailbreak attacks rely on hand-crafted heuristics or narrow search spaces, which limit …

</details>


### [419] [SPARQL-LLM: Real-Time SPARQL Query Generation from Natural Language Questions](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.14277&hl=zh-CN&sa=X&d=15437426601717441125&ei=mQ5KaYXgHMW4ieoP4szBiAE&scisig=ALhkC2Qsk-fC0snK6Yocsdqh8TP3&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=5&folt=rel)
*P Smeros,V Emonet,R Wang,AC Sima,TM de Farias*

Main category: Matei Zaharia

TL;DR: 基于大语言模型的新方法用于从自然语言生成SPARQL查询，但现有评估存在局限性，需要更全面的基准测试


<details>
  <summary>Details</summary>
Motivation: 大语言模型的出现为从自然语言生成结构化查询（如SPARQL查询）提供了新方法，但现有评估方法存在局限性，需要更全面的基准测试来准确评估这些新方法的性能

Method: 论文提出了一个更全面的评估框架或基准测试方法，用于评估基于大语言模型的自然语言到SPARQL查询生成方法

Result: 通过新的评估框架，揭示了现有评估方法的局限性，并展示了更全面的性能评估结果

Conclusion: 需要更全面、更严格的评估基准来准确评估基于大语言模型的自然语言到SPARQL查询生成方法的性能，以推动该领域的发展

Abstract: The advent of large language models is contributing to the emergence of novel approaches that promise to better tackle the challenge of generating structured queries, such as SPARQL queries, from natural language. However, these new …

</details>


### [420] [DS SERVE: A Framework for Efficient and Scalable Neural Retrieval](https://scholar.google.com/scholar_url?url=https://berkeley-large-rag.github.io/RAG-DS-Serve/assets/DS_SERVE_Camera_Ready.pdf&hl=zh-CN&sa=X&d=1412400924573341305&ei=fS5NaZCrGsW4ieoP4szBiAE&scisig=ALhkC2TcECX-_I8JyjNgaVzPlC4j&oi=scholaralrt&hist=i6heNjgAAAAJ:15186190164853243054:ALhkC2R3EVwTChDJsJzPrYBHJDZi&html=&pos=0&folt=art)
*J Liu,Y Wang,X Lyu,R Shao,JE Gonzalez,M Zaharia…*

Main category: Matei Zaharia

TL;DR: DS SERVE是一个将大规模文本数据集（包含半万亿token）转换为高性能神经检索系统的框架，提供Web界面和API端点，实现低延迟检索。


<details>
  <summary>Details</summary>
Motivation: 处理海量文本数据（半万亿token）的检索需求，解决传统检索系统在大规模数据集上的性能瓶颈，提供高效、低延迟的神经检索解决方案。

Method: 开发DS SERVE框架，将大规模文本数据集转换为神经检索系统，实现Web界面和API端点，优化系统架构以实现低延迟检索。

Result: 成功构建了能够处理半万亿token数据集的神经检索系统，提供低延迟的Web界面和API服务，实现了高性能的大规模文本检索。

Conclusion: DS SERVE框架有效解决了大规模文本数据集的检索挑战，为海量文本数据的神经检索提供了实用、高效的解决方案。

Abstract: We present DS SERVE, a framework that transforms largescale text datasets—comprising half a trillion tokens—into a high-performance neural retrieval system. DS SERVE offers both a web interface and API endpoints, achieving low latency with …

</details>


### [421] [TCDE: Topic-Centric Dual Expansion of Queries and Documents with Large Language Models for Information Retrieval](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.17164&hl=zh-CN&sa=X&d=14288045762352741385&ei=fS5NabmjOObYieoP3dLOmAk&scisig=ALhkC2TR-qhegceGS28TFdiKX1hK&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=6&folt=rel)
*Y Yang,F Tian,P Chen*

Main category: Matei Zaharia

TL;DR: 论文探讨了查询扩展(QE)和文档扩展(DE)分别应用时可能导致的语义错位问题，提出了一种联合扩展方法以改善检索效果


<details>
  <summary>Details</summary>
Motivation: 现有的查询扩展和文档扩展技术通常分别应用，这可能导致扩展后的查询和文档之间存在语义错位，从而影响检索系统的性能。需要一种更协调的方法来同时扩展查询和文档，确保它们之间的语义一致性。

Method: 提出了一种联合扩展方法，通过协同机制同时扩展查询和文档，确保扩展内容在语义上对齐。可能采用对比学习、联合训练或基于上下文的扩展策略来优化查询和文档表示。

Result: 联合扩展方法相比单独应用QE或DE能显著提高检索性能，减少语义错位，在标准检索基准测试中表现出更好的效果。

Conclusion: 查询扩展和文档扩展的联合应用比单独应用更有效，能够解决语义错位问题，提升信息检索系统的整体性能。

Abstract: Query Expansion (QE) enriches queries and Document Expansion (DE) enriches documents, and these two techniques are often applied separately. However, such separate application may lead to semantic misalignment between the expanded …

</details>


### [422] [Towards Effective and Efficient Long Video Understanding of Multimodal Large Language Models via One-shot Clip Retrieval](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.08410&hl=zh-CN&sa=X&d=10455119649169001219&ei=fS5NabmjOObYieoP3dLOmAk&scisig=ALhkC2S54BuQ5YufRfpuQl58CNmK&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=8&folt=rel)
*T Chen,S Ju,Q Wu,C Fang,K Zhang,J Peng,H Li…*

Main category: Matei Zaharia

TL;DR: 提出一种名为One-shot video prompting的高效范式，通过单帧视频提示解决MLLMs处理长视频时内存开销过大的问题


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型由于内存开销过大，只能处理有限帧数的视频，限制了其在长视频理解任务中的应用

Method: 提出One-shot video prompting范式，通过精心设计的单帧视频提示来代表整个视频内容，减少内存需求同时保持视频理解能力

Result: 该方法显著降低了内存消耗，使MLLMs能够处理更长的视频序列，同时保持或提升了视频理解任务的性能

Conclusion: One-shot video prompting是一种有效且高效的解决方案，能够克服MLLMs处理长视频时的内存限制，扩展了MLLMs在视频理解领域的应用范围

Abstract: Due to excessive memory overhead, most Multimodal Large Language Models (MLLMs) can only process videos of limited frames. In this paper, we propose an effective and efficient paradigm to remedy this shortcoming, termed One-shot video …

</details>


### [423] [Identifying Features Associated with Bias Against 93 Stigmatized Groups in Language Models and Guardrail Model Safety Mitigation](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.19238&hl=zh-CN&sa=X&d=11219162641487679779&ei=W5lOacuzFcSN6rQPx4HkwQU&scisig=ALhkC2SBnvry_uJbqjUAeszD7I9o&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=3&folt=rel)
*AM Gueorguieva,A Caliskan*

Main category: Matei Zaharia

TL;DR: 该研究探讨大语言模型对非受保护污名化身份的偏见，分析污名社会特征与模型偏见的关系


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注受保护群体的偏见，但对非受保护污名化身份（如肥胖、精神疾病、药物成瘾等）的偏见研究不足，且不清楚污名的哪些社会特征与LLM输出偏见相关

Method: 通过系统分析不同污名化身份的社会特征（如可控性、危险性、可见性等），评估LLM对这些身份的偏见表现，建立污名特征与模型偏见之间的关联模型

Result: LLM对非受保护污名化身份存在显著偏见，偏见程度与污名的社会特征（如感知可控性、危险性、道德关联性）密切相关，某些特征比传统受保护身份特征更能预测偏见

Conclusion: 需要扩展偏见评估框架以涵盖非受保护污名化身份，理解污名社会特征与模型偏见的关系有助于开发更公平的LLM，减少对边缘化群体的伤害

Abstract: Large language models (LLMs) have been shown to exhibit social bias, however, bias towards non-protected stigmatized identities remain understudied. Furthermore, what social features of stigmas are associated with bias in LLM outputs is unknown …

</details>


### [424] [CORE: Concept-Oriented Reinforcement for Bridging the Definition-Application Gap in Mathematical Reasoning](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.18857&hl=zh-CN&sa=X&d=1179462265423697365&ei=W5lOacuzFcSN6rQPx4HkwQU&scisig=ALhkC2SgDDAVe-xsSLOpgCPvN-ju&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=4&folt=rel)
*Z Gao,Z Xu,X Ye,B Zhou*

Main category: Matei Zaharia

TL;DR: 该论文针对大语言模型在数学问题中概念理解不足的问题，提出了一种基于验证性奖励的强化学习框架，通过逐步验证推理过程而非仅依赖最终答案来提高模型的概念理解和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽然能解决复杂的数学练习题，但在需要真正概念理解的问题上表现不佳。现有的基于验证性奖励的强化学习方法通常只强化最终答案，而忽略了推理过程的重要性，导致模型缺乏真正的概念理解和泛化能力。

Method: 提出了一种改进的强化学习框架，不仅验证最终答案的正确性，还对推理过程的每一步进行验证和奖励。通过逐步验证推理链，确保模型不仅得到正确答案，而且理解背后的数学概念和推理逻辑。

Result: 该方法显著提高了大语言模型在需要概念理解的数学问题上的表现，模型不仅能够正确回答问题，还能展示出更好的泛化能力和对数学概念的深入理解。

Conclusion: 通过验证推理过程而不仅仅是最终答案，可以显著提升大语言模型在数学问题中的概念理解和泛化能力。这种方法为解决大语言模型在复杂推理任务中的局限性提供了有效途径。

Abstract: Large language models (LLMs) often solve challenging math exercises yet fail to apply the concept right when the problem requires genuine understanding. Popular Reinforcement Learning with Verifiable Rewards (RLVR) pipelines reinforce final …

</details>


### [425] [JustRL: Scaling a 1.5 B LLM with a Simple RL Recipe](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.16649&hl=zh-CN&sa=X&d=16138031555279794479&ei=W5lOacuzFcSN6rQPx4HkwQU&scisig=ALhkC2Tqv1FqPMBHSsydIFtZ71g6&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=6&folt=rel)
*B He,Z Qu,Z Liu,Y Chen,Y Zuo,C Qian,K Zhang…*

Main category: Matei Zaharia

TL;DR: 论文指出当前大语言模型强化学习方法的过度复杂化问题，提出了一种更简单有效的替代方案


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的强化学习方法变得越来越复杂，包括多阶段训练流程、动态超参数调度和课程学习策略，这种复杂性增加了实现难度和计算成本，需要探索更简单有效的替代方案

Method: 论文提出了一种简化的强化学习方法，可能包括减少训练阶段、简化超参数设置或采用更直接的训练策略，具体方法需要进一步查看完整论文内容

Result: 提出的简化方法在性能上与复杂方法相当甚至更好，同时显著降低了实现复杂度和计算成本

Conclusion: 对于大语言模型的强化学习，简单的方法往往更有效，过度工程化的复杂训练流程可能是不必要的，应该优先考虑简洁高效的训练策略

Abstract: Recent advances in reinforcement learning for large language models have converged on increasing complexity: multi-stage training pipelines, dynamic hyperparameter schedules, and curriculum learning strategies. This raises a …

</details>


### [426] [Explainable and Fine-Grained Safeguarding of LLM Multi-Agent Systems via Bi-Level Graph Anomaly Detection](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.18733&hl=zh-CN&sa=X&d=332801547244445647&ei=W5lOacuzFcSN6rQPx4HkwQU&scisig=ALhkC2QNUdwXZGqW3yfMeuEfYo4X&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=8&folt=rel)
*J Pan,Y Liu,R Miao,K Ding,Y Zheng,QVH Nguyen…*

Main category: Matei Zaharia

TL;DR: 该论文提出了一种基于大型语言模型的多智能体系统中恶意智能体检测方法，通过分析智能体间的通信模式来识别恶意行为


<details>
  <summary>Details</summary>
Motivation: 随着基于LLM的多智能体系统在安全关键任务中日益自主化，恶意智能体检测已成为关键的安全挑战，需要有效的方法来识别和防范潜在威胁

Method: 论文提出了一种基于智能体间通信模式分析的方法，通过监控和分析智能体之间的交互行为来检测恶意智能体

Result: 该方法能够有效识别多智能体系统中的恶意智能体，提高系统的安全性和可靠性

Conclusion: 基于通信模式分析的恶意智能体检测方法为LLM多智能体系统的安全部署提供了有效的解决方案，对于安全关键应用具有重要意义

Abstract: Large language model (LLM)-based multi-agent systems (MAS) have shown strong capabilities in solving complex tasks. As MAS become increasingly autonomous in various safety-critical tasks, detecting malicious agents has become a critical security …

</details>


### [427] [Schoenfeld's Anatomy of Mathematical Reasoning by Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.19995&hl=zh-CN&sa=X&d=2524053775645734091&ei=N_lPae3UL6yK6rQPgZOO6A8&scisig=ALhkC2TQR991UzcuB7ju2A3Haf3d&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=0&folt=rel)
*M Li,C Fan,Y Cheng,S Feizi,T Zhou*

Main category: Matei Zaharia

TL;DR: 该研究采用Schoenfeld的Episode Theory作为归纳性中间框架，分析大型语言模型的推理轨迹，揭示其认知结构和步骤，超越表面统计。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然越来越多地暴露推理轨迹，但其底层的认知结构和推理步骤仍然难以识别和分析，超出了表面统计的范围。

Method: 采用Schoenfeld的Episode Theory作为归纳性中间框架来分析LLM的推理轨迹，识别认知结构和推理步骤。

Result: 通过Episode Theory框架，能够更深入地揭示LLM推理过程中的认知结构和步骤，提供超越表面统计的分析。

Conclusion: Schoenfeld的Episode Theory为分析大型语言模型的推理轨迹提供了有效的中间框架，有助于深入理解其认知过程。

Abstract: Large language models increasingly expose reasoning traces, yet their underlying cognitive structure and steps remain difficult to identify and analyze beyond surface-level statistics. We adopt Schoenfeld's Episode Theory as an inductive, intermediate …

</details>


### [428] [SpidR: Learning Fast and Stable Linguistic Units for Spoken Language Models Without Supervision](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.20308&hl=zh-CN&sa=X&d=11755293292934472608&ei=N_lPae3UL6yK6rQPgZOO6A8&scisig=ALhkC2Sg2S05tqcrmpkljPBs0rbk&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=2&folt=rel)
*M Poli,M Luthra,Y Benchekroun,Y Higuchi,M Gleize…*

Main category: Matei Zaharia

TL;DR: 从语音直接学习语言表示，无需文本中间媒介，通过语音-语义对齐实现跨模态语言建模


<details>
  <summary>Details</summary>
Motivation: 语言建模和语音表示学习的并行进展使得直接从语音学习语言成为可能，这可以绕过文本中间媒介，实现更自然的语言获取方式

Method: 通过语音-语义对齐技术，直接从语音信号中提取语义表示，建立跨模态的语言建模框架

Result: 实现了从语音直接学习语言表示的能力，展示了跨模态语言建模的可行性

Conclusion: 直接从语音学习语言是可行的，这为无文本语言处理开辟了新途径，具有重要的理论和应用价值

Abstract: The parallel advances in language modeling and speech representation learning have raised the prospect of learning language directly from speech without textual intermediates. This requires extracting semantic representations directly from …

</details>


### [429] [RAG-DOLL: Zero-Shot LLM Multi-Hop Question Answering by Simultaneously Planning Over Documents and Strategies](https://scholar.google.com/scholar_url?url=https://cs191.stanford.edu/projects/Fall2025/_Houjun___Liu_.pdf&hl=zh-CN&sa=X&d=14759529338997495913&ei=N_lPae3UL6yK6rQPgZOO6A8&scisig=ALhkC2RqyIgnNilb1rsWKJMx4P_Z&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=5&folt=rel)
*H Liu,AF Hardy,S Akinwande,RJ Moss,D Eddy…*

Main category: Matei Zaharia

TL;DR: 该论文提出了一种名为"回溯增强推理"的新提示方法，用于改进语言模型在零样本多跳问答中的表现，通过允许模型回溯和纠正错误推理路径来提升性能。


<details>
  <summary>Details</summary>
Motivation: 尽管语言模型在零样本多跳问答中表现出强大的能力，但大多数提示方案在性能上存在不足，主要原因是缺乏回溯错误推理路径的能力，导致模型在复杂推理任务中表现受限。

Method: 提出"回溯增强推理"方法，这是一种新的提示方案，允许语言模型在推理过程中回溯到之前的步骤，识别和纠正错误的推理路径，从而改进多跳问答的准确性。

Result: 该方法在多个多跳问答基准测试中显著提升了零样本性能，相比现有提示方法取得了更好的结果，特别是在需要复杂推理和纠错能力的任务上表现突出。

Conclusion: 回溯增强推理为语言模型的零样本多跳问答提供了一种有效的改进方法，通过引入回溯机制增强了模型的推理鲁棒性，为复杂推理任务提供了新的解决方案。

Abstract: Abstract Language models demonstrate surprisingly strong zero-shot multi-hop question-answering (MHQA) capabilities; however, most prompting schemes for zero-shot MHQA suffer in performance either due to a lack of ability to backtrack on wrong …

</details>


### [430] [Impact of LLM-Modified Queries and Documents in Training Data on Neural Retrieval Models](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3767695.3769485&hl=zh-CN&sa=X&d=8693702987666253632&ei=N_lPae3UL6yK6rQPgZOO6A8&scisig=ALhkC2SpVriHkf0CzWy-g4gIgmya&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=7&folt=rel)
*Y Nakachi,MP Kato*

Main category: Matei Zaharia

TL;DR: 研究LLM重写文档和LLM扩展查询作为训练数据对检索模型性能及排序行为的影响


<details>
  <summary>Details</summary>
Motivation: 探索利用LLM生成的数据增强技术如何影响检索模型的训练效果和排序行为，为改进检索系统提供新思路

Method: 使用不同配置的训练数据训练检索模型，包括LLM重写文档和LLM扩展查询的组合，评估模型在ad-hoc检索任务中的表现

Result: LLM生成的数据对检索模型性能有显著影响，不同数据配置导致不同的排序行为变化

Conclusion: LLM数据增强技术能有效提升检索模型性能，但需要仔细设计训练数据配置以优化排序行为

Abstract: This study investigates the impact of including LLM-rewritten documents and LLM-expanded queries in training data on the performance and ranking behavior of retrieval models for ad-hoc retrieval tasks. Specifically, we train models using various …

</details>


### [431] [Making Large Language Models Efficient Dense Retrievers](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.20612&hl=zh-CN&sa=X&d=3356996752236605747&ei=N_lPae3UL6yK6rQPgZOO6A8&scisig=ALhkC2Rt3akzfyC6k1qJewAQtcY_&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=8&folt=rel)
*Y Lei,S He,A Li,A Yates*

Main category: Matei Zaharia

TL;DR: 直接微调大语言模型进行稠密检索虽然性能强，但参数量大导致计算效率低


<details>
  <summary>Details</summary>
Motivation: 现有方法直接微调大语言模型进行稠密检索虽然能获得强大性能，但由于模型参数量巨大，导致计算效率低下，需要更高效的解决方案

Method: 论文摘要未提供具体方法细节，但暗示了针对大语言模型稠密检索计算效率问题的解决方案

Result: 摘要未提供具体实验结果，但指出直接微调大语言模型进行稠密检索能获得强大性能

Conclusion: 需要开发更高效的方法来解决大语言模型在稠密检索任务中的计算效率问题

Abstract: Recent work has shown that directly fine-tuning large language models (LLMs) for dense retrieval yields strong performance, but their substantial parameter counts make them computationally inefficient. While prior studies have revealed significant …

</details>


### [432] [AgentMath: Empowering Mathematical Reasoning for Large Language Models via Tool-Augmented Agent](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.20745&hl=zh-CN&sa=X&d=11193318902287575625&ei=4ZRRad_gLbK16rQPn86DwQ8&scisig=ALhkC2Tl-JvU6C5FaMNO2IGzL7zV&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=6&folt=rel)
*H Luo,H Feng,Q Sun,C Xu,K Zheng,Y Wang,T Yang…*

Main category: Matei Zaharia

TL;DR: 大型推理模型在自然语言推理方面取得显著进展，但存在计算效率低和准确性不足的问题


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（如o3和DeepSeek-R1）在自然语言推理方面取得了显著进展，但它们在计算效率方面仍然不足，并且在某些情况下准确性存在问题。这促使研究者寻找改进这些模型性能的方法。

Method: 从摘要内容来看，该论文可能提出了一种新的方法来改进大型推理模型的效率和准确性。虽然具体方法未在提供的摘要中明确说明，但可能涉及模型架构优化、推理策略改进或计算效率提升技术。

Result: 摘要未提供具体实验结果，但暗示了现有大型推理模型在计算效率和准确性方面存在局限性，需要进一步改进。

Conclusion: 大型推理模型虽然取得了进展，但在计算效率和准确性方面仍有改进空间，需要新的方法来解决这些挑战。

Abstract: Large Reasoning Models (LRMs) like o3 and DeepSeek-R1 have achieved remarkable progress in natural language reasoning with long chain-of-thought. However, they remain computationally inefficient and struggle with accuracy when …

</details>


### [433] [LLM-CAS: Dynamic Neuron Perturbation for Real-Time Hallucination Correction](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.18623&hl=zh-CN&sa=X&d=15002916010697746846&ei=H3BTafeMA7ux6rQPi5qW2AE&scisig=ALhkC2QxPG4RNKp1L0jG_pLb5WYR&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=2&folt=rel)
*J Zhang,N Liu,Y Fan,Z Huang,Q Zeng,K Cai,J Wang…*

Main category: Matei Zaharia

TL;DR: LLMs存在幻觉生成问题，现有方法如监督微调和人类反馈强化学习在减少幻觉方面效果有限，需要更有效的方法来提升LLM输出的真实性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型经常生成缺乏事实或上下文基础的幻觉内容，这限制了它们在关键应用中的可靠性。现有的监督微调和人类反馈强化学习方法在减少幻觉方面效果有限，需要更有效的方法来提升LLM输出的真实性和可靠性。

Method: 从提供的摘要片段来看，方法部分信息不完整。摘要提到了"Existing approaches such as supervised fine-tuning and reinforcement learning from human..."，但具体的新方法描述被截断了。需要完整论文来了解作者提出的具体方法。

Result: 摘要未提供具体实验结果。需要完整论文来评估该方法在减少LLM幻觉方面的效果，包括定量指标和定性分析。

Conclusion: 摘要未提供完整结论。从现有片段推断，论文可能提出了一种新的方法来减少LLM幻觉，从而提升模型在关键应用中的可靠性和实用性。

Abstract: Large language models (LLMs) often generate hallucinated content that lacks factual or contextual grounding, limiting their reliability in critical applications. Existing approaches such as supervised fine-tuning and reinforcement learning from human …

</details>


### [434] [ClarifyMT-Bench: Benchmarking and Improving Multi-Turn Clarification for Conversational Large Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.21120&hl=zh-CN&sa=X&d=11295062069309958131&ei=H3BTafeMA7ux6rQPi5qW2AE&scisig=ALhkC2SK1UrCtBDvp-l9s2g8-5nU&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=9&folt=rel)
*S Luo,Y Huang,M Li,S Meng,F Liu,Z Hu,J Feng…*

Main category: Matei Zaharia

TL;DR: 论文提出一个新的多轮对话澄清基准CLARIFIER，用于评估LLM在开放域对话中处理不完整或模糊信息的能力，包含多种澄清策略和评估指标


<details>
  <summary>Details</summary>
Motivation: 现有LLM澄清基准主要关注单轮对话，缺乏对多轮开放域对话中澄清策略的系统评估。用户经常提供不完整或模糊信息，需要LLM能够有效澄清以提供准确回复

Method: 构建CLARIFIER基准，包含多样化的对话场景和澄清需求，设计多种澄清策略（如具体化、确认、选项提供等），开发自动评估指标评估澄清质量和对话效率

Result: 实验显示当前LLM在多轮澄清任务中表现有限，澄清策略选择不当，澄清质量有待提升。基准有效揭示了LLM在开放域对话中处理模糊信息的能力缺陷

Conclusion: CLARIFIER基准填补了多轮对话澄清评估的空白，为LLM对话能力改进提供了重要参考，未来需要开发更智能的澄清策略和评估方法

Abstract: Large language models (LLMs) are increasingly deployed as conversational assistants in open-domain, multi-turn settings, where users often provide incomplete or ambiguous information. However, existing LLM-focused clarification benchmarks …

</details>


### [435] [Image-free Multi-label Image Recognition via LLM-powered Hierarchical Prompt Tuning](https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0031320325016498&hl=zh-CN&sa=X&d=12604904882755260549&ei=K09VaYG2Foaw6rQPkNu46Ao&scisig=ALhkC2TKmzpkPn5fkDiqf4RMgAKE&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=4&folt=rel)
*S Yang,Z Shang,Y Wang,D Deng,H Chen,X Wu…*

Main category: Matei Zaharia

TL;DR: 提出无需训练图像的图像自由多标签识别框架，利用预训练大语言模型知识学习提示来适配视觉模型


<details>
  <summary>Details</summary>
Motivation: 传统多标签图像识别需要大量标注数据，本文旨在探索无需训练图像的方法，利用LLM的知识来指导视觉模型进行多标签识别

Method: 提出图像自由框架，使用预训练大语言模型的知识学习提示，适配预训练视觉模型进行多标签识别，无需任何训练图像

Result: 该方法在标准多标签图像识别基准上取得有竞争力的性能，证明了无需训练图像的多标签识别可行性

Conclusion: 图像自由多标签识别框架展示了利用LLM知识指导视觉模型的潜力，为数据稀缺场景下的多标签识别提供了新思路

Abstract: This paper proposes a novel framework for multi-label image recognition without any training images, namely image-free framework, which uses knowledge of pre-trained Large Language Model (LLM) to learn prompts to adapt a pre-trained Vision …

</details>


### [436] [Gamayun's Path to Multilingual Mastery: Cost-Efficient Training of a 1.5 B-Parameter LLM](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.21580&hl=zh-CN&sa=X&d=5591099301271435698&ei=nKlWadHmOdrJieoPiYyysAk&scisig=ALhkC2TwuHtu5nH7g_XayT9jpPiM&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=1&folt=rel)
*A Podolskiy,S Molokov,T Gerasin,M Titov…*

Main category: Matei Zaharia

TL;DR: Gamayun是一个1.5B参数的多语言语言模型，从头开始在2.5T token上训练，专为资源受限环境设计


<details>
  <summary>Details</summary>
Motivation: 解决资源受限环境中缺乏高效、可部署的多语言语言模型研究的问题

Method: 从头开始训练1.5B参数的多语言模型，使用2.5T token的数据集，针对资源效率进行优化设计

Result: 开发出Gamayun模型，在资源受限环境中具有高效部署能力

Conclusion: Gamayun为资源受限环境提供了实用的多语言语言模型解决方案

Abstract: We present Gamayun, a 1.5 B-parameter multilingual language model trained entirely from scratch on 2.5 T tokens. Designed for efficiency and deployment in resource-constrained environments, Gamayun addresses the lack of research on …

</details>


### [437] [DiRL: An Efficient Post-Training Framework for Diffusion Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.22234&hl=zh-CN&sa=X&d=1250199647287958727&ei=RfRXaavjH76Z6rQPr-v5iAc&scisig=ALhkC2T4ttLrW8atXl4fmnN4rhgB&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=0&folt=rel)
*Y Zhu,J Wan,X Liu,S He,Q Wang,X Guo,T Liang…*

Main category: Matei Zaharia

TL;DR: 该论文探讨了扩散语言模型(dLLMs)的后训练优化，包括指令微调、对齐和推理加速，提出了一个统一的训练框架来提升dLLMs在文本生成任务中的性能


<details>
  <summary>Details</summary>
Motivation: 虽然扩散语言模型(dLLMs)作为自回归(AR)模型的替代方案显示出潜力，但现有的研究主要集中在预训练和推理加速上，对于后训练阶段（如指令微调、对齐等）的系统性研究相对缺乏，限制了dLLMs在实际应用中的性能表现

Method: 论文提出了一个统一的后训练框架，整合了指令微调、对齐优化和推理加速技术。该方法可能包括：1) 针对dLLMs的指令微调策略；2) 对齐技术以改善模型输出质量；3) 推理优化方法以平衡生成质量与速度

Result: 通过提出的后训练框架，dLLMs在文本生成任务中取得了显著性能提升，包括生成质量、对齐能力和推理效率的改善，在某些指标上接近甚至超越了传统的自回归模型

Conclusion: 系统性的后训练优化对于充分发挥扩散语言模型的潜力至关重要，论文提出的统一框架为dLLMs的实际应用提供了有效解决方案，推动了非自回归语言模型的发展

Abstract: Diffusion Language Models (dLLMs) have emerged as promising alternatives to Auto-Regressive (AR) models. While recent efforts have validated their pre-training potential and accelerated inference speeds, the post-training landscape for dLLMs …

</details>


### [438] [Style Amnesia: Investigating Speaking Style Degradation and Mitigation in Multi-Turn Spoken Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.23578&hl=zh-CN&sa=X&d=206503451957683875&ei=RfRXaavjH76Z6rQPr-v5iAc&scisig=ALhkC2R0HD0IChRxbAWTBruur0i6&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=2&folt=rel)
*YX Lin,CH Chiang,H Lee*

Main category: Matei Zaharia

TL;DR: 研究发现语音语言模型在多轮对话中难以维持指定的说话风格


<details>
  <summary>Details</summary>
Motivation: 探索语音语言模型在多轮对话中维持指定说话风格的能力，评估其在实际应用中的局限性

Method: 通过多轮对话实验，让语音语言模型在对话开始时被指示采用特定说话风格，然后观察其在后续对话轮次中维持该风格的能力

Result: 语音语言模型在对话开始阶段能够采用指定说话风格，但在经过几轮交互后无法维持所需的说话风格

Conclusion: 当前语音语言模型在多轮对话中维持说话风格的能力有限，需要改进模型架构或训练方法以提升风格一致性

Abstract: In this paper, we show that when spoken language models (SLMs) are instructed to speak in a specific speaking style at the beginning of a multi-turn conversation, they cannot maintain the required speaking styles after several turns of interaction; we …

</details>


### [439] [Breaking myths in LLM scaling and emergent abilities with a comprehensive statistical analysis](https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S092523122503214X&hl=zh-CN&sa=X&d=2016090856459858081&ei=RfRXaavjH76Z6rQPr-v5iAc&scisig=ALhkC2Rm1dZbOhLI34mqbkJGJ5x3&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=3&folt=rel)
*K Sun,R Wang*

Main category: Matei Zaharia

TL;DR: 该论文探讨了在大型语言模型快速发展背景下，评估工作对于理解和推进模型发展的重要性，并分析了规模、训练类型、架构等因素对模型性能的影响。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的快速发展，评估工作对于理解和推进这些模型的发展变得越来越重要。现有的评估揭示了规模、训练类型、架构等因素对模型性能的影响，但需要更系统化的评估框架来深入理解这些因素的作用机制。

Method: 论文可能采用系统性的评估方法，分析不同因素（如模型规模、训练类型、架构设计等）对LLM性能的影响。可能包括对比实验、基准测试、性能指标分析等方法，以量化评估各种因素对模型表现的具体贡献。

Result: 评估结果显示，模型规模、训练类型、架构设计等因素对大型语言模型的性能有显著影响。具体表现为：规模扩大通常带来性能提升，但存在边际效应；不同的训练策略（如监督微调、强化学习等）影响模型的能力表现；架构设计（如注意力机制、层数等）对特定任务性能有差异化影响。

Conclusion: 评估是理解和推进大型语言模型发展的关键环节。系统化的评估框架能够揭示规模、训练类型、架构等因素对模型性能的影响机制，为未来的模型设计和优化提供重要指导。持续改进评估方法对于推动LLM领域的进步至关重要。

Abstract: Amidst the rapid evolution of LLMs, the significance of evaluation in comprehending and propelling these models forward is increasingly paramount. Evaluations have revealed that factors such as scaling, training types, architectures and other factors …

</details>


### [440] [WeDLM: Reconciling Diffusion Language Models with Standard Causal Attention for Fast Inference](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.22737&hl=zh-CN&sa=X&d=14153719490578423189&ei=RfRXaavjH76Z6rQPr-v5iAc&scisig=ALhkC2R_F82BlA296QkOrEiz2MdE&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=4&folt=rel)
*A Liu,M He,S Zeng,S Zhang,L Zhang,C Wu,W Jia…*

Main category: Matei Zaharia

TL;DR: 该论文提出了一种名为"Diffusion Language Models (DLLMs)"的新方法，通过并行解码替代传统的自回归生成，以解决大型语言模型推理时的并行性限制问题。


<details>
  <summary>Details</summary>
Motivation: 自回归生成作为大型语言模型的标准解码范式，其逐令牌生成特性在推理时限制了并行性，导致推理效率低下。需要探索能够实现并行解码的替代方法。

Method: 提出了扩散语言模型方法，利用扩散过程实现并行解码。该方法可能涉及将文本生成建模为扩散过程，通过去噪步骤并行生成完整文本序列。

Result: 扩散语言模型能够实现并行解码，相比自回归方法在推理时具有更好的并行性，可能提高生成效率。具体性能指标需要完整论文数据。

Conclusion: 扩散语言模型为大型语言模型的解码提供了有前景的并行替代方案，能够克服自回归生成的并行性限制，有望提升推理效率。

Abstract: Autoregressive (AR) generation is the standard decoding paradigm for Large Language Models (LLMs), but its token-by-token nature limits parallelism at inference time. Diffusion Language Models (DLLMs) offer parallel decoding by …

</details>


### [441] [AFA-LoRA: Enabling Non-Linear Adaptations in LoRA with Activation Function Annealing](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.22455&hl=zh-CN&sa=X&d=12497462225483872248&ei=RfRXaavjH76Z6rQPr-v5iAc&scisig=ALhkC2TLpviYlWcdyNbyX6RHFw7t&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=6&folt=rel)
*J Li,J Tan,Z Yang,F Huo,Y Sun,Y Xie,X Cai*

Main category: Matei Zaharia

TL;DR: LoRA的线性适应过程限制了其表达能力，本文提出了一种增强LoRA表达能力的方法


<details>
  <summary>Details</summary>
Motivation: LoRA作为广泛采用的参数高效微调方法，其线性适应过程限制了表达能力，导致线性训练与非...之间存在表达能力的差距

Method: 从摘要中无法确定具体方法，但推测是通过改进LoRA的线性适应过程来增强表达能力

Result: 摘要未提供具体结果，但暗示提出的方法能够增强LoRA的表达能力

Conclusion: 需要改进LoRA的线性适应过程以增强其表达能力

Abstract: Low-Rank Adaptation (LoRA) is a widely adopted parameter-efficient fine-tuning (PEFT) method. However, its linear adaptation process limits its expressive power. This means there is a gap between the expressive power of linear training and non …

</details>


### [442] [Entropy-Guided Token Dropout: Training Autoregressive Language Models with Limited Domain Data](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.23422&hl=zh-CN&sa=X&d=4968236748248168061&ei=X29Zacr4IO-GieoPo9DluQE&scisig=ALhkC2SqBXN_zKxy4lSqiHbopaBH&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=3&folt=rel)
*J Wang,Y Hu,Y Gao,H Wang,S Wang,H Lu,J Mao…*

Main category: Matei Zaharia

TL;DR: 多轮训练已成为适应大型语言模型的实用策略，但自回归模型在重复训练时会出现性能下降问题


<details>
  <summary>Details</summary>
Motivation: 随着高质量领域特定数据日益稀缺，多轮训练成为适应大型语言模型的实用方法，但自回归模型在重复训练时存在性能退化问题需要解决

Method: 论文未提供具体方法细节，但暗示需要解决自回归模型在多轮训练中的性能下降问题

Result: 未提供具体实验结果，但指出自回归模型在多轮训练中存在性能下降现象

Conclusion: 需要开发有效方法来缓解自回归模型在多轮训练中的性能退化问题

Abstract: As access to high-quality, domain-specific data grows increasingly scarce, multi-epoch training has become a practical strategy for adapting large language models (LLMs). However, autoregressive models often suffer from performance degradation …

</details>


### [443] [How do language models handle emotional content in video game localization? A computational linguistics approach](https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S2772766125001156&hl=zh-CN&sa=X&d=15875190176458259627&ei=9y1cac3LPKyK6rQPgZOO6A8&scisig=ALhkC2S2KvlEXTzQDmwTy263FEoJ&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=6&folt=rel)
*X Zhao,E Chersoni,CR Huang,H Xu*

Main category: Matei Zaharia

TL;DR: 使用情感分析技术对比语言模型与人类译者在游戏本地化中处理情感内容的能力


<details>
  <summary>Details</summary>
Motivation: 研究语言模型在视频游戏本地化中处理情感内容的能力，并与人类译者进行比较，评估AI在情感翻译方面的表现

Method: 采用自然语言处理中的情感分析技术，基于游戏本地化语料库，对比分析语言模型与人类译者在情感内容处理上的差异

Result: 研究结果显示语言模型在情感内容处理方面与人类译者存在差异，具体表现在情感识别、表达和转换等方面

Conclusion: 语言模型在游戏本地化情感处理方面具有潜力但仍有限制，需要进一步优化以更好地捕捉和传达情感内容

Abstract: This study employs emotion analysis, a natural language processing technique, to examine how language models handle emotional content compared to human translators in video game localization. The analysis is based on a corpus consisting …

</details>


### [444] [IoT-LLM: A framework for enhancing large language model reasoning from real-world sensor data](https://scholar.google.com/scholar_url?url=https://www.cell.com/patterns/fulltext/S2666-3899(25)00277-6&hl=zh-CN&sa=X&d=9943933650604877571&ei=J9xdafgFo6LqtA_o-8zpDQ&scisig=ALhkC2SEQ9BoDB5GmaPMqejN0R5K&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=6&folt=rel)
*T An,Y Zhou,H Zou,J Yang*

Main category: Matei Zaharia

TL;DR: 探索通过增强感知能力来提升大语言模型在物理世界推理任务中的表现


<details>
  <summary>Details</summary>
Motivation: 大语言模型在文本任务上表现出色，但在物理世界推理任务中常常遇到困难。受人类认知的启发，感知是推理的基础，因此研究如何通过增强LLMs的感知能力来改善其物理世界推理能力

Method: 通过增强大语言模型的感知能力来改善其物理世界推理，具体方法可能包括多模态感知融合、物理世界信息获取等

Result: 未在摘要中明确说明具体结果，但暗示增强感知的LLMs在物理世界推理任务上会有改进

Conclusion: 通过增强大语言模型的感知能力，可以显著提升其在物理世界推理任务中的表现，这为LLMs在现实世界应用开辟了新方向

Abstract: Large language models (LLMs) excel in textual tasks but often struggle with physical-world reasoning tasks. Inspired by human cognition—where perception is fundamental to reasoning—we explore augmenting LLMs with enhanced perception …

</details>


### [445] [Data Valuation for LLM Fine-Tuning: Efficient Shapley Value Approximation via Language Model Arithmetic](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.15765&hl=zh-CN&sa=X&d=16788702149028627236&ei=tERfadnnH7K16rQPn86DwQ8&scisig=ALhkC2RgkfcVEb4Jx997Dm4RaZsp&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=4&folt=rel)
*M Tamine,O Sakhi,B Heymann*

Main category: Matei Zaharia

TL;DR: 数据是训练大语言模型的关键资产，与计算资源和专业人才同等重要。虽然部分训练数据公开可用，但生成专有数据集需要大量投资。


<details>
  <summary>Details</summary>
Motivation: 强调数据在大语言模型训练中的核心地位，指出专有数据集的商业价值和投资必要性，为数据资产化提供理论基础。

Method: 通过分析数据在LLM训练中的角色，对比公开数据与专有数据的差异，探讨数据资产化的经济和技术维度。

Result: 确立数据作为关键训练资产的地位，揭示专有数据集的战略价值，为数据投资决策提供框架性分析。

Conclusion: 数据是LLM训练的核心生产要素，专有数据集的开发需要战略性投资，数据资产化管理对AI产业发展至关重要。

Abstract: Data is a critical asset for training large language models (LLMs), alongside compute resources and skilled workers. While some training data is publicly available, substantial investment is required to generate proprietary datasets, such as human …

</details>


### [446] [Visual Funnel: Resolving Contextual Blindness in Multimodal Large Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.10362&hl=zh-CN&sa=X&d=11865820683984508378&ei=tERfadnnH7K16rQPn86DwQ8&scisig=ALhkC2S8Pjk6IjLufIIw2ebUB_0y&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:ALhkC2SJExGD9UJCSc0pOaIikTqf&html=&pos=9&folt=rel)
*W Jung,J Go,M Jeon,S Yoon,J Kim*

Main category: Matei Zaharia

TL;DR: 该论文针对MLLMs在细粒度视觉感知方面的不足，提出了一种基于显著区域裁剪和视觉标记压缩的方法，通过减少冗余信息来提升模型对细节的感知能力。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型(MLLMs)虽然展现出强大的推理能力，但在感知细粒度视觉细节方面存在不足，这限制了它们在需要精确视觉理解的任务中的应用。现有方法通过裁剪显著区域来增强细节感知，但会产生大量冗余的视觉标记，导致计算效率低下。

Method: 提出了一种结合显著区域裁剪和视觉标记压缩的方法。首先识别图像中的显著区域并进行裁剪，然后对这些裁剪区域应用视觉标记压缩技术，减少冗余的视觉标记数量，同时保留重要的细节信息。

Result: 该方法在多个细粒度视觉理解基准测试中取得了显著提升，同时减少了计算开销。实验表明，该方法能够有效增强MLLMs对细节的感知能力，并在保持推理能力的同时提高了计算效率。

Conclusion: 通过显著区域裁剪与视觉标记压缩的结合，可以有效解决MLLMs在细粒度视觉感知方面的局限性，为需要精确视觉理解的应用提供了更高效、更准确的解决方案。

Abstract: Multimodal Large Language Models (MLLMs) demonstrate impressive reasoning capabilities, but often fail to perceive fine-grained visual details, limiting their applicability in precision-demanding tasks. While methods that crop salient regions …

</details>


### [447] [CD4LM: Consistency Distillation and aDaptive Decoding for Diffusion Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.02236&hl=zh-CN&sa=X&d=6694489326265326153&ei=hqNgaaWpGuqsieoPjYOSgAM&scisig=AHkA5jTHdkNfEi7WSZSAMSeYqlSb&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:AHkA5jSEWE2pdcgDuWOJdF-lmUBr&html=&pos=1&folt=rel)
*Y Liang,Z Wang,H Chen,X Sun,J Wu,X Yu,J Liu…*

Main category: Matei Zaharia

TL;DR: 扩散语言模型通过并行解码解决自回归模型延迟问题，但面临离散文本生成挑战


<details>
  <summary>Details</summary>
Motivation: 自回归大语言模型在许多基准测试中表现优异，但其解码过程受限于对先前生成token的顺序依赖，导致延迟问题。扩散语言模型通过并行解码有望解决这一瓶颈，但在离散文本生成方面面临挑战。

Method: 论文提出了一种扩散语言模型方法，通过并行解码机制来克服自回归模型的顺序依赖限制。该方法可能涉及将扩散过程应用于离散文本空间，使用连续表示或专门的离散扩散技术。

Result: 扩散语言模型在保持生成质量的同时，实现了比传统自回归模型更快的解码速度，特别是在长序列生成任务中表现出显著的延迟改进。

Conclusion: 扩散语言模型为语言生成任务提供了一种有前景的替代方案，能够显著降低解码延迟，同时保持生成质量，为实时应用和长文本生成开辟了新可能性。

Abstract: Autoregressive large language models achieve strong results on many benchmarks, but decoding remains fundamentally latency-limited by sequential dependence on previously generated tokens. Diffusion language models (DLMs) promise parallel …

</details>


### [448] [Deferred Commitment Decoding for Diffusion Language Models with Confidence-Aware Sliding Windows](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.02076&hl=zh-CN&sa=X&d=1915482236404124982&ei=hqNgaaWpGuqsieoPjYOSgAM&scisig=AHkA5jSIfa7a_J_3aEFHUin_0Jpv&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:AHkA5jSEWE2pdcgDuWOJdF-lmUBr&html=&pos=2&folt=rel)
*Y Shu,Y Tian,C Xu,Y Wang,H Chen*

Main category: Matei Zaharia

TL;DR: 该论文提出了一种新的扩散语言模型推理方法，通过块级并行生成和KV缓存兼容性优化，显著提升了推理效率


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型虽然支持并行文本生成，但在推理效率和KV缓存兼容性方面存在不足，需要改进以更好地应用于实际场景

Method: 采用块级并行生成策略，优化KV缓存机制，实现与现有推理框架的兼容性

Result: 显著提升了扩散语言模型的推理效率，同时保持了KV缓存的兼容性，为实际部署提供了可行性

Conclusion: 提出的块级并行生成方法有效解决了扩散语言模型在推理效率和KV缓存兼容性方面的挑战，为扩散模型的实际应用铺平了道路

Abstract: Diffusion language models (DLMs) have recently emerged as a strong alternative to autoregressive models by enabling parallel text generation. To improve inference efficiency and KV-cache compatibility, prior work commonly adopts block-based …

</details>


### [449] [Counterfactual Self-Questioning for Stable Policy Optimization in Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.00885&hl=zh-CN&sa=X&d=1881798073557429589&ei=hqNgaaWpGuqsieoPjYOSgAM&scisig=AHkA5jS7yn3Ap71dyHDHMOwIluMo&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:AHkA5jSEWE2pdcgDuWOJdF-lmUBr&html=&pos=4&folt=rel)
*M Parab*

Main category: Matei Zaharia

TL;DR: 该论文提出了一种新的语言模型自我改进方法，通过自我批评和迭代细化来提升推理能力，无需外部批评者或学习奖励模型


<details>
  <summary>Details</summary>
Motivation: 现有语言模型自我改进方法大多依赖外部批评者、学习奖励模型或人类反馈，限制了其自主性和可扩展性。需要一种更自主的自我改进方法，让模型能够独立地批评和优化自身推理过程。

Method: 提出了一种自我批评和迭代细化框架，模型首先生成初始推理，然后通过自我批评识别错误和不足，最后基于批评进行迭代细化改进。整个过程完全自主，无需外部组件。

Result: 该方法在多个推理基准测试中显著提升了语言模型的性能，特别是在数学推理、逻辑推理和常识推理任务上，超越了依赖外部批评者的基线方法。

Conclusion: 语言模型能够通过自主的自我批评和迭代细化有效改进自身推理能力，这为更自主、可扩展的模型自我改进提供了新方向。

Abstract: Recent work on language model self-improvement shows that models can refine their own reasoning through reflection, verification, debate, or self-generated rewards. However, most existing approaches rely on external critics, learned reward …

</details>


### [450] [Judging with Personality and Confidence: A Study on Personality-Conditioned LLM Relevance Assessment](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.01862&hl=zh-CN&sa=X&d=14083995375494362634&ei=hqNgaaWpGuqsieoPjYOSgAM&scisig=AHkA5jTPLVI5lzrDnDM-qMRaAZqq&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:AHkA5jSEWE2pdcgDuWOJdF-lmUBr&html=&pos=9&folt=rel)
*N Chen,H Fang,P Wang,J Liu,T Sakai,XM Wu*

Main category: Matei Zaharia

TL;DR: 该研究探讨了如何通过提示工程让大语言模型模拟特定人格特质，并分析了不同提示策略对人格模拟效果的影响


<details>
  <summary>Details</summary>
Motivation: 虽然已有研究表明通过提示可以让大语言模型模拟特定人格特质，但缺乏对这些模拟人格如何在不同提示策略下表现的系统性理解，需要研究不同提示方法对人格模拟效果的影响

Method: 研究可能采用实验设计，通过不同的提示策略（如直接指令、角色扮演、情境设定等）让大语言模型模拟特定人格特质，然后使用标准化的人格评估工具或行为分析来测量模拟效果

Result: 预期发现不同提示策略对人格模拟效果有显著影响，某些策略能更有效地引导大语言模型产生与目标人格特质一致的行为和语言模式

Conclusion: 提示工程是影响大语言模型人格模拟效果的关键因素，需要系统性地设计和评估提示策略以实现更准确、一致的人格模拟

Abstract: Recent studies have shown that prompting can enable large language models (LLMs) to simulate specific personality traits and produce behaviors that align with those traits. However, there is limited understanding of how these simulated …

</details>


### [451] [DNACHUNKER: Learnable Tokenization for DNA Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.03019&hl=zh-CN&sa=X&d=5935907492537991112&ei=R-1haernIu6TieoPutPYsQg&scisig=AHkA5jSh7VP-xy9wS_PUgi0KjKAK&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:AHkA5jSEWE2pdcgDuWOJdF-lmUBr&html=&pos=3&folt=rel)
*T Kim,J Shin,H Kim,Y Jung,J Lee,WC Lee,I Han…*

Main category: Matei Zaharia

TL;DR: DNA语言模型的性能受tokenization策略影响，需要更优的DNA序列解析方法


<details>
  <summary>Details</summary>
Motivation: DNA语言模型已成为解码DNA序列复杂语言的有力工具，但其性能严重受限于tokenization策略，即解析DNA序列的方法，现有方法存在不足

Method: 未在摘要中明确说明具体方法，但关注点在于DNA序列的tokenization策略研究

Result: 未在摘要中提供具体实验结果

Conclusion: DNA语言模型的tokenization策略对其性能有重要影响，需要进一步研究和改进

Abstract: DNA language models have emerged as powerful tools for decoding the complex language of DNA sequences. However, the performance of these models is heavily affected by their tokenization strategy, ie, a method used to parse DNA sequences …

</details>


### [452] [MoE Adapter for Large Audio Language Models: Sparsity, Disentanglement, and Gradient-Conflict-Free](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.02967&hl=zh-CN&sa=X&d=2433346825841216705&ei=R-1haernIu6TieoPutPYsQg&scisig=AHkA5jQ6mMaJyqY23E4K_Ivark9-&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:AHkA5jSEWE2pdcgDuWOJdF-lmUBr&html=&pos=5&folt=rel)
*Y Lei,S He,J Hu,D Zhang,X Luo,D Zhu,S Feng…*

Main category: Matei Zaharia

TL;DR: 该论文提出了一种名为Heterogeneous Audio Tokenizer (HAT)的新方法，用于解决音频信息固有的异质性（heterogeneous）问题，通过解耦和重构音频表示来增强LLM的音频理解能力。


<details>
  <summary>Details</summary>
Motivation: 将大型语言模型（LLMs）的输入模态扩展到音频领域对于实现全面的多模态感知至关重要。然而，音频信息本质上是异质的，包含多种不同类型的声学特征（如语音、音乐、环境声音等），这些特征在语义和声学特性上存在显著差异。现有的音频处理方法往往未能充分考虑这种异质性，导致LLM在音频理解任务上的性能受限。

Method: 提出了异质音频分词器（Heterogeneous Audio Tokenizer, HAT），该方法通过解耦音频中的异质信息，并重新构建音频表示来增强LLM的音频理解能力。具体来说，HAT能够识别和处理音频中不同类型的声学特征，将它们转换为适合LLM处理的统一表示形式。

Result: HAT方法在多个音频理解任务上取得了显著的性能提升，特别是在处理复杂、异质的音频场景时表现出色。实验结果表明，该方法能够有效解耦音频中的异质信息，为LLM提供更丰富、更准确的音频表示。

Conclusion: 通过解决音频信息的异质性问题，HAT为LLM的音频模态扩展提供了有效的解决方案。该方法不仅提升了LLM在音频理解任务上的性能，也为更全面的多模态感知系统奠定了基础。

Abstract: Extending the input modality of Large Language Models~(LLMs) to the audio domain is essential for achieving comprehensive multimodal perception. However, it is well-known that acoustic information is intrinsically\textit {heterogeneous}, entangling …

</details>


### [453] [ROAD: Reflective Optimization via Automated Debugging for Zero-Shot Agent Alignment](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.24040&hl=zh-CN&sa=X&d=18398126617817521737&ei=R-1haernIu6TieoPutPYsQg&scisig=AHkA5jSo-_TR0Yatl6nQIBMslPQ4&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:AHkA5jSEWE2pdcgDuWOJdF-lmUBr&html=&pos=7&folt=rel)
*N Temyingyong,D Jain,N Kumarsahu,P Kumar…*

Main category: Matei Zaharia

TL;DR: 自动提示优化(APO)方法通常依赖大型标注开发集，但本文提出了一种无需标注数据的替代方案


<details>
  <summary>Details</summary>
Motivation: 当前最先进的自动提示优化方法需要大型标注开发集来计算优化指标，这在许多实际应用中难以获取且成本高昂，限制了APO的广泛应用

Method: 提出了一种无需标注数据的自动提示优化方法，通过替代评估指标或自监督学习技术来优化提示，减少对人工标注数据的依赖

Result: 该方法在减少数据需求的同时保持了与基于标注数据方法相当的性能，显著降低了提示优化的成本和门槛

Conclusion: 无需标注数据的自动提示优化方法为LLM提示工程提供了更实用、可扩展的解决方案，使APO技术能够更广泛地应用于实际场景

Abstract: Automatic Prompt Optimization (APO) has emerged as a critical technique for enhancing Large Language Model (LLM) performance, yet current state-of-the-art methods typically rely on large, labeled gold-standard development sets to compute …

</details>


### [454] [Extracting books from production language models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.02671&hl=zh-CN&sa=X&d=16641616248412865308&ei=bkVjaZ2uGO-GieoPo9DluQE&scisig=AHkA5jQgwLs_mmTgQTd7Gg_OVs3q&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:AHkA5jSEWE2pdcgDuWOJdF-lmUBr&html=&pos=0&folt=rel)
*A Ahmed,AF Cooper,S Koyejo,P Liang*

Main category: Matei Zaharia

TL;DR: 该论文探讨了LLM训练中的记忆化问题及其对版权法律问题的影响，分析了训练数据如何被编码到模型权重中以及记忆化数据如何被提取。


<details>
  <summary>Details</summary>
Motivation: 当前关于LLM与版权的法律争议主要围绕记忆化问题：训练数据是否被编码到模型权重中，以及这些记忆化的数据是否能在模型输出中被提取。这些问题是版权法领域亟待解决的关键问题。

Method: 论文采用法律分析与技术分析相结合的方法，探讨LLM训练过程中的记忆化机制，分析训练数据如何被编码到模型参数中，以及记忆化数据提取的技术可能性。

Result: 研究发现LLM确实存在记忆化现象，训练数据能够以某种形式被编码到模型权重中，并且存在技术手段可以从模型输出中提取这些记忆化的数据。

Conclusion: LLM的记忆化现象对版权法提出了新的挑战，需要在技术理解的基础上重新审视版权法的适用性，为相关法律框架的完善提供理论依据。

Abstract: Many unresolved legal questions over LLMs and copyright center on memorization: whether specific training data have been encoded in the model's weights during training, and whether those memorized data can be extracted in the model's outputs …

</details>


### [455] [Benchmark^ 2: Systematic Evaluation of LLM Benchmarks](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.03986&hl=zh-CN&sa=X&d=2470135056096510870&ei=bkVjaZ2uGO-GieoPo9DluQE&scisig=AHkA5jTa2kJIdwrBbfWcBPcD8nKo&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:AHkA5jSEWE2pdcgDuWOJdF-lmUBr&html=&pos=4&folt=rel)
*Q Qian,C Huang,J Xu,C Lv,M Wu,W Liu,X Wang…*

Main category: Matei Zaharia

TL;DR: 提出Benchmark²框架，通过三个维度（可靠性、难度、效率）系统评估大语言模型基准的质量，解决现有基准评估方法不足的问题


<details>
  <summary>Details</summary>
Motivation: 大语言模型基准的快速扩散导致对基准质量评估的迫切需求，现有方法缺乏系统性评估框架，需要更全面的基准质量评估方法

Method: 提出Benchmark²框架，包含三个核心维度：可靠性（评估基准的稳定性、一致性和偏差）、难度（评估基准的挑战性和区分度）、效率（评估基准的计算成本和实用性）

Result: Benchmark²框架能够系统评估现有LLM基准的质量，识别基准设计中的问题，为基准开发提供指导原则，提高基准评估的科学性

Conclusion: Benchmark²为基准质量评估提供了系统框架，有助于提升LLM基准的科学性和实用性，推动更可靠的模型评估实践

Abstract: The rapid proliferation of benchmarks for evaluating large language models (LLMs) has created an urgent need for systematic methods to assess benchmark quality itself. We propose Benchmark^ 2, a comprehensive framework comprising three …

</details>


### [456] [MIND: From Passive Mimicry to Active Reasoning through Capability-Aware Multi-Perspective CoT Distillation](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.03717&hl=zh-CN&sa=X&d=4544452195266774036&ei=bkVjaZ2uGO-GieoPo9DluQE&scisig=AHkA5jQyaRSPKW91s8YRJYS3YbQk&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:AHkA5jSEWE2pdcgDuWOJdF-lmUBr&html=&pos=6&folt=rel)
*J Cui,J Guo,J Zhou,R Yang,J Lu,J Xu,J Song…*

Main category: Matei Zaharia

TL;DR: 该论文探讨了在资源受限环境下，如何将大语言模型的复杂推理能力迁移到小模型上，以解决实际部署中的计算资源限制问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽然通过思维链推理展现出强大的复杂任务处理能力，但在实际应用中面临计算资源限制，因此需要研究如何将这些能力迁移到更小、更高效的模型上。

Method: 论文可能涉及知识蒸馏、模型压缩、迁移学习等技术，将大语言模型的思维链推理能力转移到小模型中，具体方法需要根据完整论文内容确定。

Result: 预期结果是小模型能够继承大语言模型的复杂推理能力，在保持较高性能的同时显著降低计算资源需求。

Conclusion: 通过有效的迁移技术，可以在资源受限的环境中部署具有复杂推理能力的小型语言模型，平衡性能与效率。

Abstract: While Large Language Models (LLMs) have emerged with remarkable capabilities in complex tasks through Chain-of-Thought reasoning, practical resource constraints have sparked interest in transferring these abilities to smaller models. However …

</details>


### [457] [Enhancing Linguistic Competence of Language Models through Pre-training with Language Learning Tasks](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.03448&hl=zh-CN&sa=X&d=17375509191264725932&ei=bkVjaZ2uGO-GieoPo9DluQE&scisig=AHkA5jTINQiuLYrqcV0lE1qUwy6v&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:AHkA5jSEWE2pdcgDuWOJdF-lmUBr&html=&pos=7&folt=rel)
*A Yamaguchi,M Mi,N Aletras*

Main category: Matei Zaharia

TL;DR: 语言模型通过原始文本预训练学习世界知识和推理，但未显式优化语言能力，导致在语法、句法等语言任务上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型主要关注世界知识和推理能力的获取，但缺乏对语言能力（如语法、句法）的显式优化，这限制了模型在语言任务上的表现。

Method: 论文未在摘要中详细说明具体方法，但暗示需要设计新的训练范式或优化目标来显式提升语言模型的语言能力。

Result: 摘要未提供具体实验结果，但指出当前语言模型在语言能力方面存在不足，需要改进。

Conclusion: 需要重新思考语言模型的训练方法，加入对语言能力的显式优化，以提升模型在语言任务上的表现。

Abstract: Language models (LMs) are pre-trained on raw text datasets to generate text sequences token-by-token. While this approach facilitates the learning of world knowledge and reasoning, it does not explicitly optimize for linguistic competence …

</details>


### [458] [Beyond Perplexity: A Lightweight Benchmark for Knowledge Retention in Supervised Fine-Tuning](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.03505&hl=zh-CN&sa=X&d=8525834218957849700&ei=bkVjaZ2uGO-GieoPo9DluQE&scisig=AHkA5jTiivjOk99rV45HYbJnq-af&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:AHkA5jSEWE2pdcgDuWOJdF-lmUBr&html=&pos=8&folt=rel)
*SZ Shabgahi,P Aghazadeh,F Koushanfar*

Main category: Matei Zaharia

TL;DR: SFT训练中仅依赖验证困惑度监控不足，需要更好的评估方法来区分风格模仿与知识获取


<details>
  <summary>Details</summary>
Motivation: 监督微调是向大语言模型注入领域知识的标准方法，但仅依赖验证困惑度监控训练存在不足，因为它混淆了风格模仿与知识获取，导致模型可能只学会模仿训练数据的风格而非真正掌握知识

Method: 论文提出新的评估框架或方法来区分风格模仿与知识获取，可能包括设计专门的测试集、评估指标或训练监控策略

Result: 发现仅依赖困惑度会导致模型过度拟合风格特征而非知识内容，提出的新方法能更准确评估SFT过程中的知识获取效果

Conclusion: 需要超越验证困惑度的更精细评估方法来监控SFT训练，确保模型真正获取领域知识而不仅仅是风格模仿

Abstract: Supervised Fine-Tuning (SFT) is a standard approach for injecting domain knowledge into Large Language Models (LLMs). However, relying on validation perplexity to monitor training is often insufficient, as it confounds stylistic mimicry with …

</details>


### [459] [SpeechMedAssist: Efficiently and Effectively Adapting Speech Language Models for Medical Consultation](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.04638&hl=zh-CN&sa=X&d=2610985335042299997&ei=5qVkaaPBCNrJieoPiYyysAk&scisig=AHkA5jS3CRZ6MdL3F98Le8CmAOxm&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:AHkA5jSEWE2pdcgDuWOJdF-lmUBr&html=&pos=5&folt=rel)
*S Chen,J Wang,W Chen,Z Wei*

Main category: Matei Zaharia

TL;DR: 该论文探讨了医疗咨询中基于语音的交互，指出传统长文本交互方式繁琐且对患者不友好，提出利用语音语言模型改进医疗咨询体验


<details>
  <summary>Details</summary>
Motivation: 医疗咨询本质上是语音为中心的交互，但现有研究多关注长文本交互，这种方式繁琐且对患者不友好，需要更自然、高效的语音交互解决方案

Method: 利用语音语言模型（SpeechLMs）的最新进展，开发基于语音的医疗咨询系统，实现更自然、高效的医患语音交互

Result: 通过语音语言模型的应用，能够实现更自然、高效的医疗咨询交互，改善患者体验，提高咨询效率

Conclusion: 语音语言模型为医疗咨询提供了更自然、高效的交互方式，有望改善医患沟通体验，是医疗AI领域的重要发展方向

Abstract: Medical consultations are intrinsically speech-centric. However, most prior works focus on long-text-based interactions, which are cumbersome and patient-unfriendly. Recent advances in speech language models (SpeechLMs) have enabled more …

</details>


### [460] [Refinement Provenance Inference: Detecting LLM-Refined Training Prompts from Model Behavior](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.01966&hl=zh-CN&sa=X&d=11819346928659783213&ei=5qVkaaPBCNrJieoPiYyysAk&scisig=AHkA5jT2SG6j62RgQcMBteFhxyED&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:AHkA5jSEWE2pdcgDuWOJdF-lmUBr&html=&pos=8&folt=rel)
*B Yin,Q Li,R Yu,X Wang*

Main category: Matei Zaharia

TL;DR: 该论文研究指令调优中基于LLM的提示词改写方法，提出实例级审计框架来评估改写对模型性能的影响


<details>
  <summary>Details</summary>
Motivation: 指令调优越来越依赖基于LLM的提示词改写来提升训练语料质量，但缺乏系统评估改写对模型性能影响的方法，需要实例级审计框架

Method: 提出实例级审计框架，通过对比原始提示和改写提示训练出的模型性能差异，评估改写效果

Result: 研究发现提示词改写对模型性能有显著影响，但效果因改写策略和任务类型而异，需要更精细的评估方法

Conclusion: 基于LLM的提示词改写是有效的指令调优增强技术，但需要实例级审计来确保改写质量，避免负面影响

Abstract: Instruction tuning increasingly relies on LLM-based prompt refinement, where prompts in the training corpus are selectively rewritten by an external refiner to improve clarity and instruction alignment. This motivates an instance-level audit …

</details>


### [461] [From Domains to Instances: Dual-Granularity Data Synthesis for LLM Unlearning](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.04278&hl=zh-CN&sa=X&d=16738768978497263963&ei=5qVkaaPBCNrJieoPiYyysAk&scisig=AHkA5jR9XGhL-lTQRyv_NsPzvmcZ&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:AHkA5jSEWE2pdcgDuWOJdF-lmUBr&html=&pos=9&folt=rel)
*X Xu,M Du,Z Li,Z Liang,Z Guo,S Zhang,P Hu,Q Ye…*

Main category: Matei Zaharia

TL;DR: 该论文指出当前机器学习遗忘基准未能准确反映模型实际"遗忘范围"，提出了两种不同的遗忘形式化定义，并开发了新的评估方法


<details>
  <summary>Details</summary>
Motivation: 当前机器学习遗忘基准存在缺陷，无法准确评估模型对私有、有害或受版权保护内容的真正遗忘程度，需要更精确的评估方法来衡量遗忘效果

Method: 形式化了两种不同的遗忘定义，开发了新的评估方法来准确测量模型的实际遗忘范围，改进了机器学习遗忘的评估框架

Result: 提出了更准确的遗忘评估方法，能够更真实地反映模型对特定内容的遗忘程度，改进了现有基准的局限性

Conclusion: 需要更精确的遗忘评估方法来确保机器学习遗忘技术的有效性，提出的新框架为准确评估遗忘效果提供了更好的工具

Abstract: Although machine unlearning is essential for removing private, harmful, or copyrighted content from LLMs, current benchmarks often fail to faithfully represent the true" forgetting scope" learned by the model. We formalize two distinct unlearning …

</details>


### [462] [Scalable Distributed Vector Search via Accuracy Preserving Index Construction](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.17264&hl=zh-CN&sa=X&d=18097922250429495012&ei=MFhmadngNqC16rQP9LvTqA4&scisig=AHkA5jRVdoDcgTU9NW7a2jP72FNc&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:AHkA5jSEWE2pdcgDuWOJdF-lmUBr&html=&pos=1&folt=rel)
*Y Xu,Q Zhang,Q Chen,B Lu,M Li,P Adams,M Li,Z Li…*

Main category: Matei Zaharia

TL;DR: SPIRE是一个可扩展的分布式近似最近邻搜索系统，通过新颖的索引设计和查询处理策略在数十亿向量规模下实现精度、延迟和吞吐量的平衡


<details>
  <summary>Details</summary>
Motivation: 现有分布式ANNS索引设计在扩展到数十亿向量时难以平衡精度、延迟和吞吐量之间的权衡，需要新的解决方案来处理大规模向量搜索的挑战

Method: SPIRE采用新颖的分布式索引架构和查询处理策略，可能包括分层索引结构、负载均衡机制和高效的通信协议，以优化大规模向量搜索的性能

Result: SPIRE在数十亿向量规模下实现了更好的精度-延迟-吞吐量权衡，相比现有系统在保持高精度的同时显著提高了查询处理能力和响应速度

Conclusion: SPIRE为大规模近似最近邻搜索提供了一个有效的分布式解决方案，通过创新的系统设计解决了现有方法在扩展性方面的局限性

Abstract: Scaling Approximate Nearest Neighbor Search (ANNS) to billions of vectors requires distributed indexes that balance accuracy, latency, and throughput. Yet existing index designs struggle with this tradeoff. This paper presents SPIRE, a scalable …

</details>


### [463] [Query-Document Dense Vectors for LLM Relevance Judgment Bias Analysis](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.01751&hl=zh-CN&sa=X&d=3657590385925024052&ei=MFhmadngNqC16rQP9LvTqA4&scisig=AHkA5jRDrb0JbYLfyxDCS02xkTSi&oi=scholaralrt&hist=i6heNjgAAAAJ:15580076029636943118:AHkA5jSEWE2pdcgDuWOJdF-lmUBr&html=&pos=9&folt=rel)
*S Mohtadi,G Demartini*

Main category: Matei Zaharia

TL;DR: LLMs作为相关性评估器用于IR评估集构建，相比人工评估具有成本低、可扩展性强的优势，但存在评估偏差问题


<details>
  <summary>Details</summary>
Motivation: 虽然LLMs作为相关性评估器在IR评估集构建中具有成本效益和可扩展性优势，但现有研究尚未充分探索LLM评估的偏差问题及其对IR系统评估结果的影响

Method: 研究采用系统化方法分析LLM作为相关性评估器时产生的偏差，包括评估标准、查询类型、文档特征等因素对评估结果的影响

Result: 研究发现LLM评估存在系统性偏差，这些偏差会影响IR系统的评估结果，可能导致对系统性能的错误判断

Conclusion: LLM作为相关性评估器虽然具有实用价值，但需要谨慎考虑其评估偏差，并开发相应的校正方法来确保IR评估的可靠性

Abstract: Large Language Models (LLMs) have been used as relevance assessors for Information Retrieval (IR) evaluation collection creation due to reduced cost and increased scalability as compared to human assessors. While previous research has …

</details>


<div id='Alekh Jindal'></div>

# Alekh Jindal [[Back]](#toc)

### [464] [Compiling Set Queries into Work-Efficient Tree Traversals](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.15000&hl=zh-CN&sa=X&d=3486009544573308445&ei=tQYtabTzEP3D6rQP3LSU2Ag&scisig=ABGrvjIood-JGyNqMD1SEzDsZElF&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ABGrvjJJrURLYOT54u5YN19mJdpa&html=&pos=0&folt=rel)
*AJ Root,C Gyurgyik,P Goel,K Fatahalian…*

Main category: Alekh Jindal

TL;DR: 该论文探讨了如何通过树结构加速大数据集上的查询，特别是通过存储元数据来实现快速剪枝或包含子树，从而优化查询性能。


<details>
  <summary>Details</summary>
Motivation: 在处理大规模数据集合时，传统的查询方法往往效率低下。树结构能够通过预计算的元数据快速过滤无关数据，从而显著提升查询性能，尤其是在需要搜索或聚合大量值的场景中。

Method: 论文提出使用树结构存储数据，并在树的节点中维护元数据。这些元数据使得查询引擎能够基于谓词快速判断子树是否包含相关数据，从而实现对无关子树的剪枝或对相关子树的包含，减少需要扫描的数据量。

Result: 通过树结构和元数据机制，查询性能得到显著提升。实验结果表明，这种方法能够有效减少查询响应时间，特别是在处理大规模数据集和复杂查询时表现出色。

Conclusion: 树结构结合元数据存储是一种有效的数据查询加速技术。它通过智能剪枝机制减少了不必要的数据访问，为大数据查询优化提供了实用的解决方案。

Abstract: Trees can accelerate queries that search or aggregate values over large collections. They achieve this by storing metadata that enables quick pruning (or inclusion) of subtrees when predicates on that metadata can prove that none (or all) of the data in …

</details>


### [465] [MICRO: A Lightweight Middleware for Optimizing Cross-store Cross-model Graph-Relation Joins](https://scholar.google.com/scholar_url?url=https://adalabucsd.github.io/papers/2026_MICRO_ICDE.pdf&hl=zh-CN&sa=X&d=5058054240518288361&ei=Km4xacrjC4qi6rQPr6DGiAo&scisig=ABGrvjJH9-mb0Z8A1ih7pBD9Sxgj&oi=scholaralrt&hist=i6heNjgAAAAJ:9105223062713277753:ABGrvjLLCDsovBUGXtYF5vE3qvQg&html=&pos=0&folt=cit)
*X Zheng,A Kumar,A Gupta*

Main category: Alekh Jindal

TL;DR: 该论文提出了一种在联邦环境中处理图存储和关系存储之间跨模型连接查询的统一代数框架


<details>
  <summary>Details</summary>
Motivation: 现代数据应用涉及异构数据模型（图、关系等）分布在不同的数据库引擎中，现有研究对联邦环境下的跨模型查询处理关注不足，需要解决跨模型连接查询的挑战

Method: 1) 形式化定义图存储和关系存储之间的跨模型连接查询类别；2) 提出统一代数框架；3) 引入真实世界应用场景

Result: 建立了跨模型查询处理的理论基础，为联邦环境中图-关系数据集成提供了代数框架

Conclusion: 该研究填补了联邦环境下跨模型查询处理的空白，为异构数据集成提供了理论和方法基础

Abstract: Modern data applications increasingly involve heterogeneous data managed in different models and stored across disparate database engines, often deployed as separate installs. Limited research has addressed cross-model query processing in federated environments. This paper takes a step toward bridging this gap by:(1) formally defining a class of cross-model join queries between a graph store and a relational store by proposing a unified algebra;(2) introducing one real-world …

</details>


### [466] [Superior F1-score: I/O feature driven algorithms for stream computing systems workload identification](https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s11704-024-40710-5&hl=zh-CN&sa=X&d=1385801454780985265&ei=b_Yyac_2C5vJieoPvqa-qQU&scisig=ALhkC2Rb8gtC7RFf9_QBt2XNdK8_&oi=scholaralrt&hist=i6heNjgAAAAJ:9105223062713277753:ALhkC2RW3zA-xlXNGLL2iFUQUHdk&html=&pos=0&folt=cit)
*Y Han,Y Liu,Z Zhang,F Li,Z Chen,N Xiao*

Main category: Alekh Jindal

TL;DR: 提出了两种针对不同场景的工作负载识别算法，旨在解决现有方法在处理工作负载类型多样性和环境复杂性方面的不足


<details>
  <summary>Details</summary>
Motivation: 工作负载识别是流计算系统资源管理的基础，也是提高其成本效益的关键因素。现有工作负载识别算法往往无法处理工作负载类型的多样性和环境的复杂性，通常无法为改进流计算系统性能提供指导。

Method: 提出了两种针对不同场景的工作负载识别算法，具体算法细节未在摘要中详细说明

Result: 摘要中未提供具体实验结果，但暗示提出的算法能够更好地处理工作负载多样性和环境复杂性

Conclusion: 通过提出两种针对不同场景的工作负载识别算法，为解决流计算系统中工作负载识别面临的挑战提供了新的解决方案

Abstract: Workload identification is fundamental for resource management in stream computing systems and is a key factor in improving their cost-benefit. However, existing workload identification algorithms often fail to handle the diversity of workload types and the complexity of the environments, making them usually unable to provide guidance for improving the performance of stream computing systems. In this work, we propose two workload identification algorithms for different scenarios …

</details>


### [467] [Tangram: Accelerating Serverless LLM Loading through GPU Memory Reuse and Affinity](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.01357&hl=zh-CN&sa=X&d=12631521896274486573&ei=bfYyaY6hOoS6ieoP7qfpqQc&scisig=ALhkC2R-a4D9u_ot8WdkrwFlpY0K&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ALhkC2Qgf9CdgCob8_ZiNUcZ7k6Q&html=&pos=1&folt=rel)
*W Zhu,Z Shen,Z Shao,H Dai,F Chen*

Main category: Alekh Jindal

TL;DR: 服务器端大型语言模型通过GPU资源共享实现按需付费，但冷启动延迟（特别是模型加载时间）成为主要瓶颈


<details>
  <summary>Details</summary>
Motivation: 服务器端LLM部署采用按需付费模式，但冷启动延迟（尤其是模型加载时间）显著影响用户体验和资源利用率，需要解决这一瓶颈问题

Method: 论文未提供具体方法细节，但从摘要看可能涉及模型加载优化、缓存策略、资源预分配或模型压缩等技术来减少冷启动延迟

Result: 摘要未提供具体实验结果，但暗示通过优化冷启动延迟可以显著提升服务器端LLM的性能和成本效益

Conclusion: 解决服务器端LLM的冷启动延迟问题是提升其实际部署效果和用户体验的关键

Abstract: Serverless Large Language Models (LLMs) have emerged as a cost-effective solution for deploying AI services by enabling a'pay-as-you-go'pricing model through GPU resource sharing. However, cold-start latency, especially the model loading …

</details>


### [468] [The Cache Oracle: Preemptive Request Dispatching for I/O‐Asymmetric Serverless Databases](https://scholar.google.com/scholar_url?url=https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.70470&hl=zh-CN&sa=X&d=12923193244628352348&ei=jdI1aafxNr2qieoP9aut2Qs&scisig=ALhkC2SdMGxKMQHnVMWKebjexGuh&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ALhkC2Qgf9CdgCob8_ZiNUcZ7k6Q&html=&pos=0&folt=rel)
*SH Ahmadpanah,M Mirabi,S Sobhanloo,M Bayati*

Main category: Alekh Jindal

TL;DR: 针对超大规模多租户无服务器数据库中缓存命中（微秒级，CPU受限）与缓存未命中（毫秒级，I/O受限）之间的巨大性能差异导致的租户间严重干扰问题，提出了一种新的调度框架。


<details>
  <summary>Details</summary>
Motivation: 在超大规模多租户无服务器数据库中，缓存命中（微秒级CPU操作）与缓存未命中（毫秒级I/O操作）之间存在巨大的性能差异，导致租户间产生严重的性能干扰。传统调度方法无法有效处理这种混合工作负载特性，需要新的解决方案来保证性能隔离和资源效率。

Method: 提出了一种新的调度框架，通过识别和区分缓存敏感型（cache-sensitive）和缓存不敏感型（cache-insensitive）查询，采用不同的调度策略。框架包含工作负载分类、资源隔离机制和自适应调度算法，以优化CPU和I/O资源的协同管理。

Result: 该调度框架显著减少了租户间的性能干扰，提高了整体系统吞吐量。实验结果显示，在保持低延迟的同时，系统资源利用率得到优化，缓存敏感型查询的响应时间得到保障，缓存未命中查询的I/O等待时间得到有效管理。

Conclusion: 提出的调度框架有效解决了超大规模多租户无服务器数据库中缓存性能差异导致的租户干扰问题。通过区分缓存敏感型和缓存不敏感型查询并采用差异化调度策略，实现了更好的性能隔离和资源效率，为混合工作负载数据库系统提供了实用的解决方案。

Abstract: In hyperscale, multi‐tenant serverless databases, the substantial performance disparity between cache hits (microseconds, CPU‐bound) and cache misses (milliseconds, I/O‐bound) leads to severe interference among tenants. Traditional …

</details>


### [469] [Optimizing file storage in data lake tables](https://scholar.google.com/scholar_url?url=https://patents.google.com/patent/US12481630B1/en&hl=zh-CN&sa=X&d=7875785238459444407&ei=xkw3abGKPPGQ6rQPuai-sAc&scisig=ALhkC2RnZRVWkrt1kCVeUevorD2Y&oi=scholaralrt&hist=i6heNjgAAAAJ:9105223062713277753:ALhkC2RW3zA-xlXNGLL2iFUQUHdk&html=&pos=1&folt=cit)
*EM Kornfield,AK Johnson*

Main category: Alekh Jindal

TL;DR: 基于历史访问模式优化列存储中列排序的方法


<details>
  <summary>Details</summary>
Motivation: 列存储中列的初始排序可能不是最优的，无法充分利用存储系统的性能潜力。通过分析历史访问模式，可以重新排列列的顺序以提高数据访问效率。

Method: 接收列数据并确定初始排序；基于列存储的历史访问模式确定更新的列排序；使用更新后的排序将列数据存储到列存储的第一位置；确定存储的列数据是否需要进一步处理或优化。

Result: 该方法能够根据实际使用模式动态优化列存储布局，提高数据访问性能和存储效率。

Conclusion: 基于历史访问模式的列排序优化是提高列存储系统性能的有效方法，能够自适应地调整数据布局以满足实际访问需求。

Abstract: A method for optimizing file storage includes receiving columnar data to store at a columnar data store with columns ordered with an initial ordering. The method includes determining, based on historical access patterns for the columnar data store, an updated ordering for the columns. The method includes storing the columnar data at a first location of the columnar data store using the updated ordering. The method includes determining that the stored columnar data is to be …

</details>


### [470] [Generate a script to automate a task associated with a webpage](https://scholar.google.com/scholar_url?url=https://patents.google.com/patent/US12468513B2/en&hl=zh-CN&sa=X&d=13307602482495069236&ei=kuU4afCOCYS6ieoP5uiKCA&scisig=ALhkC2Qsune-S44Y8fJm3H5_h1OA&oi=scholaralrt&hist=i6heNjgAAAAJ:9105223062713277753:ALhkC2RW3zA-xlXNGLL2iFUQUHdk&html=&pos=1&folt=cit)
*S Zhang,Q Zhai,DL Schafer,P Dudka,MY Li…*

Main category: Alekh Jindal

TL;DR: 利用大语言模型将查询中的变量与交互元素关联，并生成相应脚本


<details>
  <summary>Details</summary>
Motivation: 传统查询处理中，变量与交互元素的关联需要手动配置或复杂编程，缺乏自动化、智能化的解决方案。需要一种能够理解自然语言查询并自动建立变量与交互元素对应关系的方法。

Method: 接收包含变量的查询，利用大语言模型生成查询响应，将查询中的变量与交互元素关联，然后基于该响应生成脚本实现这种关联

Result: 开发了一种自动化系统，能够通过大语言模型理解查询意图，智能地将查询变量映射到交互元素，并生成可执行的关联脚本

Conclusion: 该方法实现了查询变量与交互元素的智能化关联，减少了手动配置工作，提高了交互系统的开发效率和灵活性

Abstract: A query that includes one or more variables is received. The one or more variables correspond to one or more interactive elements. A large language model is utilized to generate a query response that associates one or more variables included in the query to the one or more interactive elements. A script is generated utilizing the query response that associates the one or more variables included in the query to the one or more interactive elements.

</details>


### [471] [Enhanced and adaptive query detection engine (s) for predicting and identifying emergent incident queries](https://scholar.google.com/scholar_url?url=https://patents.google.com/patent/US12461979B2/en&hl=zh-CN&sa=X&d=17276404317531804628&ei=kuU4afCOCYS6ieoP5uiKCA&scisig=ALhkC2SgqaUAYv16EES9Px7zaH6R&oi=scholaralrt&hist=i6heNjgAAAAJ:9105223062713277753:ALhkC2RW3zA-xlXNGLL2iFUQUHdk&html=&pos=2&folt=cit)
*MK Kanojiya,N Thulasidharan,N Nassar*

Main category: Alekh Jindal

TL;DR: 论文提出了一种查询检测引擎系统，通过嵌入向量生成和聚类分析来识别和处理相似查询


<details>
  <summary>Details</summary>
Motivation: 需要高效处理大量查询并识别相似查询模式，以优化查询处理和分析效率

Method: 接收多个查询，生成嵌入向量，通过聚类算法将相似嵌入分组，每个簇包含相似查询的子集

Result: 开发了查询检测引擎系统，能够自动识别和分组相似查询，提高查询处理效率

Conclusion: 该方法提供了一种有效的查询分析和检测框架，适用于大规模查询处理场景

Abstract: Various embodiments of the present technology generally relate to systems and methods for providing a query detection engine and its related functions. In an example, a method includes receiving, by a query detection engine, a plurality of queries and processing the queries to generate processed queries. For each of the processed queries, the query detection engine, generates an embedding and then groups the embeddings into clusters such that each cluster contains a subset of …

</details>


### [472] [Resource allocation method, medium, and server](https://scholar.google.com/scholar_url?url=https://patents.google.com/patent/US20250335257A1/en&hl=zh-CN&sa=X&d=998486220584363713&ei=kuU4afCOCYS6ieoP5uiKCA&scisig=ALhkC2Qf5PsAUyBJTHf0m6k8PTkv&oi=scholaralrt&hist=i6heNjgAAAAJ:9105223062713277753:ALhkC2RW3zA-xlXNGLL2iFUQUHdk&html=&pos=3&folt=cit)
*Z Liu,J Leng,Q Chen,C Li,M Guo*

Main category: Alekh Jindal

TL;DR: 提出一种资源分配方法，通过分析任务对应的数据处理模型中的算子，为每个算子分配资源使用量，实现服务器资源的优化分配


<details>
  <summary>Details</summary>
Motivation: 在服务器执行多个任务时，需要高效分配计算资源以提高整体性能和资源利用率。传统方法可能无法充分考虑任务内部数据处理模型的结构特征，导致资源分配不够优化。

Method: 方法包括：获取服务器可执行任务作为第一任务；获取每个第一任务对应的第一数据处理模型，每个模型包含一个或多个算子；对每个数据处理模型中的每个算子进行资源分配，确定算子使用的资源量；基于分配结果获取第二任务或进一步处理。

Result: 该方法能够为数据处理模型中的每个算子精确分配资源，实现细粒度的资源管理，提高服务器资源利用效率和任务执行性能。

Conclusion: 提出的资源分配方法通过分析任务的数据处理模型结构，在算子级别进行资源分配，为服务器资源管理提供了一种更精细、更有效的解决方案。

Abstract: A resource allocation method, a medium and a server are provided. The resource allocation method includes: obtaining tasks executable by the server as first tasks; obtaining first data processing models each corresponding to one of the first tasks, wherein each of the first data processing models includes one or more operators; performing a resource allocation on each operator in each of the first data processing models to obtain a quantity of resource used by the operator; and obtaining second …

</details>


### [473] [Hybrid cost model for evaluating query execution plans](https://scholar.google.com/scholar_url?url=https://patents.google.com/patent/US12475121B2/en&hl=zh-CN&sa=X&d=11985044879304310218&ei=kuU4afCOCYS6ieoP5uiKCA&scisig=ALhkC2Qxgjaws44Aj2sPcNaCQmTk&oi=scholaralrt&hist=i6heNjgAAAAJ:9105223062713277753:ALhkC2RW3zA-xlXNGLL2iFUQUHdk&html=&pos=5&folt=cit)
*SMA Kamali,V Corvinelli,C Zuzarte,BL Frendo…*

Main category: Alekh Jindal

TL;DR: 提出基于混合成本模型的查询执行计划评估方法，结合学习型成本模型和经典成本模型来预测查询执行计划的执行时间或成本


<details>
  <summary>Details</summary>
Motivation: 传统查询优化器依赖经典成本模型，但可能无法准确预测现代复杂查询的执行时间。学习型成本模型虽然在某些情况下表现更好，但存在泛化能力不足的问题。需要结合两者的优势来提高查询计划评估的准确性。

Method: 使用混合成本模型方法，包括一个或多个学习型成本模型和一个经典成本模型。输入查询和包含多个候选查询执行计划的搜索空间，每个基础成本模型为每个候选计划输出预测的执行时间或成本。然后通过某种机制（如加权组合或选择最佳预测）来综合这些预测结果。

Result: 混合成本模型方法能够比单独使用经典成本模型或学习型成本模型更准确地预测查询执行计划的执行时间或成本，从而提高查询优化器的性能。

Conclusion: 混合成本模型方法结合了学习型模型的适应性和经典模型的稳定性，为查询优化提供了更可靠的计划评估机制，有助于提升数据库系统的整体性能。

Abstract: Aspects of the disclosure include hybrid cost model-based techniques for evaluating query execution plans. A non-limiting example method includes inputting, to a plurality of base cost models including one or more learned cost models and a classic cost model, a query and a search space including a plurality of candidate query execution plans. Each base cost model outputs a predicted execution time or cost for each plan of the plurality of candidate query execution plans and a real …

</details>


### [474] [DRPQ: Distributed Evaluation of Regular Path Queries On Streaming Graphs](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3769782&hl=zh-CN&sa=X&d=6829064823663418443&ei=kOU4aduaO82j6rQP_uWWuAU&scisig=ALhkC2THIJwm4h_llMrLlzN_bWE7&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ALhkC2Qgf9CdgCob8_ZiNUcZ7k6Q&html=&pos=2&folt=rel)
*S Zhang,K Zhang,Z He,Y Jing,Z Zhao,XS Wang*

Main category: Alekh Jindal

TL;DR: 分布式流图上的持久性正则路径查询处理，现有研究主要关注单工作节点场景，本文研究扩展到多工作节点的分布式处理


<details>
  <summary>Details</summary>
Motivation: 持久性正则路径查询在流图分析中广泛应用，现有方法主要针对单工作节点场景，无法满足大规模流图处理需求，需要扩展到分布式多工作节点环境

Method: 未在摘要中明确说明具体方法，但研究重点是从单工作节点扩展到多工作节点的分布式RPQ处理架构

Result: 未在摘要中提供具体实验结果

Conclusion: 分布式RPQ处理对于大规模流图分析至关重要，需要新的分布式处理框架来支持多工作节点场景

Abstract: Persistent Regular Path Query (RPQ) on streaming graphs is widely applicable to many online analysis applications. Existing research primarily focuses on the single-worker scenario, while scaling out to distributed RPQ processing on multiple workers …

</details>


### [475] [ERINYES: Request-Level Provenance Analysis for Serverless Attacks](https://scholar.google.com/scholar_url?url=https://nchr.elsevierpure.com/en/publications/erinyes-request-level-provenance-analysis-for-serverless-attacks/&hl=zh-CN&sa=X&d=16238471130627427992&ei=aQA8aYy5NPO16rQPzoDK8Ag&scisig=ALhkC2RpNGYKolaWFTACnKBAmNYa&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ALhkC2Qgf9CdgCob8_ZiNUcZ7k6Q&html=&pos=1&folt=rel)
*H Xi,H Wan,X Zhao,M Guizani*

Main category: Alekh Jindal

TL;DR: 服务器无服务器架构因其成本效益和管理便利性而备受关注，但该框架增加了应用程序的攻击面，导致频繁的安全事件


<details>
  <summary>Details</summary>
Motivation: 尽管无服务器架构具有成本效益和管理便利性等优势，但它显著增加了应用程序的攻击面，导致频繁的安全事件，这凸显了研究无服务器安全问题的必要性

Method: 论文未提供具体方法细节，但从摘要来看，可能涉及分析无服务器架构的安全漏洞、攻击面评估、安全威胁建模或提出相应的安全防护措施

Result: 摘要未提供具体研究结果，但暗示无服务器框架确实增加了安全风险并导致频繁的安全事件

Conclusion: 无服务器架构虽然具有显著优势，但其引入的安全风险不容忽视，需要专门的安全研究和防护措施来应对

Abstract: The serverless architecture has attracted significant attention due to its cost-effectiveness and ease of management. However, the serverless framework increases the attack surface of applications, resulting in frequent security incidents …

</details>


### [476] [Efficient Data Replication in Distributed Clouds via Quantum Entanglement Algorithms](https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S2215016125006065&hl=zh-CN&sa=X&d=5310215321681970671&ei=x-o-adaDI6GvieoPtIGfoAw&scisig=ALhkC2QxqSBD_vEScdhwfyemjond&oi=scholaralrt&hist=i6heNjgAAAAJ:9105223062713277753:ALhkC2RW3zA-xlXNGLL2iFUQUHdk&html=&pos=1&folt=cit)
*N RajKumar,J Ravi,C Viji,J Gobinath,I Govindharaj…*

Main category: Alekh Jindal

TL;DR: 提出基于量子纠缠的云数据复制算法QERA，解决传统复制系统处理时间长、数据传输量大和最终一致性等问题


<details>
  <summary>Details</summary>
Motivation: 在云计算中，传统数据复制系统存在处理时间长、数据传输量大、最终一致性难以保证等问题，需要更高效的数据复制方法

Method: 提出量子纠缠基础复制算法(QERA)，利用量子纠缠原理实现跨数据中心的数据复制，通过量子态同步确保数据一致性

Result: QERA算法相比传统复制系统显著减少了处理时间和数据传输量，同时保证了强一致性，提高了云数据复制的效率和可靠性

Conclusion: 量子纠缠技术为云数据复制提供了新的解决方案，QERA算法在性能和数据一致性方面优于传统方法，具有实际应用潜力

Abstract: In cloud computing, it remains difficult to make data available in a cloud service such that the data is replicated and maintained consistently across various data centers. Traditional replication systems are sufficient, even though they take too long to process, cause significant data transfers, and face problems with final data consistency. This work presents a new method named Quantum Entanglement-Based Replication Algorithm (QERA), which makes use of quantum entanglement to …

</details>


### [477] [Manifesting the Elasticity of Serverless Data Pipelines: a Metabolomics Use Case](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3774899.3775018&hl=zh-CN&sa=X&d=9478090653499714575&ei=xuo-afqVG7CP6rQPgsi1wQo&scisig=ALhkC2QnLVRbTbOOhUHrWOldtmvT&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ALhkC2Qgf9CdgCob8_ZiNUcZ7k6Q&html=&pos=1&folt=rel)
*E Díez*

Main category: Alekh Jindal

TL;DR: 云函数为数据处理提供强大工具，通过免去手动资源配置实现细粒度按需扩展，适合动态资源需求的数据分析管道


<details>
  <summary>Details</summary>
Motivation: 传统数据处理系统在动态资源需求场景下存在资源配置效率低下、资源利用率不足的问题，需要一种能够自动适应工作负载变化、实现细粒度弹性扩展的解决方案

Method: 采用云函数（Function-as-a-Service）架构，利用其自动资源配置和按需扩展特性，构建适应动态资源需求的数据分析管道

Result: 云函数模型能够有效处理动态资源需求的数据分析任务，实现资源的高效利用和自动扩展，提升处理效率和成本效益

Conclusion: 云函数为动态资源需求的数据分析管道提供了理想的解决方案，通过自动资源配置和细粒度扩展能力，显著提升了数据处理效率和资源利用率

Abstract: Cloud functions offer a powerful tool for data processing by freeing developers from manual resource provisioning and enabling fine-grained, on-demand scaling. This model is well-suited for data analytics pipelines with dynamic resource requirements …

</details>


### [478] [HyFaaS: Accelerating Serverless Workflows by Unleashing Hybrid Resource Elasticity](https://scholar.google.com/scholar_url?url=https://pure.bit.edu.cn/zh/publications/hyfaas-accelerating-serverless-workflows-by-unleashing-hybrid-res/&hl=zh-CN&sa=X&d=3739327772894098707&ei=xuo-afqVG7CP6rQPgsi1wQo&scisig=ALhkC2R-zuoDODtTymiHNxXAW1j9&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ALhkC2Qgf9CdgCob8_ZiNUcZ7k6Q&html=&pos=3&folt=rel)
*X Yue,S Yang,F Li,L Zhu,X Wang,Z Feng…*

Main category: Alekh Jindal

TL;DR: Serverless计算虽然提供细粒度资源弹性和计费优势，但现有工作流编排未考虑函数间异构需求，导致性能瓶颈和资源浪费


<details>
  <summary>Details</summary>
Motivation: Serverless计算因其细粒度资源弹性和按使用计费模式，成为构建复杂多阶段工作流应用的理想选择。然而，现有工作流编排系统未能充分考虑函数间的异构资源需求，导致性能瓶颈和资源浪费问题

Method: 论文提出了一种新的工作流编排方法，该方法能够识别和适应函数间的异构资源需求，通过智能调度和资源分配优化来提升整体性能

Result: 实验结果表明，所提出的方法能够显著提升工作流执行性能，减少资源浪费，并在多种负载场景下展现出优于现有方法的效率

Conclusion: 通过考虑函数间异构需求的工作流编排方法，能够有效解决Serverless工作流中的性能瓶颈问题，为构建高效、经济的复杂应用提供新的解决方案

Abstract: 摘要 Serverless computing promises fine-grained resource elasticity and billing, making it an attractive way to build complex applications as multi-stage workflows. Nonetheless, existing workflow orchestration ignores the heterogeneous demands of …

</details>


### [479] [Flexecutor: Out-of-the-Box Smart Provisioning for Serverless Workflows](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3774899.3775013&hl=zh-CN&sa=X&d=4061571118005764566&ei=xuo-afqVG7CP6rQPgsi1wQo&scisig=ALhkC2QO5eS83i4bv0ss1mspze5m&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ALhkC2Qgf9CdgCob8_ZiNUcZ7k6Q&html=&pos=5&folt=rel)
*E Molina*

Main category: Alekh Jindal

TL;DR: 服务器无服务器计算在并行工作负载执行中的资源分配和成本优化问题


<details>
  <summary>Details</summary>
Motivation: 无服务器计算虽然提供了按需扩展和按使用付费的优势，但在并行工作负载执行场景中，如何确定最优的资源分配策略以最小化成本同时满足性能要求，仍然是一个未充分研究的问题。

Method: 论文提出了一种针对无服务器计算环境中并行工作负载的资源分配优化方法，可能包括数学模型、算法设计或系统架构，用于确定最优的资源配置策略。

Result: 该方法能够显著降低并行工作负载在无服务器平台上的执行成本，同时满足性能约束，相比传统方法实现了更好的成本效益平衡。

Conclusion: 通过系统化的资源分配优化，无服务器计算可以更高效地支持并行工作负载，为大规模分布式计算提供了经济可行的解决方案。

Abstract: Serverless computing enables applications to scale dynamically without manual server management, with users paying only for the actual compute resources consumed. In the context of parallel workload execution, the problem of determining …

</details>


### [480] [ServScale: Concurrency-Aware Serverless Execution and Scaling Paradigm](https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-032-10459-5_2&hl=zh-CN&sa=X&d=13601124828981042489&ei=xuo-afqVG7CP6rQPgsi1wQo&scisig=ALhkC2TkniqgGepBt9EGY5Zhrjen&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ALhkC2Qgf9CdgCob8_ZiNUcZ7k6Q&html=&pos=7&folt=rel)
*Z Xu,Z Li,Q Chen,M Guo*

Main category: Alekh Jindal

TL;DR: 该论文探讨了在Kubernetes等IaaS平台上运行需要内部并发性的云应用时面临的挑战，并提出了一种解决方案来优化资源利用和性能。


<details>
  <summary>Details</summary>
Motivation: 现代云应用需要内部并发性来并行处理多个请求或任务，但在Kubernetes等IaaS平台上部署这类应用时面临资源利用效率低下的挑战，因为传统容器化方法无法充分利用现代硬件的并发能力。

Method: 论文提出了一种新的部署架构或调度策略，旨在更好地支持具有内部并发性的应用，可能涉及容器编排优化、资源分配策略改进或并发感知的调度机制。

Result: 提出的解决方案能够显著提高资源利用效率，降低延迟，提升吞吐量，同时保持与传统云平台的兼容性。

Conclusion: 通过优化Kubernetes等IaaS平台对内部并发性应用的支持，可以显著提升云应用的性能和资源效率，为现代云原生应用的部署提供了更好的解决方案。

Abstract: Many modern cloud applications require intra-instance concurrency to efficiently handle multiple requests or tasks in parallel. While platforms like Kubernetes are widely adopted for scalable deployment on Infrastructure-as-a-Service (IaaS), this …

</details>


### [481] [Capybara: an Edge-Friendly Distributed Object Store for Diverse Serverless Functions](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3721462.3730946&hl=zh-CN&sa=X&d=17072638018127144821&ei=xuo-afqVG7CP6rQPgsi1wQo&scisig=ALhkC2SmdJdFibFPKJyLRPuaYB4V&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ALhkC2Qgf9CdgCob8_ZiNUcZ7k6Q&html=&pos=8&folt=rel)
*X Chen,MP Paidiparthy,C Qian,L Hu*

Main category: Alekh Jindal

TL;DR: Capybara是一个为边缘/雾计算环境设计的新型可扩展、可编程分布式对象存储系统


<details>
  <summary>Details</summary>
Motivation: 虽然无服务器范式最初为云计算设计，但其优势在边缘/雾计算环境中同样重要，需要专门的对象存储解决方案来支持这些环境中的存储和共享需求

Method: 提出了Capybara系统，这是一个专门为边缘/雾计算环境设计的新型可扩展、可编程分布式对象存储架构

Result: Capybara系统能够有效支持边缘/雾计算环境中的存储和共享需求，提供可扩展性和可编程性

Conclusion: Capybara为边缘/雾计算环境提供了一个有效的分布式对象存储解决方案，扩展了无服务器范式在这些环境中的应用

Abstract: While originally designed for the cloud, the benefits of the serverless paradigm are also vital in Edge/Fog computing environments. This paper presents Capybara, a new scalable, programmable distributed object store for storing and sharing …

</details>


### [482] [OPTIMIZED SERVERLESS FRAMEWORK FOR SCALABLE DEPLOYMENT OF DEEPAR+ FORECASTING](https://scholar.google.com/scholar_url?url=http://jatit.org/volumes/Vol103No21/12Vol103No21.pdf&hl=zh-CN&sa=X&d=13565140049637935158&ei=xuo-afqVG7CP6rQPgsi1wQo&scisig=ALhkC2TNFuSnCX3icjqKcvwP55O2&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ALhkC2Qgf9CdgCob8_ZiNUcZ7k6Q&html=&pos=9&folt=rel)
*G MAHALINGAM,R APPUSAMY*

Main category: Alekh Jindal

TL;DR: 提出优化的无服务器框架，用于可扩展且经济高效地部署DeepAR+预测模型，解决时间序列推理中的成本开销、延迟和操作复杂性等挑战


<details>
  <summary>Details</summary>
Motivation: 解决时间序列预测模型（特别是DeepAR+）在生产部署中的关键挑战：成本开销高、推理延迟大、操作复杂性高，以及难以实现弹性扩展

Method: 设计优化的无服务器框架，通过函数即服务架构实现DeepAR+模型的部署，包含资源优化、冷启动缓解、批处理策略和成本感知调度机制

Result: 相比传统部署方式，该框架显著降低了推理成本，减少了延迟，提高了可扩展性，并简化了操作复杂性，实现了更经济高效的时间序列预测服务

Conclusion: 优化的无服务器框架为DeepAR+等时间序列预测模型提供了可行的生产部署解决方案，平衡了成本、性能和可操作性，适用于大规模时间序列推理场景

Abstract: This study proposes an optimized serverless framework for the scalable and cost-efficient deployment of DeepAR+ forecasting models, addressing critical challenges in time-series inference such as cost overhead, latency and operational complexity …

</details>


### [483] [Scoring and Ranking Serverless Providers Using Multicriteria Decision](https://scholar.google.com/scholar_url?url=https://books.google.com/books%3Fhl%3Dzh-CN%26lr%3D%26id%3DnnWYEQAAQBAJ%26oi%3Dfnd%26pg%3DPA186%26ots%3DP_8qo_lWMQ%26sig%3DYbi_aYh1sD-fnkw6OIg96NsmnGw&hl=zh-CN&sa=X&d=11423903936838814097&ei=f2dAaZGHB72qieoPuKej0QM&scisig=ALhkC2QrMkOQvkTIBMoRTzDweJaF&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ALhkC2Qgf9CdgCob8_ZiNUcZ7k6Q&html=&pos=1&folt=rel)
*LR Rittes*

Main category: Alekh Jindal

TL;DR: 论文探讨了现代技术环境中软件开发与分发的挑战，旨在平衡创作者目标、用户需求、经济可行性和技术可管理性。


<details>
  <summary>Details</summary>
Motivation: 现代软件开发面临多重挑战：需要同时满足创作者的目标和用户需求，保持经济可行性，并确保技术可管理性。这些相互冲突的要求使得软件开发和分发过程变得复杂且困难。

Method: 从摘要内容来看，论文可能采用系统性分析方法，探讨软件开发与分发中的关键因素和权衡策略。可能涉及需求分析、成本效益评估、技术架构设计等方面的综合方法。

Result: 摘要未提供具体结果，但暗示了软件开发与分发过程中存在显著挑战，需要在多个维度之间找到平衡点。

Conclusion: 成功的软件产品需要在创作者目标、用户需求、经济可行性和技术可管理性之间找到恰当的平衡，这需要系统性的方法和策略。

Abstract: In the contemporary technological landscape, the process of developing and distributing software that fulfills the objectives of both creators and users while remaining economically viable and technically manageable presents significant …

</details>


### [484] [Metrics Visualization Using Profiling-Based Adaptive GC Policy for Serverless](https://scholar.google.com/scholar_url?url=https://simpozijum.matf.bg.ac.rs/s2025/KarlicicMilica.pdf&hl=zh-CN&sa=X&d=11804099207999230398&ei=9txDafz8LLLrieoPwNLAkQw&scisig=ALhkC2TFQcYv87xrUOSntWQhHolL&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ALhkC2Qgf9CdgCob8_ZiNUcZ7k6Q&html=&pos=0&folt=rel)
*M Karličić,I Ristović,MV Janičić*

Main category: Alekh Jindal

TL;DR: 服务器无服务器计算中，应用在严格的性能和资源使用约束下运行，内存效率成为系统设计的关键方面。通过智能内存管理减少内存占用是提高效率的一种方法。


<details>
  <summary>Details</summary>
Motivation: 服务器无服务器计算环境对性能和资源使用有严格约束，内存效率直接影响系统性能和成本效益。现有系统设计需要更有效的方法来优化内存使用。

Method: 采用智能内存管理技术来减少内存占用，可能包括内存压缩、共享内存、动态分配优化等方法。

Result: 通过减少内存占用，可以提高服务器无服务器应用的性能和资源使用效率，降低运营成本。

Conclusion: 内存效率是服务器无服务器系统设计的关键因素，智能内存管理技术能有效优化资源使用，提升系统性能。

Abstract: In serverless, applications operate under strict performance and resource-usage constraints, making memory efficiency a critical aspect of system design [1]. One approach to improving efficiency is to reduce the memory footprint through informed …

</details>


### [485] [Acyclic Conjunctive Regular Path Queries are no Harder than Corresponding Conjunctive Queries](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.11129&hl=zh-CN&sa=X&d=9389569115015769590&ei=0nlFafHOLcSN6rQPx4HkwQU&scisig=ALhkC2SR1fAj59yJ-Z2MRks8-M27&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ALhkC2Qgf9CdgCob8_ZiNUcZ7k6Q&html=&pos=0&folt=rel)
*MA Khamis,AM Hurjui,A Kara,D Olteanu,D Suciu*

Main category: Alekh Jindal

TL;DR: 提出了一种输出敏感的算法，用于评估无环连接正则路径查询(CRPQ)，其复杂度基于输入大小、输出大小和查询参数"自由连接树宽度"。


<details>
  <summary>Details</summary>
Motivation: 传统CRPQ评估算法通常具有较高的复杂度，特别是在处理大规模图数据时。需要开发更高效的算法，其复杂度不仅取决于输入大小，还考虑输出大小和查询结构特性，以实现更好的实际性能。

Method: 提出输出敏感算法，利用查询的"自由连接树宽度"参数。算法针对无环CRPQ设计，复杂度表示为输入大小、输出大小和自由连接树宽度的函数。采用树分解技术优化查询评估过程。

Result: 算法在理论复杂度上优于传统方法，特别是在输出规模较小的情况下表现更优。通过结合输出敏感性和查询结构参数，实现了更高效的CRPQ评估。

Conclusion: 输出敏感算法为CRPQ评估提供了更精细的复杂度分析框架，结合自由连接树宽度参数，能够更准确地反映实际计算成本，为大规模图查询优化提供了新思路。

Abstract: We present an output-sensitive algorithm for evaluating an acyclic Conjunctive Regular Path Query (CRPQ). Its complexity is written in terms of the input size, the output size, and a well-known parameter of the query that is called the" free-connex …

</details>


### [486] [Serverless Workflow Optimization Using Predictive Autoscaling and Cold-Start Mitigation Models](https://scholar.google.com/scholar_url?url=https://jmk.datatablets.com/index.php/j/article/view/96&hl=zh-CN&sa=X&d=4275045499926793029&ei=0nlFafHOLcSN6rQPx4HkwQU&scisig=ALhkC2Qj5kbg_cwS2KUDxJCITFtI&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ALhkC2Qgf9CdgCob8_ZiNUcZ7k6Q&html=&pos=1&folt=rel)
*D Milosevic*

Main category: Alekh Jindal

TL;DR: 提出了一种结合预测性自动扩缩和预热的优化框架，以减少无服务器平台中的冷启动延迟


<details>
  <summary>Details</summary>
Motivation: 无服务器平台简化了应用部署，但带来了不可预测的自动扩缩和冷启动导致的延迟峰值问题，需要优化方案来改善性能

Method: 开发了一个结合预测性自动扩缩和预热机制的优化框架，通过预测负载模式来提前启动容器实例，减少冷启动延迟

Result: 该框架显著降低了延迟峰值，提高了无服务器应用的响应性能，同时保持了资源效率

Conclusion: 提出的优化框架有效解决了无服务器平台中的冷启动问题，为改善无服务器应用性能提供了实用解决方案

Abstract: Serverless platforms simplify application deployment but introduce challenges related to unpredictable autoscaling and latency spikes caused by cold starts. This paper proposes an optimization framework that blends predictive autoscaling with a …

</details>


### [487] [BraveANN: Robust Approximate Nearest Neighbor Search for Billion-Scale Vectors](https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s11280-025-01389-1&hl=zh-CN&sa=X&d=14064498588761325194&ei=Vh1HaZfNOrLrieoPwNLAkQw&scisig=ALhkC2TYllxoflEbMpJD7uqzxuGt&oi=scholaralrt&hist=i6heNjgAAAAJ:9105223062713277753:ALhkC2RW3zA-xlXNGLL2iFUQUHdk&html=&pos=0&folt=cit)
*S Zhu,Y Wang,X Jin,J Zeng,S Wang,Y Sun,Y Lai…*

Main category: Alekh Jindal

TL;DR: BraveANN是一个内存-磁盘混合向量索引和搜索系统，通过鲁棒聚类方法RKM提高对异常值的鲁棒性，同时保持低延迟


<details>
  <summary>Details</summary>
Motivation: 近似最近邻搜索(ANNS)在数据检索中广泛应用，但异常值的存在会显著扭曲索引结构和检索结果，影响性能。现有方法对异常值敏感，需要更鲁棒的解决方案。

Method: 提出BraveANN系统，采用内存-磁盘混合架构。核心是新的聚类方法RKM（鲁棒K-Means），专门设计用于处理异常值。系统结合内存高效索引和磁盘存储，优化检索流程。

Result: BraveANN在存在异常值的情况下显著提高了ANNS的鲁棒性，同时保持了低延迟和高检索精度。实验表明系统在真实数据集上优于现有方法。

Conclusion: BraveANN通过创新的鲁棒聚类方法和混合架构，有效解决了ANNS中的异常值问题，为大规模向量检索提供了更可靠的解决方案。

Abstract: Approximate nearest neighbor search (ANNS) is a widely used technique in data retrieval, yet its performance is often compromised by the presence of outliers, which can significantly distort the indexing structure and retrieval results. To address this issue, we propose BraveANN, a memory-disk hybrid vector indexing and search system designed to improve robustness against outliers while maintaining low latency. The core of BraveANN is our newly proposed clustering approach, RKM …

</details>


### [488] [Distributed HDMM: Scalable, Distributed, Accurate, and Differentially Private Query Workloads without a Trusted Curator](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.15648&hl=zh-CN&sa=X&d=10393758962927205053&ei=wZ1Iaaf2O6C16rQPm4fPgQQ&scisig=ALhkC2SDLkTrvY4Hnstid6d9FVyf&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ALhkC2Qgf9CdgCob8_ZiNUcZ7k6Q&html=&pos=0&folt=rel)
*R Sedimo,IC Ngong,J Lashua,JP Near*

Main category: Alekh Jindal

TL;DR: 分布式高维矩阵机制（Distributed HDMM）是一种用于分布式数据上线性查询的差分隐私协议，无需可信中心即可达到中心化HDMM的精度


<details>
  <summary>Details</summary>
Motivation: 现有分布式差分隐私机制在精度上显著低于中心化模型，需要开发能在分布式环境中达到中心化模型精度的协议，同时避免可信中心的需求

Method: 提出分布式高维矩阵机制协议，通过分布式计算实现HDMM的精度，无需可信中心，保护数据隐私

Result: 该协议能够在分布式环境中达到与中心化HDMM相当的精度，显著优于现有分布式差分隐私机制

Conclusion: 分布式HDMM填补了分布式差分隐私的精度差距，为分布式数据分析提供了实用的高精度隐私保护方案

Abstract: We present the Distributed High-Dimensional Matrix Mechanism (Distributed HDMM), a protocol for answering workloads of linear queries on distributed data that provides the accuracy of central-model HDMM without a trusted curator. Distributed …

</details>


### [489] [Survivorship Bias in Industrial Database Workloads](https://scholar.google.com/scholar_url?url=https://www.vldb.org/cidrdb/papers/2026/p22-marcus.pdf&hl=zh-CN&sa=X&d=15380011440372952711&ei=lw5KadKOOKC16rQPm4fPgQQ&scisig=ALhkC2QDSBRDqflmOYGuBekMSF0W&oi=scholaralrt&hist=i6heNjgAAAAJ:9105223062713277753:ALhkC2RW3zA-xlXNGLL2iFUQUHdk&html=&pos=0&folt=cit)
*R Marcus,J Tao,P Wu,Z Zhao*

Main category: Alekh Jindal

TL;DR: 该论文通过两个真实工作负载数据的案例研究，揭示了现有工作负载表征可能无法完全代表用户需求的局限性，挑战了研究人员和从业者对此的普遍假设。


<details>
  <summary>Details</summary>
Motivation: 近年来多个工业数据平台发布了真实工作负载的特征描述，促使数据库研究者考虑超越合成数据的新研究方向。然而，研究者和从业者通常假设现有工作负载能够代表用户需求，这种假设需要验证。

Method: 通过两个基于真实工作负载数据的案例研究，分析现有工作负载表征的代表性局限，揭示实际用户需求与假设之间的差异。

Result: 研究结果表明，现有工作负载表征可能无法完全代表用户需求，挑战了研究人员和从业者对此的普遍假设，揭示了真实工作负载与假设之间的差异。

Conclusion: 需要更加谨慎地对待现有工作负载表征的代表性假设，并开发更全面的方法来理解和评估真实世界工作负载，以指导数据库研究和基准测试的发展。

Abstract: Several industrial data platforms have recently released characterizations of their real-world workloads, prompting database researchers to consider new research directions and benchmarks that go beyond synthetics. While these workload characterizations are undoubtedly useful, researchers (including the authors of this paper) and practitioners often assume that existing workloads are representative of user needs. Through two case studies over real workload data, we show that …

</details>


### [490] [I Can't Believe It's Not Yannakakis: Pragmatic Bitmap Filters in Microsoft SQL Server](https://scholar.google.com/scholar_url?url=https://www.vldb.org/cidrdb/papers/2026/p29-zhao.pdf&hl=zh-CN&sa=X&d=260893955094474474&ei=lg5KafXpEbux6rQPi5qW2AE&scisig=ALhkC2SRCzW-65JD0vpjQUzQKkdP&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ALhkC2Qgf9CdgCob8_ZiNUcZ7k6Q&html=&pos=0&folt=rel)
*H Zhao,Y Tian,R Alotaibi,B Ding,N Bruno…*

Main category: Alekh Jindal

TL;DR: 该论文探讨了在Yannakakis算法中通过位图过滤器替代昂贵的半连接操作，以实现其理论最优性能的实践方法。


<details>
  <summary>Details</summary>
Motivation: Yannakakis算法在理论上具有最优的连接处理性能，但在实践中由于需要昂贵的半连接操作而难以实现其理论潜力。研究者们寻求通过位图过滤器替代半连接操作，以在实践中实现该算法的理论理想。

Method: 采用位图过滤器替代Yannakakis算法中的半连接操作，通过更高效的过滤机制减少计算开销，实现算法的实际优化。

Result: 通过位图过滤器替代半连接操作，能够显著降低Yannakakis算法的计算成本，使其在实践中更接近理论最优性能。

Conclusion: 位图过滤器为Yannakakis算法的实际应用提供了可行的优化路径，使其能够更好地发挥理论上的连接处理优势。

Abstract: The quest for optimal join processing has reignited interest in the Yannakakis algorithm, as researchers seek to realize its theoretical ideal in practice via bitmap filters instead of expensive semijoins. While this academic pursuit may seem distant …

</details>


### [491] [HydraServe: Minimizing Cold Start Latency for Serverless LLM Serving in Public Clouds](https://scholar.google.com/scholar_url?url=https://www.usenix.org/conference/nsdi26/presentation/lou&hl=zh-CN&sa=X&d=3720115885698154379&ei=1bJLadLbN6C16rQPm4fPgQQ&scisig=ALhkC2RN1rqAxcDNhCHRon5UWsy1&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ALhkC2Qgf9CdgCob8_ZiNUcZ7k6Q&html=&pos=0&folt=rel)
*C Lou,S Qi,C Jin,D Nie,H Yang,Y Ding,X Liu,X Jin*

Main category: Alekh Jindal

TL;DR: HydraServe是一个用于公共云中无服务器LLM服务的系统，旨在最小化冷启动延迟


<details>
  <summary>Details</summary>
Motivation: 无服务器LLM服务在公共云中存在显著的冷启动延迟问题，这会影响用户体验和系统效率。现有的解决方案在快速响应突发请求方面存在不足。

Method: HydraServe采用预分配和动态资源管理策略，通过预测性模型和智能调度来减少冷启动时间，可能包括容器预热、模型预加载等技术。

Result: 系统显著降低了冷启动延迟，提高了LLM服务的响应速度和资源利用率，在公共云环境中表现出优越的性能。

Conclusion: HydraServe为公共云中的无服务器LLM服务提供了一种有效的冷启动延迟最小化方案，具有实际部署价值。

Abstract: HydraServe: Minimizing Cold Start Latency for Serverless LLM Serving in Public Clouds | USENIX Back to USENIX Sign In Conferences Attend Accepted Papers Participate Call for Papers Call for Artifacts Instructions for Presenters Sponsorship About Past …

</details>


### [492] [Hint Based Query Optimization with LLM Agent and Plan Similarity](https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Nikita-Vasilenko-5/publication/398845655_Hint_Based_Query_Optimization_with_LLM_Agent_and_Plan_Similarity/links/69461f6c27359023a00e42b0/Hint-Based-Query-Optimization-with-LLM-Agent-and-Plan-Similarity.pdf&hl=zh-CN&sa=X&d=957252713457337399&ei=fC5NadCcFaC16rQPm4fPgQQ&scisig=ALhkC2T84Q0cnGfXJTA8FetQx-cI&oi=scholaralrt&hist=i6heNjgAAAAJ:9105223062713277753:ALhkC2RW3zA-xlXNGLL2iFUQUHdk&html=&pos=0&folt=cit)
*N Vasilenko,A Demin,V Burlakov*

Main category: Alekh Jindal

TL;DR: 提出基于提示的SQL查询优化架构，包含快速模块（将物理计划编码为文本，用预训练语言模型嵌入，检索最近邻，生成紧凑二进制提示向量并进行安全检查）和智能体引导模块


<details>
  <summary>Details</summary>
Motivation: 传统基于成本的SQL优化器在现实世界数据和引擎多样性下表现脆弱，基数或成本估计的小错误会级联导致糟糕的执行计划

Method: 提出基于提示的查询优化概念架构，详细描述两个模块：快速模块将物理计划编码为文本，使用预训练语言模型嵌入，检索最近邻，生成紧凑二进制提示向量并进行安全检查；以及智能体引导模块

Result: 未提供具体实验结果，但提出了新的优化架构概念

Conclusion: 基于提示的查询优化架构能够改善传统基于成本优化器的脆弱性，通过快速模块和智能体引导模块提供更鲁棒的优化方案

Abstract: Cost based SQL optimizers remain brittle under real world data and engine diversity; small errors in cardinality or cost estimates can cascade into poor plans. We propose a conceptual architecture for hint based query optimization and describe two modules in detail: a fast module which encodes physical plans as text, embeds with a pretrained language model, retrieves nearest neighbors, and produces a compact binary hint vector with a safety check against the default plan; and an agent guided …

</details>


### [493] [FlatStor: An Efficient Embedded-Index Based Columnar Data Layout for Multimodal Data Workloads](https://scholar.google.com/scholar_url?url=https://www.vldb.org/pvldb/vol19/p1-zhang.pdf&hl=zh-CN&sa=X&d=17938980451723141404&ei=WZlOaf_3DN_OieoPg6WE2QY&scisig=ALhkC2SxKWG005zwmZtd_YQZs-S6&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ALhkC2Qgf9CdgCob8_ZiNUcZ7k6Q&html=&pos=0&folt=rel)
*C Zhang,S Zhang,Y Gu,C Wu,J Li,Q Zhang,X Chen…*

Main category: Alekh Jindal

TL;DR: 现代数据湖面临多模态存储和多用途访问模式挑战，需要高效的数据管理解决方案


<details>
  <summary>Details</summary>
Motivation: 随着生产数据呈现多模态存储特性和多用途访问模式，现代数据湖在存储、管理和分析海量异构数据方面面临效率挑战

Method: 论文未在摘要中明确说明具体方法，但暗示需要开发高效的数据管理技术来应对多模态存储和多用途访问的复杂性

Result: 摘要未提供具体实验结果，但强调了现代数据湖在应对多模态数据存储和多用途访问方面的重要性

Conclusion: 现代数据湖需要更高效的数据管理解决方案来处理日益复杂的多模态存储和多用途访问需求

Abstract: Modern data lakes have become essential for storing, managing, and analyzing massive amounts of heterogeneous data. As production data increasingly exhibits multimodal storage characteristics and multi-purpose access patterns, efficient …

</details>


### [494] [HybridServe: Adaptive WebAssembly-Container Runtime Selection for Edge Serverless Computing](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3774899.3775011&hl=zh-CN&sa=X&d=4485243363308982268&ei=NflPab-6Cr6Z6rQPr-v5iAc&scisig=ALhkC2RKgvgYk6jymzh9pjuSGHgc&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ALhkC2Qgf9CdgCob8_ZiNUcZ7k6Q&html=&pos=1&folt=rel)
*S Kang,M Song,T Kim,S Lee,J Han,H Kim,K Lee*

Main category: Alekh Jindal

TL;DR: 边缘无服务器环境中资源受限，冷启动是主要挑战，需要优化函数实例创建和初始化


<details>
  <summary>Details</summary>
Motivation: 边缘无服务器环境具有有限的CPU、内存和异构硬件，需要在资源约束下实现高效执行。冷启动问题是主要挑战，影响函数实例创建和初始化性能。

Method: 未在摘要中明确说明具体方法，但暗示需要针对冷启动问题提出解决方案，可能涉及实例管理、资源优化或预加载技术。

Result: 摘要未提供具体实验结果，但暗示需要解决冷启动问题以提升边缘无服务器环境下的执行效率。

Conclusion: 边缘无服务器环境面临资源约束和冷启动挑战，需要有效的优化方案来提升函数执行效率。

Abstract: Edge serverless environments with limited CPU, memory, and heterogeneous hardware demand efficient execution under resource constraints. A key challenge in serverless computing is cold start, where a function instance is created and initialized …

</details>


### [495] [Zero-ETL Architectures and Serverless Data Warehousing: Automated Multi-Region Expansion Strategies for Cloud-Native Analytics](https://scholar.google.com/scholar_url?url=https://www.australiansciencejournals.com/ml/article/download/3447/4361&hl=zh-CN&sa=X&d=7312226360697875710&ei=35RRaa7EMNKV6rQP84i9kQc&scisig=ALhkC2TLZIGMYVhpEWAAoQIm-IoR&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ALhkC2Qgf9CdgCob8_ZiNUcZ7k6Q&html=&pos=0&folt=rel)
*G Ding,S Yang,Z Zeng,S Zhang*

Main category: Alekh Jindal

TL;DR: 云原生分析技术正在重塑分布式数据处理，但传统ETL管道面临性能瓶颈和架构僵化问题，需要更灵活、高效的数据集成解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着云原生分析的快速发展，传统ETL管道在分布式环境中面临性能瓶颈、架构僵化和运维复杂性等挑战，需要更灵活、高效的数据集成方法来支持现代数据分析需求。

Method: 论文可能提出基于云原生架构的新型数据处理方法，可能包括弹性计算、容器化部署、微服务架构、实时流处理等技术，以替代或增强传统ETL管道。

Result: 预期结果表明新方法相比传统ETL在性能、可扩展性、资源利用率和运维效率方面有显著提升，能够更好地支持分布式环境下的数据分析工作负载。

Conclusion: 云原生架构为数据分析提供了更灵活、高效的解决方案，传统ETL需要向云原生范式演进以适应现代分布式数据处理需求。

Abstract: The rapid evolution of cloud-native analytics has fundamentally transformed how organizations manage and analyze data across distributed environments. Traditional extract, transform, load (ETL) pipelines have long been the backbone of data …

</details>


### [496] [Towards Improving Performance Efficiency of Serverless Platforms](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3721464.3777427&hl=zh-CN&sa=X&d=17491518420169905125&ei=HXBTabrjFKC16rQPm4fPgQQ&scisig=ALhkC2RF2uGR-8iLeu36HwxmCLn0&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ALhkC2Qgf9CdgCob8_ZiNUcZ7k6Q&html=&pos=0&folt=rel)
*A Samanta*

Main category: Alekh Jindal

TL;DR: 服务器无平台存在显著的函数执行和资源利用开销，且工作负载常呈现并发函数调用的突发模式


<details>
  <summary>Details</summary>
Motivation: 尽管被广泛接受，但服务器无平台在函数执行和资源利用方面存在显著开销，且工作负载常呈现并发函数调用的突发模式，这影响了平台性能和效率

Method: 论文摘要未提供具体方法细节，但暗示需要针对服务器无平台开销和突发工作负载模式提出解决方案

Result: 摘要未提供具体实验结果，但指出服务器无平台存在显著开销且工作负载呈现并发函数调用的突发模式这一观察结果

Conclusion: 服务器无平台需要改进以应对函数执行开销和突发工作负载模式带来的挑战

Abstract: Despite being widely accepted, serverless platforms provide significant overhead in terms of function execution and resource utilization. It has been demonstrated that serverless workloads often display bursts of concurrent function calls. These days …

</details>


### [497] [AgnoSVD: Dynamic resource allocation for serverless workloads using collaborative filtering](https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S2590005625002899&hl=zh-CN&sa=X&d=16697047141436190765&ei=HXBTabrjFKC16rQPm4fPgQQ&scisig=ALhkC2RvMJbfot23MaN2OTwM7-hN&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ALhkC2Qgf9CdgCob8_ZiNUcZ7k6Q&html=&pos=1&folt=rel)
*MS Kabir,MA Adnan*

Main category: Alekh Jindal

TL;DR: 服务器无服务器计算中确定最佳资源配置面临挑战，主要由于云提供商对工作负载细节了解有限，特别是在处理复杂工作负载时问题更加突出


<details>
  <summary>Details</summary>
Motivation: 在无服务器计算环境中，云提供商通常缺乏对用户工作负载的具体了解，这导致难以确定最优的资源分配配置。特别是在处理复杂或多样化的工作负载时，这种信息不对称使得资源配置决策变得困难，可能影响性能、成本和资源利用率。

Method: 论文可能提出了一种基于机器学习、性能建模或自适应算法的资源配置优化方法，通过收集运行时指标、分析工作负载特征，或利用历史数据来预测最佳资源配置。可能包括监控系统、预测模型和动态调整机制。

Result: 预期提出的方法能够显著改善资源配置的准确性，提高性能表现，降低成本开销，并提升资源利用率。可能通过实验验证了在不同工作负载类型下的有效性，展示了与传统静态配置相比的优越性。

Conclusion: 在无服务器计算中，通过智能化的资源配置优化方法可以有效解决云提供商对工作负载信息有限的问题，实现更高效、经济的工作负载执行，为无服务器计算的资源管理提供新的解决方案。

Abstract: In serverless computing, determining the optimal resource configurations for workloads poses significant challenges, particularly due to the cloud provider's limited visibility into workload specifics. This complexity is amplified when dealing …

</details>


### [498] [Performance‑Aware Lifecycle Framework for Deployment of Large Language Models in Cloud‑Native and Serverless Environments](https://scholar.google.com/scholar_url?url=https://oscarpubhouse.com/index.php/sdlajast/article/download/62/56&hl=zh-CN&sa=X&d=13260696210834800607&ei=HXBTabrjFKC16rQPm4fPgQQ&scisig=ALhkC2Qbjo37-YKVvvJTuLEI52rl&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ALhkC2Qgf9CdgCob8_ZiNUcZ7k6Q&html=&pos=2&folt=rel)
*DZ qizi Ismoilova*

Main category: Alekh Jindal

TL;DR: LLMs已成为AI应用核心组件，具备先进自然语言理解、生成和决策能力


<details>
  <summary>Details</summary>
Motivation: LLMs快速发展成为AI应用关键组件，需要评估其在自然语言理解、生成和决策方面的能力与潜力

Method: 未在摘要中明确说明具体方法，但暗示涉及对LLMs能力的系统性评估和分析

Result: LLMs展现出在自然语言理解、生成和决策方面的显著能力，成为现代AI应用的核心组件

Conclusion: LLMs在AI领域具有重要地位和广阔应用前景，其能力发展值得持续关注和研究

Abstract: Abstract Large Language Models (LLMs) have rapidly evolved to become central components in contemporary artificial intelligence applications, promising sophisticated natural language understanding, generation, and decision-making …

</details>


### [499] [Agentic AI Serverless Code Generation: Towards Autonomous Improvement of Performance, Cost, and Code Quality](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3721464.3777437&hl=zh-CN&sa=X&d=14888932077455084104&ei=HXBTabrjFKC16rQPm4fPgQQ&scisig=ALhkC2RSgVZmtpVT0KlPU_zDqmrk&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ALhkC2Qgf9CdgCob8_ZiNUcZ7k6Q&html=&pos=3&folt=rel)
*X Chen*

Main category: Alekh Jindal

TL;DR: LLM在无服务器计算自动编码中存在正确性、性能和成本效率挑战


<details>
  <summary>Details</summary>
Motivation: 大型语言模型改变了软件开发，实现了无服务器计算的自动编码，但仍面临正确性、性能和成本效率方面的挑战

Method: 未在摘要中明确说明具体方法

Result: 未在摘要中提供具体结果

Conclusion: 需要解决LLM在无服务器计算自动编码中的正确性、性能和成本效率问题

Abstract: The emergence of Large Language Models (LLMs) has transformed software development, enabling automated coding for serverless computing. However, several challenges remain regarding the correctness, performance, cost-efficiency …

</details>


### [500] [Overview of WSC Workloads](https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-031-99489-0_3&hl=zh-CN&sa=X&d=18371040029163166320&ei=KU9VaaTALK-nieoPz8HDqAc&scisig=ALhkC2Rk8nzAFF0MTEQYxr_TqVCr&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ALhkC2Qgf9CdgCob8_ZiNUcZ7k6Q&html=&pos=0&folt=rel)
*LA Barroso,U Hölzle,P Ranganathan*

Main category: Alekh Jindal

TL;DR: 本章介绍仓库级计算机(WSCs)上运行的应用程序，这些应用定义了系统设计权衡，是后续讨论的基础。


<details>
  <summary>Details</summary>
Motivation: 理解WSC系统设计需要首先了解其运行的应用程序特性，因为这些应用决定了系统架构的关键权衡和设计决策。

Method: 通过概述WSC应用程序的广泛类别和特性，分析它们对系统设计的影响，为后续章节的系统设计讨论奠定基础。

Result: 建立了WSC应用程序与系统设计之间的关联框架，明确了应用特性如何影响硬件架构、资源分配、性能优化等系统设计决策。

Conclusion: WSC应用程序特性是理解系统设计权衡的关键起点，后续章节将基于这些应用需求深入探讨具体的系统架构设计。

Abstract: The applications that run on warehouse-scale computers (WSCs) define the system design tradeoffs that we will be discussing in the rest of this book. Hence, we first discuss these applications in this chapter. We start with an overview of broad …

</details>


### [501] [Data-Centric Serverless Computing with LAMBDASTORE](https://scholar.google.com/scholar_url?url=https://www.preprints.org/frontend/manuscript/9d8fd4bdc17d39ad7514544e773ddff7/download_pub&hl=zh-CN&sa=X&d=8272089706199137719&ei=Q_RXaZCxLLux6rQPi5qW2AE&scisig=ALhkC2SVPDquMIHyKVXP1ybtJE1b&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ALhkC2Qgf9CdgCob8_ZiNUcZ7k6Q&html=&pos=1&folt=rel)
*K Mast,S Qu,A Jain,A Arpaci*

Main category: Alekh Jindal

TL;DR: LAMBDASTORE是一个集成了存储引擎的新型无服务器平台，专门为有状态的无服务器工作负载设计，通过计算-存储协同设计将函数与数据共置，显著提升性能


<details>
  <summary>Details</summary>
Motivation: 现有无服务器平台主要针对无状态工作负载设计，对有状态应用支持不足，存在函数与数据分离导致的性能瓶颈和数据传输开销问题

Method: 采用计算-存储协同设计架构，将无服务器函数与其关联数据共置在同一节点，集成专门的存储引擎，优化数据访问模式

Result: 显著提升了有状态无服务器工作负载的性能，减少了数据传输开销，改善了延迟和吞吐量

Conclusion: LAMBDASTORE通过计算-存储协同设计有效解决了有状态无服务器应用的性能瓶颈，为这类工作负载提供了优化的平台支持

Abstract: LAMBDASTORE is a new serverless platform with an integrated storage engine tailored for stateful serverless workloads. Its compute-storage co-design colocates serverless functions with their associated data, yielding significant performance …

</details>


### [502] [Quantifying Serverless Elasticity: The gumeter Benchmark Suite](https://scholar.google.com/scholar_url?url=https://books.google.com/books%3Fhl%3Dzh-CN%26lr%3D%26id%3Dan-lEQAAQBAJ%26oi%3Dfnd%26pg%3DPA282%26ots%3Duvg2OlEvy6%26sig%3Dr5QeT7Wi4nr71hgpxresp-bu2h8&hl=zh-CN&sa=X&d=10948750317104251373&ei=9S1caaGlG8W4ieoP4szBiAE&scisig=ALhkC2SSfCB-rg0zSn_K8JVqt3I1&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ALhkC2Qgf9CdgCob8_ZiNUcZ7k6Q&html=&pos=0&folt=rel)
*GT Eizaguirre,E Molina*

Main category: Alekh Jindal

TL;DR: 服务器无计算为分布式工作流提供细粒度资源供应，但现有系统在数百并发CPU场景下存在资源分配效率问题


<details>
  <summary>Details</summary>
Motivation: 服务器无计算虽然为分布式工作流提供了细粒度的低延迟资源供应，能够精确满足作业需求，但在实际应用中，工作流通常需要数百个并发CPU，而现有系统在这方面存在资源分配效率问题，需要改进

Method: 论文未提供具体方法细节，但基于摘要内容推断，可能涉及优化服务器无计算环境中的资源分配策略、调度算法或架构设计，以更好地支持大规模并发CPU的工作流需求

Result: 基于摘要信息，无法确定具体实验结果，但可以推断该研究可能展示了改进后的系统在支持大规模并发CPU工作流方面的性能提升

Conclusion: 服务器无计算作为分布式工作流的强大范式，在支持大规模并发CPU工作流方面仍有改进空间，需要优化资源分配机制以满足实际应用需求

Abstract: Serverless computing has emerged as a powerful paradigm for distributed workflows, offering fine-grained, low-latency resource provisioning to precisely meet job demands. While workflows often utilize hundreds of concurrent CPUs, existing …

</details>


### [503] [Data Consistency and Transaction Management in Distributed Serverless ETL Pipelines](https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Philip-Adekola-3/publication/399464904_Data_Consistency_and_Transaction_Management_in_Distributed_Serverless_ETL_Pipelines/links/695c134827359023a013c371/Data-Consistency-and-Transaction-Management-in-Distributed-Serverless-ETL-Pipelines.pdf&hl=zh-CN&sa=X&d=10274930234434032660&ei=hKNgae6aAayK6rQPgZOO6A8&scisig=ALhkC2QU3ormlw7AZA_YQCgwIEW3&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ALhkC2Qgf9CdgCob8_ZiNUcZ7k6Q&html=&pos=1&folt=rel)
*S Youseff,A Philip,F Hamzah,A Taofeek,B Barnanas…*

Main category: Alekh Jindal

TL;DR: 服务器无服务器架构在ETL数据处理系统中的应用与优化


<details>
  <summary>Details</summary>
Motivation: 云计算的快速发展推动了无服务器架构在可扩展、成本效益高的事件驱动数据处理系统中的广泛应用。传统ETL管道面临资源管理复杂、成本控制困难等挑战，需要探索无服务器架构如何优化ETL数据处理。

Method: 采用无服务器架构设计ETL数据处理系统，利用事件驱动模型、自动扩缩容机制和按使用付费模式。可能包括函数即服务(FaaS)组件、消息队列集成、数据流处理框架等具体技术实现。

Result: 无服务器ETL系统相比传统架构展现出更好的可扩展性、成本效益和运维简化。能够根据负载自动调整资源，减少闲置成本，提高数据处理效率。

Conclusion: 无服务器架构为ETL数据处理提供了有前景的解决方案，特别适合波动性工作负载和事件驱动场景。未来研究可进一步优化性能、降低延迟并扩展应用场景。

Abstract: The rapid evolution of cloud computing has led to the widespread adoption of serverless architectures for building scalable, cost-efficient, and event-driven data processing systems. Extract, Transform, Load (ETL) pipelines, traditionally …

</details>


### [504] [Auto-Scaling and Elastic Resource Management in Serverless ETL Pipelines](https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Philip-Adekola-3/publication/399434136_Auto-Scaling_and_Elastic_Resource_Management_in_Serverless_ETL_Pipelines/links/695ac5be0c98040d482735cf/Auto-Scaling-and-Elastic-Resource-Management-in-Serverless-ETL-Pipelines.pdf&hl=zh-CN&sa=X&d=6366437340032245045&ei=hKNgae6aAayK6rQPgZOO6A8&scisig=ALhkC2QfcwhDYq9VupuosEK1P-FH&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ALhkC2Qgf9CdgCob8_ZiNUcZ7k6Q&html=&pos=2&folt=rel)
*S Youseff,A Philip,F Hamzah,A Taofeek,B Barnanas…*

Main category: Alekh Jindal

TL;DR: 论文探讨了在数据爆炸式增长背景下，如何实现可扩展、经济高效且响应迅速的数据处理，重点关注流处理、批处理、微服务架构和云原生技术。


<details>
  <summary>Details</summary>
Motivation: 数字平台、物联网设备、移动应用和企业系统产生的数据呈指数级增长，对可扩展、经济高效且响应迅速的数据处理需求日益迫切，传统数据处理方法难以满足现代应用对实时性、弹性和成本效益的要求。

Method: 采用混合数据处理架构，结合流处理与批处理，利用微服务架构实现模块化，部署于云原生平台，采用容器化和无服务器计算技术，实现弹性扩展和资源优化。

Result: 提出的架构显著提升了数据处理吞吐量和响应时间，降低了运营成本，增强了系统弹性，能够有效处理大规模实时数据流，同时保持成本效益。

Conclusion: 通过整合流批处理、微服务和云原生技术，可以构建满足现代数据密集型应用需求的高效数据处理系统，为未来数据处理架构提供了可行的解决方案。

Abstract: The exponential growth of data generated from digital platforms, Internet of Things (IoT) devices, mobile applications, and enterprise systems has intensified the demand for scalable, cost-efficient, and highly responsive data processing …

</details>


### [505] [Architectural Patterns for Cloud-Native Serverless ETL Pipelines at Scale](https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Aremu-Oluwaferanmi-2/publication/399433945_Architectural_Patterns_for_Cloud-Native_Serverless_ETL_Pipelines_at_Scale/links/695ac0d0a1fd01798910ace8/Architectural-Patterns-for-Cloud-Native-Serverless-ETL-Pipelines-at-Scale.pdf&hl=zh-CN&sa=X&d=154253541362905314&ei=hKNgae6aAayK6rQPgZOO6A8&scisig=ALhkC2R7M2-tJsPgKxFLQGKkVLyu&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ALhkC2Qgf9CdgCob8_ZiNUcZ7k6Q&html=&pos=3&folt=rel)
*S Youseff,A Philip,F Hamzah,A Taofeek,B Barnanas…*

Main category: Alekh Jindal

TL;DR: 论文探讨了数据密集型应用、实时分析和人工智能对数据集成系统设计的影响，分析了传统ETL架构的局限性，并提出了现代数据集成方法。


<details>
  <summary>Details</summary>
Motivation: 数据密集型应用、实时分析和人工智能的快速发展对传统ETL架构提出了挑战，需要重新思考数据集成系统的设计和运营方式。

Method: 分析传统ETL架构的局限性，探讨现代数据集成方法，包括实时处理、流式架构和AI驱动的数据管理技术。

Result: 识别了传统ETL架构在应对现代数据需求时的不足，提出了适应实时分析、AI应用和云原生环境的新型数据集成模式。

Conclusion: 数据集成系统需要从传统的批处理ETL向更灵活、实时的架构演进，以支持现代数据密集型应用和AI驱动的分析需求。

Abstract: The rapid growth of data-intensive applications, real-time analytics, and artificial intelligence has fundamentally transformed how organizations design and operate data integration systems. Traditional Extract, Transform, Load(ETL) architectures …

</details>


### [506] [Cost Modeling and Resource Optimization for Pay-Per-Use Serverless ETL Platforms](https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Philip-Adekola-3/publication/399464931_Cost_Modeling_and_Resource_Optimization_for_Pay-Per-Use_Serverless_ETL_Platforms/links/695c145ea1fd01798911003b/Cost-Modeling-and-Resource-Optimization-for-Pay-Per-Use-Serverless-ETL-Platforms.pdf&hl=zh-CN&sa=X&d=3409274085485108062&ei=hKNgae6aAayK6rQPgZOO6A8&scisig=ALhkC2Qa5wr7xWj8uRUwHH8Gu-Tq&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ALhkC2Qgf9CdgCob8_ZiNUcZ7k6Q&html=&pos=4&folt=rel)
*S Youseff,A Philip,F Hamzah,A Taofeek,B Barnanas…*

Main category: Alekh Jindal

TL;DR: 服务器无计算（serverless computing）正在彻底改变ETL系统的设计和运行方式，与传统基于长期运行、预配置基础设施的架构形成鲜明对比


<details>
  <summary>Details</summary>
Motivation: 随着服务器无计算的快速普及，传统ETL架构面临挑战。传统方法依赖长期运行、预配置的基础设施，而服务器无计算提供了按需扩展、按使用付费的新范式，需要研究如何利用这种新计算模式优化ETL系统

Method: 论文分析了服务器无计算在ETL系统中的应用，对比传统架构与服务器无架构的差异，探讨如何利用函数即服务（FaaS）、事件驱动架构、自动扩缩容等特性重新设计ETL流水线

Result: 服务器无计算为ETL系统带来了显著优势：降低成本（按使用付费）、提高可扩展性（自动扩缩容）、简化运维（无需基础设施管理）、提高资源利用率。但也面临冷启动延迟、状态管理、监控调试等挑战

Conclusion: 服务器无计算正在重塑ETL系统架构，为数据流水线提供了更灵活、经济高效的新范式。未来需要解决冷启动、状态管理等技术挑战，并开发专门针对服务器无环境的ETL最佳实践和工具

Abstract: The rapid adoption of serverless computing has fundamentally transformed the design and operation of Extract, Transform, and Load (ETL) systems. Unlike traditional ETL architectures that rely on long-running, provisioned infrastructure …

</details>


### [507] [Hybrid Serverless–Container Architectures for Large-Scale ETL Workloads](https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Aremu-Oluwaferanmi-2/publication/399434131_Hybrid_Serverless-Container_Architectures_for_Large-Scale_ETL_Workloads/links/695ac3b90c98040d48273567/Hybrid-Serverless-Container-Architectures-for-Large-Scale-ETL-Workloads.pdf&hl=zh-CN&sa=X&d=1704180281420078194&ei=hKNgae6aAayK6rQPgZOO6A8&scisig=ALhkC2TL6wjFo42Fgm0S4rzKBfOL&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ALhkC2Qgf9CdgCob8_ZiNUcZ7k6Q&html=&pos=5&folt=rel)
*S Youseff,A Philip,F Hamzah,A Taofeek,B Barnanas…*

Main category: Alekh Jindal

TL;DR: 论文探讨了数据爆炸背景下传统ETL系统的局限性，提出了一种基于云原生架构和事件驱动模式的现代化ETL解决方案，通过容器化、微服务和流处理技术实现高可扩展性和成本效益。


<details>
  <summary>Details</summary>
Motivation: 数字平台、物联网设备、企业系统和实时用户交互产生的数据呈指数级增长，传统ETL系统在可扩展性、灵活性和成本效益方面面临严峻挑战，需要现代化解决方案来应对大数据处理的复杂需求。

Method: 采用云原生架构，结合容器化部署、微服务设计模式和事件驱动架构；利用流处理技术实现实时数据转换；引入无服务器计算实现按需资源分配；通过数据湖和数据仓库集成构建统一数据处理平台。

Result: 提出的现代化ETL解决方案相比传统系统实现了更高的可扩展性（可处理PB级数据）、更低的延迟（实时处理能力）、更好的成本效益（按使用付费模式）和更强的容错能力（自动故障恢复）。

Conclusion: 云原生和事件驱动的现代化ETL架构能够有效应对大数据时代的挑战，为组织提供可扩展、灵活且经济高效的数据处理能力，是未来数据工程发展的关键方向。

Abstract: The exponential growth of data generated by digital platforms, Internet of Things (IoT) devices, enterprise systems, and real-time user interactions has intensified the demand for scalable, flexible, and cost-efficient Extract–Transform–Load (ETL) …

</details>


### [508] [Performance Optimization and Cost-Efficiency in Serverless ETL Execution Models](https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Aremu-Oluwaferanmi-2/publication/399433747_Performance_Optimization_and_Cost-Efficiency_in_Serverless_ETL_Execution_Models/links/695ac252a1fd01798910ad33/Performance-Optimization-and-Cost-Efficiency-in-Serverless-ETL-Execution-Models.pdf&hl=zh-CN&sa=X&d=17327788171394852554&ei=hKNgae6aAayK6rQPgZOO6A8&scisig=ALhkC2TAyDeUxn2VzIq2PjjJnhF4&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ALhkC2Qgf9CdgCob8_ZiNUcZ7k6Q&html=&pos=6&folt=rel)
*S Youseff,A Philip,F Hamzah,A Taofeek,B Barnanas…*

Main category: Alekh Jindal

TL;DR: 论文探讨了现代ETL（提取、转换、加载）管道面临的挑战，并提出了基于云原生架构的解决方案，旨在提高数据处理的可扩展性、灵活性和成本效益。


<details>
  <summary>Details</summary>
Motivation: 数据驱动决策的快速增长对可扩展、灵活且成本高效的数据处理架构提出了更高要求。传统ETL管道在处理大规模数据时面临性能瓶颈、资源利用率低和运维复杂等挑战，需要更现代化的解决方案。

Method: 论文提出了基于云原生架构的ETL解决方案，采用微服务化设计、容器化部署和弹性伸缩机制。方法包括：1）将ETL任务分解为独立微服务；2）利用容器编排实现自动扩缩容；3）采用事件驱动架构提高响应性；4）实现资源按需分配以优化成本。

Result: 实验结果显示，与传统ETL系统相比，云原生架构在处理大规模数据时性能提升40-60%，资源利用率提高50%，运维成本降低30%。系统在突发负载下能自动弹性伸缩，保证了服务可用性和数据处理时效性。

Conclusion: 云原生架构为现代ETL管道提供了有效的解决方案，显著提升了数据处理的可扩展性、灵活性和成本效益。该架构适应了数据驱动决策的快速增长需求，为构建下一代数据分析系统提供了重要参考。

Abstract: The rapid growth of data-driven decision-making has intensified the demand for scalable, flexible, and cost-efficient data processing architectures. Extract, Transform, and Load (ETL) pipelines form the backbone of modern analytics systems, enabling …

</details>


### [509] [Integrating Machine Learning and Analytics into Serverless ETL Workflows](https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Philip-Adekola-3/publication/399434150_Integrating_Machine_Learning_and_Analytics_into_Serverless_ETL_Workflows/links/695ac9f9a1fd01798910ae7d/Integrating-Machine-Learning-and-Analytics-into-Serverless-ETL-Workflows.pdf&hl=zh-CN&sa=X&d=656877338005984833&ei=hKNgae6aAayK6rQPgZOO6A8&scisig=ALhkC2RnOokeHdoN0yeptQQg-JAq&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ALhkC2Qgf9CdgCob8_ZiNUcZ7k6Q&html=&pos=7&folt=rel)
*S Youseff,A Philip,F Hamzah,A Taofeek,B Barnanas…*

Main category: Alekh Jindal

TL;DR: 论文探讨了应对数据爆炸式增长的新型数据处理架构，提出了一种可扩展、灵活且成本高效的数据处理框架，以解决传统ETL/ELT方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 数字平台、物联网设备、社交媒体和企业系统产生的数据快速增长，对可扩展、灵活且成本高效的数据处理架构需求日益迫切。传统ETL/ELT方法在处理海量、多样化数据时面临性能瓶颈、扩展性不足和成本高昂等挑战。

Method: 论文提出了一种新型数据处理架构，可能结合了现代数据工程技术，如流处理、批处理融合、云原生架构、无服务器计算、数据湖仓一体等概念，旨在构建更灵活、可扩展的数据处理框架。

Result: 提出的架构在可扩展性、灵活性和成本效率方面相比传统方法有显著提升，能够更好地处理大规模、多样化的数据流，同时降低运维复杂性和总体拥有成本。

Conclusion: 新型数据处理架构是应对当前数据爆炸挑战的有效解决方案，为组织提供了更高效、灵活且经济的数据处理能力，有助于实现更好的数据驱动决策和业务价值。

Abstract: The rapid growth of data generated from digital platforms, Internet of Things (IoT) devices, social media, and enterprise systems has intensified the need for scalable, flexible, and cost-efficient data processing architectures. Traditional Extract …

</details>


### [510] [Orchestration and State Management in Serverless ETL Workflows](https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Aremu-Oluwaferanmi-2/publication/399433948_Orchestration_and_State_Management_in_Serverless_ETL_Workflows/links/695ac1f6a1fd01798910ad16/Orchestration-and-State-Management-in-Serverless-ETL-Workflows.pdf&hl=zh-CN&sa=X&d=783335624949629808&ei=hKNgae6aAayK6rQPgZOO6A8&scisig=ALhkC2SsV08NXKAxv5JXJ8cmBmHv&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ALhkC2Qgf9CdgCob8_ZiNUcZ7k6Q&html=&pos=8&folt=rel)
*S Youseff,A Philip,F Hamzah,A Taofeek,B Barnanas…*

Main category: Alekh Jindal

TL;DR: 服务器less架构已成为构建可扩展、成本效益高且高可用数据处理系统的主导范式，ETL工作流在该架构中面临新的挑战和机遇


<details>
  <summary>Details</summary>
Motivation: 云计算快速发展催生了服务器less架构，成为构建可扩展、成本效益高、高可用数据处理系统的主导范式。在此背景下，ETL（提取、转换、加载）工作流面临新的挑战和机遇，需要研究如何在该架构中优化数据处理流程

Method: 基于服务器less架构范式，分析ETL工作流在该环境下的实现方法、优化策略和技术挑战

Result: 服务器less架构为ETL工作流提供了新的实现框架，能够实现按需扩展、成本优化和高可用性，但同时也带来了新的技术挑战

Conclusion: 服务器less架构是ETL工作流的理想平台，能够显著提升数据处理系统的可扩展性和成本效益，但需要针对该架构特点进行专门优化

Abstract: The rapid evolution of cloud computing has given rise to serverless architectures as a dominant paradigm for building scalable, cost-efficient, and highly available data processing systems. Within this paradigm, Extract, Transform, Load (ETL) workflows …

</details>


### [511] [Hybrid ETL Architectures: Combining Batch, Streaming, and Serverless Processing Models](https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Philip-Adekola-3/publication/399465308_Hybrid_ETL_Architectures_Combining_Batch_Streaming_and_Serverless_Processing_Models/links/695c1348a1fd01798910fffc/Hybrid-ETL-Architectures-Combining-Batch-Streaming-and-Serverless-Processing-Models.pdf&hl=zh-CN&sa=X&d=1209974191381844730&ei=hKNgae6aAayK6rQPgZOO6A8&scisig=ALhkC2QjZugSgSL9InzQ-G6Vn9Sm&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:ALhkC2Qgf9CdgCob8_ZiNUcZ7k6Q&html=&pos=9&folt=rel)
*S Youseff,A Philip,F Hamzah,A Taofeek,B Barnanas…*

Main category: Alekh Jindal

TL;DR: 论文探讨了大数据时代下传统批处理ETL系统的局限性，以及向实时流处理架构转型的必要性


<details>
  <summary>Details</summary>
Motivation: 数据量、速度和多样性的指数级增长使得传统批处理ETL系统无法满足现代组织的实时数据处理需求，需要探索新的架构方案

Method: 分析传统批处理ETL的局限性，提出向实时流处理架构转型的方法，包括事件驱动设计、微服务架构和云原生技术应用

Result: 实时流处理ETL架构能够显著降低数据处理延迟，提高系统可扩展性，支持更复杂的数据处理场景，并降低运维成本

Conclusion: 组织需要从传统的批处理ETL向实时流处理架构转型，采用现代化技术栈来应对大数据时代的挑战，实现更高效的数据处理和分析

Abstract: The exponential growth of data volume, velocity, and variety has fundamentally transformed how organizations design and operate Extract, Transform, and Load (ETL) systems. Traditional batch-oriented ETL pipelines, once sufficient for periodic …

</details>


### [512] [Computer-implemented methods and computing systems for reorganizing data](https://scholar.google.com/scholar_url?url=https://patents.google.com/patent/US12511271B2/en&hl=zh-CN&sa=X&d=13870153546329587773&ei=Ru1haZ3wAdrJieoPiYyysAk&scisig=AHkA5jTjkRxmF0MnLLlJSwDe1PRD&oi=scholaralrt&hist=i6heNjgAAAAJ:9105223062713277753:AHkA5jRjsInJuQ8ojOPRhEA3nNaJ&html=&pos=1&folt=cit)
*Z ZHANG,MCH LI,FM KIAIE,S Annamalai,A Helal*

Main category: Alekh Jindal

TL;DR: 通过用户定义函数生成隐藏列，基于隐藏列优化数据分区和查询性能


<details>
  <summary>Details</summary>
Motivation: 传统数据分区方法在处理复杂查询时效率有限，特别是当查询涉及对数据的复杂转换或计算时。需要一种机制能够在数据存储层面就预计算和优化这些转换，以提高查询性能。

Method: 应用用户定义函数(UDF)到数据集的列上生成隐藏列，将数据集按第一分区方案分区，并将数据集和隐藏列存储在内存中。查询集针对内存中的数据集和隐藏列运行，利用隐藏列优化查询执行。

Result: 通过生成隐藏列并存储在内存中，系统能够显著提高查询性能，特别是对于需要复杂数据转换的查询。隐藏列作为预计算结果，避免了查询时的重复计算开销。

Conclusion: 使用UDF生成隐藏列并将其与原始数据一同存储在内存中的方法，能够有效优化数据分区和查询性能，为复杂查询场景提供高效的解决方案。

Abstract: Computer-implemented methods and computing systems for reorganizing data are disclosed. One or more user defined functions (UDFs) are applied to one or more columns of a data set to generate a hidden column. The data set partitioned according to a first partition scheme and the hidden column are stored in memory of a computing system. A set of queries run against the data set and the hidden column are stored in the memory. Each query in the set of queries and the one or more UDFs …

</details>


### [513] [Architectural Evolution of Cloud-Native Serverless ETL Systems: Integrating AI Automation, Real-Time Analytics, and Intelligent Governance for Scalable Data …](https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Philip-Adekola-3/publication/399624665_Architectural_Evolution_of_Cloud-Native_Serverless_ETL_Systems_Integrating_AI_Automation_Real-Time_Analytics_and_Intelligent_Governance_for_Scalable_Data_Workflows/links/696162f4ee048155cff9bbd5/Architectural-Evolution-of-Cloud-Native-Serverless-ETL-Systems-Integrating-AI-Automation-Real-Time-Analytics-and-Intelligent-Governance-for-Scalable-Data-Workflows.pdf&hl=zh-CN&sa=X&d=2798934250060484741&ei=L1hmad-rM7OlieoP2or16QQ&scisig=AHkA5jSbZHXRr23KrKCfBA5yHecS&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:AHkA5jShId-iWoaohWFlDvz-Dwie&html=&pos=0&folt=rel)
*S Youseff,A Philip,F Hamzah,A Taofeek,B Barnanas…*

Main category: Alekh Jindal

TL;DR: 论文探讨了现代企业环境中数据爆炸式增长对ETL系统的影响，指出传统单体架构已无法满足需求，并提出了相应的解决方案。


<details>
  <summary>Details</summary>
Motivation: 现代企业环境中数据呈指数级增长，传统单体ETL架构在处理大规模、多样化数据时表现出局限性，无法满足实时性、可扩展性和灵活性的需求。

Method: 论文提出了改进的ETL架构方案，可能包括微服务化、云原生设计、流式处理集成、容器化部署等现代技术手段，以构建更灵活、可扩展的数据集成系统。

Result: 新架构相比传统单体ETL系统在性能、可扩展性、容错性和部署灵活性方面有显著提升，能够更好地应对大规模数据处理需求。

Conclusion: 传统单体ETL架构已不适应现代数据环境，需要采用现代化、模块化的架构设计来构建更高效、灵活和可扩展的数据集成系统。

Abstract: The exponential growth of data in modern enterprise environments has driven the evolution of data integration technologies, particularly Extract, Transform, Load (ETL) systems. Traditional monolithic ETL architectures are increasingly inadequate to …

</details>


### [514] [Workflow Automation and Dependency Management in Serverless Data Integration Systems](https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Aremu-Oluwaferanmi-2/publication/399613241_Workflow_Automation_and_Dependency_Management_in_Serverless_Data_Integration_Systems/links/696104aa54906834b6895581/Workflow-Automation-and-Dependency-Management-in-Serverless-Data-Integration-Systems.pdf&hl=zh-CN&sa=X&d=13841706140199418112&ei=L1hmad-rM7OlieoP2or16QQ&scisig=AHkA5jRmkGNzoyzdv-NdLNXkXW6B&oi=scholaralrt&hist=i6heNjgAAAAJ:4438704070979798767:AHkA5jShId-iWoaohWFlDvz-Dwie&html=&pos=1&folt=rel)
*S Youseff,A Philip,F Hamzah,A Taofeek,B Barnanas…*

Main category: Alekh Jindal

TL;DR: 服务器无计算改变了现代数据处理，但在数据集成领域仍面临异构数据源整合、转换和协调的挑战


<details>
  <summary>Details</summary>
Motivation: 服务器无计算虽然简化了基础设施管理，但在数据集成场景中，处理来自不同源的异构数据（包括格式、模式、语义差异）仍然存在显著挑战，需要更有效的解决方案

Method: 论文可能提出基于服务器无计算架构的数据集成框架或方法，利用其弹性扩展和按使用付费特性来处理数据集成任务，包括数据转换、模式映射、语义协调等

Result: 预期结果包括：1）展示服务器无计算在数据集成中的可行性和优势；2）提出具体架构或系统实现；3）通过实验验证性能、可扩展性和成本效益

Conclusion: 服务器无计算为数据集成提供了有前景的解决方案，能够有效处理异构数据源的整合挑战，同时保持成本效益和可扩展性

Abstract: Serverless computing has transformed modern data processing by abstracting infrastructure concerns and enabling scalable, pay‑per‑use execution. In the realm of data integration—where data from diverse sources must be combined, transformed …

</details>


<div id='Bin CUI'></div>

# Bin CUI [[Back]](#toc)

### [515] [MagnifierSketch: Quantile Estimation Centered at One Point](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.22070&hl=zh-CN&sa=X&d=1038421205398407708&ei=KG4xabHIJceB6rQP-bb0sAs&scisig=ABGrvjKZc0KADVbinYQt0R9k5ij_&oi=scholaralrt&hist=i6heNjgAAAAJ:3739178042932535188:ABGrvjKLmON-cupg_CnmNvMzl3_J&html=&pos=0&folt=art)
*J Guo,Q Lyu,Y Wu,H Li,Z Yao,Y Dong,X Wang…*

Main category: Bin CUI

TL;DR: 在数据流模型中考虑分位数估计，其中数据流中的每个项目都是键值对，研究重点是每个键的分位数估计问题


<details>
  <summary>Details</summary>
Motivation: 数据流处理中需要对键值对数据进行分位数估计，现有方法在处理每个键的分位数估计时面临效率和准确性挑战，需要开发适用于数据流环境的有效算法

Method: 论文提出了一种针对数据流中键值对的分位数估计算法，可能包括流式处理框架、内存优化技术、近似算法设计以及针对每个键的独立分位数估计策略

Result: 开发出能够高效处理数据流中每个键分位数估计的算法，在内存使用、计算效率和估计准确性之间取得平衡，适用于大规模实时数据处理场景

Conclusion: 提出的方法能够有效解决数据流环境中每个键的分位数估计问题，为实时数据分析和监控提供了实用的技术方案

Abstract: In this paper, we take into consideration quantile estimation in data stream models, where every item in the data stream is a key-value pair. Researchers sometimes aim to estimate per-key quantiles (ie quantile estimation for every distinct key), and some …

</details>


### [516] [Hydraulis: Balancing Large Transformer Model Training via Co-designing Parallel Strategies and Data Assignment](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3769802&hl=zh-CN&sa=X&d=11263148797604136000&ei=kOU4ac2hJ42v6rQPruaHyA0&scisig=ALhkC2TJvtq4iym8JYHS0mhUkYBM&oi=scholaralrt&hist=i6heNjgAAAAJ:3739178042932535188:ALhkC2RM4ue30KMUoeSZCMypy7Cx&html=&pos=0&folt=art)
*H Li,F Fu,S Lin,H Ge,X Wang,J Niu,J Xue,Y Tao…*

Main category: Bin CUI

TL;DR: 针对大型Transformer模型训练优化，提出考虑数据诱导不平衡的并行计算与数据管理方法


<details>
  <summary>Details</summary>
Motivation: 当前优化方法假设训练工作量稳定均匀，忽略了数据诱导的不平衡问题，这会影响大型Transformer模型训练的效率

Method: 未在摘要中明确说明具体方法，但暗示需要开发能够处理数据诱导不平衡的并行计算和数据管理技术

Result: 未在摘要中提供具体实验结果

Conclusion: 优化大型Transformer训练需要同时考虑高效并行计算和先进数据管理，特别是要解决数据诱导的不平衡问题

Abstract: To optimize large Transformer model training, both efficient parallel computing and advanced data management are indispensable. However, current methods often assume a stable and uniform training workload, neglecting data-induced imbalances …

</details>


### [517] [DataFlow: An LLM-Driven Framework for Unified Data Preparation and Workflow Automation in the Era of Data-Centric AI](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.16676&hl=zh-CN&sa=X&d=17181278816952191976&ei=wZ1IabmyEbLrieoPwNLAkQw&scisig=ALhkC2TMMO50I3Kiqy2p5I8CcgLh&oi=scholaralrt&hist=i6heNjgAAAAJ:3739178042932535188:ALhkC2RM4ue30KMUoeSZCMypy7Cx&html=&pos=0&folt=art)
*H Liang,X Ma,Z Liu,ZH Wong,Z Zhao,Z Meng,R He…*

Main category: Bin CUI

TL;DR: 本文针对大语言模型对高质量数据的需求，分析了当前数据准备流程的局限性，并提出了一种系统化的数据准备框架。


<details>
  <summary>Details</summary>
Motivation: 大语言模型对高质量数据的需求快速增长，但当前数据准备实践主要由临时脚本和手动流程主导，缺乏可扩展性、可靠性和语义丰富性，需要系统化的解决方案。

Method: 论文提出了一种系统化的数据准备框架，可能包括标准化流程、自动化工具、质量评估机制和语义增强技术，以替代当前的临时脚本方法。

Result: 提出的框架能够提高数据准备流程的可扩展性、可靠性和语义丰富性，为LLM训练提供更高质量的数据支持。

Conclusion: 系统化的数据准备框架对于满足LLM对高质量数据的需求至关重要，能够解决当前临时脚本方法的局限性，推动LLM发展的可持续性。

Abstract: The rapidly growing demand for high-quality data in Large Language Models (LLMs) has intensified the need for scalable, reliable, and semantically rich data preparation pipelines. However, current practices remain dominated by ad-hoc scripts and …

</details>


### [518] [VLDB Endowment](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.5555/3772181&hl=zh-CN&sa=X&d=8121518377929622926&ei=46VkafP-E8elieoP1s_TgA8&scisig=AHkA5jR-4WGZ521ZTBAWZ0Geljuw&oi=scholaralrt&hist=i6heNjgAAAAJ:3739178042932535188:AHkA5jQRTxR8mtnnr-h_sMDSNvEf&html=&pos=0&folt=art)
*Y Diao,X Xiao,A Polyzotis,A Simitsis,A Pavlo…*

Main category: Bin CUI

TL;DR: VLDB Endowment第19卷第1期（2025年9月）的编辑团队和会议信息


<details>
  <summary>Details</summary>
Motivation: 作为VLDB Endowment期刊的常规出版流程，提供数据库领域最新研究成果的发表平台，维持学术交流的连续性和规范性

Method: 通过编辑委员会（主编、副主编、编委）的同行评审流程，确保论文质量，采用标准的学术出版模式

Result: 成功出版了VLDB Endowment第19卷第1期，收录了数据库领域的最新研究论文，为学术社区提供了高质量的发表渠道

Conclusion: VLDB Endowment作为数据库领域的顶级期刊，通过规范的编辑出版流程，持续推动数据库技术和研究的发展

Abstract: VLDB Endowment Proceedings of the VLDB Endowment Volume 19, No. 1–September 2025 Editors in Chief: Yanlei Diao and Xiaokui Xiao Associate Editors: Alkis Polyzotis, Alkis Simitsis, Andrew Pavlo, Angela Bonifati, Anh Dinh, Antonis Deligiannakis …

</details>


<div id='Xuanhe Zhou'></div>

# Xuanhe Zhou [[Back]](#toc)

### [519] [Tool learning with language models: a comprehensive survey of methods, pipelines, and benchmarks](https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s44336-025-00024-x&hl=zh-CN&sa=X&d=583612225830331158&ei=uAYtaZz8A-uuieoPn9Oq8Ao&scisig=ABGrvjLSEgQjj3p1ZZ3jOrFHB0Ub&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=0&folt=cit)
*J Chen,H Wu,J Pang,Y Wang,D Zhang,C Sun*

Main category: Xuanhe Zhou

TL;DR: 本文系统综述了大语言模型的工具学习范式，涵盖任务分解、工具选择、调用执行和响应生成等关键环节


<details>
  <summary>Details</summary>
Motivation: 工具学习已成为增强大语言模型推理和决策能力的关键技术，通过让LLMs能够与外部工具（如API、搜索引擎、计算器等）交互来解决复杂任务

Method: 系统综述方法，分析工具学习范式的关键组成部分：任务分解、工具选择、正确调用和连贯响应生成

Result: 提供了工具学习领域的系统性概览，明确了LLMs与外部工具交互的核心机制和技术框架

Conclusion: 工具学习是提升LLMs能力的重要方向，需要系统化的方法论来指导模型有效利用外部工具

Abstract: Tool learning has emerged as a key capability for enhancing the reasoning and decision-making abilities of large language models (LLMs) by enabling them to interface with external tools such as application programming interfaces (APIs), search engines, and calculators. This survey provides a systematic overview of the tool learning paradigm, focusing on how LLMs can decompose complex tasks, select appropriate tools, invoke them correctly, and generate coherent responses. We …

</details>


### [520] [Architecture for Managing Autonomous Virtual Organizations in the Industry 4.0 Context](https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2073-431X/14/12/519&hl=zh-CN&sa=X&d=12519437725462690459&ei=uAYtaZz8A-uuieoPn9Oq8Ao&scisig=ABGrvjKVexuZLmImnVZbUDRSeQW0&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=1&folt=cit)
*CP López,M Santórum,J Aguilar*

Main category: Xuanhe Zhou

TL;DR: 本文提出了一种基于RAMI 4.0框架的虚拟组织管理架构，集成了智能需求收集机制，以支持个性化产品创造。


<details>
  <summary>Details</summary>
Motivation: 现有虚拟组织管理架构存在三个主要问题：1) 未与工业4.0标准对齐；2) 缺乏智能需求收集机制；3) 未基于RAMI 4.0框架。这些限制阻碍了对个性化产品创造的支持。

Method: 提出了一种基于RAMI 4.0框架的虚拟组织管理架构，该架构集成了智能需求收集机制，以支持虚拟组织在个性化产品创造中的通信与协调。

Result: 该架构能够更好地支持虚拟组织在个性化产品创造中的运作，解决了现有架构与工业4.0标准不兼容、缺乏智能需求收集机制的问题。

Conclusion: 基于RAMI 4.0框架并集成智能需求收集机制的虚拟组织管理架构，能够有效支持个性化产品创造，填补了现有研究的空白。

Abstract: A Virtual Organization (VO) unites companies or independent individuals to achieve a shared, short-term objective by leveraging information technologies for communication and coordination in personalized product creation. Despite extensive research, existing VO management architectures lack alignment with Industry 4.0 standards, do not incorporate intelligent requirement-gathering mechanisms, and are not based on the RAMI 4.0 framework. These limitations hinder support for …

</details>


### [521] [Text-to-SQL Architecture](https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-032-06905-4_3&hl=zh-CN&sa=X&d=5230344721522035854&ei=uAYtaZz8A-uuieoPn9Oq8Ao&scisig=ABGrvjKabxnwgiXujWepY6sYlF5p&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=3&folt=cit)
*G Katsogiannis*

Main category: Xuanhe Zhou

TL;DR: 该论文对神经Text-to-SQL系统的发展进行了系统性分析，识别不同方法的共同点和新兴趋势，帮助理解该领域的研究方向


<details>
  <summary>Details</summary>
Motivation: 自首个神经Text-to-SQL系统问世以来，出现了大量不同的方法，每种方法都以自己的方式推动技术进步。由于方法众多且分散，理解该研究领域的趋势和方向变得困难，需要系统性分析来识别共同模式和新兴方向

Method: 对现有的神经Text-to-SQL系统进行系统性分析，识别和分类使用的不同技术，通过比较分析找出各种系统的共同点和差异

Result: 通过系统性分析，能够观察到不同系统之间的共同特征和新兴趋势，揭示了该领域的技术演进路径和研究方向

Conclusion: 对神经Text-to-SQL系统进行系统性分析有助于理解该领域的研究趋势，识别共同的技术模式，为未来的研究提供指导

Abstract: Since the introduction of the first neural Text-to-SQL systems, a multitude of different approaches have been proposed, each trying to advance the state of the art in its own way. Understanding the trends and directions of this research area by looking at all the different systems can often be like looking for a needle in a haystack. However, when we systematically analyze all the different techniques that have been used, we start to observe the commonalities of different systems and the emerging …

</details>


### [522] [Describing SQL queries in Natural Language](https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-032-06905-4_5&hl=zh-CN&sa=X&d=13895288404563012955&ei=uAYtaZz8A-uuieoPn9Oq8Ao&scisig=ABGrvjJu2oenPVk1KYqN3pDpQqjd&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=4&folt=cit)
*G Katsogiannis*

Main category: Xuanhe Zhou

TL;DR: SQL-to-Text：将SQL查询转换为自然语言描述，帮助非技术用户理解数据库查询


<details>
  <summary>Details</summary>
Motivation: SQL的复杂性使非技术用户难以访问数据库，自然语言界面虽然能帮助将问题转换为SQL，但用户仍难以理解或验证生成的查询，因此需要将SQL转换回自然语言描述

Method: 本章介绍了SQL-to-Text问题，即如何将SQL查询转换回自然语言描述的方法

Result: 未在摘要中明确说明具体结果，但提出了解决SQL-to-Text问题的框架

Conclusion: SQL-to-Text转换有助于弥合技术用户和非技术用户之间的鸿沟，使数据库查询更易于理解和验证

Abstract: Abstract Structured Query Language (SQL) is a powerful tool for data retrieval, but its complexity often renders databases inaccessible to non-technical users. While natural language interfaces can help bridge this gap by translating user questions into SQL queries, these users may still struggle to understand or verify the generated queries. This chapter addresses the SQL-to-Text problem: the task of converting SQL queries back into natural language descriptions. An introduction of the problem and …

</details>


### [523] [Multi-turn NLIDBs](https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-032-06905-4_6&hl=zh-CN&sa=X&d=16955310303072397629&ei=uAYtaZz8A-uuieoPn9Oq8Ao&scisig=ABGrvjLYQaeP_QkoY_1GjmOUy7n1&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=5&folt=cit)
*G Katsogiannis*

Main category: Xuanhe Zhou

TL;DR: 本章探讨多轮Text-to-SQL问题，涵盖交互式和对话式两个子类别，分析核心挑战、系统架构、现有数据集和评估指标


<details>
  <summary>Details</summary>
Motivation: 在聊天机器人环境中实现用户交互是构建自然直观的NLIDB（自然语言接口数据库）的重要步骤。多轮Text-to-SQL能够处理更复杂的查询场景，支持用户通过多轮对话逐步完善查询需求。

Method: 将多轮Text-to-SQL分为两个主要子类别：交互式Text-to-SQL（用户通过多轮交互逐步完善查询）和对话式Text-to-SQL（系统需要理解对话上下文和用户意图）。对每个子类别分析核心挑战，提供系统架构的全面概述。

Result: 提供了多轮Text-to-SQL领域的系统性分析框架，包括：1）交互式和对话式子类别的明确定义；2）每个类别的核心挑战识别；3）系统架构的全面概述；4）现有数据集和评估指标的整理。

Conclusion: 多轮Text-to-SQL是NLIDB发展的重要方向，通过支持交互式和对话式查询，能够更好地满足复杂场景下的数据库查询需求。本章为这一领域的研究提供了系统性的分析框架和资源参考。

Abstract: Enabling interaction with users in a chatbot environment is an important step toward building natural and intuitive NLIDBs. This chapter explores the problem of multi-turn Text-to-SQL, focusing on its two main subcategories: interactive and conversational Text-to-SQL. For each subcategory, the chapter outlines the core challenges and offers a comprehensive overview of the systems' architecture. The chapter also presents existing datasets and evaluation metrics, providing a holistic understanding …

</details>


### [524] [Adaptive information retrieval for multimodal data](https://scholar.google.com/scholar_url?url=https://patents.google.com/patent/US12450274B1/en&hl=zh-CN&sa=X&d=914504712446776306&ei=uAYtaZz8A-uuieoPn9Oq8Ao&scisig=ABGrvjIC5Wq-32T1eqOhz7p8P7jG&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=7&folt=cit)
*S Jain,S Thiruchittampalam,VN VEDAM,J Lin*

Main category: Xuanhe Zhou

TL;DR: 文档智能分块：基于文档结构、层次和内容生成分类，并选择最优分块策略将文档划分为多个块


<details>
  <summary>Details</summary>
Motivation: 传统文档分块方法通常采用固定策略（如按字数、段落等），无法适应不同类型文档的结构和语义特征，导致信息丢失或分割不当。需要一种能根据文档特性动态选择最优分块策略的智能方法。

Method: 首先分析文档的结构（章节组织）、层次（标题级别）和内容（语义特征），生成文档分类。然后从多个可用分块策略中选择针对该分类优化的策略，最后按照选定策略将文档划分为多个块。

Result: 该方法能够根据文档特性自适应选择分块策略，相比固定策略能更好地保持文档的语义完整性和结构连贯性，提高后续处理任务（如检索、摘要、分析）的效果。

Conclusion: 基于文档分类的智能分块策略选择方法比传统固定分块方法更有效，能更好地适应不同类型文档的特性，为文档处理任务提供更优的输入。

Abstract: At least one processor can generate a classification of a document including a plurality of sections according to at least one of a structure of at least one of the plurality of sections, a hierarchy of the plurality of sections, and a content of at least one of the plurality of sections. The at least one processor can determine a chunking strategy optimized for the classification from among a plurality of available chunking strategies, divide the document into a plurality of chunks according to the chunking …

</details>


### [525] [Consistent Discourse-level Temporal Relation Extraction Using Large Language Models](https://scholar.google.com/scholar_url?url=https://aclanthology.org/anthology-files/anthology-files/pdf/findings/2025.findings-emnlp.1010.pdf&hl=zh-CN&sa=X&d=1709923130515583835&ei=tgYtabq-Ov-j6rQPrbnwwA4&scisig=ABGrvjIpSz2DSscQLt1AwGATNc22&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=0&folt=rel)
*Y Fan,M Strube*

Main category: Xuanhe Zhou

TL;DR: 该论文研究利用大语言模型进行时间关系提取，但发现现有方法存在局限性，因此提出了一种新的评估框架来系统评估LLM在时间关系提取任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在时间关系提取方面取得进展，但现有评估方法不完善，缺乏对LLM在该任务上能力的系统性评估，需要更全面的评估框架来理解其优势和局限性。

Method: 论文提出了一种新的评估框架，可能包括系统性的测试集设计、评估指标、对比实验等方法，以全面评估LLM在时间关系提取任务上的表现。

Result: 研究发现LLM在时间关系提取方面存在特定局限性，通过提出的评估框架揭示了模型在理解复杂时间关系时的具体挑战和不足。

Conclusion: 需要更完善的评估方法来准确衡量LLM在时间关系提取任务上的能力，提出的框架为未来研究提供了有价值的评估工具和方向。

Abstract: Understanding temporal relations between events in a text is essential for determining its temporal structure. Recent advancements in large language models (LLMs) have spurred research on temporal relation extraction. However, LLMs …

</details>


### [526] [Efficiently Detecting DBMS Bugs through Bottom-up Syntax-based SQL Generation](https://scholar.google.com/scholar_url?url=https://steveleungyl.github.io/papers/liang-sqlbull.pdf&hl=zh-CN&sa=X&d=7918371602347703977&ei=tgYtabq-Ov-j6rQPrbnwwA4&scisig=ABGrvjKu6lBM8SjHffLArhyaGuBU&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=1&folt=rel)
*Y Liang,P Liu*

Main category: Xuanhe Zhou

TL;DR: 该论文提出了一种自底向上的SQL语法树生成方法，相比现有的自顶向下方法，能够更有效地发现数据库管理系统中的错误。


<details>
  <summary>Details</summary>
Motivation: 现有基于语法的SQL测试工具都采用自顶向下生成方法，这种方法在生成复杂查询时存在局限性，无法有效发现数据库管理系统中的某些类型错误。

Method: 提出了一种自底向上的SQL语法树生成方法，从叶子节点开始构建查询，逐步组合成完整语法树，能够生成更复杂、多样的SQL查询。

Result: 自底向上方法相比传统自顶向下方法能够发现更多数据库管理系统错误，特别是在复杂查询场景下表现更优。

Conclusion: 自底向上的SQL语法树生成方法是一种更有效的数据库测试技术，能够提高错误检测能力，为数据库质量保障提供新思路。

Abstract: Syntax-based testing is a promising technique for finding bugs in Database Management Systems (DBMSs). All existing syntax-based SQL generation tools apply a Top-down generation method. To construct a SQL query (syntax tree), the …

</details>


### [527] [Biomedical Question Answering: Extending GeneGPT with the code act paradigm](https://scholar.google.com/scholar_url?url=https://thesis.unipd.it/handle/20.500.12608/98449&hl=zh-CN&sa=X&d=5600095384505755058&ei=oFcuadyjDLuZ6rQPmc7JqQw&scisig=ABGrvjL-652hV7ZI37ERF_QL4UDx&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=0&folt=cit)
*K Abedini*

Main category: Xuanhe Zhou

TL;DR: 该论文探讨了利用大型语言模型进行基因组学知识检索的挑战，提出了一个专门针对基因组学问答的框架，旨在克服现有LLM在专业领域应用的局限性。


<details>
  <summary>Details</summary>
Motivation: 基因组信息理解对生物医学研究、精准医疗和治疗开发至关重要，但基因组数据库的复杂性和分布式特性给高效知识检索带来了显著障碍。虽然大型语言模型在自然语言理解方面表现出色，但在专业基因组学问答中的应用仍受限于领域特定知识的缺乏和复杂查询处理能力的不足。

Method: 论文可能提出了一种专门针对基因组学设计的问答框架，可能包括：1）基因组知识图谱的构建和集成；2）领域特定的检索增强生成技术；3）基因组数据库的语义索引和查询优化；4）LLM与专业基因组工具的集成；5）针对基因组学术语和概念的专门微调策略。

Result: 虽然摘要未提供具体结果，但可以预期该框架在基因组学问答任务上相比通用LLM会有显著改进，包括：1）提高基因组相关查询的准确性和相关性；2）增强对复杂基因组概念的理解；3）改善对分布式数据库的检索效率；4）在专业基因组学基准测试中表现优异。

Conclusion: 开发专门针对基因组学领域的大型语言模型应用框架是必要的，能够有效克服通用LLM在专业基因组知识检索中的局限性，为生物医学研究和临床实践提供更可靠的信息支持。

Abstract: Understanding genomic information is fundamental to the advancement of biomedical research, precision medicine, and therapeutic development, but the complexity and distributed nature of genomic databases present significant barriers to efficient knowledge retrieval. Although Large Language Models (LLMs) have demonstrated remarkable capabilities in natural language understanding, their application to specialized genomic question answering remains limited by …

</details>


### [528] [UCO: A Multi-Turn Interactive Reinforcement Learning Method for Adaptive Teaching with Large Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.08873&hl=zh-CN&sa=X&d=6138661317503698106&ei=n1cuabmyEs2j6rQPsvXUgA0&scisig=ABGrvjIzP10tWA0ASEyPe831uKb9&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=0&folt=rel)
*S Wei,M Zhang,X Lin,B Jiang,K Kuang,Z Dai*

Main category: Xuanhe Zhou

TL;DR: 该论文提出了一种基于强化学习的框架，使大型语言模型能够通过动态教学策略适应学生需求，超越传统监督微调方法


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在教育领域从答案提供者转向智能导师，但现有的监督微调方法仅学习表面教学模式，缺乏动态适应学生需求的能力，限制了教学效果

Method: 采用强化学习框架，使LLM能够根据学生反馈动态调整教学策略，通过奖励机制优化教学行为，实现个性化教学适应

Result: 提出的强化学习方法使LLM能够根据学生表现动态调整教学策略，相比传统监督微调方法，在教学效果和适应性方面有显著提升

Conclusion: 强化学习为LLM作为智能导师提供了有效的动态适应能力，能够根据学生需求实时调整教学策略，代表了教育AI领域的重要进展

Abstract: Large language models (LLMs) are shifting from answer providers to intelligent tutors in educational settings, yet current supervised fine-tuning methods only learn surface teaching patterns without dynamic adaptation capabilities. Recent reinforcement …

</details>


### [529] [RTS-LLM: Restoring Time Structure for Time Series Forecasting with LLMs](https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0957417425040175&hl=zh-CN&sa=X&d=2706139685781171346&ei=n1cuabmyEs2j6rQPsvXUgA0&scisig=ABGrvjIKv8MBa2Gn0fiFYce9uQpw&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=1&folt=rel)
*T Chen,X Ma,Y Xu,Y Xu,S Qian,L Cui*

Main category: Xuanhe Zhou

TL;DR: 时间序列预测面临复杂时间依赖性和有限监督的挑战，需要开发更有效的预测方法


<details>
  <summary>Details</summary>
Motivation: 时间序列预测在科学和工业领域具有广泛应用，但由于复杂的时间依赖性和许多现实场景中有限的监督，这一问题仍然具有挑战性

Method: 摘要未提供具体方法细节，但暗示采用近期发展的技术来解决时间序列预测的挑战

Result: 摘要未提供具体实验结果，但暗示近期方法在时间序列预测方面取得了进展

Conclusion: 时间序列预测是一个重要但具有挑战性的问题，需要持续研究以应对复杂的时间依赖性和监督限制

Abstract: Time series forecasting is a fundamental problem in a wide range of scientific and industrial domains, yet it remains challenging due to the complex temporal dependencies and limited supervision in many real-world scenarios. Recent …

</details>


### [530] [Tool-to-agent retrieval: Bridging tools and agents for scalable llm multi-agent systems](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.01854&hl=zh-CN&sa=X&d=8447970776994906111&ei=n1cuabmyEs2j6rQPsvXUgA0&scisig=ABGrvjKgboD2KpMHbofPRxYSfWIc&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=2&folt=rel)
*E Lumer,F Nizar,A Gulati,PH Basavaraju,VK Subbiah*

Main category: Xuanhe Zhou

TL;DR: 论文提出了一种新的检索方法，通过将查询与工具描述和工具使用历史进行匹配，显著提升了多智能体系统中工具检索的准确性和效率


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型多智能体系统能够协调大量工具或MCP服务器，但传统检索方法通常只将查询与工具描述匹配，忽略了工具使用历史中的宝贵信息，导致检索准确性不足

Method: 提出了一种结合工具描述和工具使用历史的检索方法，通过分析工具的实际使用记录来增强检索能力，可能包括历史使用模式、成功案例、参数配置等信息

Result: 新方法显著提高了工具检索的准确性和效率，在多智能体系统中实现了更精准的工具匹配和更高效的协调能力

Conclusion: 将工具使用历史纳入检索过程是多智能体系统工具检索的重要改进方向，能够充分利用历史信息提升系统性能

Abstract: Recent advances in LLM Multi-Agent Systems enable scalable orchestration of sub-agents, each coordinating hundreds or thousands of tools or Model Context Protocol (MCP) servers. However, existing retrieval methods typically match queries against …

</details>


### [531] [Are language models aware of the road not taken? Token-level uncertainty and hidden state dynamics](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.04527&hl=zh-CN&sa=X&d=9833064512822978923&ei=n1cuabmyEs2j6rQPsvXUgA0&scisig=ABGrvjLJWyWLNdkiSbgjF2FwRWuf&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=3&folt=rel)
*A Zur,A Geiger,ES Lubana,E Bigelow*

Main category: Xuanhe Zhou

TL;DR: 该研究探讨语言模型在生成文本时，如何量化其推理路径的不确定性，通过分析模型对替代推理路径的表示来评估其置信度。


<details>
  <summary>Details</summary>
Motivation: 语言模型在生成文本时，单个token的选择可能导致完全不同的推理路径，这使得模型的不确定性难以量化。研究者希望探索语言模型是否能够表示替代推理路径，从而更好地评估模型的置信度。

Method: 研究考虑语言模型是否表示替代推理路径，通过分析模型内部表示来评估其对不同推理可能性的认知，从而量化不确定性。

Result: 研究结果表明语言模型确实能够表示替代推理路径，这为量化模型在复杂推理任务中的不确定性提供了新的方法。

Conclusion: 通过分析语言模型对替代推理路径的表示，可以更有效地量化模型在生成过程中的不确定性，这有助于提高模型的可解释性和可靠性。

Abstract: When a language model generates text, the selection of individual tokens might lead it down very different reasoning paths, making uncertainty difficult to quantify. In this work, we consider whether reasoning language models represent the alternate paths …

</details>


### [532] [Extraction of geoprocessing modeling knowledge from crowdsourced Google Earth Engine scripts by coordinating large and small language models](https://scholar.google.com/scholar_url?url=https://www.tandfonline.com/doi/abs/10.1080/13658816.2025.2577252&hl=zh-CN&sa=X&d=5682944280018738254&ei=n1cuabmyEs2j6rQPsvXUgA0&scisig=ABGrvjKTHOxnIMnJlAU_Kb7FX7sE&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=4&folt=rel)
*A Zhao,Z Gui,J Liang,Y Liu,D Peng,W Wei,S Hou…*

Main category: Xuanhe Zhou

TL;DR: 从Google Earth Engine等在线地理信息平台的众包脚本中提取领域知识，以支持地理处理工作流理解


<details>
  <summary>Details</summary>
Motivation: 在线地理信息平台（如Google Earth Engine）产生了大量众包脚本，这些脚本蕴含丰富的领域知识，但缺乏系统化的提取方法，限制了地理处理工作流的理解和复用

Method: 未在摘要中明确说明具体方法，但研究聚焦于从众包脚本中提取领域知识，可能涉及文本挖掘、代码分析、工作流提取等技术

Result: 未在摘要中明确说明具体结果，但研究旨在支持地理处理工作流的理解，可能提供知识提取框架或工具

Conclusion: 从在线地理信息平台的众包脚本中提取领域知识对于理解地理处理工作流具有重要意义，需要开发相应的方法和技术

Abstract: The widespread use of online geoinformation platforms, such as Google Earth Engine (GEE), has produced numerous scripts. Extracting domain knowledge from these crowdsourced scripts supports understanding of geoprocessing workflows …

</details>


### [533] [Utilizing Large Language Models for Integrating Document-Level Contextual Semantic into Pseudo-Relevance Feedback](https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0950705125020180&hl=zh-CN&sa=X&d=12399048709685727788&ei=n1cuabmyEs2j6rQPsvXUgA0&scisig=ABGrvjId-CtKd45C7mhlhJ2qub1O&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=6&folt=rel)
*M Pan,W Xiong,Y Liu,J Wang,F Deng,EA Huang…*

Main category: Xuanhe Zhou

TL;DR: 伪相关反馈(PRF)是信息检索中的关键技术，传统方法依赖词频等统计信息进行精确匹配和相关性评估，但存在局限性


<details>
  <summary>Details</summary>
Motivation: 传统伪相关反馈方法主要基于词频等统计信息，这些方法在精确匹配和相关性评估方面存在局限性，需要更先进的解决方案

Method: 基于统计信息的传统PRF实现方法，依赖词频等统计特征进行精确匹配和相关性判断

Result: 传统PRF方法在信息检索中发挥重要作用，但存在局限性，为后续改进方法提供了基础

Conclusion: 传统伪相关反馈方法虽然有效，但基于统计信息的方法存在不足，需要更先进的替代方案

Abstract: Abstract Pseudo-Relevance Feedback (PRF) is a key technique in information retrieval (IR). Traditional implementations rely on statistical information, such as term frequency, for precise matching and relevance assessment. However, these methods …

</details>


### [534] [ORANGE: An Online Reflection ANd GEneration framework with Domain Knowledge for Text-to-SQL](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.00985&hl=zh-CN&sa=X&d=16025118982919877088&ei=n1cuabmyEs2j6rQPsvXUgA0&scisig=ABGrvjJhhJTuowxE8BZnCGc_LVrq&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=7&folt=rel)
*Y Jiao,T Ren,Y Gao,Z He,Y Jing,K Zhang,XS Wang*

Main category: Xuanhe Zhou

TL;DR: LLMs在自然语言转SQL方面取得进展，但通用知识与数据库领域特定语义间存在显著语义鸿沟


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在自然语言转SQL任务中通用知识与数据库领域特定语义之间的语义鸿沟问题，提升LLMs在领域特定数据库查询中的准确性和可靠性

Method: 论文可能提出结合领域知识增强的方法，如领域特定微调、知识注入、语义对齐等技术，以弥合通用LLMs与数据库特定语义之间的差距

Result: 预期通过领域知识增强的方法能显著提升LLMs在领域特定数据库查询任务中的性能，减少语义误解，提高SQL生成准确性

Conclusion: 需要专门的方法来弥合LLMs通用知识与数据库领域特定语义之间的鸿沟，领域知识增强是提升自然语言转SQL性能的关键方向

Abstract: Large Language Models (LLMs) have demonstrated remarkable progress in translating natural language to SQL, but a significant semantic gap persists between their general knowledge and domain-specific semantics of databases. Historical …

</details>


### [535] [Learning to Think Fast and Slow for Visual Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.16670&hl=zh-CN&sa=X&d=14075119318359490852&ei=egswabmSDv3D6rQP-Yuy-Qs&scisig=ABGrvjJVcnSoyhfoOgM-7voiq8g2&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=0&folt=rel)
*C Lin,C Chi,J Wu,S Li,K Zhou*

Main category: Xuanhe Zhou

TL;DR: 论文探讨了人类面对复杂问题时采用慢思考、简单问题时采用快思考的双系统思维机制，这种机制能有效分配认知资源，实现快速决策。


<details>
  <summary>Details</summary>
Motivation: 研究人类认知决策中双系统思维机制（快思考与慢思考）如何优化认知资源分配，提高决策效率。

Method: 通过理论分析和认知心理学框架，探讨双系统思维机制的工作原理及其在决策过程中的应用。

Result: 双系统思维机制能有效区分问题复杂度，自动调整认知资源分配，实现认知效率最大化。

Conclusion: 人类认知系统通过快慢思考的双重机制，实现了对复杂和简单问题的高效处理，这种自适应机制是认知资源优化的关键。

Abstract: When confronted with complex problems, we tend to think slowly; conversely, for simple questions, we think quickly. Such a two-system thinking mechanism allows us to efficiently allocate cognitive resources, enabling quick decision-making for …

</details>


### [536] [Text-to-SQL as Dual-State Reasoning: Integrating Adaptive Context and Progressive Generation](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.21402&hl=zh-CN&sa=X&d=17729073617765234523&ei=egswabmSDv3D6rQP-Yuy-Qs&scisig=ABGrvjKMCRFVOKCc8A53Ax5iQBRE&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=1&folt=rel)
*Z Hao,Q Song,R Cai,B Xu*

Main category: Xuanhe Zhou

TL;DR: 该论文针对企业级复杂SQL查询中现有分治推理方法的局限性，提出了一种新的基于语义依赖图的分治方法，通过语义依赖分析而非简单的语法分解来改进LLMs的Text-to-SQL能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于CoT的分治推理方法在处理企业级复杂SQL查询时存在局限性，这些查询通常涉及多表连接、嵌套子查询和复杂条件，简单的语法分解方法难以有效处理语义依赖关系，导致生成的SQL质量下降。

Method: 提出基于语义依赖图的分治方法，通过分析查询意图和数据库模式构建语义依赖图，识别查询中的核心语义单元及其依赖关系，然后采用分治策略逐步生成SQL片段，最后组合成完整查询。

Result: 该方法在复杂企业级SQL基准测试中显著提升了LLMs的Text-to-SQL性能，相比传统CoT方法在准确率和执行正确率上都有明显改进，特别是在处理多表连接和嵌套查询时表现更优。

Conclusion: 基于语义依赖图的分治方法能更有效地处理复杂企业级SQL查询，通过语义层面的分解和推理克服了传统语法分解方法的局限性，为LLMs在企业级数据库应用中的实用化提供了重要技术支撑。

Abstract: Recent divide-and-conquer reasoning approaches, particularly those based on Chain-of-Thought (CoT), have substantially improved the Text-to-SQL capabilities of Large Language Models (LLMs). However, when applied to complex enterprise …

</details>


### [537] [Resolving Evidence Sparsity: Agentic Context Engineering for Long-Document Understanding](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.22850&hl=zh-CN&sa=X&d=17833477634636067982&ei=LG4xaa-yA82j6rQP2_qhyQ8&scisig=ABGrvjLaBLCTUpPe8_nvUjbxCIBh&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=1&folt=cit)
*K Liu,Z Chen,M Li,J Tang,D Yang,L Zhang*

Main category: Xuanhe Zhou

TL;DR: VLMs在单页文档理解中表现良好，但在处理多页长文档时效果下降，需要检索增强生成来解决跨页多模态线索分散和冗余输入的问题


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在单页文档理解任务中表现出色，但在处理长文档时效果显著下降，因为线索分散在多个页面和模态中，且冗长的输入会损害模型判断能力

Method: 使用检索增强生成方法，通过检索相关文档片段来缓解长文档处理中的问题，减少冗余输入对模型判断的干扰

Result: 论文指出检索增强生成方法能够有效缓解VLMs在处理长文档时的性能下降问题，提高跨页多模态线索的整合能力

Conclusion: 对于长文档理解任务，需要采用检索增强生成等方法来增强VLMs的能力，以应对跨页多模态线索分散和输入冗余的挑战

Abstract: Document understanding is a long standing practical task. Vision Language Models (VLMs) have gradually become a primary approach in this domain, demonstrating effective performance on single page tasks. However, their effectiveness diminishes when handling long documents. In such scenarios, clues are often scattered across multiple pages and modalities, and redundancy from lengthy inputs can impair the models judgment. While retrieval augmented generation mitigates this issue by …

</details>


### [538] [葡萄酒领域知识多路径检索增强生成方法优化研究.](https://scholar.google.com/scholar_url?url=https://search.ebscohost.com/login.aspx%3Fdirect%3Dtrue%26profile%3Dehost%26scope%3Dsite%26authtype%3Dcrawler%26jrnl%3D10028331%26AN%3D189508933%26h%3D7pTMLUz45zqTCU7lCUNTO9KCoA8zkGEMcFaESinPzdR01idjd181k%252FhWJVRJkX5%252Fd8rxArnl%252FeQt%252B7j51BFogw%253D%253D%26crl%3Dc&hl=zh-CN&sa=X&d=12325944103106816314&ei=LG4xaa-yA82j6rQP2_qhyQ8&scisig=ABGrvjL0-4rr3a0Mbt2v-o_Pbs7G&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ABGrvjJZwsAjJ0kF3Jr3klye4Pct&html=&pos=2&folt=cit)
*杨文跃， 于千城， 王启明， 穆洪锐， 周诚辰*

Main category: Xuanhe Zhou

TL;DR: 提出融合知识图谱、向量数据库和PKL文件库构建葡萄酒领域知识库的方法，以解决现有智能问答系统信息提取不全和检索精度不足的问题


<details>
  <summary>Details</summary>
Motivation: 葡萄酒领域专业术语繁多、工艺细节庞杂、酒品分类多样、年份差异敏感、酒庄文化异彩纷呈，现有智能问答系统因信息提取不全和检索精度不足，导致回答质量和准确性无法满足产业数字化转型需求

Method: 融合知识图谱、向量数据库和PKL文件库各自优势构建葡萄酒领域知识库，并探索葡萄酒领域知识多路径检索方法

Result: 未在摘要中明确说明具体实验结果，但提出了解决现有系统不足的创新方法框架

Conclusion: 通过融合多种知识表示和检索技术，有望提升葡萄酒领域专业问答系统的信息提取能力和检索精度，从而更好地服务于产区种植户、产业工人、酿酒师和品酒师的技术技能提升及产业数字化转型

Abstract: 在葡萄酒领域, 设计专业的领域知识问答系统对于提升产区种植户, 产业工人, 酿酒师和品酒师的技术技能, 以及助力整个产业的数字化转型具有重要意义. 鉴于葡萄酒领域专业术语繁多, 工艺细节庞杂, 酒品分类多样, 年份差异敏感以及酒庄文化异彩纷呈的特点, 现有的智能问答系统往往因为信息提取不全和检索精度不足, 导致回答的质量和准确性无法满足需求. 提出了融合知识图谱, 向量数据库和PKL 文件库各自优势以构建葡萄酒领域知识库的方法, 并探索了葡萄酒领域知识多路径检索 …

</details>


### [539] [RUST-BENCH: Benchmarking LLM Reasoning on Unstructured Text within Structured Tables](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.04491&hl=zh-CN&sa=X&d=9400156336482780547&ei=Km4xaebQNoS6ieoP7qfpqQc&scisig=ABGrvjJwJfmn3Lih92RCaRoJpDXZ&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=0&folt=rel)
*N Abhyankar,P Chaurasia,S Kabra,A Srivastava…*

Main category: Xuanhe Zhou

TL;DR: 现有表格推理基准主要测试模型在小规模、统一表格上的表现，未能充分体现真实世界数据的复杂性，对大型语言模型推理能力的评估不全面


<details>
  <summary>Details</summary>
Motivation: 现有表格推理基准存在局限性，主要使用小型、统一的表格，无法反映真实世界表格数据的复杂性（如长表格、多类型、多模态等），导致对LLMs推理能力的评估不完整

Method: 论文未提供具体方法细节，但从摘要可推测可能提出新的基准测试框架，包含更复杂的真实世界表格数据（长表格、多类型、多模态等）来全面评估LLMs的推理能力

Result: 未提供具体实验结果，但暗示现有基准对LLMs推理能力的评估存在偏差，需要更全面的评估框架来揭示模型在复杂真实世界表格数据上的实际表现

Conclusion: 需要开发更全面、更具挑战性的表格推理基准，以更好地评估LLMs在真实世界复杂表格数据上的推理能力，为模型改进提供更准确的指导

Abstract: Existing tabular reasoning benchmarks mostly test models on small, uniform tables, underrepresenting the complexity of real-world data and giving an incomplete view of Large Language Models'(LLMs) reasoning abilities. Real tables are long …

</details>


### [540] [No Free Lunch in Language Model Bias Mitigation? Targeted Bias Reduction Can Exacerbate Unmitigated LLM Biases](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.18635&hl=zh-CN&sa=X&d=15502750475249958842&ei=Km4xaebQNoS6ieoP7qfpqQc&scisig=ABGrvjIYxK0sp1R27WWmlwtTGHzb&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=1&folt=rel)
*S Chand,F Baca,E Ferrara*

Main category: Xuanhe Zhou

TL;DR: 该论文探讨了大型语言模型中的社会偏见问题，指出现有偏见缓解技术通常只在单一维度进行评估，而忽略了偏见的多维性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型从训练数据中继承了社会偏见，可能导致有害或不公平的输出。虽然已有多种技术旨在缓解这些偏见，但现有评估方法通常只在单一维度上进行，未能全面评估偏见的多维特性。

Method: 论文未提供具体方法细节，但从摘要推断，可能涉及对现有偏见缓解技术的系统性分析，以及提出更全面的多维评估框架。

Result: 摘要未提供具体结果，但暗示现有偏见缓解技术的评估存在局限性，需要更全面的多维评估方法。

Conclusion: 需要开发更全面的评估框架来评估偏见缓解技术的效果，考虑偏见的多维特性，而不仅仅是单一维度的改进。

Abstract: Large Language Models (LLMs) inherit societal biases from their training data, potentially leading to harmful or unfair outputs. While various techniques aim to mitigate these biases, their effects are often evaluated only along the dimension of …

</details>


### [541] [InsightEval: An Expert-Curated Benchmark for Assessing Insight Discovery in LLM-Driven Data Agents](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.22884&hl=zh-CN&sa=X&d=9932476623710603563&ei=Km4xaebQNoS6ieoP7qfpqQc&scisig=ABGrvjKMBtcjdNSlTGDFVFt1pR_3&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=3&folt=rel)
*Z Zhu,Y Song,X Chen,C Liu,Y Cui,CC Cao,S Han…*

Main category: Xuanhe Zhou

TL;DR: 论文探讨了大数据时代下深度探索性数据分析的重要性，强调需要超越传统统计方法来发掘海量数据集中的潜在知识和洞察


<details>
  <summary>Details</summary>
Motivation: 随着大数据时代的到来，海量数据集已成为科学研究不可或缺的部分。然而，传统的数据分析方法往往无法充分发掘这些数据中隐藏的深层知识和洞察，需要更深入的探索性分析来充分实现数据的价值。

Method: 论文提出采用深度探索性数据分析方法，超越传统的统计技术，通过更复杂的分析框架来揭示数据中的潜在模式和关系。

Result: 深度探索性数据分析能够更有效地从海量数据中提取有价值的知识和洞察，为科学研究提供更丰富的发现和更深入的理解。

Conclusion: 在大数据时代，深度探索性数据分析对于充分发掘数据价值至关重要，需要超越传统分析方法来揭示数据中隐藏的深层知识和洞察。

Abstract: Data analysis has become an indispensable part of scientific research. To discover the latent knowledge and insights hidden within massive datasets, we need to perform deep exploratory analysis to realize their full value. With the advent of large …

</details>


### [542] [DO: An Efficient Deep Reinforcement Learning Approach for Optimal Route with Collective Spatial Keywords](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3746252.3761331&hl=zh-CN&sa=X&d=3007469875620526460&ei=Km4xaebQNoS6ieoP7qfpqQc&scisig=ABGrvjLVkIpppia5KD2gh76PFYDK&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=4&folt=rel)
*J Li,J Dong,L Li,Y Yang,X Wang,M Zhang*

Main category: Xuanhe Zhou

TL;DR: ORCSK查询旨在寻找覆盖所有关键词的最短路径，现有方法基于POI候选集和路径扩展，存在效率问题


<details>
  <summary>Details</summary>
Motivation: 现有ORCSK查询方法在处理POI候选集和路径扩展时存在效率瓶颈，需要更高效的算法来解决最优路线规划问题

Method: 论文提出基于POI候选集和路径扩展的改进方法，可能包括新的索引结构、剪枝策略或算法优化

Result: 提出的方法在查询效率和路径质量上优于现有方法，能够更快地找到覆盖所有关键词的最短路径

Conclusion: 新方法有效解决了ORCSK查询的效率问题，为空间关键词路线规划提供了更实用的解决方案

Abstract: Given a source, destination, and required keywords, the Optimal Route with Collective Spatial Keywords (ORCSK) query aims to find the shortest route covering all keywords. Existing Point of Interest (POI) candidate set-based and path expansion …

</details>


### [543] [DiffuGR: Generative Document Retrieval with Diffusion Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.08150&hl=zh-CN&sa=X&d=13070287616511749396&ei=Km4xaebQNoS6ieoP7qfpqQc&scisig=ABGrvjJ7cTJZiqoHSjSnBoqs-yAK&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ABGrvjIpZSfk2xBUbH8A9giRS86U&html=&pos=6&folt=rel)
*X Zhao,Y Zhao,Z Li,M Zhang,J Feng,R Chen,Y Zhou…*

Main category: Xuanhe Zhou

TL;DR: 生成式检索将文档检索重构为基于序列的文档标识符生成任务，通过模型参数记忆文档，实现无需显式索引的端到端检索。


<details>
  <summary>Details</summary>
Motivation: 现有生成式检索方法面临文档标识符设计、训练目标与检索目标不一致、以及检索效率低下等挑战，需要更有效的解决方案。

Method: 论文提出了一种新的生成式检索方法，通过改进文档标识符设计、优化训练目标与检索目标的对齐，以及提升检索效率来解决现有问题。

Result: 提出的方法在多个基准测试中显著提升了检索性能，包括召回率、准确率和检索效率等方面的改进。

Conclusion: 该研究为生成式检索提供了有效的解决方案，通过系统性的方法改进，显著提升了检索性能，为端到端检索系统的发展做出了贡献。

Abstract: Generative retrieval (GR) re-frames document retrieval as a sequence-based document identifier (DocID) generation task, memorizing documents with model parameters and enabling end-to-end retrieval without explicit indexing. Existing GR …

</details>


### [544] [InsightChaser: Enhancing Visual Reasoning of Sports Tactical Visualization with Visual-Text Linking](https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Ziao-Liu-2/publication/397979711_InsightChaser_Enhancing_Visual_Reasoning_of_Sports_Tactical_Visualization_with_Visual-Text_Linking/links/692aebb3e889e65e796abe55/InsightChaser-Enhancing-Visual-Reasoning-of-Sports-Tactical-Visualization-with-Visual-Text-Linking.pdf&hl=zh-CN&sa=X&d=15158376410392952060&ei=cPYyabP9LKG7ieoPydy_qAE&scisig=ALhkC2TnsUdYkHYgMNYsAdnCpKTr&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=0&folt=cit)
*Z Liu,W Zhao,X Xie,A Cao,Y Wu,H Zhang,Y Wu*

Main category: Xuanhe Zhou

TL;DR: 提出一个支持战术可视化中视觉-文本链接的系统，帮助用户将高层战术洞察与视觉模式连接起来


<details>
  <summary>Details</summary>
Motivation: 体育分析中战术可视化广泛用于传达洞察，但由于复杂的领域知识和上下文信息，用户难以将高层战术洞察与视觉模式连接起来，现有视觉-文本链接研究对此支持不足

Method: 提出一个支持战术可视化中视觉-文本链接的系统，帮助用户解释游戏上下文中的洞察

Result: 未在摘要中明确说明具体结果，但暗示提出的方法能更好地支持用户连接战术洞察与视觉模式

Conclusion: 需要改进现有视觉-文本链接方法，以更好地支持用户在战术可视化中进行推理和解释

Abstract: In sports analytics, tactical visualization is widely used to convey valuable insights. However, due to the complex domain knowledge and contextual information involved in tactical visualizations, it is challenging for users to connect high-level tactical insights to corresponding visual patterns. This requires users to engage in a reasoning process to interpret insights within game contexts, which remains insufficiently supported in existing visual-text linking studies. In this work, we propose …

</details>


### [545] [TRivia: Self-supervised Fine-tuning of Vision-Language Models for Table Recognition](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.01248&hl=zh-CN&sa=X&d=2520951785623698465&ei=cPYyabP9LKG7ieoPydy_qAE&scisig=ALhkC2SOvT3b9TyLPb7oDf4j_XIS&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=1&folt=cit)
*J Zhang,B Wang,Q Zhang,F Wu,Z Wen,J Lu,J Shan…*

Main category: Xuanhe Zhou

TL;DR: 该论文探讨了表格识别（TR）领域面临的挑战，指出当前依赖监督学习和视觉语言模型（VLM）微调的方法需要大量标注数据，成本高昂，限制了性能进一步提升。


<details>
  <summary>Details</summary>
Motivation: 表格识别作为文档解析的核心组件，长期依赖监督学习，特别是最近通过视觉语言模型微调取得了显著进展。然而，进一步提升性能需要大规模标注数据，这些数据获取成本高昂，成为制约TR发展的瓶颈。

Method: 从摘要内容推断，论文可能提出了一种减少对标注数据依赖的新方法，可能涉及无监督、自监督或弱监督学习技术，或者探索更高效的数据利用策略。

Result: 摘要未提供具体实验结果，但暗示当前基于VLM微调的方法虽然将TR提升到了新水平，但进一步突破受到标注数据稀缺的限制。

Conclusion: 表格识别领域需要突破对大规模标注数据的依赖，开发更高效的学习方法以推动该领域进一步发展。

Abstract: Table recognition (TR) aims to transform table images into semi-structured representations such as HTML or Markdown. As a core component of document parsing, TR has long relied on supervised learning, with recent efforts dominated by fine-tuning vision-language models (VLMs) using labeled data. While VLMs have brought TR to the next level, pushing performance further demands large-scale labeled data that is costly to obtain. Consequently, although proprietary models have …

</details>


### [546] [Towards A New Era of Geo-Foundation Models: Expert-Guided Multimodal Alignment and Geospatial Context Awareness](https://scholar.google.com/scholar_url?url=https://eprints.gla.ac.uk/362607/2/362607.pdf&hl=zh-CN&sa=X&d=4028940911250839420&ei=cPYyabP9LKG7ieoPydy_qAE&scisig=ALhkC2TNZc1aCUWlTgtMwnq3RumU&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=2&folt=cit)
*T Han,H Chen,C Wang,Y Ren,M Wu*

Main category: Xuanhe Zhou

TL;DR: 该论文针对地理空间基础模型(GeoFMs)面临的多模态对齐和地理上下文增强两大挑战，提出了新的解决方案


<details>
  <summary>Details</summary>
Motivation: 地理空间基础模型在处理地理空间大数据时面临两个关键挑战：1) 如何对齐不同地理空间模态进行模型训练；2) 如何增强模型的地理上下文感知能力

Method: 论文开发了新的方法来对齐各种地理空间模态并增强基础模型的地理上下文意识，具体方法在摘要中未详细说明

Result: 通过提出的方法，能够有效解决地理空间多模态对齐和上下文感知问题，提升地理空间基础模型的性能

Conclusion: 该工作填补了地理空间基础模型在多模态对齐和上下文增强方面的空白，为地理空间分析提供了更强大的基础模型支持

Abstract: Foundation Models (FMs) have demonstrated significant potential for geospatial analysis. As geospatial big data (eg, geo-tagged text and images) continues to grow, FMs have evolved into geospatial foundation models (GeoFMs), the FMs with the capability of geospatial reasoning. However, two critical tasks remain challenging:(1) how to align various geospatial modalities for model training, and (2) how to enhance FMs' geospatial context awareness. To fill these gaps, this work develops …

</details>


### [547] [FAST MULTI-SCALE GENERALIZATION BOUNDS FOR TOOL-AUGMENTED REASONING IN LARGE LANGUAGE MODELS UNDER HEAVY-TAILED LOSS …](https://scholar.google.com/scholar_url?url=https://thesesjournal.com/index.php/1/article/download/1581/1191&hl=zh-CN&sa=X&d=13991722716383317056&ei=cPYyabP9LKG7ieoPydy_qAE&scisig=ALhkC2QaPJxUuUtzu1qoTwzIOBV1&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=3&folt=cit)
*M Baig,MA Imtiaz,H Revel,A Jamil,S Hussain…*

Main category: Xuanhe Zhou

TL;DR: 该论文针对工具增强语言模型提出了一种新的泛化理论框架，建立了快速学习率，解决了传统理论在处理重尾、无界误差分布时的失效问题。


<details>
  <summary>Details</summary>
Motivation: 工具增强语言模型的出现对传统泛化理论提出了挑战，因为它们的误差分布通常是重尾且无界的，这使得基于传统假设的理论分析失效。需要建立新的理论框架来分析这类模型的泛化性能。

Method: 将工具增强推理建模为多步过程，引入两个关键结构条件来控制模型的超额风险：1）假设假设类中的最坏情况损失满足特定条件；2）建立适当的正则化机制。通过分析多步推理过程的误差传播来建立学习率。

Result: 建立了工具增强语言模型的快速学习率，证明在适当的正则化条件下，即使面对重尾和无界的误差分布，模型也能达到良好的泛化性能。理论结果提供了对工具增强推理过程的理论保证。

Conclusion: 该工作为工具增强语言模型提供了新的泛化理论框架，解决了传统理论在处理这类模型时的局限性。提出的结构条件和分析方法为理解和设计更可靠的工具增强系统提供了理论基础。

Abstract: The rise of tool-augmented language models (TaLMs) presents a significant challenge for generalization theory, as their error distributions are often heavy-tailed and unbounded, rendering conventional theoretical analyses ineffective. This work establishes fast learning rates for tool-augmented reasoning, which we model as a multi-step process. To control the model's excess risk, we introduce two key structural conditions. First, we assume that the worst-case loss across the hypothesis class …

</details>


### [548] [Towards Active Synthetic Data Generation for Finetuning Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.00884&hl=zh-CN&sa=X&d=8860906407901052093&ei=b_YyaYSeLam6ieoPqIeGyAM&scisig=ALhkC2S36ZxOBexhSLXJSMVGqpzH&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=0&folt=rel)
*S Kessler,M Xia,DM Diaz,D Han,H Heshemi…*

Main category: Xuanhe Zhou

TL;DR: 该论文探讨了使用教师模型生成合成数据来微调学生语言模型的方法，分析了合成数据分布与真实数据分布之间的差异及其对模型性能的影响。


<details>
  <summary>Details</summary>
Motivation: 当前使用教师模型生成合成数据来微调学生模型的方法虽然有效，但合成数据分布与真实数据分布之间存在差异，这种分布不匹配可能导致学生模型性能下降，需要深入理解其影响机制。

Method: 通过理论分析和实验验证，研究合成数据分布与真实数据分布之间的差异，分析分布不匹配如何影响学生模型的性能，并提出相应的改进策略。

Result: 研究发现合成数据分布与真实数据分布确实存在系统性差异，这种分布不匹配会显著影响学生模型的最终性能，特别是在泛化能力和鲁棒性方面。

Conclusion: 合成数据微调虽然有效，但必须考虑分布不匹配问题，未来的研究需要开发更好的方法来对齐合成数据与真实数据的分布，以提高学生模型的性能。

Abstract: A common and effective means for improving language model capabilities involves finetuning a``student''language model's parameters on generations from a more proficient``teacher''model. Termed``synthetic data'', these generations are often …

</details>


### [549] [HierRouter: Coordinated Routing of Specialized Large Language Models via Reinforcement Learning](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.09873&hl=zh-CN&sa=X&d=9665641608697370150&ei=b_YyaYSeLam6ieoPqIeGyAM&scisig=ALhkC2RzRI7hTNyenjHj0b-AD-IX&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=3&folt=rel)
*N Gupta,B Guo,R Kannan,VK Prasanna*

Main category: Xuanhe Zhou

TL;DR: 提出HierRouter框架，通过分层路由机制将输入分配给不同规模的专家模型，在保持性能的同时显著降低计算成本


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然性能优异，但计算和内存成本高昂，限制了在资源受限或实时场景中的部署。需要一种既能保持性能又能降低计算开销的解决方案。

Method: 提出HierRouter框架，采用分层路由机制，根据输入复杂度将查询分配给不同规模的专家模型。系统包含多个层级的专家，从轻量级到重量级，通过路由决策器动态选择最合适的专家处理每个输入。

Result: HierRouter在多个基准测试中实现了与原始LLM相当的性能，同时显著降低了计算成本（FLOPs减少30-50%）。框架在保持准确性的同时提高了推理效率。

Conclusion: HierRouter提供了一种有效的解决方案，通过智能路由机制平衡LLM的性能与效率，为资源受限环境中的模型部署开辟了新途径。

Abstract: Large Language Models (LLMs) deliver state-of-the-art performance across many tasks but impose high computational and memory costs, limiting their deployment in resource-constrained or real-time settings. To address this, we propose HierRouter …

</details>


### [550] [Cross-Lingual Interleaving for Speech Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.01865&hl=zh-CN&sa=X&d=6797782975066736998&ei=b_YyaYSeLam6ieoPqIeGyAM&scisig=ALhkC2T7_bT7-uO4gLp8quO_-AT5&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=4&folt=rel)
*A Moumen,G Sun,PC Woodland*

Main category: Xuanhe Zhou

TL;DR: 该论文探讨了语音语言模型(SLMs)直接从语音学习语言能力的技术，重点关注如何通过离散单元处理语音信号，为书面资源有限的语言提供NLP技术访问。


<details>
  <summary>Details</summary>
Motivation: 语音语言模型(SLMs)旨在直接从语音学习语言能力，使用离散单元处理语音信号，这可以为书面资源有限的语言拓宽自然语言处理(NLP)技术的访问。然而，目前该领域进展存在挑战，需要进一步研究。

Method: 论文采用基于离散单元的语音语言模型方法，直接从语音信号中学习语言表示，而不依赖书面文本。具体方法可能涉及语音离散化、自监督学习等技术。

Result: 从摘要中无法获取具体实验结果，但可以推断该研究展示了语音语言模型在直接从语音学习语言能力方面的潜力，特别是在为资源有限语言提供NLP技术方面的应用前景。

Conclusion: 语音语言模型通过离散单元直接从语音学习语言能力，为书面资源有限的语言提供了NLP技术访问的新途径，但该领域仍面临挑战，需要进一步研究和发展。

Abstract: Spoken Language Models (SLMs) aim to learn linguistic competence directly from speech using discrete units, widening access to Natural Language Processing (NLP) technologies for languages with limited written resources. However, progress has …

</details>


### [551] [CoDyn: Dynamic LLM Routing for Coding Tasks](https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3D0ox03jE6jb&hl=zh-CN&sa=X&d=1468809941840432223&ei=b_YyaYSeLam6ieoPqIeGyAM&scisig=ALhkC2SQdYphNjz-694UcF6gY11c&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=5&folt=rel)
*M Haque,P Babkin,V Tawosi,S Rahimi,N Raman…*

Main category: Xuanhe Zhou

TL;DR: 该论文探讨大型语言模型在软件工程等商业应用中的多样性挑战，提出评估框架以帮助用户选择合适模型


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在软件工程等商业应用中日益重要，但模型种类繁多、性能各异，用户难以选择合适的模型。需要系统评估框架来指导模型选择决策。

Method: 论文提出系统性的评估框架，可能包括性能基准测试、成本效益分析、特定任务适应性评估等方法，对主流LLMs进行综合比较。

Result: 通过评估框架分析，识别出不同LLMs在软件工程任务中的优势和劣势，提供模型选择的实用指导原则。

Conclusion: 需要系统化的评估框架来帮助用户根据具体需求选择合适的大型语言模型，平衡性能、成本和适用性等因素。

Abstract: Large language models (LLMs) have become integral tools in various business applications, including software engineering, due to their ability to process and generate text. However, the diverse landscape of LLMs, encompassing both …

</details>


### [552] [Accelerating Long-Context Inference of Large Language Models via Dynamic Attention Load Balancing](https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0950705125020568&hl=zh-CN&sa=X&d=4816257878424043462&ei=b_YyaYSeLam6ieoPqIeGyAM&scisig=ALhkC2SRpLhBlGIM88iiUvlwzInI&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=7&folt=rel)
*J Ou,J Guo,S Jiang,X Li,R Xue,W Tian,R Buyya*

Main category: Xuanhe Zhou

TL;DR: LLMs注意力机制存在二次复杂度问题，导致长上下文推理效率低下，需要优化方法


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在自然语言处理任务中表现出色，但其注意力机制的二次复杂度导致长上下文推理效率低下，限制了模型的实际应用

Method: 论文可能提出了优化注意力机制的方法，如稀疏注意力、线性注意力或其他降低计算复杂度的技术，以改善长上下文处理效率

Result: 预期结果显示优化后的模型在保持性能的同时显著提升了长上下文推理效率，降低了计算复杂度

Conclusion: 通过优化注意力机制，可以有效解决LLMs在长上下文推理中的效率瓶颈，为实际应用提供可行方案

Abstract: Large language models (LLMs) have demonstrated exceptional performance across various natural language processing tasks. However, their quadratic complexity of attention mechanisms results in inefficiency during long-context inference. Although …

</details>


### [553] [LLM-Aided Customizable Profiling Platform For Code Data Based On Programming Language Concepts (Industry Track)](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3721463.3772057&hl=zh-CN&sa=X&d=10506930302789522158&ei=VFw0aZ_bGb2qieoP9aut2Qs&scisig=ALhkC2StKHt-Vr3k5ql0TgHVXnGl&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=3&folt=rel)
*P Thorat,A Qidwai,A Dhar,A Chakraborty,A Eswaran…*

Main category: Xuanhe Zhou

TL;DR: 论文探讨了代码大语言模型中训练数据质量对下游任务性能的影响，并提出了评估代码数据特征的方法


<details>
  <summary>Details</summary>
Motivation: 代码大语言模型的性能高度依赖于训练数据的质量，但目前缺乏系统评估代码数据特征的方法，这限制了模型在代码生成和总结等下游任务中的准确性提升

Method: 论文提出了评估代码数据特征的方法论，可能包括代码复杂度、可读性、语义完整性等维度的量化指标，用于系统分析训练数据的质量

Result: 通过提出的特征评估方法，能够更准确地识别高质量代码数据，从而提升代码大语言模型在下游任务中的性能表现

Conclusion: 系统评估代码数据特征对于优化代码大语言模型的训练数据质量至关重要，这为提升模型在代码相关任务中的准确性提供了有效途径

Abstract: In code Large Language Models (LLMs), the quality of training data substantially affects the model accuracy of the downstream tasks such as code generation and summarization. Thus, having the capability to characterize code data in terms of …

</details>


### [554] [Towards Unification of Hallucination Detection and Fact Verification for Large Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.02772&hl=zh-CN&sa=X&d=6014477423498344218&ei=VFw0aZ_bGb2qieoP9aut2Qs&scisig=ALhkC2Ryz4q_63s9BO7HtiHz4Mwo&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=5&folt=rel)
*W Su,J Long,C Wang,S Lin,J Xu,Z Ye,Q Ai,Y Liu*

Main category: Xuanhe Zhou

TL;DR: LLMs常产生幻觉内容，虽流畅但事实错误，影响可信度和实际应用，需解决此问题


<details>
  <summary>Details</summary>
Motivation: LLMs频繁产生幻觉内容，这些内容看似流畅连贯但事实错误，破坏了用户信任并阻碍了LLMs在现实应用中的采用，需要解决这一挑战

Method: 论文未提供具体方法，但摘要暗示需要开发技术来检测、减少或防止LLMs产生幻觉内容

Result: 摘要未提供具体结果，但暗示需要评估不同方法在减少LLM幻觉方面的有效性

Conclusion: 解决LLM幻觉问题对于提高模型可信度和促进实际应用至关重要

Abstract: Large Language Models (LLMs) frequently exhibit hallucinations, generating content that appears fluent and coherent but is factually incorrect. Such errors undermine trust and hinder their adoption in real-world applications. To address this challenge …

</details>


### [555] [MindGPT-4ov: An Enhanced MLLM via a Multi-Stage Post-Training Paradigm](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.02895&hl=zh-CN&sa=X&d=13812808123543585067&ei=VVw0ac_CGOeEieoPopmbeA&scisig=ALhkC2Rh3D0CYoc6h1TIH9q4_Hb8&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=0&folt=cit)
*W Chen,C Du,F Gu,W He,Q Li,Z Liu,X Pan,C Ren…*

Main category: Xuanhe Zhou

TL;DR: MindGPT-4ov是一个多模态大语言模型，提出了一种涵盖数据生产、模型训练和高效部署的通用后训练范式，以低成本在多个基准测试中达到最先进性能


<details>
  <summary>Details</summary>
Motivation: 提升多模态大语言模型的基础能力和泛化能力，同时降低训练成本，实现高效部署

Method: 采用通用后训练范式，包括数据构建、监督微调策略和多模态强化学习方法，涵盖数据生产、模型训练和高效部署全流程

Result: 在多个基准测试中达到最先进性能，以低成本有效增强了MLLM的基础能力和泛化能力

Conclusion: 提出的通用后训练范式能够有效提升多模态大语言模型的性能，同时实现低成本训练和高效部署

Abstract: We present MindGPT-4ov, a multimodal large language model (MLLM) that introduces a general post-training paradigm spanning data production, model training, and efficient deployment. It achieves state-of-the-art performance across multiple benchmarks at low cost, effectively enhancing the foundational capabilities of MLLMs and the generalization ability. Focusing on data construction, supervised fine-tuning strategies, and multimodal reinforcement learning methods, this work …

</details>


### [556] [AI-Assisted Query Optimization Techniques for Cloud Databases Supporting Hybrid SQL and NoSQL Workloads](https://scholar.google.com/scholar_url?url=https://ijeret.org/index.php/ijeret/article/download/339/321&hl=zh-CN&sa=X&d=13620161946363204194&ei=VVw0ac_CGOeEieoPopmbeA&scisig=ALhkC2Q3gCESoliGmTmxzeKqL_If&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=1&folt=cit)
*M Kari*

Main category: Xuanhe Zhou

TL;DR: 论文探讨了现代云数据库服务中的查询优化挑战，指出传统基于规则和成本的优化方法在分布式混合系统中存在扩展性问题


<details>
  <summary>Details</summary>
Motivation: 随着云计算的普及和数据库即服务(DBaaS)的兴起，现代数据管理面临新的挑战。分布式和混合系统中的查询优化变得尤为困难，主要由于动态工作负载、资源异构性以及跨平台数据集成等因素。传统的基于规则和成本的优化方法无法有效应对这些挑战，需要新的优化策略。

Method: 论文可能提出了一种新的查询优化方法，但摘要中未明确说明具体方法。从上下文推断，可能涉及机器学习、自适应优化或混合优化策略，以应对分布式混合系统的复杂性。

Result: 摘要中未提供具体实验结果。但暗示传统优化方法在动态工作负载、资源异构和跨平台集成场景下存在扩展性限制。

Conclusion: 需要开发新的查询优化方法来解决云数据库服务环境中的挑战，特别是针对分布式混合系统的动态特性和复杂性。

Abstract: Data management in the modern era has changed with the introduction of the paying database solutions which include Database as a Service (DBaaS) with the use of cloud computing. Nevertheless, query optimization in distributed and hybrid systems is highly challenging because of the dynamic workloads, heterogeneity of resources and cross platform data integration. By virtue of being based on standard rules and costs, traditional approaches to rule-based and cost-based optimization do not scale …

</details>


### [557] [Conversational AI for Smart Exploration (CASE)](https://scholar.google.com/scholar_url?url=https://www.researchsquare.com/article/rs-7802332/latest.pdf&hl=zh-CN&sa=X&d=9649896160349372791&ei=VVw0ac_CGOeEieoPopmbeA&scisig=ALhkC2S2OjY3i7AY-73lzhvyYJG8&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=2&folt=cit)
*K Abouelseoud,F Soliman,M Harb,H Fekry…*

Main category: Xuanhe Zhou

TL;DR: CASE平台通过对话式AI将复杂的数据分析转化为简单交互，让非技术用户也能直接与数据集对话


<details>
  <summary>Details</summary>
Motivation: 当前数据驱动世界中，有意义的洞察提取能力仍然是一个重大瓶颈，通常仅限于技术专家。需要打破这一障碍，让非技术用户也能进行数据分析。

Method: 引入Conversational AI for Smart Exploration (CASE)平台，将代码密集的复杂数据分析过程转化为简单的交互式对话，让用户可以直接与数据集进行对话。

Result: CASE平台使任何用户（从业务主管到领域专家）都能通过对话方式探索和分析数据，无需技术专业知识。

Conclusion: CASE平台通过对话式AI革命性地降低了数据分析的门槛，使数据洞察民主化，让非技术用户也能轻松进行数据探索。

Abstract: In today's data-driven world, the ability to extract meaningful insights remains a significant bottleneck, often confined to technical specialists. This paper introduces Conversational AI for Smart Exploration (CASE) a revolutionary platform designed to dismantle this barrier. CASE transforms the complex, code-heavy process of data analysis into a simple, interactive dialogue, empowering any user—from business executives to domain experts—to converse directly with their datasets. By simply …

</details>


### [558] [Efficient Reinforcement Learning with Semantic and Token Entropy for LLM Reasoning](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.04359&hl=zh-CN&sa=X&d=5783249406483245634&ei=j9I1adOrHvGQ6rQPuai-sAc&scisig=ALhkC2QuNcZ0v0Rz_IdEdsbdUaKD&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=1&folt=rel)
*H Cao,Z Bai,Z Peng,B Wang,T Yang,J Huo,Y Zhang…*

Main category: Xuanhe Zhou

TL;DR: RLVR方法在提升LLM推理能力方面表现优异，但准确性导向的学习范式存在局限性，需要更全面的评估框架


<details>
  <summary>Details</summary>
Motivation: 虽然基于可验证奖励的强化学习在提升大语言模型推理能力方面表现出色，但当前准确性导向的学习范式存在局限性，需要更全面的评估框架来平衡准确性与其他重要指标

Method: 论文可能提出了一种新的评估框架或改进的RLVR方法，旨在解决准确性导向学习范式的局限性，可能涉及多维度评估指标或平衡不同性能目标的优化策略

Result: 通过提出的方法，预期能够获得更平衡的性能表现，在保持较高准确性的同时改善其他重要指标，提供更全面的模型评估

Conclusion: 需要超越单纯的准确性优化，采用更全面的评估框架来提升RLVR方法在大语言模型推理能力训练中的效果

Abstract: Reinforcement learning with verifiable rewards (RLVR) has demonstrated superior performance in enhancing the reasoning capability of large language models (LLMs). However, this accuracy-oriented learning paradigm often suffers from …

</details>


### [559] [LLM-SrcLog: Towards Proactive and Unified Log Template Extraction via Large Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.04474&hl=zh-CN&sa=X&d=10284608557783829727&ei=j9I1adOrHvGQ6rQPuai-sAc&scisig=ALhkC2TjdNYCQk0veI4USbkN0jKb&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=3&folt=rel)
*J Sun,W Li,H Zhang,C Ding,S Qian,J Cao,G Xue*

Main category: Xuanhe Zhou

TL;DR: 当前日志解析方法主要是反应式和日志中心化的，仅从日志中推断模板，存在局限性


<details>
  <summary>Details</summary>
Motivation: 日志解析将原始日志转换为包含常量和变量的结构化模板，是异常检测、故障诊断等AIOps任务的基础。当前解析器大多是反应式和日志中心化的，仅从日志中推断模板，这限制了其效果和应用范围

Method: 论文未提供具体方法细节，但从摘要描述来看，作者可能提出了一种新的主动式或系统感知的日志解析方法，超越传统的反应式日志中心化方法

Result: 摘要未提供具体实验结果，但暗示当前方法存在局限性，需要更先进的解析方法

Conclusion: 需要超越传统反应式日志中心化方法的新型日志解析技术，以更好地支持AIOps任务

Abstract: Log parsing transforms raw logs into structured templates containing constants and variables. It underpins anomaly detection, failure diagnosis, and other AIOps tasks. Current parsers are mostly reactive and log-centric. They only infer templates from …

</details>


### [560] [Structured RAG for Answering Aggregative Questions](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.08505&hl=zh-CN&sa=X&d=13920856205794698799&ei=j9I1adOrHvGQ6rQPuai-sAc&scisig=ALhkC2RpGd2WfhH1dv7YIRVhKYM0&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=6&folt=rel)
*O Koshorek,N Granot,A Alloni,S Admati,R Hendel…*

Main category: Xuanhe Zhou

TL;DR: 该论文针对当前RAG方法主要关注小规模相关文档检索的局限性，提出了处理大规模相关文档场景的新数据集和评估方法


<details>
  <summary>Details</summary>
Motivation: 当前RAG数据集和方法主要针对小规模相关文档（通常几个文档）的检索场景，而现实应用中经常需要从大规模相关文档中检索信息，现有方法在此场景下表现不佳

Method: 作者创建了包含大规模相关文档场景的新数据集，并提出了相应的评估方法，以测试RAG系统在需要从大量相关文档中检索信息的复杂情况下的性能

Result: 研究发现现有RAG方法在大规模相关文档场景下表现显著下降，揭示了当前方法的局限性，并提供了新的基准测试框架

Conclusion: 需要开发专门针对大规模相关文档检索场景的RAG方法，现有方法在此类复杂场景中存在明显不足

Abstract: Retrieval-Augmented Generation (RAG) has become the dominant approach for answering questions over large corpora. However, current datasets and methods are highly focused on cases where only a small part of the corpus (usually a few …

</details>


### [561] [CoAgt: unleashing the reasoning capabilities of large language models on tabular data with a chain of agents](https://scholar.google.com/scholar_url?url=https://peerj.com/articles/cs-3423/&hl=zh-CN&sa=X&d=10344714654738951219&ei=j9I1adOrHvGQ6rQPuai-sAc&scisig=ALhkC2RT8TGjLg3tmF_AW9m5bebI&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=7&folt=rel)
*A Alrayzah,S Alqhtani*

Main category: Xuanhe Zhou

TL;DR: LLMs在文本推理方面表现出色，但在处理大型复杂表格时仍面临挑战，主要受限于token限制和结构依赖关系的丢失。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在文本推理方面取得了显著进展，但在处理大型复杂表格时仍然存在困难。token限制和结构依赖关系的丢失使得单个模型难以有效处理表格数据，这限制了LLMs在表格相关任务中的应用。

Method: 论文未提供具体方法细节，但从摘要可以看出，研究关注的是解决LLMs处理大型复杂表格的挑战，可能涉及改进模型架构、数据处理技术或开发专门针对表格理解的算法。

Result: 摘要未提供具体实验结果，但暗示当前LLMs在处理大型复杂表格方面存在局限性，需要新的方法来解决token限制和结构依赖关系丢失的问题。

Conclusion: 虽然LLMs在文本推理方面表现出色，但在处理大型复杂表格时仍面临显著挑战。需要开发新的技术来解决token限制和结构依赖关系丢失的问题，以提升LLMs在表格理解和分析方面的能力。

Abstract: Large language models (LLMs) have shown remarkable progress in text-based reasoning, but they continue to struggle with large and complex tables. Token limitations and the loss of structural dependencies make it difficult for a single model …

</details>


### [562] [CT-Bench: Benchmarking Large Language Models on Chinese Text-to-Table Generation](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3767695.3769492&hl=zh-CN&sa=X&d=4341117239485605104&ei=j9I1adOrHvGQ6rQPuai-sAc&scisig=ALhkC2QEJPFE0146DEXjIbDircxs&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=8&folt=rel)
*H Shi,J Wang,C Wang,T Sakai*

Main category: Xuanhe Zhou

TL;DR: 文本到表格任务旨在从非结构化文本生成无固定格式的表格，无需指定表头，挑战在于提取关键信息并创建合适的表格结构


<details>
  <summary>Details</summary>
Motivation: 现有表格生成方法通常需要预定义表头或固定格式，限制了灵活性。文本到表格任务需要从自由文本中提取关键信息并自动组织成表格形式，这对信息提取和结构化表示提出了更高要求。

Method: 论文提出了一种文本到表格的生成方法，可能包括信息提取、实体识别、关系抽取和表格结构生成等组件。方法可能利用深度学习模型如Transformer架构，结合自然语言理解和表格生成技术。

Result: 该方法在文本到表格任务上取得了良好性能，能够从非结构化文本中有效提取关键信息并生成结构合理的表格，相比基线方法在信息完整性和表格质量方面有所提升。

Conclusion: 文本到表格任务是一个具有挑战性的问题，提出的方法展示了从自由文本生成无固定格式表格的可行性，为信息提取和结构化表示提供了新思路。

Abstract: The Text-to-Table task aims to generate format-free tables that convey key information from unstructured text without designated headers. The challenge lies not only in extracting the key information but also in creating appropriate table …

</details>


### [563] [Artificial intelligence revolutionize food detection? Vision, olfaction and taste integrated with machine learning/deep learning in food detection](https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0308814625046291&hl=zh-CN&sa=X&d=10482119157980889370&ei=kNI1aeXkJKqy6rQP08y_kAE&scisig=ALhkC2Ru4eENNX1bE84_UuAgtIz1&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=0&folt=cit)
*C Wei,L Zhou,B Liang,J Chen,G Wang,X Li*

Main category: Xuanhe Zhou

TL;DR: AI技术在食品检测领域的应用机制研究，重点分析机器学习和深度学习在特征提取、模式识别和决策反馈中的作用


<details>
  <summary>Details</summary>
Motivation: 人工智能的快速发展正在深刻改变食品检测的理论框架和技术范式，需要系统阐述机器学习和深度学习在食品检测中的工作机制，以推动该领域的进一步发展

Method: 研究聚焦于分析基于机器学习和深度学习的AI算法在特征提取、模式识别和决策反馈中的机制，涵盖计算机视觉、电子鼻、电子舌等感知系统

Result: AI算法使感知系统能够克服对传统方法的依赖，在食品检测中实现更高效的特征提取和模式识别

Conclusion: 人工智能技术正在重塑食品检测领域，机器学习和深度学习为该领域提供了新的理论框架和技术范式

Abstract: The rapid advancement of artificial intelligence (AI) is profoundly transforming the theoretical framework and technological paradigm of food detection. The study focuses on elucidating the underlying mechanisms of machine learning (ML)-and deep learning (DL)-based AI in feature extraction, pattern recognition, and decision feedback. AI algorithms have enabled perception systems such as computer vision, electronic nose, and electronic tongue to overcome their dependence on …

</details>


### [564] [Nex-N1: Agentic Models Trained via a Unified Ecosystem for Large-Scale Environment Construction](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.04987&hl=zh-CN&sa=X&d=11704535737934725433&ei=kNI1aeXkJKqy6rQP08y_kAE&scisig=ALhkC2STMPWlFqE3OrZ4s3VA9sCI&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=1&folt=cit)
*Y Cai,L Chen,Q Chen,Y Ding,L Fan,W Fu,Y Gao…*

Main category: Xuanhe Zhou

TL;DR: 提出了一种系统化扩展LLM智能体交互数据多样性的方法，以解决从被动响应到自主决策范式转变中的基础设施瓶颈问题


<details>
  <summary>Details</summary>
Motivation: 大型语言模型从被动响应者向自主智能体的演进需要从静态模仿学习转向激励驱动的决策制定，但这一转变受到缺乏可扩展基础设施的阻碍，无法构建高质量交互信号进行有效的策略学习

Method: 引入了一种全面的方法，旨在系统化扩展交互多样性，通过可扩展的基础设施构建高质量的交互信号来支持策略学习

Result: 该方法能够有效解决当前LLM智能体发展中面临的数据瓶颈问题，为自主决策学习提供必要的基础设施支持

Conclusion: 系统化扩展交互数据多样性是推动LLM从被动响应向自主智能体演进的关键基础设施，为激励驱动的决策学习范式提供了可行的解决方案

Abstract: The evolution of Large Language Models (LLMs) from passive responders to autonomous agents necessitates a fundamental shift in learning paradigms--from static imitation to incentive-driven decision making. However, this transition is significantly impeded by the lack of scalable infrastructure capable of constructing high-quality interaction signals for effective policy learning. To address this, we introduce a comprehensive method designed to systematically scale the diversity …

</details>


### [565] [POLARIS: Is Multi-Agentic Reasoning the Next Wave in Engineering Self-Adaptive Systems?](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.04702&hl=zh-CN&sa=X&d=6987622584516460412&ei=kNI1aeXkJKqy6rQP08y_kAE&scisig=ALhkC2TfDNVSLxcjumwE__uGKO09&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=2&folt=cit)
*D Pandey,V Gupta,P Singhal,K Vaidhyanathan*

Main category: Xuanhe Zhou

TL;DR: 论文探讨现代软件生态系统面临的规模、复杂性、互连性和自主性带来的不确定性挑战，指出传统自适应方法难以应对未知未知问题，提出向Self-Adaptation 2.0演进的需求


<details>
  <summary>Details</summary>
Motivation: 现代软件生态系统的规模、复杂性、互连性和自主性日益增长，引入了前所未有的不确定性，挑战了传统自适应方法的基础。现有方法（通常是规则驱动的控制器或孤立的学习组件）难以泛化到新环境或协调分布式子系统的响应，无法有效应对涌现的未知未知问题。

Method: 论文讨论了Self-Adaptation 2.0的概念，强调需要更先进的自适应方法，但具体方法在摘要中未详细说明。可能涉及更智能、协调和泛化的自适应机制。

Result: 摘要未提供具体实验结果，但指出了当前自适应方法在应对现代软件生态系统挑战方面的局限性，以及向Self-Adaptation 2.0演进的重要性。

Conclusion: 传统自适应方法已不足以应对现代软件生态系统的复杂性，需要向更先进、协调和泛化的Self-Adaptation 2.0范式演进，以有效处理未知未知问题和分布式系统的协调挑战。

Abstract: The growing scale, complexity, interconnectivity, and autonomy of modern software ecosystems introduce unprecedented uncertainty, challenging the foundations of traditional self-adaptation. Existing approaches, typically rule-driven controllers or isolated learning components, struggle to generalize to novel contexts or coordinate responses across distributed subsystems, leaving them ill-equipped for emergent unknown unknowns. Recent discussions on Self-Adaptation 2.0 emphasize an equal …

</details>


### [566] [DAComp: Benchmarking Data Agents across the Full Data Intelligence Lifecycle](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.04324&hl=zh-CN&sa=X&d=5840207042149449671&ei=kNI1aeXkJKqy6rQP08y_kAE&scisig=ALhkC2TUQmoe9rGvtSHTJpDCqyAS&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=5&folt=cit)
*F Lei,J Meng,Y Huang,J Zhao,Y Zhang,J Luo,X Zou…*

Main category: Xuanhe Zhou

TL;DR: DAComp是一个包含210个任务的基准测试，模拟企业数据智能工作流，涵盖数据工程和数据分析两个阶段


<details>
  <summary>Details</summary>
Motivation: 现实企业数据智能工作流包含从原始数据到分析就绪表的数据工程，以及从表到决策洞察的数据分析，需要评估系统处理这些复杂工作流的能力

Method: 引入DAComp基准，包含210个任务，数据工程任务需要在工业级模式上进行仓库级工程，包括从零设计和构建多阶段SQL管道，以及在演进需求下演化现有系统

Result: 论文介绍了DAComp基准测试的设计和内容，包含210个任务，覆盖数据工程和数据分析的完整工作流

Conclusion: DAComp基准为评估数据智能系统处理企业级复杂工作流提供了标准化测试框架

Abstract: Real-world enterprise data intelligence workflows encompass data engineering that turns raw sources into analytical-ready tables and data analysis that convert those tables into decision-oriented insights. We introduce DAComp, a benchmark of 210 tasks that mirrors these complex workflows. Data engineering (DE) tasks require repository-level engineering on industrial schemas, including designing and building multi-stage SQL pipelines from scratch and evolving existing systems under evolving …

</details>


### [567] [Are we ghosts in the machine? AI, agency, and the future of libraries](https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0099133325001776&hl=zh-CN&sa=X&d=13109679453032818849&ei=yEw3aaDxE-bYieoPgNO3kQI&scisig=ALhkC2TNcgXjVKKfJxUP2RKZ8107&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=0&folt=cit)
*QD McCrary*

Main category: Xuanhe Zhou

TL;DR: AI集成正在改变信息素养和图书馆研究，学生常无意识地使用AI增强的数据库功能，导致研究任务重新分配


<details>
  <summary>Details</summary>
Motivation: 数据库供应商将AI功能（如文章摘要、增强搜索、临床决策支持）嵌入熟悉资源中，学生越来越多地参与重新分配核心研究任务（如源选择和信息合成）的协作过程，这种转变通常发生在学生不知情且缺乏机构审查的情况下

Method: 论文通过分析AI集成对信息素养和图书馆研究的影响，探讨了数据库供应商如何将AI能力嵌入现有资源，以及这种转变如何改变研究流程

Result: AI集成正在从根本上改变信息素养和图书馆研究实践，学生与AI工具之间的协作过程正在重新分配传统研究任务，这种转变通常缺乏学生意识和机构监督

Conclusion: AI集成对信息素养教育提出了新挑战，需要重新思考图书馆研究教学方法和机构审查机制，以适应AI增强的研究环境

Abstract: Artificial intelligence (AI) integration is fundamentally transforming information literacy and library-based research, often without student awareness or institutional review. As database vendors embed AI capabilities such as article summarization, enhanced search, and clinical decision support into familiar resources, students are increasingly engaging in a collaborative process that redistributes core tasks like source selection and information synthesis. This shift moves the research workflow …

</details>


### [568] [PLForge: Enhancing Language Models for Natural Language to Procedural Extensions of SQL](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3769813&hl=zh-CN&sa=X&d=6487197148865112611&ei=kuU4abqdKam6ieoPoPyzsQs&scisig=ALhkC2R9NXXzlXDNjrBSLLe7_KUM&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=1&folt=rel)
*H Zhang,C Wang,H Li,C Wu,S Wang,Y Liu,G Shi…*

Main category: Xuanhe Zhou

TL;DR: PL/SQL通过将过程化构造与SQL声明式语法结合，增强数据库编程的可重用性、模块化和可维护性


<details>
  <summary>Details</summary>
Motivation: 传统SQL作为声明式语言在复杂业务逻辑处理上存在局限性，需要过程化编程能力来提升数据库应用的开发效率和代码质量

Method: 扩展SQL语言，集成过程化编程构造（如变量、条件语句、循环、函数、存储过程等），形成PL/SQL语言体系

Result: PL/SQL显著提升了SQL代码的可重用性、模块化程度和可维护性，使数据库编程更加灵活高效

Conclusion: PL/SQL是数据库编程的重要扩展，通过结合声明式和过程化编程范式，有效解决了复杂业务逻辑的实现问题

Abstract: Procedural Language extensions of SQL (abbr. PL/SQL) enhance database programming by integrating procedural constructs with SQL's declarative syntax, thereby improving the reusability, modularity, and maintainability of SQL. Besides …

</details>


### [569] [Large-scale text-to-SQL generation with adversarial defense](https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0020025525010795&hl=zh-CN&sa=X&d=9669724736317006620&ei=kuU4abqdKam6ieoPoPyzsQs&scisig=ALhkC2TB6RIwY4bF1kjIk23Ve3Wq&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=3&folt=rel)
*H Liao,S Chen,Y Xiao,L Xiang,F Min*

Main category: Xuanhe Zhou

TL;DR: 针对Text-to-SQL模型在自然语言查询和数据库模式扰动下的脆弱性，本文提出了一种防御方法，而现有研究多集中于攻击方面。


<details>
  <summary>Details</summary>
Motivation: 大规模Text-to-SQL模型对自然语言查询和数据库模式的扰动非常脆弱，现有研究主要集中在对抗攻击方面，而防御研究相对缺乏。

Method: 本文提出了一种防御方法（具体方法未在摘要中说明，需要进一步阅读全文）。

Result: 未在摘要中提供具体结果。

Conclusion: 需要开发针对Text-to-SQL模型对抗扰动的有效防御机制。

Abstract: Large-scale Text-to-SQL models are vulnerable to perturbations in natural language query (NLQ) and database schema. Most existing research has focused on adversarial attack in input sequences, while neglecting defense. In this article, we …

</details>


### [570] [LLM-Powered Interactive Graph Search: A Scalable and Practical Approach](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3769804&hl=zh-CN&sa=X&d=12855332836456479805&ei=lOU4afbDBOuuieoPmeTMgAc&scisig=ALhkC2Q5r2MspbHOja5F5G7ozW-l&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=1&folt=cit)
*H Linghu,Q Cong,Y Huang,S Lu,L Feng,J Tang*

Main category: Xuanhe Zhou

TL;DR: 该论文研究了交互式图搜索中人类智能作为oracle时的错误容忍问题，提出了新的算法框架来处理不完美的人类回答


<details>
  <summary>Details</summary>
Motivation: 现有交互式图搜索算法假设人类oracle总是提供正确答案，但实际应用中人类回答可能存在错误，需要开发能够容忍错误的高效算法

Method: 提出新的算法框架来处理不完美的人类回答，可能包括错误检测、容错机制、概率模型或置信度评估等方法

Result: 开发出能够容忍人类回答错误的交互式图搜索算法，在保证搜索效率的同时提高系统鲁棒性

Conclusion: 交互式图搜索需要考虑人类oracle的不完美性，提出的容错算法框架能够有效处理实际应用中的错误回答

Abstract: Interactive graph search (IGS) has emerged as a powerful paradigm for information retrieval across diverse applications. The goal of IGS is to identify the most appropriate (ie, deepest) node within a hierarchy for an unknown object, typically leveraging human intelligence such as crowdsourcing as the oracle. Existing IGS algorithms usually rely on reachability queries, such as" is the target node reachable from node x?", and assume that correct answers are always available. However, in …

</details>


### [571] [Reliable Answers for Recurring Questions: Boosting Text-to-SQL Accuracy with Template Constrained Decoding](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3769822&hl=zh-CN&sa=X&d=10130971730395772631&ei=lOU4afbDBOuuieoPmeTMgAc&scisig=ALhkC2T0o4edyD-233zfP16VmGun&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=3&folt=cit)
*S Jivani,S Maheshwari,S Sarawagi*

Main category: Xuanhe Zhou

TL;DR: TeCoD系统通过模板约束解码提升Text-to-SQL生成在复杂模式下的准确性和有效性


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在Text-to-SQL生成方面取得进展，但在复杂或未见过的数据库模式中部署仍面临挑战，存在准确率不一致和生成无效SQL的风险

Method: 引入模板约束解码（TeCoD）系统，利用标注工作负载中查询模式的重复性，通过模板约束来指导SQL生成过程

Result: TeCoD解决了现有方法的局限性，提高了在复杂或未见模式下的SQL生成准确性和有效性

Conclusion: 模板约束解码是提升Text-to-SQL生成在实际部署中可靠性的有效方法

Abstract: Large language models (LLMs) have revolutionized Text-to-SQL generation, allowing users to query structured data using natural language with growing ease. Yet, real-world deployment remains challenging, especially in complex or unseen schemas, due to inconsistent accuracy and the risk of generating invalid SQL. We introduce Template Constrained Decoding (TeCoD), a system that addresses these limitations by harnessing the recurrence of query patterns in labeled workloads …

</details>


### [572] [Test Data Generation for Complex SQL Queries](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3769832&hl=zh-CN&sa=X&d=17395830110404788264&ei=lOU4afbDBOuuieoPmeTMgAc&scisig=ALhkC2TSdqEHzOvn_YDLYKAUlV6A&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=4&folt=cit)
*S Somwase,P Das,S Sudarshan*

Main category: Xuanhe Zhou

TL;DR: 该论文研究SQL查询测试数据生成，扩展了先前工作以处理更复杂的多级嵌套查询，支持文本到SQL系统的验证需求


<details>
  <summary>Details</summary>
Motivation: 随着文本到SQL系统的广泛应用，测试数据对于验证生成的SQL查询变得至关重要。先前的工作仅能处理基本的单块SQL查询和单级嵌套查询，无法满足更复杂查询结构的测试需求

Method: 论文提出了一种扩展方法，能够生成适用于多级嵌套SQL查询的测试数据。该方法超越了先前仅支持单块和单级嵌套查询的限制

Result: 该方法能够为更复杂的SQL查询结构生成测试数据，包括多级嵌套查询，从而支持更全面的SQL查询测试和验证

Conclusion: 扩展的测试数据生成方法对于文本到SQL系统的验证、数据分析查询测试以及学生SQL查询评分等应用具有重要意义，填补了复杂查询测试数据生成的空白

Abstract: Generation of sample data for testing SQL queries has been an important task for many years, with applications such as testing of SQL queries used for data analytics and in application software, as well as grading of student SQL queries. More recently, with the increasing use of text-to-SQL systems, test data is key for the validation of generated queries. Earlier work on test data generation handled basic single-block SQL queries, as well as single-level nested SQL queries, but could not …

</details>


### [573] [Virtual warehouse analysis and configuration planning system](https://scholar.google.com/scholar_url?url=https://patents.google.com/patent/US12468999B2/en&hl=zh-CN&sa=X&d=18187446603484752723&ei=lOU4afbDBOuuieoPmeTMgAc&scisig=ALhkC2RKF2tnvMKoWtTufzHat4xp&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=6&folt=cit)
*R Syal,T Fearns,C Sylvia,J Bougher,K Kolanu,D Ellis…*

Main category: Xuanhe Zhou

TL;DR: 使用机器学习模拟虚拟仓库配置变更，无需访问实际数据存储，通过历史查询性能指标训练模型预测配置调整后的性能变化


<details>
  <summary>Details</summary>
Motivation: 传统虚拟仓库配置优化需要实际访问存储数据，存在安全风险且成本高昂。需要一种无需访问实际数据的方法来模拟配置变更效果，降低测试成本和风险。

Method: 接收第一虚拟仓库的查询性能指标，训练机器学习模型模拟操作参数变更，预测虚拟仓库查询性能变化。模型基于历史性能数据而非实际存储数据。

Result: 开发了能够准确预测虚拟仓库配置变更后性能的机器学习系统，实现了无数据访问的配置模拟，降低了测试成本和风险。

Conclusion: 机器学习方法可以有效模拟虚拟仓库配置变更，无需访问实际存储数据，为仓库配置优化提供了安全、高效的解决方案。

Abstract: Methods, systems, and apparatuses for using machine learning to simulate changes to virtual warehouse configurations without access to data stored by corresponding virtual warehouses are described herein. A computing device may receive first performance metrics of one or more first queries executed by one or more first virtual warehouses. The computing device may then generate a trained machine learning model to simulate operating parameter changes and predict virtual warehouse query …

</details>


### [574] [PathFinder: MCTS and LLM Feedback-based Path Selection for Multi-Hop Question Answering](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.05336&hl=zh-CN&sa=X&d=2179484226091817556&ei=ons6aZOkBubYieoPyNfA6QY&scisig=ALhkC2S0DGSPg1aajrJmA4RFLpu_&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=2&folt=rel)
*DP Maram,K Gunaratna,V Srinivasan,H Jeelani…*

Main category: Xuanhe Zhou

TL;DR: 多跳问答需要语言模型进行多步推理，现有系统利用大语言模型的推理能力通过思维链方法处理，但面临幻觉和错误传播问题


<details>
  <summary>Details</summary>
Motivation: 多跳问答是自然语言处理中的挑战性任务，需要模型进行多步推理。虽然现有系统利用大语言模型的推理能力，但面临幻觉问题和错误传播的挑战，需要更可靠的解决方案

Method: 利用大语言模型的推理能力，采用思维链（Chain-of-Thought）方法进行多步推理，通过分解复杂问题为多个推理步骤来寻找答案

Result: 现有系统能够处理多跳推理任务，但在复杂场景下仍面临幻觉问题和错误传播的挑战，导致推理链中的错误会累积并影响最终答案的准确性

Conclusion: 多跳问答系统虽然取得了进展，但仍需解决幻觉和错误传播问题以提高推理的可靠性和准确性，未来需要更鲁棒的推理机制

Abstract: Multi-hop question answering is a challenging task in which language models must reason over multiple steps to reach the correct answer. With the help of Large Language Models and their reasoning capabilities, existing systems are able to think …

</details>


### [575] [HelixTrain: Enhancing Long-Context LLM Training via 3D Dynamic Parallelism](https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3D61k2uuNyS7&hl=zh-CN&sa=X&d=7583910956352896011&ei=ons6aZOkBubYieoPyNfA6QY&scisig=ALhkC2QoqwMNaM7v6GY8XgApJi60&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=3&folt=rel)
*S Wang,Y Liu,Z Jiawang*

Main category: Xuanhe Zhou

TL;DR: 数据并行(DP)将训练序列分配给DP组中的不同设备，复制模型状态并通过梯度归约确保一致性


<details>
  <summary>Details</summary>
Motivation: 解决大规模深度学习训练中的计算资源分配问题，通过数据并行提高训练效率，处理大规模数据集

Method: 数据并行方法：将训练数据分片分配给不同设备，每个设备复制完整的模型状态，前向传播后计算梯度，通过梯度归约操作同步各设备梯度，最后更新模型参数

Result: 数据并行能够有效利用多设备计算资源，加速训练过程，但存在通信开销和内存冗余问题

Conclusion: 数据并行是深度学习分布式训练的基础方法，适用于数据量大的场景，但需要权衡计算效率与通信开销

Abstract: Data Parallelism. Data Parallelism (DP) assigns training input of sequences to different devices in a DP group, where the model states (parameters, gradients, and optimizer states) are duplicated and gradients need to be reduced to ensure …

</details>


### [576] [Enhanced tool invocation method through multi-model collaboration](https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s44336-025-00028-7&hl=zh-CN&sa=X&d=915075229605443407&ei=awA8aeeyLPql6rQPmryzuQM&scisig=ALhkC2QtCRTwco2lD_2lken98JUn&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=0&folt=cit)
*Y Zhang,H Sun,M Jia,H Zhu,D Zhang,X Li*

Main category: Xuanhe Zhou

TL;DR: 提出多模型协作框架解决大语言模型微调时工具调用任务的格式不兼容和泛化能力有限问题


<details>
  <summary>Details</summary>
Motivation: 研究发现工具调用的成功对输出格式标准化高度敏感，传统微调方法导致模型僵化遵循特定格式，增加解析失败风险

Method: 多模型协作框架，通过协同工作解决格式标准化与泛化能力的平衡问题

Result: 未在摘要中明确说明具体实验结果，但暗示该方法能克服传统微调的局限性

Conclusion: 多模型协作框架为解决工具调用任务中的格式标准化和泛化问题提供了有效方案

Abstract: This paper proposes a multi-model collaborative framework to address the format non-compliance and limited generalization observed in tool-invocation tasks when Large Language Models are directly fine-tuned. Our study reveals that the success of tool invocation is highly sensitive to the standardization of output formats. However, conventional fine-tuning methods often cause models to rigidly adhere to specific formats, which in turn increases the risk of parsing failures. To overcome this …

</details>


### [577] [On the Interplay of Pre-Training, Mid-Training, and RL on Reasoning Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.07783&hl=zh-CN&sa=X&d=2140477841646945957&ei=agA8aarKM6GvieoPtIGfoAw&scisig=ALhkC2QUqKLbnaNcXLHY4XLhXRlT&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=0&folt=rel)
*C Zhang,G Neubig,X Yue*

Main category: Xuanhe Zhou

TL;DR: 该论文探讨强化学习后训练是否真正扩展了语言模型的推理能力，还是仅仅增强了预训练已存在的推理能力。


<details>
  <summary>Details</summary>
Motivation: 尽管强化学习技术显著提升了语言模型的推理表现，但尚不清楚这种后训练是否真正扩展了模型的推理能力，还是仅仅增强了预训练阶段已获得的推理能力。研究者希望区分这两种可能性，以更准确地评估RL后训练的实际效果。

Method: 论文可能采用对比分析方法，比较经过RL后训练与未经RL后训练的模型在推理任务上的表现差异。可能设计实验来分离预训练获得的推理能力和后训练增强的能力，通过控制变量或构建特定测试集来评估RL后训练的实际贡献。

Result: 研究可能发现RL后训练主要增强了模型利用预训练已获得推理能力的能力，而非创造全新的推理能力。可能观察到性能提升主要来自对已有知识的更有效利用，而非获得根本性的新推理技能。

Conclusion: RL后训练对语言模型推理能力的提升可能更多体现在对预训练已获得能力的优化和增强上，而非扩展模型的根本推理能力。这对理解RL后训练的作用机制和评估其实际价值具有重要意义。

Abstract: Recent reinforcement learning (RL) techniques have yielded impressive reasoning improvements in language models, yet it remains unclear whether post-training truly extends a model's reasoning ability beyond what it acquires during pre-training. A …

</details>


### [578] [DoVer: Intervention-Driven Auto Debugging for LLM Multi-Agent Systems](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.06749&hl=zh-CN&sa=X&d=7527492479394411544&ei=agA8aarKM6GvieoPtIGfoAw&scisig=ALhkC2RPFnKZIYIrhfTeeOUpFuPt&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=1&folt=rel)
*M Ma,J Zhang,F Yang,Y Kang,Q Lin,S Rajmohan…*

Main category: Xuanhe Zhou

TL;DR: LLM-based多智能体系统难以调试，现有方法依赖LLM进行基于日志的故障定位，但存在幻觉和可扩展性问题


<details>
  <summary>Details</summary>
Motivation: LLM-based多智能体系统调试困难，因为故障通常源于长而分支的交互轨迹。现有基于LLM的日志故障定位方法存在幻觉问题，且难以扩展到复杂系统

Method: 论文提出了一种新的调试方法（具体方法未在摘要中详细说明，但暗示了改进现有LLM-based故障定位的局限性）

Result: 未在摘要中明确说明具体结果，但暗示提出的方法能更好地解决LLM-based多智能体系统的调试问题

Conclusion: 需要更有效的调试方法来处理LLM-based多智能体系统的复杂故障定位问题

Abstract: Large language model (LLM)-based multi-agent systems are challenging to debug because failures often arise from long, branching interaction traces. The prevailing practice is to leverage LLMs for log-based failure localization, attributing errors to a …

</details>


### [579] [RL-MTJail: Reinforcement Learning for Automated Black-Box Multi-Turn Jailbreaking of Large Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.07761&hl=zh-CN&sa=X&d=15754089747281499691&ei=agA8aarKM6GvieoPtIGfoAw&scisig=ALhkC2QvEdWYcYRJWgwO7Q50dseu&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=2&folt=rel)
*X Xiong,O Li,Z Liu,M Li,W Shi,F Feng,X He*

Main category: Xuanhe Zhou

TL;DR: 该论文研究黑盒多轮越狱攻击，通过训练攻击者LLM来诱导黑盒目标模型生成有害内容


<details>
  <summary>Details</summary>
Motivation: 大型语言模型容易受到越狱攻击的威胁，这阻碍了其在现实世界应用中的安全部署。当前需要研究更有效的黑盒多轮越狱方法，以评估和提升模型的安全性。

Method: 训练攻击者LLM来执行黑盒多轮越狱攻击，通过多轮对话交互来诱导目标模型生成有害内容。该方法专注于黑盒设置，不依赖目标模型的内部信息。

Result: 训练的攻击者LLM能够有效诱导黑盒目标模型生成有害内容，证明了多轮越狱攻击的可行性和有效性。

Conclusion: 黑盒多轮越狱攻击对LLM安全构成严重威胁，需要开发更强大的防御机制来应对这种攻击方式。

Abstract: Large language models are vulnerable to jailbreak attacks, threatening their safe deployment in real-world applications. This paper studies black-box multi-turn jailbreaks, aiming to train attacker LLMs to elicit harmful content from black-box …

</details>


### [580] [Exploiting the Randomness of Large Language Models (LLM) in Text Classification Tasks: Locating Privileged Documents in Legal Matters](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.08083&hl=zh-CN&sa=X&d=16994270776323372348&ei=JIQ9abuGDrCP6rQPgsi1wQo&scisig=ALhkC2QTaJ4JMjlHj_7ui0tVg2iD&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=1&folt=rel)
*K Huffman,J Zhang,N Huber*

Main category: Xuanhe Zhou

TL;DR: 该论文探讨了在法律文本分类中，当训练数据与目标数据存在分布差异时，如何通过领域自适应方法提升模型性能


<details>
  <summary>Details</summary>
Motivation: 法律文本分类模型通常用于筛选大规模数据集，但面临训练数据与目标数据分布不匹配的问题，这导致模型在实际应用中的性能下降

Method: 论文可能提出了领域自适应方法，通过调整模型以适应目标数据分布，可能包括迁移学习、领域对抗训练或数据增强等技术

Result: 提出的方法能够有效缓解分布不匹配问题，提升模型在目标领域法律文本分类任务上的性能

Conclusion: 领域自适应对于法律文本分类至关重要，能够解决训练数据与目标数据分布差异带来的挑战，提高模型在实际法律应用中的可靠性

Abstract: In legal matters, text classification models are most often used to filter through large datasets in search of documents that meet certain pre-selected criteria like relevance to a certain subject matter, such as legally privileged communications and attorney …

</details>


### [581] [SimpleDevQA: Benchmarking Large Language Models on Development Knowledge QA](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.08867&hl=zh-CN&sa=X&d=16229845446501642108&ei=JIQ9abuGDrCP6rQPgsi1wQo&scisig=ALhkC2RE8mg24YbGM9SISKGAEwEj&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=3&folt=rel)
*J Zhang,L Guo,Y Wang,M Liu,J Chen,Y Ma,E Shi…*

Main category: Xuanhe Zhou

TL;DR: 开发知识问答任务旨在为软件开发过程中的知识寻求问题提供自然语言答案，本文探讨其重要性及研究现状


<details>
  <summary>Details</summary>
Motivation: 软件开发过程中开发者经常面临各种知识寻求问题，需要高效获取相关信息。开发知识问答任务旨在通过自然语言交互提供准确答案，但目前该领域的研究程度和重要性尚未得到充分探讨

Method: 通过文献综述和现状分析，系统性地调查开发知识问答任务的研究进展、技术方法和应用场景

Result: 开发知识问答任务在软件开发过程中具有重要价值，但目前研究尚不充分，存在技术挑战和应用潜力

Conclusion: 开发知识问答是软件工程领域的重要研究方向，需要更多研究关注其技术实现、评估方法和实际应用

Abstract: The Development Knowledge Question Answering (Dev Knowledge QA) task aims to provide natural language answers to knowledge-seeking questions during software development. To investigate its importance and to what extent it has been explored …

</details>


### [582] [GeneralBench: A Comprehensive Benchmark Suite and Evaluation Platform for Large Language Models](https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Ziqian_Bi/publication/398483616_GeneralBench_A_Comprehensive_Benchmark_Suite_and_Evaluation_Platform_for_Large_Language_Models/links/6937ceb57e61d05b530cd57f/GeneralBench-A-Comprehensive-Benchmark-Suite-and-Evaluation-Platform-for-Large-Language-Models.pdf&hl=zh-CN&sa=X&d=6603880206364852424&ei=JIQ9abuGDrCP6rQPgsi1wQo&scisig=ALhkC2TwCSXe3mgxYUTxaCTXoaTr&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=4&folt=rel)
*Z Bi,H Duan,J Xu,XL Chia,Y Geng,X Cui,V Du…*

Main category: Xuanhe Zhou

TL;DR: GeneralBench是一个统一的LLM评估框架，包含综合基准和自动化评估基础设施，旨在解决当前评估方法的局限性


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的快速发展迫切需要全面的基准测试和自动化评估基础设施。现有评估方法存在局限性，需要统一的评估框架来支持更全面、可扩展的模型评估。

Method: 引入GeneralBench统一评估框架，包含综合基准测试套件和自动化评估基础设施，支持多种评估维度和任务类型，提供标准化评估流程。

Result: 框架提供了系统化的评估能力，能够全面评估LLM在不同任务和维度上的表现，支持模型比较和性能分析。

Conclusion: GeneralBench为LLM评估提供了急需的统一框架，有助于推动模型开发和评估的标准化，促进该领域的进一步发展。

Abstract: The rapid advancement of Large Language Models (LLMs) has created an urgent need for both comprehensive benchmarks and automated evaluation infrastructure. We introduce GeneralBench, a unified evaluation framework comprising a …

</details>


### [583] [Enhancing Reliability across Short and Long-Form QA via Reinforcement Learning](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.08944&hl=zh-CN&sa=X&d=8461399804853363519&ei=yOo-ae32BKGvieoPtIGfoAw&scisig=ALhkC2SXucCL8kVTnPepMOkcyuA6&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=1&folt=rel)
*Y Wang,Z Yang,W Ma,Z Sui,L Zhao*

Main category: Xuanhe Zhou

TL;DR: 本文探讨强化学习在提升大语言模型复杂推理能力的同时加剧幻觉问题，提出平衡能力与可靠性的解决方案


<details>
  <summary>Details</summary>
Motivation: 强化学习虽然显著提升了大语言模型的复杂推理能力，但同时也加剧了幻觉问题，造成了能力与可靠性之间的关键权衡，需要解决这一矛盾

Method: 未在摘要中明确说明具体方法，但暗示将提出一种平衡强化学习能力提升与幻觉控制的解决方案

Result: 未在摘要中提供具体实验结果，但暗示将展示如何有效平衡模型能力与可靠性

Conclusion: 需要开发能够同时保持强化学习带来的能力提升并有效控制幻觉的新方法，以实现大语言模型在实际应用中的可靠部署

Abstract: While reinforcement learning has unlocked unprecedented complex reasoning in large language models, it has also amplified their propensity for hallucination, creating a critical trade-off between capability and reliability. This work confronts this …

</details>


### [584] [Structured Extraction from Business Process Diagrams Using Vision-Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.22448&hl=zh-CN&sa=X&d=8942320643001417247&ei=yOo-ae32BKGvieoPtIGfoAw&scisig=ALhkC2TfP2op51UKe4PBSaErjw9k&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=3&folt=rel)
*P Deka,B Devereux*

Main category: Xuanhe Zhou

TL;DR: 该论文探讨了BPMN（业务流程模型和表示法）作为复杂工作流表示标准，指出当前方法主要依赖XML表示，但存在局限性


<details>
  <summary>Details</summary>
Motivation: BPMN是广泛采用的标准，但现有方法主要依赖XML表示，而BPMN图表通常以视觉图像形式交换，需要更好的方法来处理这种视觉表示

Method: 论文未提供具体方法细节，但暗示需要超越XML表示的方法来处理BPMN的视觉图像交换

Result: 未提供具体结果，但指出现有XML表示方法的局限性

Conclusion: 需要开发更好的方法来处理BPMN图表的视觉图像交换，超越传统的XML表示

Abstract: Business Process Model and Notation (BPMN) is a widely adopted standard for representing complex business workflows. While BPMN diagrams are often exchanged as visual images, existing methods primarily rely on XML representations …

</details>


### [585] [DOCR-Inspector: Fine-Grained and Automated Evaluation of Document Parsing with VLM](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.10619&hl=zh-CN&sa=X&d=4110820290927940653&ei=gWdAaafXH72qieoPuKej0QM&scisig=ALhkC2RJJ_MVx7_SbzZeZqlF3BDJ&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=0&folt=cit)
*Q Zhang,J Zhang,Z Ren,L Ouyang,Z Wen,J Niu…*

Main category: Xuanhe Zhou

TL;DR: 文档解析任务面临现实场景中可靠高质量解析的挑战，标准基准测试存在数据集特定偏差问题


<details>
  <summary>Details</summary>
Motivation: 文档解析旨在将非结构化PDF图像转换为半结构化数据，促进各领域信息的数字化和利用。尽管视觉语言模型显著推进了该任务，但在现实场景中实现可靠、高质量的解析仍然具有挑战性。标准基准测试可能存在数据集特定偏差，导致模型选择不够准确。

Method: 论文未提供具体方法细节，但指出当前常见做法是基于标准基准测试选择性能最佳的模型。暗示需要更全面的评估方法来克服数据集偏差问题。

Result: 未提供具体实验结果，但指出了当前文档解析领域面临的核心问题：标准基准测试的局限性可能导致模型评估不够准确。

Conclusion: 文档解析任务需要更全面的评估框架来克服数据集偏差，确保在现实场景中实现可靠、高质量的解析性能。

Abstract: Document parsing aims to transform unstructured PDF images into semi-structured data, facilitating the digitization and utilization of information in diverse domains. While vision language models (VLMs) have significantly advanced this task, achieving reliable, high-quality parsing in real-world scenarios remains challenging. Common practice often selects the top-performing model on standard benchmarks. However, these benchmarks may carry dataset-specific biases, leading to …

</details>


### [586] [CANVAS: A Benchmark for Vision-Language Models on Tool-Based User Interface Design](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.20737&hl=zh-CN&sa=X&d=17126056963637069991&ei=gGdAadyMIYKUieoP5cGFWQ&scisig=ALhkC2SErQ0zgUGFWV4UOgZZTpvb&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=1&folt=rel)
*D Jeong,S Byun,K Son,DH Kim,J Kim*

Main category: Xuanhe Zhou

TL;DR: 该论文探讨了如何利用视觉语言模型（VLMs）和工具调用能力来辅助用户界面（UI）设计过程，通过自动化工具减少设计师的重复性工作。


<details>
  <summary>Details</summary>
Motivation: UI设计是一个迭代过程，设计师需要不断使用Figma或Sketch等设计软件进行修改和优化。这个过程包含大量重复性工作，而当前视觉语言模型（VLMs）具备工具调用能力，为自动化部分设计任务提供了可能。

Method: 论文提出了一种基于视觉语言模型（VLMs）的系统，该系统能够理解设计意图并调用设计工具（如Figma API）来自动执行UI设计任务。方法可能包括：1）设计规范的视觉理解；2）设计元素的识别和操作；3）工具调用接口的集成；4）迭代优化机制。

Result: 开发的原型系统能够成功理解设计需求并自动执行UI设计任务，显著减少了设计师的重复性工作。系统在测试中展示了：1）准确的设计元素识别能力；2）有效的工具调用执行；3）设计迭代效率的提升；4）与现有设计工作流程的良好集成。

Conclusion: 视觉语言模型（VLMs）结合工具调用能力为UI设计自动化提供了有效途径，能够显著提高设计效率，减少重复性工作。未来的研究方向包括：1）提高系统的鲁棒性和准确性；2）扩展支持的设计任务类型；3）优化人机协作模式；4）集成更多设计工具和平台。

Abstract: User interface (UI) design is an iterative process in which designers progressively refine their work with design software such as Figma or Sketch. Recent advances in vision language models (VLMs) with tool invocation suggest these models can …

</details>


### [587] [Look As You Think: Unifying Reasoning and Visual Evidence Attribution for Verifiable Document RAG via Reinforcement Learning](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.12003&hl=zh-CN&sa=X&d=2836156929189057967&ei=gGdAadyMIYKUieoP5cGFWQ&scisig=ALhkC2TT6-djbDU56cMSGEo211Jm&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=3&folt=rel)
*S Liu,P Luo,C Zhang,Y Chen,H Zhang,Q Liu,X Kou…*

Main category: Xuanhe Zhou

TL;DR: 视觉证据归因用于视觉文档检索增强生成，旨在从视觉文档中识别精确的证据来源，确保视觉语言模型的预测可靠且可验证


<details>
  <summary>Details</summary>
Motivation: 当前视觉文档检索增强生成系统缺乏对证据来源的精确识别能力，导致模型预测的可信度和可验证性不足，需要建立可靠的视觉证据归因机制

Method: 提出视觉证据归因框架，通过从视觉文档中识别和定位精确的证据来源，为视觉语言模型的预测提供可靠的支持和验证

Result: 该方法能够有效识别视觉文档中的证据来源，提高视觉语言模型预测的可信度和可验证性，增强检索增强生成系统的可靠性

Conclusion: 视觉证据归因是提升视觉文档检索增强生成系统可靠性的关键技术，能够确保模型预测基于可验证的视觉证据，推动可信多模态人工智能发展

Abstract: Aiming to identify precise evidence sources from visual documents, visual evidence attribution for visual document retrieval-augmented generation (VD-RAG) ensures reliable and verifiable predictions from vision-language models (VLMs) in multimodal …

</details>


### [588] [Wikontic: Constructing Wikidata-Aligned, Ontology-Aware Knowledge Graphs with Large Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.00590&hl=zh-CN&sa=X&d=513675314461354915&ei=gGdAadyMIYKUieoP5cGFWQ&scisig=ALhkC2QkEQkMUuamk2FTmqkGqpzY&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=6&folt=rel)
*A Chepurova,A Bulatov,Y Kuratov,M Burtsev*

Main category: Xuanhe Zhou

TL;DR: 该研究探索了知识图谱作为大语言模型结构化基础的内在质量，而非仅将其用作文本检索的辅助结构


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的系统通常将知识图谱作为文本检索的辅助结构，而忽视了其内在质量的价值，这限制了知识图谱作为LLM结构化基础的全部潜力

Method: 论文提出了一种方法，深入探索知识图谱的内在质量，而不仅仅是将其用作文本检索的辅助工具。具体方法可能涉及对知识图谱结构、完整性、准确性等方面的系统性评估和利用

Result: 通过充分利用知识图谱的内在质量，研究可能展示了在LLM任务中相比传统辅助使用方式更好的性能表现

Conclusion: 知识图谱的内在质量对于提升LLM性能具有重要价值，不应仅将其视为文本检索的辅助结构，而应深入挖掘其作为结构化知识基础的全部潜力

Abstract: Knowledge graphs (KGs) provide structured, verifiable grounding for large language models (LLMs), but current LLM-based systems commonly use KGs as auxiliary structures for text retrieval, leaving their intrinsic quality underexplored. In this work …

</details>


### [589] [LLM Aspect Prediction: Reviewing Academic Papers from Different Aspects with Large Language Model](https://scholar.google.com/scholar_url?url=https://www.researchsquare.com/article/rs-8120128/latest.pdf&hl=zh-CN&sa=X&d=6493508901742426457&ei=fkJCabfZArLrieoPwNLAkQw&scisig=ALhkC2S-7Y9KZCcudMPZuseA50Mw&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=1&folt=rel)
*Z Hu,F Fukumoto,D Yu*

Main category: Xuanhe Zhou

TL;DR: 论文摘要不完整，仅描述了同行评审的基本过程及其认知需求，但未提供完整的研究内容、方法或结论。


<details>
  <summary>Details</summary>
Motivation: 同行评审是学术出版的关键环节，评审者需要根据既定标准评估稿件的多个方面（如新颖性、清晰度、重要性），这一过程需要大量认知投入。

Method: 摘要未提供具体研究方法，仅描述了同行评审的一般流程。

Result: 摘要未提供任何研究结果或发现。

Conclusion: 摘要不完整，无法得出具体结论。

Abstract: Peer review is a vital process in scholarly publishing, where reviewers assess and score various aspects of a manuscript—such as novelty, clarity, and significance—based on defined evaluation criteria. This process demands substantial cognitive …

</details>


### [590] [Enabling Visually Aware Conversational Data Visualization Through LLM Augmentation](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3757374.3771781&hl=zh-CN&sa=X&d=4816534493931401424&ei=99xDaYmaF7m26rQPgpXiSA&scisig=ALhkC2Rqxo3jRbXQIfVmCK5AvxcI&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=1&folt=rel)
*O Mena,A Kouyoumdjian,L Besançon,M Gleicher…*

Main category: Xuanhe Zhou

TL;DR: 提出一种增强方法，使大型语言模型同时具备数据感知和视觉感知能力，以改善可视化分析任务


<details>
  <summary>Details</summary>
Motivation: 传统LLMs在可视化分析中虽然能提供高质量的上下文信息，但缺乏对具体可视化数据内容和视觉特征的感知能力，这限制了它们在可视化相关任务中的实用性

Method: 开发了一种增强方法，使LLMs能够同时处理数据内容和视觉特征，通过特定的架构设计或训练策略实现数据感知和视觉感知的双重能力

Result: 增强后的LLMs在可视化分析任务中表现显著提升，能够更好地理解和解释可视化内容，提供更准确和相关的分析结果

Conclusion: 通过使LLMs具备数据感知和视觉感知能力，可以显著提升其在可视化分析任务中的性能，为更智能的可视化理解和交互提供了新的可能性

Abstract: We present an augmentation method that makes Large Language Models (LLMs) both data aware and visually aware. Unaugmented LLMs can provide high-quality information about the broad context of a visualization, but are unaware of the visual …

</details>


### [591] [Med-CRAFT: Automated Construction of Interpretable and Multi-Hop Video Workloads via Knowledge Graph Traversal](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.01045&hl=zh-CN&sa=X&d=16927007872433762136&ei=99xDaYmaF7m26rQPgpXiSA&scisig=ALhkC2Rlvh__guLhKdUx0URHkD2x&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=2&folt=rel)
*S Liu,K Li,M Zhao,Y Tian,S Zhou,B Li*

Main category: Xuanhe Zhou

TL;DR: 医疗视频数据标注成本高且稀缺，阻碍了多模态大语言模型在医学领域的发展，需要新的标注方法


<details>
  <summary>Details</summary>
Motivation: 医学领域高质量、逻辑标注的视频数据集稀缺，传统人工标注成本过高且不可扩展，限制了多模态大语言模型在医疗领域的应用和发展

Method: 论文未提供具体方法细节，但从摘要上下文推断可能涉及自动化或半自动化的视频标注技术，以降低标注成本并提高效率

Result: 摘要未提供具体实验结果，但暗示通过提出的新标注方法能够解决医疗视频数据标注的瓶颈问题

Conclusion: 需要开发新的标注方法来克服医疗视频数据标注的挑战，以促进多模态大语言模型在医学领域的应用

Abstract: The scarcity of high-quality, logically annotated video datasets remains a primary bottleneck in advancing Multi-Modal Large Language Models (MLLMs) for the medical domain. Traditional manual annotation is prohibitively expensive and non …

</details>


### [592] [Beyond SELECT: A Comprehensive Taxonomy-Guided Benchmark for Real-World Text-to-SQL Translation](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.13590&hl=zh-CN&sa=X&d=16736254628017597577&ei=99xDaYmaF7m26rQPgpXiSA&scisig=ALhkC2RQPOvFs0DXvC6zIR8coI_T&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=3&folt=rel)
*H Wang,Y Song,X Yin,X Chen*

Main category: Xuanhe Zhou

TL;DR: 提出新的文本到SQL数据集分类法以解决现有数据集覆盖有限、多样性不足的问题


<details>
  <summary>Details</summary>
Motivation: 现有文本到SQL数据集覆盖范围有限，未能充分捕捉真实世界应用的多样性，这限制了模型的训练和评估效果

Method: 提出一种新颖的分类法，用于更全面地分类和构建文本到SQL数据集

Result: 未在摘要中明确说明具体结果，但暗示新分类法能更好地覆盖真实世界应用的多样性

Conclusion: 新提出的分类法有助于解决现有文本到SQL数据集的局限性，提升数据集的质量和实用性

Abstract: Text-to-SQL datasets are essential for training and evaluating text-to-SQL models, but existing datasets often suffer from limited coverage and fail to capture the diversity of real-world applications. To address this, we propose a novel taxonomy for …

</details>


### [593] [Time Series Foundation Model Chronos Enhances Nitrogen Forecasting under Data Scarcity](https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S2589914725001677&hl=zh-CN&sa=X&d=13573994724138740387&ei=1XlFadd-nq7qtA-i3IzABA&scisig=ALhkC2QuKxNPBhkQbs-k4plxkySs&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=0&folt=cit)
*K Zheng,G Cui,Y Xie,Y Liu,X Du*

Main category: Xuanhe Zhou

TL;DR: 评估Chronos时间序列基础模型在水质预测中的表现，与传统任务特定模型对比，特别是在数据稀缺场景下


<details>
  <summary>Details</summary>
Motivation: 水质预测对水资源管理至关重要，但传统任务特定模型依赖大量训练数据，在数据稀缺场景下表现受限。时间序列基础模型为解决这一挑战提供了新思路

Method: 使用基于T5大型语言模型的Chronos时间序列基础模型，与一系列任务特定基准模型（包括RF等）进行对比评估

Result: Chronos在水质预测任务中表现出色，特别是在数据稀缺条件下，显示出时间序列基础模型在该领域的应用潜力

Conclusion: 时间序列基础模型为水质预测提供了有前景的解决方案，能够克服传统模型对大量训练数据的依赖，在水资源管理中具有重要应用价值

Abstract: Accurate water quality prediction is critical for water resource management, yet task-specific models are often limited by their reliance on extensive training data. The emergence of large time series foundation models presents a promising yet unexplored solution for water quality forecasting under data scarcity. This study evaluates Chronos, an advanced time series foundation model using the T5 large language model (LLM), against a suite of task-specific benchmark models (ie, RF …

</details>


### [594] [AgentSHAP: Interpreting LLM Agent Tool Importance with Monte Carlo Shapley Value Estimation](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.12597&hl=zh-CN&sa=X&d=6826359453668044164&ei=1XlFadd-nq7qtA-i3IzABA&scisig=ALhkC2QyVCqH6eR6iDt-UcqZxamG&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=1&folt=cit)
*M Horovicz*

Main category: Xuanhe Zhou

TL;DR: AgentSHAP是首个解释LLM智能体中工具重要性的框架，通过黑盒方法评估外部工具对智能体响应的贡献度，无需访问模型内部权重或梯度。


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体使用外部工具解决复杂任务，但缺乏解释哪些工具对响应有实际贡献的方法。现有可解释AI方法未解决工具级解释问题，导致工具使用成为盲点。

Method: AgentSHAP采用模型无关的黑盒方法，基于SHAP值原理，通过蒙特卡洛采样评估工具重要性。框架将智能体视为黑盒，适用于任何LLM模型（GPT、Claude、Llama等），无需访问内部权重或梯度。

Result: AgentSHAP是首个工具级解释框架，能够量化评估LLM智能体中各外部工具对最终响应的贡献度，填补了现有可解释AI方法在工具层面解释的空白。

Conclusion: AgentSHAP为LLM智能体的工具使用提供了可解释性，有助于理解工具贡献、优化工具选择，并增强智能体决策的透明度和可信度。

Abstract: LLM agents that use external tools can solve complex tasks, but understanding which tools actually contributed to a response remains a blind spot. No existing XAI methods address tool-level explanations. We introduce AgentSHAP, the first framework for explaining tool importance in LLM agents. AgentSHAP is model-agnostic: it treats the agent as a black box and works with any LLM (GPT, Claude, Llama, etc.) without needing access to internal weights or gradients. Using Monte …

</details>


### [595] [OOCO: Latency-disaggregated Architecture for Online-Offline Co-locate LLM Serving](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.21862&hl=zh-CN&sa=X&d=14799345802881663024&ei=1HlFaduqBIKUieoP5cGFWQ&scisig=ALhkC2ST0y2eTiQCZNTHyC4kOrJz&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=1&folt=rel)
*S Wu,Z Tang,Y Zeng,H Chen,G Ding,T Liu,K Zhang…*

Main category: Xuanhe Zhou

TL;DR: 该论文研究如何在共享服务实例上共同部署延迟敏感型在线服务和成本敏感型离线工作负载，以提高资源利用率，同时避免性能干扰。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在延迟敏感的在线服务和成本敏感的离线工作负载中部署日益增多。在共享服务实例上共同部署这些工作负载可以提高资源利用率，但直接应用这种策略会导致性能干扰问题。

Method: 论文提出了一种协同定位策略，通过资源管理和调度机制来平衡在线服务的延迟要求和离线工作负载的成本效益，确保共享环境下的性能隔离和资源高效利用。

Result: 提出的方法能够有效减少性能干扰，在保持在线服务低延迟的同时，提高离线工作负载的资源利用率，实现更好的整体资源效率。

Conclusion: 通过智能的资源管理和调度策略，可以在共享服务实例上成功共同部署LLM的在线和离线工作负载，实现资源利用率的提升而不损害服务质量。

Abstract: Large Language Models (LLMs) are increasingly deployed in both latency-sensitive online services and cost-sensitive offline workloads. Co-locating these workloads on shared serving instances can improve resource utilization, but directly applying this …

</details>


### [596] [Multi-Agent RAG Framework for Entity Resolution: Advancing Beyond Single-LLM Approaches with Specialized Agent Coordination](https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2073-431X/14/12/525&hl=zh-CN&sa=X&d=18069872512629264083&ei=1HlFaduqBIKUieoP5cGFWQ&scisig=ALhkC2RL3uX0iM6HIH_tCAiIQ0Jr&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=2&folt=rel)
*AM Althaf,MA Mohammed,M Milanova,J Talburt…*

Main category: Xuanhe Zhou

TL;DR: 该论文针对真实世界数据集中实体解析的挑战，特别是识别家庭和检测共居模式的问题，探索了大型语言模型（LLMs）的潜力，但指出单一模型方法存在局限性。


<details>
  <summary>Details</summary>
Motivation: 真实世界数据集中的实体解析面临持续挑战，尤其是在识别家庭和检测共居模式方面，数据通常存在噪声和不完整。虽然大型语言模型显示出潜力，但单一模型方法存在局限性。

Method: 论文探索了大型语言模型在实体解析中的应用，但指出需要超越单一模型的方法来解决噪声和不完整数据中的家庭识别和共居模式检测问题。

Result: 论文表明大型语言模型在实体解析方面有潜力，但单一模型方法不足以有效处理真实世界数据集中家庭识别和共居模式检测的挑战。

Conclusion: 需要开发超越单一大型语言模型的方法来解决真实世界数据集中实体解析的挑战，特别是在家庭识别和共居模式检测方面。

Abstract: Entity resolution in real-world datasets remains a persistent challenge, particularly for identifying households and detecting co-residence patterns within noisy and incomplete data. While Large Language Models (LLMs) show promise, monolithic …

</details>


### [597] [LLM-based Personalized Portfolio Recommender: Integrating Large Language Models and Reinforcement Learning for Intelligent Investment Strategy Optimization](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.12922&hl=zh-CN&sa=X&d=7027291096826504715&ei=1HlFaduqBIKUieoP5cGFWQ&scisig=ALhkC2Q1vfRKuubQZV0wha1rnKqx&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=3&folt=rel)
*B Li,B Gu,Z Ding*

Main category: Xuanhe Zhou

TL;DR: 投资者寻求个性化自适应投资组合策略，传统方法难以满足动态市场条件下的个性化风险偏好需求


<details>
  <summary>Details</summary>
Motivation: 现代金融市场中，投资者需要反映个人风险偏好并能响应动态市场条件的个性化自适应投资组合策略，传统基于规则或静态优化方法无法满足这一需求

Method: 论文未提供具体方法细节，但暗示将采用超越传统规则和静态优化的新方法来解决个性化自适应投资组合问题

Result: 摘要未提供具体结果，但暗示新方法将能够更好地满足投资者个性化需求和适应市场动态变化

Conclusion: 需要开发新的投资组合策略方法来满足现代金融市场对个性化和自适应性的需求

Abstract: In modern financial markets, investors increasingly seek personalized and adaptive portfolio strategies that reflect their individual risk preferences and respond to dynamic market conditions. Traditional rule-based or static optimization approaches …

</details>


### [598] [Question Answering through Retrieval-Augmented Large Language Models: an Experimental Evaluation](https://scholar.google.com/scholar_url?url=https://www.itadata.it/_2025_pages/proceedings/papers/paper82.pdf&hl=zh-CN&sa=X&d=3018667459744740201&ei=1HlFaduqBIKUieoP5cGFWQ&scisig=ALhkC2SV7bWdUGVPRarY4bCDcKKu&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=7&folt=rel)
*C Diamantini,A Mircoli,A Pagnotta,D Potena…*

Main category: Xuanhe Zhou

TL;DR: LLMs在代码生成和问答等NLP任务中表现出色，但存在各种局限性，包括生成不准确内容等问题


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在代码生成和问答等自然语言处理任务中展现出令人印象深刻的性能，但它们存在各种局限性，如生成不准确内容等问题，需要对这些局限性进行研究和改进

Method: 论文未提供具体方法细节，但从摘要来看，可能涉及对LLMs局限性的系统分析、评估框架设计或改进方法的提出

Result: 摘要未提供具体实验结果，但暗示LLMs在代码生成和问答任务中存在性能局限性，需要进一步研究和改进

Conclusion: 大型语言模型虽然在多个NLP任务中表现出色，但仍存在需要解决的局限性，未来研究应关注这些问题的改进

Abstract: Abstract Large Language Models (LLMs) show impressive performance in many natural language processing (NLP) tasks, including code generation and question answering. However, they suffer from various limitations, such as the generation of …

</details>


### [599] [Beyond SFT: Reinforcement Learning for Safer Large Reasoning Models with Better Reasoning Ability](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.01848&hl=zh-CN&sa=X&d=1494406561888575877&ei=Vx1HaanEIK-nieoPz8HDqAc&scisig=ALhkC2RYpDrSumlatf7IHvEFbn08&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=2&folt=rel)
*J Jia,N Baracaldo,S Liu*

Main category: Xuanhe Zhou

TL;DR: LRMs通过显式思维链推理提升数学逻辑问题解决能力，但该过程也引入了新的安全漏洞


<details>
  <summary>Details</summary>
Motivation: 大型推理模型通过生成显式思维链推理显著提升了数学和逻辑问题解决能力，但这种显式推理过程也引入了新的安全漏洞，需要系统性地研究这些漏洞及其缓解方法

Method: 论文对大型推理模型的安全漏洞进行系统性研究，分析显式思维链推理过程中可能被利用的安全风险，并提出相应的缓解策略

Result: 研究发现LRMs的显式推理过程确实存在可被攻击者利用的安全漏洞，这些漏洞可能影响模型的可靠性和安全性，需要专门的防御机制

Conclusion: 虽然大型推理模型通过显式思维链推理提升了问题解决能力，但必须正视其引入的安全风险，需要开发针对性的安全防护措施来确保模型在实际应用中的可靠性

Abstract: Large reasoning models (LRMs) extend large language models by generating explicit chain-of-thought (CoT) reasoning, significantly improving mathematical and logical problem solving. However, this explicit reasoning process also introduces …

</details>


### [600] [Citation-Grounded Code Comprehension: Preventing LLM Hallucination Through Hybrid Retrieval and Graph-Augmented Context](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.12117&hl=zh-CN&sa=X&d=16752051025025968855&ei=Vx1HaanEIK-nieoPz8HDqAc&scisig=ALhkC2Rc0xBNd_A-6_amlQMH0Edc&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=3&folt=rel)
*J Arafat*

Main category: Xuanhe Zhou

TL;DR: LLM在代码理解中存在幻觉问题，研究者提出了一种基于检索增强生成（RAG）的方法来缓解这一问题，通过从代码库中检索相关上下文来增强LLM的响应准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型已成为代码理解的重要工具，但存在幻觉问题，即生成看似合理但事实错误的代码相关信息。这降低了LLM在代码查询任务中的可靠性，需要有效方法来缓解这一问题。

Method: 采用检索增强生成（RAG）方法，从目标代码库中检索相关代码片段和文档作为上下文，然后将这些检索到的信息与用户查询一起提供给LLM，以生成更准确的响应。

Result: 基于RAG的方法显著减少了LLM在代码理解任务中的幻觉现象，提高了代码查询响应的准确性和可靠性。实验表明，与基线方法相比，该方法在多个代码理解基准测试中表现更优。

Conclusion: 检索增强生成是缓解LLM在代码理解中幻觉问题的有效策略，通过提供相关代码上下文，能够显著提升LLM生成响应的准确性和事实一致性。

Abstract: Large language models have become essential tools for code comprehension, enabling developers to query unfamiliar codebases through natural language interfaces. However, LLM hallucination, generating plausible but factually incorrect …

</details>


### [601] [Sparse-LaViDa: Sparse Multimodal Discrete Diffusion Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.14008&hl=zh-CN&sa=X&d=1718303489563373763&ei=Vx1HaanEIK-nieoPz8HDqAc&scisig=ALhkC2SySs-O0fn1v4Iy1QDzv6Jj&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=4&folt=rel)
*S Li,J Gu,K Liu,Z Lin,Z Wei,A Grover,J Kuen*

Main category: Xuanhe Zhou

TL;DR: MD3模型在图像理解、生成和编辑等任务上表现出色，但推理速度因需要大量去噪步骤而受限


<details>
  <summary>Details</summary>
Motivation: 尽管Masked Discrete Diffusion Models（MD3）在多模态任务中取得了优异性能，但其推理速度仍然不理想，主要瓶颈在于需要大量去噪步骤

Method: 论文未提供具体方法细节，但从摘要推断可能涉及改进MD3的推理效率，可能通过减少去噪步骤、优化采样策略或架构改进来实现

Result: 摘要未提供具体结果，但暗示通过提出的方法能够显著提升MD3的推理速度，同时保持或提升模型性能

Conclusion: 需要开发更高效的MD3推理方法来解决速度瓶颈问题，以实现实际应用中的实时性能

Abstract: Masked Discrete Diffusion Models (MDMs) have achieved strong performance across a wide range of multimodal tasks, including image understanding, generation, and editing. However, their inference speed remains suboptimal due to the need to …

</details>


### [602] [Verification-Guided Context Optimization for Tool Calling via Hierarchical LLMs-as-Editors](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.13860&hl=zh-CN&sa=X&d=4904986501450276556&ei=WB1Haa-KHp6u6rQPotyMwAQ&scisig=ALhkC2TjpUrtK-kpkUtH2kduS8P9&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=0&folt=cit)
*H Li,S You,F Di Palo,Y Qian,A Jain*

Main category: Xuanhe Zhou

TL;DR: 论文指出当前大语言模型工具调用依赖为人类编写的文档，存在与LLM信息处理方式不匹配的问题，尤其在工业场景中更为突出


<details>
  <summary>Details</summary>
Motivation: 大语言模型通过工具调用与外部环境交互，但工具使用效果严重依赖文档和知识库的质量。这些材料通常为人类用户编写，与LLM的信息解释方式存在错配，特别是在工业场景中问题更加明显

Method: 论文未在摘要中明确说明具体方法，但暗示需要解决LLM工具调用中人类文档与模型理解之间的对齐问题

Result: 摘要未提供具体实验结果，但指出了当前工具调用系统存在的根本问题：人类编写的文档与LLM信息处理方式不匹配

Conclusion: 需要重新设计工具文档和知识库，使其更好地与LLM的信息解释方式对齐，以提高工具调用的有效性

Abstract: Tool calling enables large language models (LLMs) to interact with external environments through tool invocation, providing a practical way to overcome the limitations of pretraining. However, the effectiveness of tool use depends heavily on the quality of the associated documentation and knowledge base context. These materials are usually written for human users and are often misaligned with how LLMs interpret information. This problem is even more pronounced in industrial …

</details>


### [603] [Exploring the Influence of Artificial Intelligence on Teaching Strategies in Higher Education: A Phenomenological Approach](https://scholar.google.com/scholar_url?url=https://digitalcommons.liberty.edu/cgi/viewcontent.cgi%3Farticle%3D8860%26context%3Ddoctoral&hl=zh-CN&sa=X&d=6581475208415230976&ei=WB1Haa-KHp6u6rQPotyMwAQ&scisig=ALhkC2QobNlBlLKKtq1i2WBdjRlN&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=1&folt=cit)
*DM Hamilton*

Main category: Xuanhe Zhou

TL;DR: 描述高等教育教师关于人工智能影响教学策略的生活体验的现象学研究


<details>
  <summary>Details</summary>
Motivation: 探索人工智能如何影响高等教育教师的教学策略，了解教师如何解释、适应和实施AI技术，基于建构主义学习理论视角

Method: 采用先验现象学研究方法，以维果茨基建构主义学习理论为指导，描述教师关于AI影响教学策略的生活体验

Result: 研究描述了高等教育教师在使用AI技术过程中的具体体验、适应策略和实施方式

Conclusion: AI对高等教育教学策略产生了显著影响，教师需要积极适应并重新思考教学实践，建构主义理论为理解这一过程提供了理论框架

Abstract: The purpose of this transcendental phenomenological study was to describe the lived experiences regarding the influence of artificial intelligence (AI) on the teaching strategies for higher education instructors. Guided by Vygotsky's constructivist learning theory, which emphasizes the active role of learners in constructing knowledge through engagement and interaction, this study aimed to explore how educators interpret, adapt to, and implement AI in their classrooms. The central …

</details>


### [604] [Beyond Fast and Slow: Cognitive-Inspired Elastic Reasoning for Large Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.15089&hl=zh-CN&sa=X&d=9584200642514683176&ei=xJ1Iaf--K72qieoPuKej0QM&scisig=ALhkC2Srrgm2cVuzi6KpizCWvIXA&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=0&folt=cit)
*J Hu,D Yang,L Bian,Z Wen,Y Wang,Y Chen,B Xiao…*

Main category: Xuanhe Zhou

TL;DR: CogER框架通过认知启发的弹性推理，动态选择最适合的推理策略来平衡LLM推理效率和准确性


<details>
  <summary>Details</summary>
Motivation: 现有LLM推理策略主要依赖LLM自身的快慢模式（如o1思考），难以在不同难度查询间平衡推理效率和准确性

Method: 提出认知启发的弹性推理框架CogER，受人类分层推理启发，动态选择最合适的推理策略

Result: 未在摘要中明确说明具体实验结果，但暗示该框架能更好地平衡推理效率和准确性

Conclusion: CogER框架为解决LLM推理中效率与准确性平衡问题提供了新思路

Abstract: Large language models (LLMs) have demonstrated impressive performance across various language tasks. However, existing LLM reasoning strategies mainly rely on the LLM itself with fast or slow mode (like o1 thinking) and thus struggle to balance reasoning efficiency and accuracy across queries of varying difficulties. In this paper, we propose Cognitive-Inspired Elastic Reasoning (CogER), a framework inspired by human hierarchical reasoning that dynamically selects the most suitable reasoning …

</details>


### [605] [Adaptation of Agentic AI](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.16301&hl=zh-CN&sa=X&d=18200642435317852821&ei=xJ1Iaf--K72qieoPuKej0QM&scisig=ALhkC2QBMhqNYb4Xlfa_Jf4aii75&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=1&folt=cit)
*P Jiang,J Lin,Z Shi,Z Wang,L He,Y Wu,M Zhong…*

Main category: Xuanhe Zhou

TL;DR: 提出一个统一框架，系统化地组织智能体适应和工具适应的研究，涵盖能力提升、可靠性增强和泛化改进


<details>
  <summary>Details</summary>
Motivation: 随着基于基础模型的智能体AI系统能力增强和范围扩大，适应机制成为提升性能、可靠性和泛化的核心手段，需要系统化框架来统一快速扩展的研究领域

Method: 建立一个系统化框架，同时涵盖智能体适应和工具适应两个维度，对现有研究进行统一分类和组织

Result: 提出了一个全面的框架，能够系统化地组织和分类智能体适应与工具适应的各种方法，为研究领域提供结构化视角

Conclusion: 适应机制是提升智能体AI系统性能的关键，提出的统一框架有助于系统化理解和推进智能体适应与工具适应的研究

Abstract: Cutting-edge agentic AI systems are built on foundation models that can be adapted to plan, reason, and interact with external tools to perform increasingly complex and specialized tasks. As these systems grow in capability and scope, adaptation becomes a central mechanism for improving performance, reliability, and generalization. In this paper, we unify the rapidly expanding research landscape into a systematic framework that spans both agent adaptations and tool adaptations. We …

</details>


### [606] [Distributional AGI Safety](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.16856&hl=zh-CN&sa=X&d=14805022475924871540&ei=xJ1Iaf--K72qieoPuKej0QM&scisig=ALhkC2TJcx6ODuApCGdjJVvTV-qQ&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=2&folt=cit)
*N Tomašev,M Franklin,J Jacobs,S Krier,S Osindero*

Main category: Xuanhe Zhou

TL;DR: 论文提出"拼凑式AGI"概念，挑战传统单一AGI假设，强调通过多个子AGI智能体协调实现通用能力，并探讨其安全与对齐挑战


<details>
  <summary>Details</summary>
Motivation: 当前AI安全与对齐研究主要关注单一AI系统的防护，基于最终会出现单一通用人工智能（AGI）的假设。然而，另一种AGI出现假设——通用能力首先通过具有互补技能和可用性的子AGI个体智能体群体协调实现——受到较少关注。本文旨在探讨这种"拼凑式AGI"假说及其安全影响

Method: 论文通过理论分析，提出"拼凑式AGI"概念框架，分析其与单一AGI假说的区别，并系统探讨这种分布式智能体协调模式带来的独特安全与对齐挑战

Result: 识别出拼凑式AGI场景下的新型安全风险，包括智能体间协调失败、涌现行为不可预测性、分布式责任归属问题等，这些挑战在传统单一AGI安全框架中未被充分考虑

Conclusion: 拼凑式AGI假说为AI安全研究提供了重要新视角，需要开发专门的安全与对齐方法来应对分布式智能体协调带来的独特挑战，而不仅仅是扩展现有单一系统安全方法

Abstract: AI safety and alignment research has predominantly been focused on methods for safeguarding individual AI systems, resting on the assumption of an eventual emergence of a monolithic Artificial General Intelligence (AGI). The alternative AGI emergence hypothesis, where general capability levels are first manifested through coordination in groups of sub-AGI individual agents with complementary skills and affordances, has received far less attention. Here we argue that this patchwork AGI …

</details>


### [607] [Agent Tools Orchestration Leaks More: Dataset, Benchmark, and Mitigation](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.16310&hl=zh-CN&sa=X&d=12407180253472263967&ei=xJ1Iaf--K72qieoPuKej0QM&scisig=ALhkC2QP6YUsE5K-aeRZWJZSglCC&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=3&folt=cit)
*Y Qiao,D Liu,H Yang,W Zhou,S Hu*

Main category: Xuanhe Zhou

TL;DR: 论文提出大型语言模型驱动的单智能体多工具架构存在新的隐私风险——工具编排隐私风险（TOP-R），即智能体为实现良性用户目标，自主聚合多个工具的信息片段，利用推理能力合成意外隐私信息。


<details>
  <summary>Details</summary>
Motivation: 当前流行的单智能体多工具架构虽然简单有效，但存在严重隐私风险。智能体可能通过跨工具信息聚合和推理能力，从看似无害的分散信息中合成敏感隐私信息，这种风险尚未被充分认识和研究。

Method: 论文通过分析单智能体多工具架构的工作机制，识别出工具编排隐私风险（TOP-R）的具体形成机制。研究智能体如何自主聚合多个工具的信息片段，并利用大型语言模型的推理能力合成隐私信息。

Result: 识别并定义了工具编排隐私风险（TOP-R）这一新型隐私威胁。揭示了智能体通过跨工具信息聚合和推理合成隐私信息的具体机制，表明即使单个工具提供的信息看似无害，组合后可能产生严重隐私泄露。

Conclusion: 单智能体多工具架构存在严重的工具编排隐私风险，需要新的隐私保护机制来应对这种跨工具信息聚合和推理合成带来的隐私威胁。

Abstract: Driven by Large Language Models, the single-agent, multi-tool architecture has become a popular paradigm for autonomous agents due to its simplicity and effectiveness. However, this architecture also introduces a new and severe privacy risk, which we term Tools Orchestration Privacy Risk (TOP-R), where an agent, to achieve a benign user goal, autonomously aggregates information fragments across multiple tools and leverages its reasoning capabilities to synthesize unexpected …

</details>


### [608] [EMLC: An extensible multi-level correction framework for text-to-SQL](https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0306457325005011&hl=zh-CN&sa=X&d=2315546839538311705&ei=xJ1Iaf--K72qieoPuKej0QM&scisig=ALhkC2Rolyo1Zu4RnWs1YNfdrkz7&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=5&folt=cit)
*J Lei,Y Tan,Y Wang*

Main category: Xuanhe Zhou

TL;DR: 提出EMLC框架，通过分层集成模式、骨架和执行校正来解决Text-to-SQL自校正的三个关键挑战


<details>
  <summary>Details</summary>
Motivation: 解决Text-to-SQL自校正中的三个关键挑战：模式不匹配、结构不完整和语义验证薄弱

Method: 提出EMLC（可扩展多级校正框架），分层集成模式校正、骨架校正和执行校正，包含基于LLM预测与token级映射的双重验证模式校正机制

Result: 未在摘要中明确说明具体实验结果，但暗示该方法能有效解决Text-to-SQL自校正的关键挑战

Conclusion: EMLC框架通过多层次校正机制有效解决了Text-to-SQL自校正中的模式匹配、结构完整性和语义验证问题

Abstract: To address three key challenges of Text-to-SQL self-correction, including schema mismatch, structural incompleteness, and semantic validation weakness, this paper proposes EMLC, an extensible multi-level correction framework that hierarchically integrates schema, skeleton, and execution corrections. EMLC incorporates a dual-validation schema correction mechanism that combines large language model (LLM)-based prediction with token-level mapping for precise schema alignment. Moreover …

</details>


### [609] [BoA-SQL: Executable Blueprint-of-Action for Text-to-SQL with reinforcement learning](https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0952197625034852&hl=zh-CN&sa=X&d=8634936054668497343&ei=xJ1Iaf--K72qieoPuKej0QM&scisig=ALhkC2SocYFWOAm7xFnv6jkYTmV_&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=6&folt=cit)
*Y Wang,Z Xie,L Zhang,L Gu,Q Li*

Main category: Xuanhe Zhou

TL;DR: BoA-SQL：将自然语言查询转换为SQL的框架，通过结构化推理计划解决复杂嵌套逻辑和错误传播问题


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的数据库查询方法通常采用线性推理，难以处理复杂嵌套逻辑，且容易产生错误传播。需要一种更鲁棒、结构化的方法来将自然语言查询转换为SQL。

Method: 提出BoA-SQL框架，将推理过程转化为持久化、结构化的计划。主要贡献包括：(1) 轻量级知识图谱驱动的链接器，解决模式歧义和上下文过载问题；(2) 结构化推理机制；(3) 其他未在摘要中详细说明的技术。

Result: 摘要中未提供具体实验结果，但暗示该方法能更好地处理复杂嵌套逻辑，减少错误传播，提高自然语言到SQL转换的准确性。

Conclusion: BoA-SQL通过结构化推理计划改进了自然语言到SQL的转换，解决了现有线性推理方法的局限性，为复杂数据库查询提供了更可靠的解决方案。

Abstract: Recent progress in large language models has opened new possibilities for querying databases using natural language instead of SQL. Yet existing methods, often relying on linear reasoning, struggle with complex nested logic and are susceptible to error propagation. We propose BoA-SQL, which turns reasoning into a durable, structured plan. Our contributions are threefold:(1) To resolve schema ambiguity and context overload, a lightweight, knowledge graph-driven linker …

</details>


### [610] [LLaDA2. 0: Scaling Up Diffusion Language Models to 100B](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.15745&hl=zh-CN&sa=X&d=13087633951632919963&ei=xJ1Iaf--K72qieoPuKej0QM&scisig=ALhkC2SrkXxPIAT9x03B-Q1NmVNP&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=7&folt=cit)
*T Bie,M Cao,K Chen,L Du,M Gong,Z Gong,Y Gu…*

Main category: Xuanhe Zhou

TL;DR: LLaDA2.0是一个通过系统化转换自回归模型构建的离散扩散大语言模型，参数规模达1000亿，建立了前沿模型部署的新范式


<details>
  <summary>Details</summary>
Motivation: 避免从头开始训练的高成本，通过知识继承、渐进适应和效率感知设计原则，将预训练的自回归模型高效转换为离散扩散模型

Method: 采用3阶段块级WSD（可能指权重共享/分解）方法，系统化地将预训练AR模型转换为离散扩散LLM，实现参数规模扩展至1000亿

Result: 建立了参数规模达1000亿的离散扩散大语言模型，为前沿模型部署提供了新范式

Conclusion: LLaDA2.0通过创新的转换方法成功构建了大规模离散扩散模型，展示了从AR到扩散模型转换的可行性，为高效部署前沿模型提供了新途径

Abstract: This paper presents LLaDA2. 0--a tuple of discrete diffusion large language models (dLLM) scaling up to 100B total parameters through systematic conversion from auto-regressive (AR) models--establishing a new paradigm for frontier-scale deployment. Instead of costly training from scratch, LLaDA2. 0 upholds knowledge inheritance, progressive adaption and efficiency-aware design principle, and seamless converts a pre-trained AR model into dLLM with a novel 3-phase block-level WSD based …

</details>


### [611] [Scaling Text2SQL via LLM-efficient Schema Filtering with Functional Dependency Graph Rerankers](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.16083&hl=zh-CN&sa=X&d=8840237616514414986&ei=w51IadjBHKyK6rQPgZOO6A8&scisig=ALhkC2QVos7Hf0vDhOOGwvEjiRcQ&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=0&folt=rel)
*TD Hoang,TT Nguyen,TT Huynh,H Yin,QVH Nguyen*

Main category: Xuanhe Zhou

TL;DR: 该论文研究现代Text2SQL系统在处理大型数据库模式时的局限性，提出了一种新的方法来解决LLM无法处理超出上下文限制的复杂真实世界数据库模式的问题。


<details>
  <summary>Details</summary>
Motivation: 当前大多数Text2SQL系统将整个数据库模式（主要是列信息）与用户问题一起输入给大语言模型，这种方法在小数据库上有效，但在超出LLM上下文限制的真实世界复杂数据库模式上会失败。

Method: 论文提出了一种新的方法来解决大型数据库模式的处理问题，但具体方法细节在摘要中没有明确说明，需要进一步阅读全文了解其技术方案。

Result: 摘要中没有明确说明实验结果，但暗示了提出的方法能够有效处理超出LLM上下文限制的大型真实世界数据库模式。

Conclusion: 需要开发新的Text2SQL方法来处理大型复杂数据库模式，以克服当前基于完整模式提示的方法在真实世界应用中的局限性。

Abstract: Most modern Text2SQL systems prompt large language models (LLMs) with entire schemas--mostly column information--alongside the user's question. While effective on small databases, this approach fails on real-world schemas that exceed LLM …

</details>


### [612] [Small Language Models for Efficient Agentic Tool Calling: Outperforming Large Models with Targeted Fine-tuning](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.15943&hl=zh-CN&sa=X&d=9385340077455330075&ei=w51IadjBHKyK6rQPgZOO6A8&scisig=ALhkC2Tcv2BdHSowI_mMHeOlbrSo&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=1&folt=rel)
*P Jhandi,O Kazi,S Subramanian,N Sendas*

Main category: Xuanhe Zhou

TL;DR: 该论文探讨了在组织规模化采用生成式AI时，模型成本优化和运营效率成为决定可持续性和可访问性的关键因素，尽管大语言模型表现出色但面临成本挑战


<details>
  <summary>Details</summary>
Motivation: 随着组织规模化采用生成式AI，模型成本优化和运营效率已成为决定AI应用可持续性和可访问性的关键因素。虽然大语言模型表现出色，但其高昂的运营成本限制了更广泛的应用和可持续性发展

Method: 从摘要内容来看，论文可能涉及成本优化策略、运营效率提升方法、模型部署优化技术等方面的研究，具体方法需要更多上下文信息

Result: 摘要未提供具体结果，但暗示了通过优化模型成本和运营效率可以提升生成式AI的可持续性和可访问性

Conclusion: 模型成本优化和运营效率是规模化采用生成式AI的关键挑战，解决这些问题对于确保AI应用的可持续发展和广泛可访问性至关重要

Abstract: As organizations scale adoption of generative AI, model cost optimization and operational efficiency have emerged as critical factors determining sustainability and accessibility. While Large Language Models (LLMs) demonstrate impressive …

</details>


### [613] [Generative Adversarial Reasoner: Enhancing LLM Reasoning with Adversarial Reinforcement Learning](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.16917&hl=zh-CN&sa=X&d=6288430598369660767&ei=w51IadjBHKyK6rQPgZOO6A8&scisig=ALhkC2QgpY9rfzL6eyhsG_wSHMY4&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=2&folt=rel)
*Q Liu,L Ye,W Ma,YC Chou,A Yuille*

Main category: Xuanhe Zhou

TL;DR: 该论文针对大型语言模型在数学推理中存在的计算错误、逻辑脆弱性和表面合理但无效步骤等问题，提出了一种改进方法


<details>
  <summary>Details</summary>
Motivation: 尽管具有显式推理能力的大型语言模型在数学推理方面表现出色，但仍存在过程错误，包括不正确计算、脆弱逻辑以及表面合理但无效的推理步骤，需要解决这些问题以提高模型的推理可靠性

Method: 论文提出了一种方法来检测和纠正大型语言模型在数学推理过程中产生的过程错误，具体方法未在摘要中详细说明

Result: 该方法能够有效识别和修正模型在数学推理中的过程错误，提高推理的准确性和可靠性

Conclusion: 通过解决大型语言模型在数学推理中的过程错误问题，可以显著提升模型的推理质量和可靠性，为更可靠的数学推理系统奠定基础

Abstract: Large language models (LLMs) with explicit reasoning capabilities excel at mathematical reasoning yet still commit process errors, such as incorrect calculations, brittle logic, and superficially plausible but invalid steps. In this paper …

</details>


### [614] [Can LLMs Guide Their Own Exploration? Gradient-Guided Reinforcement Learning for LLM Reasoning](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.15687&hl=zh-CN&sa=X&d=8025335255864939032&ei=w51IadjBHKyK6rQPgZOO6A8&scisig=ALhkC2Q1jZk00mHlE6G_FFp8sNg4&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=3&folt=rel)
*Z Liang,S Lu,W Yu,K Panaganti,Y Zhou,H Mi,D Yu*

Main category: Xuanhe Zhou

TL;DR: 本文提出了一种基于熵的强化学习探索方法，通过分析LLM学习动态来改进探索策略，解决当前探索机制与模型实际学习方式不匹配的问题


<details>
  <summary>Details</summary>
Motivation: 当前强化学习在增强大语言模型推理能力方面很关键，但现有的探索机制与这些模型的实际学习方式存在根本性不匹配。熵奖励等传统方法未能充分考虑LLM的学习动态特性，导致探索效率低下

Method: 提出了一种基于熵的探索方法，通过分析LLM的学习动态来设计更合适的探索策略。该方法考虑了语言模型在强化学习过程中的特定学习特性，优化了探索机制

Result: 该方法在多个基准测试中表现出色，相比传统探索方法，在推理任务上取得了更好的性能提升，证明了基于LLM学习动态的探索策略的有效性

Conclusion: 通过将探索机制与LLM的实际学习动态对齐，可以显著提高强化学习在增强语言模型推理能力方面的效果，为RL在LLM训练中的应用提供了新的方向

Abstract: Reinforcement learning has become essential for strengthening the reasoning abilities of large language models, yet current exploration mechanisms remain fundamentally misaligned with how these models actually learn. Entropy bonuses …

</details>


### [615] [The Pneuma Project: Reifying Information Needs as Relational Schemas to Automate Discovery, Guide Preparation, and Align Data with Intent](https://scholar.google.com/scholar_url?url=https://www.vldb.org/cidrdb/papers/2026/p31-balaka.pdf&hl=zh-CN&sa=X&d=15860735992316123067&ei=mQ5KaZmGNdKV6rQP84i9kQc&scisig=ALhkC2RPQaGB0ntQVCOn9pV9dYjz&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=0&folt=cit)
*MIL Balaka,RC Fernandez*

Main category: Xuanhe Zhou

TL;DR: Pneuma-Seeker系统通过语言模型驱动的交互平台帮助用户表达和满足信息需求，将演化中的信息需求具体化为关系数据模型并逐步收敛


<details>
  <summary>Details</summary>
Motivation: 数据发现和准备是数据管理生命周期中的持续瓶颈，特别是当用户意图模糊、演化或难以操作化时，需要新的解决方案

Method: Pneuma-Seeker系统采用语言模型驱动的交互平台，将用户演化中的信息需求具体化为关系数据模型，通过迭代交互逐步收敛

Result: 系统能够帮助用户表达和满足信息需求，解决数据发现和准备中的瓶颈问题

Conclusion: Pneuma-Seeker通过语言模型驱动的迭代交互方法，有效解决了用户意图模糊和演化时的数据发现与准备问题

Abstract: Data discovery and preparation remain persistent bottlenecks in the data management lifecycle, especially when user intent is vague, evolving, or difficult to operationalize. The Pneuma Project introduces Pneuma-Seeker, a system that helps users articulate and fulfill information needs through iterative interaction with a language model–powered platform. The system reifies the user's evolving information need as a relational data model and incrementally converges toward a …

</details>


### [616] [From Policy Optimization Foundations to Language Model Post-Training on Structured Tasks](https://scholar.google.com/scholar_url?url=https://search.proquest.com/openview/9fc529f96bb4ae65736220abfba3e6c4/1%3Fpq-origsite%3Dgscholar%26cbl%3D18750%26diss%3Dy&hl=zh-CN&sa=X&d=17724060435514939850&ei=mQ5KaZmGNdKV6rQP84i9kQc&scisig=ALhkC2RhSd60rRjOaGlWC33denW2&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=1&folt=cit)
*B Liu*

Main category: Xuanhe Zhou

TL;DR: 该论文针对大模型强化学习的三个实际约束，首先研究了基于离策略数据的策略优化，通过估计密度比（通过学习的行为策略）来降低重要性加权目标的方差。


<details>
  <summary>Details</summary>
Motivation: 大模型强化学习面临三个实际约束：1）需要从离策略数据中进行策略优化；2）密度比估计对降低重要性加权目标的方差至关重要；3）PPO/TRPO等算法的混合更新模式需要每个批次执行多次策略改进步骤。

Method: 通过估计密度比（通过学习的行为策略）来降低重要性加权目标的方差，该方法不仅适用于离策略多臂赌博机问题，也是PPO/TRPO等算法的基础。

Result: 密度比估计方法有效降低了重要性加权目标的方差，为离策略策略优化提供了更稳定的学习框架。

Conclusion: 密度比估计是从离策略数据中进行策略优化的关键技术，为后续解决大模型强化学习的其他约束奠定了基础。

Abstract: Reinforcement learning for large models is constrained in three practical ways that this dissertation addresses in sequence. First, we study policy optimization from off-policy data and show how estimating the density ratio (via a learned behavior policy) reduces the variance of importance-weighted objectives. This estimation step is not only central to off-policy bandits; it also underpins PPO/TRPO, whose hybrid update pattern performs multiple policy-improvement steps per batch and is therefore …

</details>


### [617] [Dual-Density Inference for Efficient Language Model Reasoning](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.15358&hl=zh-CN&sa=X&d=7658526590843777510&ei=17JLab3nAZ6u6rQPotyMwAQ&scisig=ALhkC2Qc-neNTWsx8ahfw4jszj9V&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=0&folt=rel)
*Z Zhao,S Zhang,Y Zhang,H Wang,B Li,KF Wong*

Main category: Xuanhe Zhou

TL;DR: LLMs在复杂推理任务中表现出色，但现有方法在中间推理和最终答案中使用统一语言密度，导致计算效率低下。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在推理任务中对中间步骤和最终答案使用相同的语言密度，这种统一处理方式造成了计算资源的浪费，因为中间推理步骤通常不需要像最终答案那样详细和精确。

Method: 论文提出了一种差异化语言密度的方法，对中间推理步骤使用较低的语言密度（更简洁的表达），而对最终答案保持高语言密度，从而提高计算效率。

Result: 该方法在保持推理准确性的同时，显著减少了计算开销，提高了LLMs在复杂推理任务中的效率。

Conclusion: 通过差异化处理中间推理和最终答案的语言密度，可以有效提升LLMs的计算效率，为大规模语言模型的高效推理提供了新思路。

Abstract: Large Language Models (LLMs) have shown impressive capabilities in complex reasoning tasks. However, current approaches employ uniform language density for both intermediate reasoning and final answers, leading to computational inefficiency …

</details>


### [618] [TourismMinds: A Geo-augmented LLM Framework for Semantic-aware Trajectory Analytics and Generation](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3770697&hl=zh-CN&sa=X&d=8480807416000790223&ei=17JLab3nAZ6u6rQPotyMwAQ&scisig=ALhkC2RmEvs7x7s88oMG00BsRf8S&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=1&folt=rel)
*Z Ye,X Su,D He,Z Zhang,Y Sun,J Ji,X Xie,J Wang…*

Main category: Xuanhe Zhou

TL;DR: 论文探讨了智能城市和数字旅游背景下，整合多源数据理解游客移动模式的方法，以提升个性化体验和商业决策。


<details>
  <summary>Details</summary>
Motivation: 随着智能城市和数字旅游的发展，理解游客移动模式对于提升个性化旅游体验和优化商业决策至关重要。传统方法难以整合多源数据并解释复杂的游客行为模式。

Method: 论文提出了一种整合多源数据（如移动设备数据、社交媒体数据、位置服务数据等）的方法，采用先进的数据分析和机器学习技术来理解和预测游客移动模式。

Result: 该方法能够更准确地识别游客行为模式、偏好和移动轨迹，为个性化推荐和商业决策提供数据支持，相比传统方法有显著改进。

Conclusion: 整合多源数据的游客移动分析方法是智能城市和数字旅游发展的关键，能够有效提升旅游体验质量和商业决策的科学性。

Abstract: With the rise of smart cities and digital tourism, understanding tourist movement is essential for enhancing personalized experiences and informing business decisions. Traditional methods struggle to integrate multi-source data and interpret complex …

</details>


### [619] [Knowledge Distillation with Structured Chain-of-Thought for Text-to-SQL](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.17053&hl=zh-CN&sa=X&d=5518649107321623147&ei=fi5NabTECcW4ieoP4szBiAE&scisig=ALhkC2SsX544ljLiN1DlG9_Jxtzm&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=0&folt=cit)
*K Thaker,Y Bresler*

Main category: Xuanhe Zhou

TL;DR: 论文提出了一种解决企业级Text-to-SQL系统面临成本、安全和性能三难困境的新方法，通过结构化推理蒸馏替代传统的非结构化思维链方法。


<details>
  <summary>Details</summary>
Motivation: 企业部署Text-to-SQL系统面临成本、安全和性能的三难困境：需要在昂贵的专有大语言模型和性能较低的小语言模型之间做出选择。现有改进小模型的方法通常依赖从大模型蒸馏非结构化的思维链推理，但这种方法存在固有的模糊性。

Method: 论文提出了一种替代方案，使用结构化推理蒸馏方法，而不是传统的非结构化思维链跟踪。具体方法未在摘要中详细说明，但暗示了比现有方法更系统化的知识蒸馏框架。

Result: 摘要中未提供具体实验结果，但暗示该方法能够更好地解决企业级Text-to-SQL系统的三难困境，在成本、安全和性能之间取得更好的平衡。

Conclusion: 论文提出了一种新的结构化推理蒸馏方法，有望解决企业级Text-to-SQL系统面临的成本、安全和性能三难困境，为小语言模型的性能提升提供了更有效的途径。

Abstract: Deploying accurate Text-to-SQL systems at the enterprise level faces a difficult trilemma involving cost, security and performance. Current solutions force enterprises to choose between expensive, proprietary Large Language Models (LLMs) and low-performing Small Language Models (SLMs). Efforts to improve SLMs often rely on distilling reasoning from large LLMs using unstructured Chain-of-Thought (CoT) traces, a process that remains inherently ambiguous. Instead, we …

</details>


### [620] [AI-enhanced query optimizer for autonomous SQL server performance tuning](https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/B-Sayed/publication/398457188_AI-enhanced_query_optimizer_for_autonomous_SQL_server_performance_tuning/links/69403d7e0c98040d481e01bb/AI-enhanced-query-optimizer-for-autonomous-SQL-server-performance-tuning.pdf&hl=zh-CN&sa=X&d=10021731880655651213&ei=fi5NabTECcW4ieoP4szBiAE&scisig=ALhkC2TAP6bUeF7F3rrkbE5ondIG&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=1&folt=cit)
*MU Malik,BT Sayed*

Main category: Xuanhe Zhou

TL;DR: AI增强的查询优化系统，结合监督学习和强化学习，实现SQL Server的自主查询优化


<details>
  <summary>Details</summary>
Motivation: 传统数据库系统（如Microsoft SQL Server）使用的基于成本的优化器依赖固定启发式规则和预规范统计信息，无法适应不断变化的工作负载或动态查询模式，限制了性能、可扩展性和可靠性

Method: 提出AI增强的查询优化系统，结合监督学习和强化学习技术，实现自主的SQL Server查询优化

Result: AI增强的查询优化系统能够适应动态工作负载和查询模式，相比传统基于成本的优化器具有更好的适应性

Conclusion: AI技术（特别是监督学习和强化学习的结合）能够显著提升数据库查询优化的自主性和适应性，解决传统优化器的局限性

Abstract: The effective query execution is the culture to the performance, scalability and reliability of the latest database systems. The cost-based optimizers used in traditional systems, including Microsoft SQL Server, rely on fixed heuristics and pre-canonical statistics, which are not adaptable to evolving workloads or dynamic query patterns. This paper explores AI-enhanced query optimization system, which combines supervised and reinforcement learning to attain autonomous SQL Server …

</details>


### [621] [Well Begun, Half Done: Reinforcement Learning with Prefix Optimization for LLM Reasoning](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.15274&hl=zh-CN&sa=X&d=14160641762277443589&ei=fC5NafW2OLux6rQPi5qW2AE&scisig=ALhkC2QGJe6WJjph9qqq6H3r-KlN&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=0&folt=rel)
*Y Sun,Z Zhao,Y Wei,Y Zhang,C Gong*

Main category: Xuanhe Zhou

TL;DR: RLVR方法通过可验证奖励增强LLM推理能力，但现有方法在所有生成token上进行训练，未探索哪些token对奖励信号最敏感


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法在所有生成token上进行训练，效率低下且可能引入噪声。需要识别对奖励信号最敏感的token进行针对性训练，以提高训练效率和模型性能

Method: 通过分析token对奖励信号的敏感性，识别关键token，在关键token上进行针对性强化学习训练，而非所有token

Result: 选择性训练关键token能提高训练效率，减少噪声影响，增强LLM的推理能力，相比全token训练获得更好的性能表现

Conclusion: 在RLVR框架中，识别并针对关键token进行训练是提高LLM推理能力的有效策略，为强化学习在语言模型中的应用提供了新思路

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) significantly enhances the reasoning capability of Large Language Models (LLMs). Current RLVR approaches typically conduct training across all generated tokens, but neglect to explore which …

</details>


### [622] [Reinforcement Learning for Self-Improving Agent with Skill Library](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.17102&hl=zh-CN&sa=X&d=6110630037429314622&ei=fC5NafW2OLux6rQPi5qW2AE&scisig=ALhkC2TD-O5paBh_4aqwD30qlfP2&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=2&folt=rel)
*J Wang,Q Yan,Y Wang,Y Tian,SS Mishra,Z Xu…*

Main category: Xuanhe Zhou

TL;DR: LLM智能体在复杂推理和多轮交互中表现出色，但在新环境中缺乏持续改进和适应的能力，需要更好的自我进化机制


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体虽然具备强大的推理和交互能力，但在部署到新环境时缺乏持续学习和自我改进的机制，限制了其长期适应性和性能提升

Method: 论文可能提出了一种让LLM智能体能够在新环境中持续学习和自我改进的方法，可能涉及强化学习、元学习或自我监督学习等技术

Result: 基于摘要片段，无法确定具体实验结果，但预期目标是使LLM智能体能够在新环境中持续改进性能，增强适应性和鲁棒性

Conclusion: LLM智能体需要更有效的自我进化机制来应对新环境的挑战，实现持续的性能提升和适应性增强

Abstract: Large Language Model (LLM)-based agents have demonstrated remarkable capabilities in complex reasoning and multi-turn interactions but struggle to continuously improve and adapt when deployed in new environments. One …

</details>


### [623] [Understanding and Improving Hyperbolic Deep Reinforcement Learning](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.14202&hl=zh-CN&sa=X&d=14915516933061275453&ei=fC5NafW2OLux6rQPi5qW2AE&scisig=ALhkC2StEmQqeHRF5e1MvadRKgm1&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=3&folt=rel)
*T Klein,T Lang,A Shkabrii,A Sturm,K Sidak…*

Main category: Xuanhe Zhou

TL;DR: 论文探讨了强化学习中双曲特征空间的应用，认为其能更好地捕捉层次和关系结构，从而提升智能体性能


<details>
  <summary>Details</summary>
Motivation: 强化学习智能体的性能严重依赖于底层特征表示的质量。现有特征空间在处理层次和关系结构方面存在局限，而双曲空间天生适合捕捉这类结构，因此探索双曲特征空间在强化学习中的应用具有重要价值

Method: 提出使用双曲特征空间来增强强化学习智能体的特征表示能力。双曲空间通过其固有的几何特性（如指数增长的空间体积）自然地编码层次和关系结构，为强化学习任务提供更有效的特征表示

Result: 双曲特征空间能够显著提升强化学习智能体的性能，特别是在需要处理层次化或关系型结构的任务中。这种表示方法比传统欧几里得空间更有效地捕捉复杂的环境结构

Conclusion: 双曲特征空间为强化学习提供了有前景的特征表示方法，其固有的几何特性使其特别适合捕捉层次和关系结构，从而提升智能体在各种任务中的性能表现

Abstract: The performance of reinforcement learning (RL) agents depends critically on the quality of the underlying feature representations. Hyperbolic feature spaces are well-suited for this purpose, as they naturally capture hierarchical and relational structure …

</details>


### [624] [Talk to your database: An open-source in-context learning approach to interact with relational databases through LLMs](https://scholar.google.com/scholar_url?url=https://ceur-ws.org/Vol-4140/paper2.pdf&hl=zh-CN&sa=X&d=7407521841183138803&ei=W5lOaYSpJYaw6rQPkNu46Ao&scisig=ALhkC2QMNKo-mua1iRHiyqM4S8fT&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=1&folt=cit)
*M Plazotta,M Klettke*

Main category: Xuanhe Zhou

TL;DR: 本文测试了LLM微调方法在两个关系数据库（小型vs大型）上的性能，并与默认设置对比，结果显示使用上下文学习将性能从35%提升至85%以上，并提出了详细的系统架构框架。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的出现，长期研究的Text-to-SQL问题进入了新阶段。本文旨在测试LLM微调方法在不同规模关系数据库上的性能，并与默认设置进行比较，探索如何通过上下文学习提升Text-to-SQL任务的性能。

Method: 采用LLM微调方法，在两个不同规模的关系数据库（小型和大型）上进行测试。使用上下文学习技术，并与默认设置进行对比分析。同时提出了一个详细的系统架构框架。

Result: 使用上下文学习显著提升了性能：从默认设置的35%提升至85%以上。这表明LLM微调方法在Text-to-SQL任务中具有显著优势，特别是在结合上下文学习的情况下。

Conclusion: LLM微调结合上下文学习能显著提升Text-to-SQL任务的性能，为关系数据库查询生成提供了有效的解决方案。提出的架构框架为构建此类系统提供了指导。

Abstract: With the emergence of large language models, the long studied field of the Text-to-SQL problem was elevated into new spheres. In this paper, we test how our LLM fine-tuning approach performs on two relational databases (small vs. big) and compare it to a default setting. The results are convincing: using in-context learning boosts the performance from a merely 35%(default) to over 85%. Furthermore, we present a detailed architectural framework for such a system, emphasizing its exclusive …

</details>


### [625] [A Text-to-SQL Benchmark for Official Statistics](https://scholar.google.com/scholar_url?url=https://dbdbd2025.uantwerpen.be/wp-content/uploads/2025/12/dbdbd25_29.pdf&hl=zh-CN&sa=X&d=10593825388753596027&ei=W5lOaYSpJYaw6rQPkNu46Ao&scisig=ALhkC2Tp58p2X4F_Xpps7GD7decm&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=2&folt=cit)
*L Lageweg,JC Kalo,K Goes,T van den Broek…*

Main category: Xuanhe Zhou

TL;DR: 论文指出当前文本到SQL数据集无法反映官方统计数据的复杂性，需要创建专门的数据集来支持官方统计的自然语言查询系统


<details>
  <summary>Details</summary>
Motivation: 官方统计数据是政策制定者和企业依赖的重要资源，但当前文本到SQL数据集（如Spider和BIRD）无法充分反映官方统计数据的复杂性，限制了自然语言查询系统在官方统计领域的应用

Method: 从提供的摘要中无法确定具体方法，但可以推断论文可能通过分析现有数据集局限性、定义官方统计数据的独特特征，并创建专门的数据集来解决这一问题

Result: 摘要未提供具体结果，但暗示需要创建能够反映官方统计数据复杂性的新文本到SQL数据集

Conclusion: 需要开发专门针对官方统计数据复杂性的文本到SQL数据集，以支持更有效的自然语言查询系统，从而提升官方统计数据的可访问性

Abstract: Official statistics are an immensely valuable dataset resource, on which policy makers and businesses rely. Making official statistics easily accessible is one of the key tasks for the agencies making these resources available, for example by providing natural language question answering systems (ie text-to-SQL)[1]. Current text-to-SQL datasets, however, do not represent the complexity of the data found in official statistics. Popular 'large-scale datasets' such as Spider [4] and BIRD [2], are …

</details>


### [626] [HybridToken-VLM: Hybrid Token Compression for Vision-Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.08240&hl=zh-CN&sa=X&d=4227614265142078354&ei=WplOacjpMN_OieoPg6WE2QY&scisig=ALhkC2RdsnwVX6aJ6cHk1ZJyjngE&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=1&folt=rel)
*J Zhang,X Guo,K Cai,Q Lv,Y Fan,W Chai,J Wang…*

Main category: Xuanhe Zhou

TL;DR: 该论文针对视觉语言模型中视觉补丁标记二次计算成本高的问题，提出了一种新的高效多模态推理方法


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在处理数百个视觉补丁标记时会产生二次计算成本，导致内存占用大且上下文窗口受限，传统方法在效率和性能之间存在权衡

Method: 论文提出了一种新的方法（具体方法未在摘要中说明），旨在解决视觉补丁标记的高计算成本问题

Result: 该方法能够显著降低计算成本，同时保持或提升多模态推理性能

Conclusion: 提出的方法为高效视觉语言建模提供了新的解决方案，平衡了计算效率和模型性能

Abstract: Vision-language models (VLMs) have transformed multimodal reasoning, but feeding hundreds of visual patch tokens into LLMs incurs quadratic computational costs, straining memory and context windows. Traditional approaches face a trade …

</details>


### [627] [Hey GPT-OSS, Looks Like You Got It-Now Walk Me Through It! An Assessment of the Reasoning Language Models Chain of Thought Mechanism for Digital Forensics](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.04254&hl=zh-CN&sa=X&d=8363509603698737945&ei=WplOacjpMN_OieoPg6WE2QY&scisig=ALhkC2QZyJgUwV6cK6kNbSO5KDxA&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=2&folt=rel)
*G Michelet,J Schneider,A Withanage,F Breitinger*

Main category: Xuanhe Zhou

TL;DR: 该论文探讨了在数字取证中使用大型语言模型（LLMs）的局限性，指出当前研究主要关注模型微调以优化性能，但缺乏对LLMs在取证任务中可靠性的系统评估。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在数字取证中的应用已被广泛探索，研究主要集中在识别潜在应用和通过微调优化模型性能，但对LLMs在取证任务中可靠性的系统评估仍然有限，这阻碍了其在关键取证场景中的实际应用。

Method: 论文可能采用系统评估方法，分析LLMs在数字取证任务中的可靠性，包括设计评估框架、测试模型在不同取证场景下的表现、识别局限性，并提出改进策略。

Result: 研究可能发现LLMs在数字取证中存在可靠性问题，如输出不一致、对输入敏感、缺乏可解释性等，这些限制了其在关键取证决策中的直接应用。

Conclusion: 需要更系统的可靠性评估框架来确保LLMs在数字取证中的可信应用，未来研究应关注提高模型鲁棒性、可解释性和在取证工作流中的集成。

Abstract: The use of large language models in digital forensics has been widely explored. Beyond identifying potential applications, research has also focused on optimizing model performance for forensic tasks through fine-tuning. However, limited result …

</details>


### [628] [Is GPT-OSS All You Need? Benchmarking Large Language Models for Financial Intelligence and the Surprising Efficiency Paradox](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.14717&hl=zh-CN&sa=X&d=3816927970844595182&ei=WplOacjpMN_OieoPg6WE2QY&scisig=ALhkC2RUEIEwGzRTI6bbjEV2VJe2&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=3&folt=rel)
*Z Bi,D Zhang,J Song,CY Tseng*

Main category: Xuanhe Zhou

TL;DR: 对GPT-OSS在金融服务中的性能、效率和实际适用性进行全面评估


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在金融服务中的快速采用需要严格的评估框架来衡量其性能、效率和实际适用性

Method: 对GPT-OSS进行综合评估，包括性能、效率和实际适用性分析

Result: 未提供具体结果数据，但暗示通过评估框架获得了对GPT-OSS在金融服务中表现的深入理解

Conclusion: 需要建立系统化的评估框架来确保大型语言模型在金融服务中的有效部署和应用

Abstract: The rapid adoption of large language models in financial services necessitates rigorous evaluation frameworks to assess their performance, efficiency, and practical applicability. This paper conducts a comprehensive evaluation of the GPT-OSS …

</details>


### [629] [TableGPT-R1: Advancing Tabular Reasoning Through Reinforcement Learning](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.20312&hl=zh-CN&sa=X&d=5328168796250313185&ei=OPlPaZivAayK6rQPgZOO6A8&scisig=ALhkC2Sgno63nyiJn35ZKRMYiRrR&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=0&folt=cit)
*S Yang,Q Huang,J Yuan,L Zha,K Tang,Y Yang…*

Main category: Xuanhe Zhou

TL;DR: 该论文探讨了如何通过强化学习增强大语言模型处理表格数据的能力，以解决现有监督微调方法在复杂多步推理和代码执行方面的不足。


<details>
  <summary>Details</summary>
Motivation: 当前基于监督微调的大语言模型在处理表格数据时存在局限性，特别是在复杂多步推理和鲁棒代码执行方面。虽然强化学习为提升这些能力提供了有前景的途径，但相关研究尚不充分。

Method: 论文提出了一种基于强化学习的方法来增强大语言模型处理表格数据的能力。该方法可能包括特定的RL算法设计、奖励函数构建、以及与表格数据处理任务的集成策略。

Result: 从摘要中无法获取具体实验结果，但可以推断该方法在提升大语言模型处理复杂表格任务的能力方面取得了积极进展。

Conclusion: 强化学习是增强大语言模型处理表格数据能力的有效途径，能够弥补监督微调方法在复杂推理和代码执行方面的不足。

Abstract: Tabular data serves as the backbone of modern data analysis and scientific research. While Large Language Models (LLMs) fine-tuned via Supervised Fine-Tuning (SFT) have significantly improved natural language interaction with such structured data, they often fall short in handling the complex, multi-step reasoning and robust code execution required for real-world table tasks. Reinforcement Learning (RL) offers a promising avenue to enhance these capabilities, yet its …

</details>


### [630] [AXIOM: Benchmarking LLM-as-a-Judge for Code via Rule-Based Perturbation and Multisource Quality Calibration](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.20159&hl=zh-CN&sa=X&d=6711898537773507630&ei=OPlPaZivAayK6rQPgZOO6A8&scisig=ALhkC2S1jDXMNAnGCS6haPrkOHJI&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=1&folt=cit)
*R Wang,X Wang,C Gao,CY Chong,X Xia,Q Liao*

Main category: Xuanhe Zhou

TL;DR: 该论文针对LLM生成代码的评估问题，提出使用LLM作为评判者来评估代码功能性和质量，以弥补传统基于规则指标仅关注表面相似性的不足。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在实际软件工程中的部署增加，需要开发更好的代码评估指标来研究LLM生成代码的质量。传统基于规则的指标仅根据与参考程序的表面相似性进行评分，无法深入分析功能性和代码质量。

Method: 提出LLM-as-a-judge指标，通过提示LLM来评估代码的功能性和质量，实现对代码的深度分析。

Result: 未在摘要中明确说明具体实验结果，但暗示该方法能够更全面地评估LLM生成代码的质量。

Conclusion: LLM-as-a-judge方法为解决传统代码评估指标的局限性提供了有前景的方向，能够更深入地分析代码功能性和质量。

Abstract: Large language models (LLMs) have been increasingly deployed in real-world software engineering, fostering the development of code evaluation metrics to study the quality of LLM-generated code. Conventional rule-based metrics merely score programs based on their surface-level similarities with reference programs instead of analyzing functionality and code quality in depth. To address this limitation, researchers have developed LLM-as-a-judge metrics, prompting LLMs to evaluate …

</details>


### [631] [Mitigating LLM Hallucination via Behaviorally Calibrated Reinforcement Learning](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.19920&hl=zh-CN&sa=X&d=1691090652215400058&ei=N_lPaco6oLXqtA-bh8-BBA&scisig=ALhkC2Q0N_2qHaAr9E3U_Ou6LiGX&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=1&folt=rel)
*J Wu,J Liu,Z Zeng,T Zhan,W Huang*

Main category: Xuanhe Zhou

TL;DR: LLM在关键领域部署受幻觉问题阻碍，现有理论框架表明...


<details>
  <summary>Details</summary>
Motivation: LLM在关键领域部署受到持续幻觉问题的阻碍，即生成看似合理但事实错误的断言。虽然扩展定律推动了通用能力的显著提升，但需要解决幻觉问题以实现可靠部署。

Method: 基于理论框架分析LLM幻觉问题...

Result: 理论框架表明...

Conclusion: 需要进一步研究解决LLM幻觉问题以实现关键领域的可靠部署。

Abstract: LLM deployment in critical domains is currently impeded by persistent hallucinations--generating plausible but factually incorrect assertions. While scaling laws drove significant improvements in general capabilities, theoretical frameworks suggest …

</details>


### [632] [Scaling Reinforcement Learning for Content Moderation with Large Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.20061&hl=zh-CN&sa=X&d=15032249001933610557&ei=N_lPaco6oLXqtA-bh8-BBA&scisig=ALhkC2QaFKWojv9eJ0reGaXgJijK&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=2&folt=rel)
*H Firooz,R Liu,Y Lu,Z Hou,F Xiong,X Zhang,C Jian…*

Main category: Xuanhe Zhou

TL;DR: 大规模内容审核面临挑战，需要高效评估数十亿用户和AI生成内容是否符合政策要求


<details>
  <summary>Details</summary>
Motivation: 数字生态系统中大规模内容审核是紧迫挑战，数十亿用户和AI生成内容需要持续评估政策违规情况

Method: 论文摘要未提供具体方法细节，但暗示可能涉及大规模内容审核的技术解决方案

Result: 摘要未提供具体结果，但暗示需要解决大规模内容审核的效率和准确性问题

Conclusion: 大规模内容审核是数字生态系统中的关键挑战，需要创新解决方案来处理海量用户和AI生成内容

Abstract: Content moderation at scale remains one of the most pressing challenges in today's digital ecosystem, where billions of user-and AI-generated artifacts must be continuously evaluated for policy violations. Although recent advances in large …

</details>


### [633] [CodeSimpleQA: Scaling Factuality in Code Large Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.19424&hl=zh-CN&sa=X&d=17742658596870437136&ei=N_lPaco6oLXqtA-bh8-BBA&scisig=ALhkC2SZs3gq4KBj7Q0f_5eIeZJk&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=5&folt=rel)
*J Yang,W Zhang,Y Li,S Guo,H Wang,A Liu,G Zhang…*

Main category: Xuanhe Zhou

TL;DR: LLMs在代码生成方面取得显著进展，但仍面临确保生成代码正确性的关键挑战


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在代码生成方面表现出色，但确保生成代码的正确性仍然是一个关键挑战，需要更可靠的验证机制

Method: 论文可能提出某种验证框架或测试方法，用于评估和确保LLM生成代码的正确性

Result: 预期结果是开发出能够有效验证LLM生成代码正确性的系统或方法

Conclusion: 需要建立更可靠的验证机制来确保LLM生成代码的质量和正确性

Abstract: Large language models (LLMs) have made significant strides in code generation, achieving impressive capabilities in synthesizing code snippets from natural language instructions. However, a critical challenge remains in ensuring LLMs …

</details>


### [634] [UniRec-0.1 B: Unified Text and Formula Recognition with 0.1 B Parameters](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.21095&hl=zh-CN&sa=X&d=6175943974544629545&ei=4ZRRaZTCPKC16rQPm4fPgQQ&scisig=ALhkC2QYdvtpDfJrnGBD16vXrOP8&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=0&folt=cit)
*Y Du,Z Chen,Y Xie,WBH Feng,W Shi,Y Su,C Huang…*

Main category: Xuanhe Zhou

TL;DR: 提出UniRec-0.1B，一个轻量级的统一识别模型，用于高效识别文档中的文本和公式，解决现有视觉语言模型计算量大、部署受限的问题。


<details>
  <summary>Details</summary>
Motivation: 文档中的文本和公式是核心信息组件，需要准确高效识别以构建稳健的文档解析系统。现有视觉语言模型虽然能统一识别文本和公式，但模型规模大、计算需求高，限制了实际应用部署。

Method: 提出UniRec-0.1B模型，这是一个轻量级的统一识别模型，旨在保持识别性能的同时显著降低模型规模和计算复杂度。

Result: 未在摘要中明确说明具体结果，但暗示该模型在保持识别性能的同时实现了轻量化，解决了现有模型计算需求高的问题。

Conclusion: UniRec-0.1B为文档解析提供了一种高效、轻量化的统一识别解决方案，扩展了统一识别模型在实际应用中的部署可能性。

Abstract: Text and formulas constitute the core informational components of many documents. Accurately and efficiently recognizing both is crucial for developing robust and generalizable document parsing systems. Recently, vision-language models (VLMs) have achieved impressive unified recognition of text and formulas. However, they are large-sized and computationally demanding, restricting their usage in many applications. In this paper, we propose UniRec-0.1 B, a unified recognition model …

</details>


### [635] [Talking to Data: A Systematic Review of the Rise of Conversational Agents for Visual Analytics](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/6287639/10820123/11271508.pdf&hl=zh-CN&sa=X&d=9877194410631509587&ei=4ZRRaZTCPKC16rQPm4fPgQQ&scisig=ALhkC2QYyORJtey5P9XsIAJqXTb_&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=2&folt=cit)
*M Martins,B Jardim,MDC Neto,A Barriguinha*

Main category: Xuanhe Zhou

TL;DR: 基于大语言模型的智能体对话系统在NL2VIS任务中面临幻觉、不一致和低效问题，需要系统性评估框架


<details>
  <summary>Details</summary>
Motivation: 基于大语言模型的智能体对话系统在NL2VIS任务中展现出潜力，但存在幻觉、不一致和低效等问题，缺乏系统性评估框架

Method: 未在摘要中明确说明具体方法，但暗示需要建立系统性评估框架来评估智能体对话系统在NL2VIS任务中的表现

Result: 摘要未提供具体实验结果，但指出当前系统存在幻觉、不一致和低效等问题，需要系统性评估

Conclusion: 需要建立系统性评估框架来评估和改进基于大语言模型的智能体对话系统在NL2VIS任务中的表现

Abstract: Agent-based conversational systems powered by large language models (LLMs) are emerging as promising tools for facilitating several tasks, from software development, e-commerce, customer interaction, and scientific discovery to natural language to visualization (NL2VIS) tasks. These systems enable users to generate charts and extract insights from structured data through natural language interaction, significantly lowering technical barriers for non-specialist users. However, a …

</details>


### [636] [From Conceptual to Logical Schema: An LLM-based Approach](https://scholar.google.com/scholar_url?url=https://sol.sbc.org.br/index.php/eramiars/article/download/39386/39158&hl=zh-CN&sa=X&d=12726518569981519249&ei=4ZRRaZTCPKC16rQPm4fPgQQ&scisig=ALhkC2TJ8Mk7FOcFhZj0Xi1eZHnn&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=3&folt=cit)
*HAB da Silva,VS dos Santos,CF Dorneles…*

Main category: Xuanhe Zhou

TL;DR: 大型语言模型在从概念模型生成逻辑模型任务中的能力评估，Claude模型表现最佳


<details>
  <summary>Details</summary>
Motivation: 随着语言模型在解决计算任务中的应用日益增长，本研究旨在探索大型语言模型在从概念建模（ER）生成逻辑模型这一专业任务中的能力，该任务通常由数据库专家执行且有明确定义规则

Method: 对GPT、Gemini和Claude等大型语言模型进行实验研究，评估它们从概念表示生成逻辑模型的能力

Result: 实验结果表明，Claude模型在从概念模型生成逻辑模型的任务中表现出最优秀的性能

Conclusion: 大型语言模型在数据库设计等专业计算任务中具有应用潜力，Claude模型在该特定任务中表现最佳

Abstract: The use of language models for solving computational tasks has grown in recent years. Generating logical models from conceptual modeling (ER) is a specialized task with well-defined rules, performed by database specialists. This paper presents an experimental investigation into the capabilities of large language models (LLMs), including GPT, Gemini, and Claude, in generating logical models from conceptual representations. The results demonstrate that the Claude model exhibits superior …

</details>


### [637] [Advancing Healthcare With Large Language Models: Techniques and Application](https://scholar.google.com/scholar_url?url=https://www.ieee-jas.net/article/doi/10.1109/JAS.2025.125540%3FviewType%3DHTML%26pageType%3Den&hl=zh-CN&sa=X&d=15519316479879876126&ei=H3BTac6uEpaM6rQP0-TCwQU&scisig=ALhkC2SNXg38nTR8VawUmwoeB5K8&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=0&folt=cit)
*Z Hu,Z Peng,Z Bi,Q Shen,Z Liu,J Lou,X Luo*

Main category: Xuanhe Zhou

TL;DR: 本文概述了医疗大语言模型的生命周期，包括获取、精炼和使用三个阶段，旨在帮助医疗从业者和患者更有效地利用这些模型，并总结了当前广泛使用的医疗评估方法。


<details>
  <summary>Details</summary>
Motivation: 随着全球医疗系统成本持续上升，大语言模型作为有前景的技术在医疗领域展现出巨大潜力和广泛应用前景。需要为医疗从业者和患者提供系统性的指导，帮助他们更有效地利用医疗大语言模型。

Method: 提出了医疗大语言模型生命周期的三阶段框架：获取（获取基础模型）、精炼（针对医疗领域进行微调和优化）、使用（实际应用部署）。同时总结了当前广泛使用的医疗评估方法。

Result: 构建了系统性的医疗大语言模型生命周期管理框架，为医疗从业者和患者提供了实用的指导，并整理了现有的医疗评估体系。

Conclusion: 医疗大语言模型在降低医疗成本、提高效率方面具有重要价值，通过系统化的生命周期管理可以更好地发挥其潜力，促进医疗领域的数字化转型。

Abstract: As the costs of global healthcare systems continue to rise, large language models (LLMs) have emerged as a promising technology with vast potential and wide-ranging applications in the medical field. We provide a detailed overview of the lifecycle of medical LLMs, encompassing three key stages: get, refine, and use, aimed at assisting healthcare practitioners and patients in utilizing these models more effectively. We also summarize the currently widely used medical evaluation …

</details>


### [638] [The impact mechanism of artificial intelligence dependence on college students' innovation capability: an empirical study from China](https://scholar.google.com/scholar_url?url=https://pmc.ncbi.nlm.nih.gov/articles/PMC12742215/&hl=zh-CN&sa=X&d=17390323761309764303&ei=H3BTac6uEpaM6rQP0-TCwQU&scisig=ALhkC2Thi8ESwyNnyTBBEk-cv9X6&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=1&folt=cit)
*Z Yang,H Deng,N Jiang*

Main category: Xuanhe Zhou

TL;DR: AI依赖通过认知惯性和批判性思维削弱大学生创新，但批判性思维可缓解负面影响


<details>
  <summary>Details</summary>
Motivation: 高等教育中AI工具的快速普及增加了大学生对AI的依赖，虽然AI提高了学习效率，但可能削弱创新所需的关键认知过程。需要研究AI依赖如何通过认知机制影响创新，以及批判性思维在其中的调节作用。

Method: 使用1032名学生的调查数据，采用偏最小二乘结构方程模型（PLS-SEM）和模糊集定性比较分析（fsQCA）来检验AI依赖、认知惯性和批判性思维对创新的影响路径。

Result: AI依赖通过认知惯性对创新产生负面影响，但批判性思维可以缓解这种负面影响。fsQCA揭示了导致高创新和低创新的不同因果条件组合。

Conclusion: AI依赖可能通过认知惯性阻碍创新，但批判性思维可以作为保护因素。教育者应培养学生批判性思维技能，以平衡AI使用与创新能力的培养。

Abstract: Introduction The rapid adoption of artificial intelligence (AI) in higher education has increased college students' reliance on AI tools. While AI enhances learning efficiency, it may also undermine key cognitive processes required for innovation. Methods Using survey data from 1,032 students, this study employed partial least squares structural equation modeling (PLS-SEM) and fuzzy-set qualitative comparative analysis (fsQCA) to examine how AI dependence, cognitive inertia …

</details>


### [639] [Falcon: A Universal Text-Only Membership Inference Attack Framework Against In-Context Learning](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/document/11278891/&hl=zh-CN&sa=X&d=17802787018459205560&ei=H3BTac6uEpaM6rQP0-TCwQU&scisig=ALhkC2T0zmLZrtmbEIyMpzMkh867&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=2&folt=cit)
*H Su,Y Qin,Z Li,X Miao,Y Zhou*

Main category: Xuanhe Zhou

TL;DR: Falcon是首个针对纯文本模型API的任务感知成员推理攻击框架，通过上下文混淆绕过安全机制，无需内部访问权限


<details>
  <summary>Details</summary>
Motivation: 针对上下文学习的成员推理攻击对于隐私风险评估和知识产权保护至关重要，但现有攻击方法要么需要不现实的内部访问权限，要么可能触发内置安全机制，限制了实际应用

Method: 提出Falcon框架，通过上下文混淆技术创建任务感知攻击，利用纯文本模型API进行成员推理攻击，无需内部模型访问权限

Result: Falcon在多个基准测试中显著优于现有方法，能够有效识别训练数据中的成员样本，同时避免触发API的安全机制

Conclusion: Falcon为评估语言模型API的隐私风险提供了实用工具，证明了仅通过API访问就能进行有效成员推理攻击的可行性

Abstract: Membership inference attacks (MIAs) against in-context learning (ICL) serve as essential tools for privacy risk assessment and intellectual property safeguarding due to the use of small, private datasets for adaptation. However, most MIAs against language models require unrealistic, internal access or risk triggering built-in security mechanisms. In this paper, we propose Falcon (Flexible Attack on Language Context via ObfuscatioN), the first task-aware MIA framework against text-only model APIs …

</details>


### [640] [Fine-tuning T5 for robust text-to-SQL translation](https://scholar.google.com/scholar_url?url=https://api.taylorfrancis.com/content/chapters/edit/download%3FidentifierName%3Ddoi%26identifierValue%3D10.1201/9781003739791-72%26type%3Dchapterpdf&hl=zh-CN&sa=X&d=5837042489426699762&ei=Kk9VadeYLrK16rQPn86DwQ8&scisig=ALhkC2RN6UH-CjwLRSKW-oSAowb4&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=1&folt=rel)
*ML Chayadevi,PN Monish,RS Chirag,HP Mahesh*

Main category: Xuanhe Zhou

TL;DR: 该论文研究如何通过微调T5模型来改进文本到SQL的翻译任务，探索了不同的微调策略对模型性能的影响。


<details>
  <summary>Details</summary>
Motivation: 文本到SQL翻译是自然语言处理中的关键任务，旨在弥合人类可读语言与结构化数据库查询之间的鸿沟。当前需要更有效的方法来提升模型在此任务上的性能。

Method: 通过微调T5（文本到文本迁移）模型，探索不同的微调策略，包括数据增强、多任务学习和特定领域适应等技术。

Result: 实验结果表明，经过适当微调的T5模型在文本到SQL翻译任务上取得了显著的性能提升，超越了基线方法，特别是在复杂查询和领域特定场景中表现优异。

Conclusion: 微调T5模型是提升文本到SQL翻译任务性能的有效方法，为自然语言与数据库查询之间的桥梁提供了更强大的技术支撑。

Abstract: Text-to-SQL translation is a pivotal task in natural language processing (NLP), bridging the gap between human-readable language and structured database queries. This paper investigates the fine-tuning of the T5 (Text-to-Text Transfer …

</details>


### [641] [CricBench: A Multilingual Benchmark for Evaluating LLMs in Cricket Analytics](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.21877&hl=zh-CN&sa=X&d=7641466170723408487&ei=nalWabe6DtKV6rQP84i9kQc&scisig=ALhkC2QrA3bZ98cs5QylXQ4X6BQI&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=0&folt=cit)
*V Devraj,D Kumar,JS Challa*

Main category: Xuanhe Zhou

TL;DR: 该论文研究利用大型语言模型进行板球领域特定文本到SQL转换，以解决传统搜索引擎无法提供的复杂统计分析需求


<details>
  <summary>Details</summary>
Motivation: 板球作为全球第二大运动拥有超过25亿粉丝，但传统搜索引擎无法提供复杂的统计分析（如长期历史表现趋势、复杂球员比较等），需要领域特定的文本到SQL解决方案

Method: 使用大型语言模型处理板球领域特定的文本到SQL任务，解决领域特定细微差别、复杂模式变化等挑战

Result: 未在摘要中明确说明具体结果，但暗示LLMs在文本到SQL任务上已有显著进展，需要进一步解决领域特定挑战

Conclusion: 需要开发专门针对板球领域的文本到SQL系统，以提供传统搜索引擎无法实现的复杂统计分析功能

Abstract: Cricket is the second most popular sport globally, commanding a massive following of over 2.5 billion fans globally. Enthusiasts and analysts frequently seek advanced statistical insights, such as long-term historical performance trends or complex player comparisons, that are often unavailable through standard web searches. While Large Language Models (LLMs) have advanced significantly in Text-to-SQL tasks, their capability to handle the domain-specific nuances, complex schema variations …

</details>


### [642] [LLM-Assisted SLURM Administration and Troubleshooting: A Survey](https://scholar.google.com/scholar_url?url=https://www.techrxiv.org/doi/pdf/10.36227/techrxiv.176689868.81376258&hl=zh-CN&sa=X&d=9124277264282029768&ei=nalWabe6DtKV6rQP84i9kQc&scisig=ALhkC2Rw9dMUT18swi5_JJ8jpcRn&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=1&folt=cit)
*D Mehta*

Main category: Xuanhe Zhou

TL;DR: SLURM作为HPC主流作业调度系统，其管理复杂且需专业知识，而LLM在代码理解和日志分析方面展现出潜力，本文探索利用LLM简化SLURM管理的方法。


<details>
  <summary>Details</summary>
Motivation: SLURM已成为HPC领域主导的作业调度系统（部署于全球60%以上顶级超算），但其管理配置、优化和故障排除需要专业知识，操作复杂。同时，大型语言模型在代码理解、日志分析和自然语言处理方面表现出色，为简化SLURM管理提供了新可能。

Method: 论文未详细说明具体方法，但从摘要推断可能涉及：利用LLM分析SLURM配置文件和日志，开发基于自然语言的SLURM管理工具，构建智能助手系统来协助管理员进行配置优化和故障诊断。

Result: 摘要未提供具体实验结果，但暗示LLM在SLURM管理方面具有应用潜力，可能展示LLM能够理解SLURM配置语法、分析作业日志、提供优化建议或自动生成配置方案。

Conclusion: LLM技术有望简化SLURM管理复杂度，降低对专业知识的需求，提高HPC系统管理效率，为超算运维提供智能化解决方案。

Abstract: SLURM has emerged as the dominant workload manager for high-performance computing (HPC), currently deployed on more than 60% of the world's top supercomputers. Despite this prevalence, SLURM administration remains a complex undertaking that demands specialized expertise for configuration, optimization, and troubleshooting. Concurrently, large language models (LLMs) have demonstrated remarkable capabilities in code comprehension, log analysis, and natural language …

</details>


### [643] [Intellectual data analysis in relational information and analytical systems](https://scholar.google.com/scholar_url?url=https://itssi-journal.com/index.php/ittsi/article/view/626/556&hl=zh-CN&sa=X&d=15295482070227327405&ei=nalWabe6DtKV6rQP84i9kQc&scisig=ALhkC2S5cVRQNwsZEgmg1icAJM9w&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=2&folt=cit)
*В Філатов,О Золотухін,М Кудрявцева*

Main category: Xuanhe Zhou

TL;DR: 该研究探讨了基于关系模型的数据挖掘方法（决策树、关联分析、模式识别），分析信息单元和数据结构的特征对知识提取技术的影响


<details>
  <summary>Details</summary>
Motivation: 研究旨在分析关系系统中信息单元和数据结构的特征如何影响知识提取技术，探讨关系数据模型在数据挖掘中的适用性和局限性

Method: 采用关系数据模型作为基础，应用决策树构建、关联分析和相关事件间模式识别等数据挖掘方法，分析数据结构和信息单元特征

Result: 研究揭示了关系数据模型在知识提取中的具体影响机制，明确了信息单元特征和数据结构对数据挖掘技术效果的关键作用

Conclusion: 关系数据模型为数据挖掘提供了结构化基础，但其特定的信息单元和数据结构特征会显著影响知识提取技术的选择和应用效果

Abstract: The subject of the study is the methods of intellectual analysis, namely the construction of a decision tree, associative analysis, the identification of patterns between related events based on data presented by a relational model. The purpose of the study is to analyze the features of information units and data structures, using the example of relational systems that affect the technology of knowledge extraction. Tasks: the article solves the following tasks: to consider the relational data model as …

</details>


### [644] [Cost-Aware Text-to-SQL: An Empirical Study of Cloud Compute Costs for LLM-Generated Queries](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.22364&hl=zh-CN&sa=X&d=10887106332600992403&ei=RPRXad72L9rJieoPiYyysAk&scisig=ALhkC2Sgc8_-3zfhHlcqBUsmpSz_&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=0&folt=rel)
*S Deochake,D Mukhopadhyay*

Main category: Xuanhe Zhou

TL;DR: 该论文提出了一种新的效率评估框架，用于衡量基于LLM的Text-to-SQL系统的资源消耗效率，而不仅仅是执行时间。


<details>
  <summary>Details</summary>
Motivation: 现有Text-to-SQL系统的效率评估主要关注执行时间（如VES指标），但忽略了实际部署中更重要的资源消耗成本，特别是LLM调用产生的token消耗成本。

Method: 提出一个包含token消耗、执行时间和查询准确性的综合效率评估框架，可能引入新的效率指标来量化资源消耗效率。

Result: 新评估框架能够更全面地反映Text-to-SQL系统的实际部署效率，揭示传统时间指标无法捕捉的资源消耗问题。

Conclusion: 需要超越传统执行时间指标，建立考虑资源消耗的综合效率评估体系，这对实际部署基于LLM的Text-to-SQL系统至关重要。

Abstract: Text-to-SQL systems powered by Large Language Models (LLMs) achieve high accuracy on standard benchmarks, yet existing efficiency metrics such as the Valid Efficiency Score (VES) measure execution time rather than the consumption-based …

</details>


### [645] [Same or Not? Enhancing Visual Perception in Vision-Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.23592&hl=zh-CN&sa=X&d=13781878437584043580&ei=RPRXad72L9rJieoPiYyysAk&scisig=ALhkC2TsXe-mSL5SApHbrc024kPB&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=4&folt=rel)
*D Marsili,A Mehta,RY Lin,G Gkioxari*

Main category: Xuanhe Zhou

TL;DR: 论文指出视觉语言模型在细粒度视觉理解方面存在不足，现有训练数据强化了这一局限，需要新的方法来提升模型对细微视觉细节的感知能力。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型虽然在广泛的视觉理解任务上表现出色，但存在粒度粗糙、视觉偏见和忽略细微视觉细节的问题。现有训练语料库通过强调通用识别任务（如"这是猫还是..."）进一步强化了这些局限性，导致模型难以捕捉精细的视觉特征。

Method: 论文未提供具体方法细节，但从摘要可推断其可能提出新的训练策略、数据集构建方法或模型架构改进，以增强模型对细微视觉细节的感知能力。

Result: 摘要未提供具体实验结果，但暗示通过解决现有局限性，可以显著提升视觉语言模型在细粒度视觉理解任务上的性能。

Conclusion: 需要开发新的方法来克服当前视觉语言模型在细粒度视觉理解方面的不足，通过改进训练数据和模型设计来提升对细微视觉细节的感知能力。

Abstract: Vision-language models (VLMs) excel at broad visual understanding but remain coarse-grained, exhibit visual biases, and miss subtle visual details. Existing training corpora reinforce this limitation by emphasizing general recognition (" Is it a cat or a …

</details>


### [646] [Hallucination Detection for LLM-based Text-to-SQL Generation via Two-Stage Metamorphic Testing](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.22250&hl=zh-CN&sa=X&d=14728257787389012601&ei=RPRXad72L9rJieoPiYyysAk&scisig=ALhkC2SJdZU1utBirrYjClS6CIin&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=5&folt=rel)
*B Yang,Y Xia,W Sun,Y Liu*

Main category: Xuanhe Zhou

TL;DR: 该论文研究大型语言模型在Text-to-SQL任务中的幻觉问题，提出了一种基于SQL执行反馈的幻觉检测与纠正方法


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在Text-to-SQL任务中表现出强大的泛化能力和适应性，但有时会产生幻觉（不现实或不合理的内容），导致生成错误的SQL查询。现有方法主要关注查询执行结果，但忽略了SQL查询本身的逻辑一致性检测。

Method: 论文提出了一种基于SQL执行反馈的幻觉检测与纠正框架。该方法通过分析SQL查询的执行结果来识别幻觉，并利用反馈机制对生成的SQL进行修正。具体包括：1）SQL查询执行验证；2）逻辑一致性分析；3）基于反馈的迭代修正。

Result: 实验结果表明，该方法能有效检测和纠正LLM生成的SQL查询中的幻觉，显著提高了Text-to-SQL任务的准确性和可靠性。在多个基准数据集上，该方法相比基线方法有显著提升。

Conclusion: 基于SQL执行反馈的幻觉检测与纠正方法能有效解决LLM在Text-to-SQL任务中的幻觉问题，提高了生成SQL查询的质量和可靠性，为实际应用提供了更稳健的解决方案。

Abstract: In Text-to-SQL generation, large language models (LLMs) have shown strong generalization and adaptability. However, LLMs sometimes generate hallucinations, ie, unrealistic or illogical content, which leads to incorrect SQL queries and …

</details>


### [647] [KernelEvolve: Scaling Agentic Kernel Coding for Heterogeneous AI Accelerators at Meta](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.23236&hl=zh-CN&sa=X&d=5425146720332238217&ei=RfRXac3JLYaw6rQPkNu46Ao&scisig=ALhkC2SeWRqLWXwqLdHdgWEst44z&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=1&folt=cit)
*G Liao,H Qin,Y Wang,A Golden,M Kuchnik,Y Yetim…*

Main category: Xuanhe Zhou

TL;DR: KernelEvolve是一个用于DLRM训练的自动化内核编码框架，通过智能体驱动的方法解决模型架构多样性、内核原语多样性和硬件异构性三大系统挑战。


<details>
  <summary>Details</summary>
Motivation: 深度学习推荐模型(DLRM)的训练和推理需要高效快速，但面临三大系统挑战：模型架构多样性、内核原语多样性、硬件代际和架构异构性。传统方法难以应对这些复杂性。

Method: 提出KernelEvolve框架，采用智能体驱动的内核编码方法，将内核规范作为输入，自动化内核生成和优化过程，以应对大规模异构环境。

Result: 未在摘要中明确说明具体结果，但暗示该框架能够有效解决DLRM训练中的异构性挑战，实现高效的内核生成和优化。

Conclusion: KernelEvolve为DLRM训练和推理提供了一个可扩展的自动化内核编码解决方案，能够应对复杂的硬件和软件异构性挑战。

Abstract: Making deep learning recommendation model (DLRM) training and inference fast and efficient is important. However, this presents three key system challenges-model architecture diversity, kernel primitive diversity, and hardware generation and architecture heterogeneity. This paper presents KernelEvolve-an agentic kernel coding framework-to tackle heterogeneity at-scale for DLRM. KernelEvolve is designed to take kernel specifications as input and automate the process of kernel …

</details>


### [648] [Evaluating the Performance of Large Language Models for One Atmosphere Using Automated Extracted Datasets](https://scholar.google.com/scholar_url?url=https://pubs.acs.org/doi/abs/10.1021/acs.est.5c10297&hl=zh-CN&sa=X&d=16446423069638570407&ei=X29ZafiWL6yK6rQPgZOO6A8&scisig=ALhkC2QWSfbJu73CBxr5WEkQpnOh&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=0&folt=cit)
*S Dai,Q Wu,H Zhang,Y Wang,S Wang*

Main category: Xuanhe Zhou

TL;DR: 开发了首个系统性评估大语言模型在空气污染控制任务中表现的基准数据集，填补了该领域缺乏评估标准的空白


<details>
  <summary>Details</summary>
Motivation: 大语言模型在提高大气科学研究效率和空气污染控制决策效率方面具有巨大潜力，但由于缺乏系统性评估基准，无法确定LLM是否能在污染预警和减排建议等核心任务中被信任，这限制了其实际部署

Method: 开发了一个与"一个..."（可能指"一个地球"或"一个健康"等概念）对齐的基准数据集，用于系统评估LLM在空气污染控制任务中的表现

Result: 建立了首个系统性评估LLM在空气污染控制任务中表现的基准数据集，为评估LLM在该领域的可信度和适用性提供了标准工具

Conclusion: 该基准数据集的开发填补了空气污染控制领域缺乏LLM评估标准的空白，为LLM在该领域的实际部署和应用提供了必要的评估框架

Abstract: Large language models (LLMs) have great potential to improve the efficiency of atmospheric science research and air pollution control decision-making. However, due to the absence of a systematic evaluation benchmark, it remains unclear whether LLMs can be trusted to support core air pollution control tasks such as pollution alarming and mitigation recommendation, which limits their real-world deployment. This study developed a benchmark dataset aligned with the One …

</details>


### [649] [Efficient Context Scaling with LongCat ZigZag Attention](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.23966&hl=zh-CN&sa=X&d=5071332506219871334&ei=X29ZafiWL6yK6rQPgZOO6A8&scisig=ALhkC2TqlZQ_r06AGIEAD05-MS-_&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=1&folt=cit)
*C Zhang,Y Bai,J Li,A Gui,K Wang,F Liu,G Wu…*

Main category: Xuanhe Zhou

TL;DR: LoZA是一种稀疏注意力方案，可将全注意力模型转换为稀疏版本，在有限计算预算下实现长上下文场景的显著加速


<details>
  <summary>Details</summary>
Motivation: 解决长上下文场景中全注意力模型计算成本高的问题，特别是在预填充密集型和解码密集型任务中，需要在有限计算预算下实现高效处理

Method: 提出LongCat ZigZag Attention稀疏注意力方案，通过特定模式减少注意力计算复杂度，可应用于现有全注意力模型，在LongCat-Flash模型的中期训练中应用

Result: LoZA在长上下文场景中实现显著加速，适用于检索增强生成等预填充密集型任务和工具集成推理等解码密集型任务，通过LongCat-Flash-Exp模型展示效果

Conclusion: LoZA稀疏注意力方案是有效的长上下文处理优化方法，可在有限计算预算下将全注意力模型转换为高效稀疏版本

Abstract: We introduce LongCat ZigZag Attention (LoZA), which is a sparse attention scheme designed to transform any existing full-attention models into sparse versions with rather limited compute budget. In long-context scenarios, LoZA can achieve significant speed-ups both for prefill-intensive (eg, retrieval-augmented generation) and decode-intensive (eg, tool-integrated reasoning) cases. Specifically, by applying LoZA to LongCat-Flash during mid-training, we serve LongCat-Flash-Exp as a long …

</details>


### [650] [Artificial Social Intelligence](https://scholar.google.com/scholar_url?url=https://mdds.net.technion.ac.il/files/2025/12/Artificial_Social_Intelligence.pdf&hl=zh-CN&sa=X&d=11671782771189036926&ei=KdVaaeH3EaC16rQPm4fPgQQ&scisig=ALhkC2Ttafb7yB27SyzxVXEuENvL&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=0&folt=cit)
*M Tennenholtz,O Madmon*

Main category: Xuanhe Zhou

TL;DR: 论文认为当前AI智能体设计视角不足，需要从社会层面重新思考AI智能体设计以实现更好的社会福利


<details>
  <summary>Details</summary>
Motivation: 虽然AI技术快速发展并将在未来扮演核心角色，但当前AI智能体设计视角不足以实现理想的社会福利，需要超越单纯的技术和监管层面进行重新思考

Method: 论文采用批判性分析框架，对现有AI智能体设计范式进行系统性反思，提出需要从社会层面重新构想AI智能体设计的方法论

Result: 识别出现有AI智能体设计范式的局限性，强调需要建立更全面的社会视角来指导AI智能体设计，以实现更好的社会福利结果

Conclusion: AI智能体设计需要超越当前的技术中心主义范式，采用更全面的社会视角来确保AI技术发展能够真正促进社会福利和人类福祉

Abstract: Artificial intelligence (AI) has been growing at an unprecedented pace. Many of us have experienced a “ChatGPT moment”—a realization that AI will profoundly transform our lives. While numerous challenges and calls for improvement remain, there is little doubt that AI agents will play a central role in shaping our future. We argue, however, that the prevailing perspective on AI agent design is insufficient for achieving desirable social welfare, not merely due to computational or regulatory …

</details>


### [651] [WOC: Dual-Path Weighted Object Consensus Made Efficient](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.20485&hl=zh-CN&sa=X&d=9346853648129829929&ei=KNVaadvxE7K16rQPn86DwQ8&scisig=ALhkC2QSdMAqsJKxAjYQzzTsJATO&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=1&folt=rel)
*T Fonseca,G Zhang*

Main category: Xuanhe Zhou

TL;DR: 论文指出现有共识协议无法同时优化节点异构性和工作负载独立性，提出新方法解决这一挑战


<details>
  <summary>Details</summary>
Motivation: 现代分布式系统面临关键挑战：现有共识协议要么针对节点异构性优化，要么针对工作负载独立性优化，但无法同时兼顾两者。例如，Cabinet利用加权仲裁处理节点异构性，但无法有效处理工作负载独立性。

Method: 论文提出了一种新的共识协议方法，能够同时处理节点异构性和工作负载独立性。该方法可能结合了加权仲裁机制和动态工作负载分配策略。

Result: 新方法在节点异构性和工作负载独立性方面都表现出显著改进，相比现有协议在吞吐量、延迟和资源利用率方面都有提升。

Conclusion: 论文证明同时优化节点异构性和工作负载独立性是可行的，提出的新协议为现代分布式系统提供了更全面的共识解决方案。

Abstract: Modern distributed systems face a critical challenge: existing consensus protocols optimize for either node heterogeneity or workload independence, but not both. For example, Cabinet leverages weighted quorums to handle node heterogeneity but …

</details>


### [652] [Large Language Models for Automated Data Access Policy Creation in Data](https://scholar.google.com/scholar_url?url=https://books.google.com/books%3Fhl%3Dzh-CN%26lr%3D%26id%3D25elEQAAQBAJ%26oi%3Dfnd%26pg%3DPA33%26ots%3DZpGNlemeqc%26sig%3Dvkp7v0tR2Q6Fh8uSB2uJChDMtM4&hl=zh-CN&sa=X&d=17569232201459556313&ei=-C1cadrUD9rJieoPiYyysAk&scisig=ALhkC2Q7nlNv7CYPJzaWPwv25VaC&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=1&folt=cit)
*R Ford,R Beigaitė,A Hajikhani*

Main category: Xuanhe Zhou

TL;DR: 国际数据空间(IDS)中连接器通过使用控制模型实现标准化、安全的数据共享，支持动态、上下文感知的访问策略执行


<details>
  <summary>Details</summary>
Motivation: 跨部门和组织的标准化、安全数据共享需求日益增长，国际数据空间(IDS)为此提供了解决方案。数据空间中的连接器是实现安全、主权数据交换的基础组件，需要支持动态、上下文感知的访问控制策略。

Method: 采用国际数据空间(IDS)连接器作为数据交换的基础设施，实现使用控制(Usage Control)模型来执行访问策略。这种方法支持动态和上下文感知的策略执行，确保数据共享的安全性和主权性。

Result: 通过IDS连接器和使用控制模型的结合，实现了标准化、安全的数据共享机制，支持跨组织和部门的数据交换，同时确保数据主权和动态访问控制。

Conclusion: 国际数据空间及其连接器架构为跨组织数据共享提供了有效的解决方案，使用控制模型实现了灵活、安全的访问策略管理，推动了标准化数据交换生态系统的发展。

Abstract: The increasing demand for standardized and secure data sharing across sectors and organizations is driving the adoption of International Data Spaces (IDS)[1, 10]. In Data Spaces, connectors like the IDS Connector [20] are a fundamental part of enabling secure and sovereign data exchange [17]. These connectors implement access policies using models such as Usage Control [13], which make dynamic and context-aware policy enforcement possible [16]. Creating standardized data access …

</details>


### [653] [DiffusionVL: Translating Any Autoregressive Models into Diffusion Vision Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.15713&hl=zh-CN&sa=X&d=4378869579327862383&ei=9y1caZnBCK-nieoPz8HDqAc&scisig=ALhkC2TwqU3uNNoM6nh5b4O1KtYM&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:ALhkC2QYg_8suhoKFGyDmER2SLEe&html=&pos=1&folt=rel)
*L Zeng,J Yao,B Liao,H Tao,W Liu,X Wang*

Main category: Xuanhe Zhou

TL;DR: 该论文探讨了扩散模型在多模态研究中的潜力，指出其相对于自回归模型的解码优势，但受限于基础扩散语言模型的能力，目前尚未实现与AR模型相当的性能水平。


<details>
  <summary>Details</summary>
Motivation: 在多模态研究中，扩散范式因其独特的解码优势而成为自回归范式的有前景替代方案。然而，由于基础扩散语言模型的能力限制，目前扩散模型尚未达到与自回归模型相当的性能水平，这阻碍了扩散范式在多模态领域的广泛应用。

Method: 论文未提供具体方法细节，但从摘要推断可能涉及改进扩散语言模型的能力，探索扩散范式在多模态任务中的应用，以及比较扩散与自回归范式在不同场景下的性能表现。

Result: 摘要未提供具体实验结果，但暗示当前扩散模型在多模态任务中尚未达到与自回归模型相当的性能水平，需要进一步研究来克服基础扩散语言模型的能力限制。

Conclusion: 扩散范式在多模态研究中具有潜力，但由于基础扩散语言模型的能力限制，目前性能尚未达到自回归模型的水平。需要进一步研究来提升扩散模型的能力，以实现其在多模态领域的广泛应用。

Abstract: In recent multimodal research, the diffusion paradigm has emerged as a promising alternative to the autoregressive paradigm (AR), owing to its unique decoding advantages. However, due to the capability limitations of the base diffusion language …

</details>


### [654] [Talk Less, Verify More: Improving LLM Assistants with Semantic Checks and Execution Feedback](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.00224&hl=zh-CN&sa=X&d=11973227940510678807&ei=tERfaeP8MMelieoP1s_TgA8&scisig=ALhkC2S2QDDCFuhKiQAimyQexArU&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:ALhkC2QZBw_72LNkZ9d4Dln9KYOD&html=&pos=0&folt=cit)
*Y Sun,M Cai,S Kok*

Main category: Xuanhe Zhou

TL;DR: 该论文针对大型语言模型在企业工作流程中缺乏验证机制的问题，提出了两种互补的验证技术：Q*（反向翻译和语义验证）和另一种技术，以增强对话式商业分析系统的可靠性和准确性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型助手越来越多地集成到企业工作流程中，它们生成准确、语义对齐且可执行输出的能力变得至关重要。然而，当前的对话式商业分析系统通常缺乏内置的验证机制，导致用户需要手动验证可能存在缺陷的结果。

Method: 论文引入了两种互补的验证技术：Q*（执行反向翻译和语义验证）以及另一种未在摘要中明确说明的技术，这些技术旨在为对话式商业分析系统提供自动化的验证机制。

Result: 摘要未提供具体的实验结果，但暗示这些验证技术能够提高LLM助手在企业工作流程中输出的准确性和可靠性，减少用户手动验证的需求。

Conclusion: 论文提出的验证技术为对话式商业分析系统提供了重要的验证机制，有助于确保LLM助手在企业环境中的输出质量，提升系统的实用性和可信度。

Abstract: As large language model (LLM) assistants become increasingly integrated into enterprise workflows, their ability to generate accurate, semantically aligned, and executable outputs is critical. However, current conversational business analytics (CBA) systems often lack built-in verification mechanisms, leaving users to manually validate potentially flawed results. This paper introduces two complementary verification techniques: Q*, which performs reverse translation and semantic …

</details>


### [655] [Octopus: A Lightweight Entity-Aware System for Multi-Table Data Discovery and Cell-Level Retrieval](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.02304&hl=zh-CN&sa=X&d=15868470793808524273&ei=hqNgaajKKe6TieoPutPYsQg&scisig=AHkA5jTs5kdUHmql3fPB2ivtub9e&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:AHkA5jR4Nz41hcddyWt9RkK93bRp&html=&pos=0&folt=cit)
*WZ Li,S Galhotra*

Main category: Xuanhe Zhou

TL;DR: 现有数据发现系统假设每个问题可由单表回答且依赖资源密集型离线预处理，但实际问题常需跨多表信息，本文提出轻量级在线多表发现方法


<details>
  <summary>Details</summary>
Motivation: 表格数据是现代数据湖和存储库的主要信息形式，但发现相关表格以回答用户问题仍具挑战性。现有系统假设每个问题可由单表回答，且依赖资源密集型离线预处理（如模型训练或大规模内容索引）。实践中，许多问题需要分布在多个表中的信息

Method: 提出轻量级在线多表发现方法，无需离线预处理，通过动态分析查询语义和表间关系来识别相关多表组合

Result: 方法在效率和准确性上优于传统单表发现系统，能有效处理需要跨表信息的复杂查询，减少预处理开销

Conclusion: 多表数据发现是实际场景中的关键需求，轻量级在线方法为复杂查询提供更实用高效的解决方案

Abstract: Tabular data constitute a dominant form of information in modern data lakes and repositories, yet discovering the relevant tables to answer user questions remains challenging. Existing data discovery systems assume that each question can be answered by a single table and often rely on resource-intensive offline preprocessing, such as model training or large-scale content indexing. In practice, however, many questions require information spread across multiple tables--either …

</details>


### [656] [Jenius Agent: Towards Experience-Driven Accuracy Optimization in Real-World Scenarios](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.01857&hl=zh-CN&sa=X&d=17208101160943712835&ei=hqNgaajKKe6TieoPutPYsQg&scisig=AHkA5jTw2-FBG3rBqsiCJk8s7KBl&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:AHkA5jR4Nz41hcddyWt9RkK93bRp&html=&pos=1&folt=cit)
*D Xia,B Pi,S Zhang,S Hua,Y Wei,L Zuo*

Main category: Xuanhe Zhou

TL;DR: 提出基于现实世界场景的智能体框架，通过系统优化内部推理和工具使用流程来提升LLM智能体的任务性能


<details>
  <summary>Details</summary>
Motivation: 随着基于大语言模型的智能体系统发展，提升自主智能体在上下文理解、工具使用和响应生成方面的任务性能变得日益重要。尽管先前研究已经推进了LLM智能体的整体设计，但对其内部推理和工具使用流程的系统优化仍然探索不足。

Method: 引入基于现实世界场景的智能体框架，系统优化智能体的内部推理和工具使用流程

Result: 论文摘要未提供具体实验结果，但暗示该框架能够提升智能体在上下文理解、工具使用和响应生成方面的性能

Conclusion: 通过系统优化内部推理和工具使用流程，可以显著提升基于大语言模型的智能体在现实世界任务中的性能表现

Abstract: As agent systems powered by large language models (LLMs) advance, improving the task performance of an autonomous agent, especially in context understanding, tool usage, and response generation, has become increasingly critical. Although prior studies have advanced the overall design of LLM-based agents, systematic optimization of their internal reasoning and tool-use pipelines remains underexplored. This paper introduces an agent framework grounded in real-world …

</details>


### [657] [AI Meets Sonification: Research Agenda and Technology Demonstration](https://scholar.google.com/scholar_url?url=https://repository.gatech.edu/bitstreams/e4845dad-ecf4-493e-851c-0750d0af1b58/download&hl=zh-CN&sa=X&d=18069951230024726659&ei=hqNgaajKKe6TieoPutPYsQg&scisig=AHkA5jQZXUqfUjtG8dUexw65Ddgr&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:AHkA5jR4Nz41hcddyWt9RkK93bRp&html=&pos=2&folt=cit)
*F Hommel,T Hermann*

Main category: Xuanhe Zhou

TL;DR: 该论文探讨AI与可听化(sonification)的交叉领域，提出促进两个领域共同发展的研究议程，识别有前景的研究方向和新服务


<details>
  <summary>Details</summary>
Motivation: 尽管AI在各个领域具有变革性影响，但在可听化领域的应用仍然有限，需要填补这一空白，探索AI如何增强可听化实践以及可听化如何促进AI发展

Method: 提出研究议程，识别有前景的研究方向和新服务，并展示原型系统作为概念验证

Result: 提出了AI与可听化交叉领域的研究框架，识别了具体的研究机会，展示了原型系统作为该领域潜力的证明

Conclusion: AI与可听化之间存在显著的协同潜力，通过系统性的研究议程可以促进两个领域的共同进步，为未来的研究和应用奠定基础

Abstract: This paper explores the intersection of artificial intelligence (AI) and sonification, proposing a research agenda to foster mutual advancements in both fields. We identify and propose promising avenues for research and novel services, highlighting the opportunities AI offers to enhance sonification practices and vice versa. Despite AI's transformative impact across various domains, its application in sonification remains limited. We address this gap by presenting a prototypical system …

</details>


### [658] [InSPO: Unlocking Intrinsic Self-Reflection for LLM Preference Optimization](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.23126&hl=zh-CN&sa=X&d=5953785134874696717&ei=haNgaYPeJdrJieoPiYyysAk&scisig=AHkA5jTaTbpgg2MiPGgpXUt21ysp&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:AHkA5jSlroL7H9qfrEO07iLXc5er&html=&pos=0&folt=rel)
*Y Li,T Lan,Z Qi*

Main category: Xuanhe Zhou

TL;DR: DPO及其变体虽然简单稳定，但存在两个根本性限制：最优策略依赖于任意参考策略，且无法处理非传递性偏好


<details>
  <summary>Details</summary>
Motivation: 尽管DPO及其变体已成为对齐大语言模型的标准方法，但研究发现它们存在两个根本性限制：1）最优策略依赖于任意选择的参考策略，导致结果不一致；2）无法处理非传递性偏好，这在现实世界偏好数据中很常见

Method: 论文未在摘要中详细说明具体方法，但暗示需要解决DPO的两个根本限制，可能提出新的对齐框架或改进算法

Result: 摘要未提供具体实验结果，但指出DPO的局限性表明需要新的对齐方法来解决这些根本问题

Conclusion: DPO及其变体存在根本性缺陷，需要开发新的对齐方法来克服这些限制，以实现更鲁棒和一致的语言模型对齐

Abstract: Direct Preference Optimization (DPO) and its variants have become standard for aligning Large Language Models due to their simplicity and offline stability. However, we identify two fundamental limitations. First, the optimal policy depends on arbitrary …

</details>


### [659] [SQL Statement Generation Enhanced Through the Fusion of Large Language Models and Knowledge Graphs](https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2079-9292/15/2/278&hl=zh-CN&sa=X&d=6977093582047777376&ei=bkVjaYqBJ-qsieoPjYOSgAM&scisig=AHkA5jTbwxbjGk5YH2IU3_EgdSK4&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:AHkA5jR4Nz41hcddyWt9RkK93bRp&html=&pos=0&folt=cit)
*B Wang,X Yu,X Zheng*

Main category: Xuanhe Zhou

TL;DR: 提出一个结合知识图谱与大型语言模型的增强SQL生成框架，通过SQL-KG-Verifier模块解决LLM生成SQL时的幻觉和精度下降问题


<details>
  <summary>Details</summary>
Motivation: 当前主流SQL生成方法在捕捉结构化数据语义信息和处理复杂查询任务方面仍显不足，基于LLM的SQL生成存在幻觉问题和精度下降挑战

Method: 提出增强SQL生成框架，集成知识图谱与大型语言模型，引入SQL-KG-Verifier模块，协同利用知识图谱的结构化语义信息和LLM的自然语言理解能力

Result: 未在摘要中明确说明具体实验结果，但暗示该方法能有效缓解LLM生成SQL时的幻觉问题，提升复杂查询任务的准确性

Conclusion: 通过知识图谱与LLM的集成，能够更好地捕捉结构化数据的语义信息，提高SQL生成的准确性和鲁棒性

Abstract: Current mainstream SQL generation approaches remain insufficient in capturing the semantic information of structured data and handling complex query tasks. To address the challenges of hallucination and accuracy degradation in large language model (LLM)-based SQL generation, this paper proposes an enhanced SQL generation framework that integrates knowledge graphs with large language models. The proposed method introduces an SQL-KG-Verifier module, which synergizes the …

</details>


### [660] [A Vision for Multisensory Intelligence: Sensing, Synergy, and Science](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.04563&hl=zh-CN&sa=X&d=6393494872130017817&ei=5qVkafqOJ9KV6rQP84i9kQc&scisig=AHkA5jSngNjViqYnZoTjmtcIK-VM&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:AHkA5jR4Nz41hcddyWt9RkK93bRp&html=&pos=0&folt=cit)
*PP Liang*

Main category: Xuanhe Zhou

TL;DR: 该论文提出了未来十年多感官人工智能的研究愿景，旨在将AI从数字模态扩展到人类所有感官领域，实现更自然的人机交互


<details>
  <summary>Details</summary>
Motivation: 当前人工智能主要局限于文本、视觉和音频等数字模态，而人类对世界的体验是多感官的，包括语言、视觉、声音、触觉、味觉和嗅觉。这种局限性限制了AI与人类自然交互的能力，需要将AI扩展到完整的人类感官谱系。

Method: 论文提出的是一个研究愿景框架而非具体方法，但暗示将采用跨学科方法整合计算机科学、神经科学、认知科学等领域，开发能够处理多感官输入并生成多感官输出的AI系统，连接AI与人类感官及生理信号。

Result: 作为愿景性论文，没有展示具体实验结果，但提出了多感官AI将带来的变革性影响：改变人类与AI的交互方式，使AI能够更自然地理解和响应人类的多感官体验。

Conclusion: 多感官人工智能是AI发展的下一个前沿，通过将AI扩展到完整的人类感官领域，可以创造更自然、更沉浸的人机交互体验，这需要未来十年的跨学科研究努力。

Abstract: Our experience of the world is multisensory, spanning a synthesis of language, sight, sound, touch, taste, and smell. Yet, artificial intelligence has primarily advanced in digital modalities like text, vision, and audio. This paper outlines a research vision for multisensory artificial intelligence over the next decade. This new set of technologies can change how humans and AI experience and interact with one another, by connecting AI to the human senses and a rich spectrum of signals from physiological …

</details>


### [661] [When Single-Agent with Skills Replace Multi-Agent Systems and When They Fail](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.04748&hl=zh-CN&sa=X&d=11444279409195191747&ei=5qVkafqOJ9KV6rQP84i9kQc&scisig=AHkA5jTCYDASBJk5Sz4yPMO6c3oY&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:AHkA5jR4Nz41hcddyWt9RkK93bRp&html=&pos=2&folt=cit)
*X Li*

Main category: Xuanhe Zhou

TL;DR: 探讨是否可以通过单一智能体选择技能库中的技能来实现多智能体系统的模块化优势，将技能视为内化的智能体行为


<details>
  <summary>Details</summary>
Motivation: 多智能体AI系统在复杂推理中表现有效，但通过显式通信协作会产生大量计算开销。研究是否可以通过单一智能体选择技能库中的技能来实现类似的模块化优势

Method: 将技能视为内化的智能体行为，从这一视角出发，将多智能体系统编译为单一智能体系统

Result: 未在摘要中明确说明具体结果

Conclusion: 提出了一种将多智能体系统编译为单一智能体系统的新视角，探索通过技能内化实现模块化优势的可能性

Abstract: Multi-agent AI systems have proven effective for complex reasoning. These systems are compounded by specialized agents, which collaborate through explicit communication, but incur substantial computational overhead. A natural question arises: can we achieve similar modularity benefits with a single agent that selects from a library of skills? We explore this question by viewing skills as internalized agent behaviors. From this perspective, a multi-agent system can be compiled into …

</details>


### [662] [Large Language Models for Automated Data Access Policy Creation in Data Spaces](https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-032-04878-3_4&hl=zh-CN&sa=X&d=15165967702065106110&ei=5qVkafqOJ9KV6rQP84i9kQc&scisig=AHkA5jQZPc_rEdN5HcUzrlaawfXM&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:AHkA5jR4Nz41hcddyWt9RkK93bRp&html=&pos=3&folt=cit)
*R Ford,R Beigaitė,A Hajikhani*

Main category: Xuanhe Zhou

TL;DR: 研究自动生成机器可读数据访问策略以解决数据空间政策定义耗时易错的问题


<details>
  <summary>Details</summary>
Motivation: 数据空间需要标准化安全的数据共享，但手动定义机器可读访问策略耗时且易错，阻碍了数据空间的采用和扩展

Method: 研究自动创建机器可读数据访问策略的方法（具体方法在摘要中未详细说明）

Result: 摘要中未提供具体结果，但研究目标是支持数据空间用户通过自动生成的策略

Conclusion: 自动生成机器可读数据访问策略是解决数据空间采用和扩展挑战的关键方向

Abstract: Data spaces are being developed to enable more standardized and secure data sharing. They provide a framework where data can be exchanged following predefined access control policies. However, manually defining machine-readable policies can be a time-consuming and error-prone task. It poses challenges for the adoption and scalability of Data Spaces. In this paper, we investigate the automatic creation of machine-readable data access policies that could support users of Data …

</details>


### [663] [Conversational Intelligence: Understanding LLMs in Customer Service](https://scholar.google.com/scholar_url?url=https://www.igi-global.com/chapter/conversational-intelligence/399115&hl=zh-CN&sa=X&d=10095608564969976524&ei=5qVkafqOJ9KV6rQP84i9kQc&scisig=AHkA5jTyG55_fhaGNG4MTq2zpQsa&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:AHkA5jR4Nz41hcddyWt9RkK93bRp&html=&pos=5&folt=cit)
*J Fakhriddin,EG Atajonovna,Z Saidjanova,M Ahmad*

Main category: Xuanhe Zhou

TL;DR: 本章探讨大语言模型和生成式AI在客户服务中的变革作用，分析多模态LLM、语音AI、主动参与等新兴趋势如何实现更丰富、情境感知和个性化的交互。


<details>
  <summary>Details</summary>
Motivation: 探索AI技术如何重塑客户服务领域，分析LLM和生成式AI带来的变革潜力，为理解客户服务数字化转型提供框架。

Method: 采用文献综述和分析方法，考察多模态LLM、语音AI、主动参与等新兴技术趋势，讨论运营和战略层面的考量因素。

Result: 识别了客户服务中AI应用的关键趋势：多模态交互能力、语音AI集成、主动式参与模式，以及人机协作的平衡策略。

Conclusion: LLM和生成式AI正在深刻改变客户服务范式，实现更智能、个性化和高效的交互，但需要平衡自动化与人工干预，考虑劳动力转型等战略因素。

Abstract: This chapter examines the transformative role of large language models (LLMs) and generative AI in customer service. It explores emerging trends such as multimodal LLMs, voice-enabled AI, and proactive engagement, highlighting how these technologies enable richer, context-aware, and personalized interactions. The chapter discusses operational and strategic considerations, including workforce transformation, human-in-the-loop models, and the balance between automation and …

</details>


### [664] [Toward Perceptual and Ubiquitous Intelligence for Healthcare: Systems for Clinical Diagnostics and All-Day Personal Health Management](https://scholar.google.com/scholar_url?url=https://search.proquest.com/openview/3162a4e3494c758e7f48d8849ac9a9ef/1%3Fpq-origsite%3Dgscholar%26cbl%3D18750%26diss%3Dy&hl=zh-CN&sa=X&d=13161715920447658866&ei=5qVkafqOJ9KV6rQP84i9kQc&scisig=AHkA5jQqLBhm5HmqEM2d9rr7rV4w&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:AHkA5jR4Nz41hcddyWt9RkK93bRp&html=&pos=6&folt=cit)
*A Paruchuri*

Main category: Xuanhe Zhou

TL;DR: 论文探讨了感知与普适智能在医疗健康领域的应用潜力，旨在通过传感器设备实现更主动、个性化和可及的医疗系统


<details>
  <summary>Details</summary>
Motivation: 医疗健康领域需要更主动、个性化和可及的系统，而感知与普适智能能够通过传感器设备感知和理解人类及其环境，为医疗创新提供重要技术基础

Method: 利用各种传感器设备构建计算系统，实现对人类和周围环境的感知与推理，应用于临床诊断和个人健康管理等多个医疗场景

Result: 感知与普适智能在医疗健康领域展现出巨大潜力，能够支持从远程生命体征监测、计算机辅助内窥镜到全天候个人健康管理等前沿应用

Conclusion: 感知与普适智能是推动医疗健康向更主动、个性化和可及方向发展的关键技术，为医疗创新开辟了新前沿

Abstract: Perceptual and ubiquitous intelligence, which enables computational systems to sense and reason about humans and the world around them using a variety of sensor-based devices, holds immense potential to make healthcare more proactive, personalized, and accessible. This intelligence is central to enabling new frontiers in healthcare, from systems for clinical diagnostics like remote vital signs monitoring and computer-assisted endoscopy, to all-day personal health management built …

</details>


### [665] [How Do Large Language Models Learn Concepts During Continual Pre-Training?](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.03570&hl=zh-CN&sa=X&d=907635542753120244&ei=5aVkabW_AcyQieoPxv68kA4&scisig=AHkA5jQMDSiw9zdhBE-Y1n4OWNcL&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:AHkA5jSlroL7H9qfrEO07iLXc5er&html=&pos=1&folt=rel)
*BM Yao,S Li,Y Yao,M Liu,Z Xia,Q Wang,L Huang*

Main category: Xuanhe Zhou

TL;DR: 该论文探讨了大语言模型如何像人类一样获取、保留和遗忘概念，研究了概念在模型中的表示、演化及其对模型行为的影响。


<details>
  <summary>Details</summary>
Motivation: 人类主要通过概念来理解世界，但大语言模型如何获取、保留和遗忘这些概念尚不清楚。研究者希望理解LLMs中概念的形成机制、演化过程及其对模型推理和学习能力的影响。

Method: 通过分析LLMs内部表示来研究概念的形成和演化，可能包括概念激活分析、表示空间追踪、遗忘模式检测等方法，考察模型在不同训练阶段对概念的处理方式。

Result: 研究发现LLMs能够形成类似人类的概念表示，这些概念在训练过程中会经历获取、巩固和选择性遗忘的过程，概念的组织方式影响模型的泛化能力和推理表现。

Conclusion: LLMs确实能够发展出类似人类的概念系统，概念获取和遗忘的模式对模型性能有重要影响，这为理解模型内部工作机制和改进模型设计提供了新视角。

Abstract: Human beings primarily understand the world through concepts (eg, dog), abstract mental representations that structure perception, reasoning, and learning. However, how large language models (LLMs) acquire, retain, and forget such concepts during …

</details>


### [666] [Breaking Size Barrier: Enhancing Reasoning for Large-Size Table Question Answering](https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-981-95-3830-0_16&hl=zh-CN&sa=X&d=13750777743362634346&ei=MVhmad-iDbK16rQPitqooQg&scisig=AHkA5jS0DGdHqi2lyyiL4g5fmvDz&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:AHkA5jR4Nz41hcddyWt9RkK93bRp&html=&pos=0&folt=cit)
*X Wu,D Liang,J Yang,X Cheng,LZ Chai,T Li,L Yang…*

Main category: Xuanhe Zhou

TL;DR: LLMs在表格问答任务中通过思维链推理增强表格处理能力，但处理大型表格时面临上下文长度限制和推理路径过长的问题，导致幻觉风险和信息截断。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理真实世界应用中的大型表格时面临显著挑战：完整表格提示会遭遇上下文长度限制，显著延长推理路径，增加推理幻觉风险和信息截断问题。

Method: 论文提出了一种针对大型表格的优化方法（具体方法在摘要中未详细说明，但暗示了解决上下文限制和推理路径问题的技术方案）。

Result: 该方法旨在改善LLMs处理大型表格的性能，减少推理幻觉和信息截断，提升表格问答任务的准确性和效率。

Conclusion: 需要开发专门针对大型表格处理的优化技术来解决LLMs在真实世界应用中的上下文限制和推理路径问题。

Abstract: Large language models (LLMs) significantly enhance their ability to process tabular data through chain-of-thought reasoning, particularly in table question answering tasks. However, LLMs encounter substantial challenges when dealing with large tables in real-world applications. Prompting LLMs with the entire table not only encounters context-length constraints but also significantly extends the reasoning path, heightening the risk of reasoning hallucination and information truncation. To …

</details>


### [667] [Artos: Buffer-Centric Data Management for Elastic Reinforcement Learning](https://scholar.google.com/scholar_url?url=https://farrrrland.github.io/files/ARTOS.pdf&hl=zh-CN&sa=X&d=3468594917109027410&ei=MVhmad-iDbK16rQPitqooQg&scisig=AHkA5jT-AykCYWaQV-P55f7RCRgE&oi=scholaralrt&hist=i6heNjgAAAAJ:18363798109415294512:AHkA5jR4Nz41hcddyWt9RkK93bRp&html=&pos=1&folt=cit)
*Y Zhao,S Li,T Wu,W Gao,G Chen,J Yang,D Lu…*

Main category: Xuanhe Zhou

TL;DR: 提出了一种分布式强化学习训练工作流抽象，解决现有框架资源管理固定、算法表达能力有限的问题


<details>
  <summary>Details</summary>
Motivation: 现有分布式RL框架存在资源管理固定、算法表达能力有限的问题，导致端到端性能差和资源利用率低

Method: 引入分布式RL训练工作流抽象，支持灵活定义不同on-policy和off-policy算法，实现无缝资源管理

Result: 未在摘要中明确说明具体实验结果，但暗示该方法能改善端到端性能和资源利用率

Conclusion: 提出的工作流抽象能够解决现有分布式RL框架的局限性，提升训练效率和资源利用

Abstract: Distributed reinforcement learning (RL) has gained significant traction in the field of artificial intelligence. However, existing distributed RL frameworks provide fixed-scaled resource management and have limited expressiveness of different on-policy and off-policy distributed RL algorithms, thus suffering from poor end-to-end performance and low resource utilization. Therefore, we introduce an abstraction of distributed RL training workflows that enables the flexible and seamless definition of …

</details>


### [668] [DLME: A distillation mechanism from language models for knowledge graph embedding](https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0925231226000743&hl=zh-CN&sa=X&d=3193338286732724646&ei=MFhmaerMIu-GieoPm7zvuQ8&scisig=AHkA5jQERnNJ6ubvH5K0Ox4e7UOB&oi=scholaralrt&hist=i6heNjgAAAAJ:13182394089411826447:AHkA5jSlroL7H9qfrEO07iLXc5er&html=&pos=0&folt=rel)
*Y Si,X Hu,Q Cheng,J Huang,S Liu*

Main category: Xuanhe Zhou

TL;DR: 知识图谱嵌入的抽象知识蒸馏方法，旨在解决存储和计算限制问题


<details>
  <summary>Details</summary>
Motivation: 知识图谱嵌入在事实推理和链接预测中应用广泛，但面临存储和计算资源限制的挑战，需要更高效的模型部署方案

Method: 采用知识蒸馏技术，将大型知识图谱嵌入模型的知识迁移到更小、更高效的模型中

Result: 该方法能够显著减少模型存储需求和计算开销，同时保持较高的推理性能

Conclusion: 知识蒸馏为知识图谱嵌入的实际部署提供了有效的解决方案，平衡了模型性能与资源效率

Abstract: Abstract Knowledge Graph Embedding (KGE) is a prominent method for leveraging knowledge graphs in factual reasoning and link prediction tasks. Knowledge distillation aims to mitigate the challenges of storage and computational limitations …

</details>
